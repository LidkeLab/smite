//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30672275
// Cuda compilation tools, release 11.5, V11.5.119
// Based on NVVM 7.0.1
//

.version 7.5
.target sm_52
.address_size 64

	// .globl	_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0,
	.param .b64 __internal_accurate_pow_param_1
)
;
.global .align 1 .b8 d_assert[1024];

.visible .entry _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i(
	.param .u64 _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_0,
	.param .f32 _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_1,
	.param .u32 _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_2,
	.param .u32 _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_3,
	.param .u64 _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_4,
	.param .u64 _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_5,
	.param .u64 _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_6,
	.param .u32 _Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_7
)
{
	.reg .pred 	%p<382>;
	.reg .f32 	%f<1814>;
	.reg .b32 	%r<539>;
	.reg .f64 	%fd<372>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd9, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_0];
	ld.param.f32 	%f317, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_1];
	ld.param.u32 	%r86, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_2];
	ld.param.u32 	%r88, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_7];
	cvta.to.global.u64 	%rd1, %rd9;
	mov.u32 	%r89, %ntid.x;
	mov.u32 	%r90, %ctaid.x;
	mov.u32 	%r91, %tid.x;
	mad.lo.s32 	%r1, %r90, %r89, %r91;
	setp.ge.s32 	%p19, %r1, %r88;
	@%p19 bra 	$L__BB0_261;

	mul.lo.s32 	%r92, %r86, %r86;
	mul.lo.s32 	%r2, %r92, %r1;
	setp.lt.s32 	%p20, %r86, 1;
	mov.f32 	%f1709, 0f00000000;
	mov.f32 	%f1700, %f1709;
	mov.f32 	%f1701, %f1709;
	mov.f32 	%f1702, %f1709;
	@%p20 bra 	$L__BB0_11;

	add.s32 	%r3, %r86, -1;
	and.b32  	%r4, %r86, 3;
	sub.s32 	%r5, %r86, %r4;
	shl.b32 	%r6, %r86, 2;
	mov.u32 	%r93, 0;
	setp.lt.u32 	%p21, %r3, 3;
	setp.eq.s32 	%p23, %r4, 0;
	setp.eq.s32 	%p24, %r4, 1;
	setp.eq.s32 	%p25, %r4, 2;
	cvt.s64.s32 	%rd12, %r6;
	mov.u32 	%r524, %r93;

$L__BB0_3:
	cvt.rn.f32.s32 	%f4, %r524;
	mov.u32 	%r527, %r93;
	@%p21 bra 	$L__BB0_6;

	mov.u32 	%r527, %r93;
	mov.u32 	%r526, %r5;

$L__BB0_5:
	mad.lo.s32 	%r96, %r527, %r86, %r524;
	add.s32 	%r97, %r96, %r2;
	mul.wide.s32 	%rd10, %r97, 4;
	add.s64 	%rd11, %rd1, %rd10;
	ld.global.f32 	%f325, [%rd11];
	fma.rn.f32 	%f326, %f325, %f4, %f1700;
	cvt.rn.f32.s32 	%f327, %r527;
	fma.rn.f32 	%f328, %f325, %f327, %f1701;
	add.f32 	%f329, %f1702, %f325;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.f32 	%f330, [%rd13];
	fma.rn.f32 	%f331, %f330, %f4, %f326;
	add.s32 	%r98, %r527, 1;
	cvt.rn.f32.s32 	%f332, %r98;
	fma.rn.f32 	%f333, %f330, %f332, %f328;
	add.f32 	%f334, %f329, %f330;
	add.s64 	%rd14, %rd13, %rd12;
	ld.global.f32 	%f335, [%rd14];
	fma.rn.f32 	%f336, %f335, %f4, %f331;
	add.s32 	%r99, %r527, 2;
	cvt.rn.f32.s32 	%f337, %r99;
	fma.rn.f32 	%f338, %f335, %f337, %f333;
	add.f32 	%f339, %f334, %f335;
	add.s64 	%rd15, %rd14, %rd12;
	ld.global.f32 	%f340, [%rd15];
	fma.rn.f32 	%f1700, %f340, %f4, %f336;
	add.s32 	%r100, %r527, 3;
	cvt.rn.f32.s32 	%f341, %r100;
	fma.rn.f32 	%f1701, %f340, %f341, %f338;
	add.f32 	%f1702, %f339, %f340;
	add.s32 	%r527, %r527, 4;
	add.s32 	%r526, %r526, -4;
	setp.ne.s32 	%p22, %r526, 0;
	@%p22 bra 	$L__BB0_5;

$L__BB0_6:
	@%p23 bra 	$L__BB0_10;

	mad.lo.s32 	%r13, %r527, %r86, %r524;
	add.s32 	%r101, %r13, %r2;
	mul.wide.s32 	%rd16, %r101, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.f32 	%f342, [%rd17];
	fma.rn.f32 	%f1700, %f342, %f4, %f1700;
	cvt.rn.f32.s32 	%f343, %r527;
	fma.rn.f32 	%f1701, %f342, %f343, %f1701;
	add.f32 	%f1702, %f1702, %f342;
	@%p24 bra 	$L__BB0_10;

	add.s32 	%r14, %r13, %r86;
	add.s32 	%r102, %r14, %r2;
	mul.wide.s32 	%rd18, %r102, 4;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.f32 	%f344, [%rd19];
	fma.rn.f32 	%f1700, %f344, %f4, %f1700;
	add.s32 	%r103, %r527, 1;
	cvt.rn.f32.s32 	%f345, %r103;
	fma.rn.f32 	%f1701, %f344, %f345, %f1701;
	add.f32 	%f1702, %f1702, %f344;
	@%p25 bra 	$L__BB0_10;

	add.s32 	%r104, %r527, 2;
	add.s32 	%r105, %r14, %r86;
	add.s32 	%r106, %r105, %r2;
	mul.wide.s32 	%rd20, %r106, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.f32 	%f346, [%rd21];
	fma.rn.f32 	%f1700, %f346, %f4, %f1700;
	cvt.rn.f32.s32 	%f347, %r104;
	fma.rn.f32 	%f1701, %f346, %f347, %f1701;
	add.f32 	%f1702, %f1702, %f346;

$L__BB0_10:
	add.s32 	%r524, %r524, 1;
	setp.lt.s32 	%p26, %r524, %r86;
	@%p26 bra 	$L__BB0_3;

$L__BB0_11:
	div.rn.f32 	%f1763, %f1700, %f1702;
	div.rn.f32 	%f1762, %f1701, %f1702;
	mov.f32 	%f350, 0f3F000000;
	div.rn.f32 	%f351, %f350, %f317;
	div.rn.f32 	%f34, %f351, %f317;
	mov.f32 	%f1760, 0f51BA43B7;
	@%p20 bra 	$L__BB0_51;

	cvt.f64.f32 	%fd1, %f34;
	mov.f64 	%fd129, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd129;
	}
	and.b32  	%r17, %r16, 2146435072;
	and.b32  	%r18, %r16, 2147483647;
	setp.gt.s32 	%p28, %r16, -1;
	selp.b32 	%r19, 2146435072, 0, %p28;
	mov.u32 	%r107, 0;
	or.b32  	%r20, %r19, -2147483648;
	mul.wide.s32 	%rd22, %r2, 4;
	add.s64 	%rd2, %rd1, %rd22;
	setp.eq.s32 	%p30, %r17, 1062207488;
	setp.lt.s32 	%p31, %r16, 0;
	setp.ne.s32 	%p36, %r18, 1071644672;
	setp.eq.s32 	%p63, %r18, 2146435072;
	mov.u32 	%r528, %r107;

$L__BB0_13:
	mov.u32 	%r529, %r107;

$L__BB0_14:
	mov.f32 	%f1712, 0f00000000;
	mov.f32 	%f1713, %f1712;
	mov.u32 	%r530, %r107;

$L__BB0_15:
	mov.u32 	%r508, 1;
	sub.s32 	%r531, %r508, %r529;
	add.s32 	%r532, %r529, -1;
	sub.s32 	%r26, %r530, %r528;
	cvt.rn.f32.s32 	%f356, %r26;
	cvt.f64.f32 	%fd2, %f356;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd2;
	}
	abs.f64 	%fd130, %fd2;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd130;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd129;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 0
	setp.lt.s32 	%p29, %r27, 0;
	and.pred  	%p1, %p29, %p30;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd4;
	}
	and.b32  	%r29, %r114, 2146435072;
	setp.ne.s32 	%p32, %r29, 2146435072;
	setp.gtu.f64 	%p33, %fd130, 0d7FF0000000000000;
	setp.gt.f64 	%p34, %fd130, 0d3FF0000000000000;
	selp.b32 	%r115, 2146435072, 0, %p34;
	xor.b32  	%r116, %r115, 2146435072;
	selp.b32 	%r117, %r116, %r115, %p31;
	setp.eq.s32 	%p35, %r26, -1;
	selp.b32 	%r30, 1072693248, %r117, %p35;
	and.pred  	%p37, %p36, %p1;
	selp.b32 	%r32, %r20, %r19, %p37;
	or.pred  	%p2, %p32, %p33;
	mul.lo.s32 	%r118, %r86, %r530;
	mul.wide.s32 	%rd23, %r118, 4;
	add.s64 	%rd47, %rd2, %rd23;
	mov.u32 	%r533, %r107;

$L__BB0_16:
	not.pred 	%p38, %p1;
	mov.f64 	%fd340, %fd3;
	@%p38 bra 	$L__BB0_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r119}, %fd3;
	}
	xor.b32  	%r120, %r119, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd3;
	}
	mov.b64 	%fd340, {%r121, %r120};

$L__BB0_18:
	sub.s32 	%r509, %r530, %r528;
	setp.eq.s32 	%p39, %r509, 0;
	@%p39 bra 	$L__BB0_22;

	sub.s32 	%r511, %r530, %r528;
	cvt.rn.f32.s32 	%f1683, %r511;
	cvt.f64.f32 	%fd329, %f1683;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r510}, %fd329;
	}
	setp.gt.s32 	%p40, %r510, -1;
	@%p40 bra 	$L__BB0_23;

	cvt.rzi.f64.f64 	%fd133, %fd129;
	setp.eq.f64 	%p41, %fd133, 0d4000000000000000;
	@%p41 bra 	$L__BB0_23;

	mov.f64 	%fd340, 0dFFF8000000000000;
	bra.uni 	$L__BB0_23;

$L__BB0_22:
	sub.s32 	%r523, %r530, %r528;
	cvt.rn.f32.s32 	%f1687, %r523;
	cvt.f64.f32 	%fd338, %f1687;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r522}, %fd338;
	}
	selp.b32 	%r521, %r522, 0, %p30;
	or.b32  	%r520, %r521, 2146435072;
	selp.b32 	%r519, %r520, %r521, %p31;
	mov.u32 	%r122, 0;
	mov.b64 	%fd340, {%r122, %r519};

$L__BB0_23:
	sub.s32 	%r512, %r530, %r528;
	cvt.rn.f32.s32 	%f1684, %r512;
	cvt.f64.f32 	%fd331, %f1684;
	add.f64 	%fd330, %fd331, 0d4000000000000000;
	selp.f64 	%fd341, %fd340, %fd330, %p32;
	@%p2 bra 	$L__BB0_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd129;
	}
	setp.eq.s32 	%p44, %r123, 0;
	and.pred  	%p45, %p63, %p44;
	@%p45 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_25;

$L__BB0_27:
	mov.u32 	%r126, 0;
	mov.b64 	%fd341, {%r126, %r30};
	bra.uni 	$L__BB0_28;

$L__BB0_25:
	sub.s32 	%r518, %r530, %r528;
	cvt.rn.f32.s32 	%f1686, %r518;
	cvt.f64.f32 	%fd337, %f1686;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r517}, %fd337;
	}
	and.b32  	%r516, %r517, 2147483647;
	sub.s32 	%r513, %r530, %r528;
	cvt.rn.f32.s32 	%f1685, %r513;
	cvt.f64.f32 	%fd332, %f1685;
	setp.ne.s32 	%p46, %r516, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd332;
	}
	setp.ne.s32 	%p47, %r124, 0;
	or.pred  	%p48, %p46, %p47;
	mov.f64 	%fd341, %fd340;
	@%p48 bra 	$L__BB0_28;

	mov.u32 	%r125, 0;
	mov.b64 	%fd341, {%r125, %r32};

$L__BB0_28:
	sub.s32 	%r514, %r530, %r528;
	setp.eq.s32 	%p49, %r514, 1;
	selp.f64 	%fd136, 0d3FF0000000000000, %fd341, %p49;
	mov.f64 	%fd137, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd136, %fd1;
	neg.f64 	%fd138, %fd13;
	mov.f64 	%fd139, 0d4338000000000000;
	mov.f64 	%fd140, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd141, %fd138, %fd140, %fd139;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd141;
	}
	mov.f64 	%fd142, 0dC338000000000000;
	add.rn.f64 	%fd143, %fd141, %fd142;
	mov.f64 	%fd144, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd145, %fd143, %fd144, %fd138;
	mov.f64 	%fd146, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd147, %fd143, %fd146, %fd145;
	mov.f64 	%fd148, 0d3E928AF3FCA213EA;
	mov.f64 	%fd149, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd150, %fd149, %fd147, %fd148;
	mov.f64 	%fd151, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd152, %fd150, %fd147, %fd151;
	mov.f64 	%fd153, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd154, %fd152, %fd147, %fd153;
	mov.f64 	%fd155, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd156, %fd154, %fd147, %fd155;
	mov.f64 	%fd157, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd158, %fd156, %fd147, %fd157;
	mov.f64 	%fd159, 0d3F81111111122322;
	fma.rn.f64 	%fd160, %fd158, %fd147, %fd159;
	mov.f64 	%fd161, 0d3FA55555555502A1;
	fma.rn.f64 	%fd162, %fd160, %fd147, %fd161;
	mov.f64 	%fd163, 0d3FC5555555555511;
	fma.rn.f64 	%fd164, %fd162, %fd147, %fd163;
	mov.f64 	%fd165, 0d3FE000000000000B;
	fma.rn.f64 	%fd166, %fd164, %fd147, %fd165;
	fma.rn.f64 	%fd167, %fd166, %fd147, %fd137;
	fma.rn.f64 	%fd168, %fd167, %fd147, %fd137;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd168;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd168;
	}
	shl.b32 	%r127, %r36, 20;
	add.s32 	%r128, %r38, %r127;
	mov.b64 	%fd342, {%r37, %r128};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd138;
	}
	mov.b32 	%f357, %r129;
	abs.f32 	%f43, %f357;
	setp.lt.f32 	%p50, %f43, 0f4086232B;
	@%p50 bra 	$L__BB0_31;

	setp.gt.f64 	%p51, %fd13, 0d8000000000000000;
	mov.f64 	%fd169, 0d7FF0000000000000;
	sub.f64 	%fd170, %fd169, %fd13;
	selp.f64 	%fd342, 0d0000000000000000, %fd170, %p51;
	setp.geu.f32 	%p52, %f43, 0f40874800;
	@%p52 bra 	$L__BB0_31;

	mov.f64 	%fd328, 0d4338000000000000;
	mov.f64 	%fd327, 0d3FF71547652B82FE;
	neg.f64 	%fd326, %fd13;
	fma.rn.f64 	%fd325, %fd326, %fd327, %fd328;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r505, %temp}, %fd325;
	}
	shr.u32 	%r130, %r505, 31;
	add.s32 	%r131, %r505, %r130;
	shr.s32 	%r132, %r131, 1;
	shl.b32 	%r133, %r132, 20;
	add.s32 	%r134, %r38, %r133;
	mov.b64 	%fd171, {%r37, %r134};
	sub.s32 	%r135, %r505, %r132;
	shl.b32 	%r136, %r135, 20;
	add.s32 	%r137, %r136, 1072693248;
	mov.u32 	%r138, 0;
	mov.b64 	%fd172, {%r138, %r137};
	mul.f64 	%fd342, %fd171, %fd172;

$L__BB0_31:
	add.s32 	%r139, %r532, 1;
	cvt.rn.f32.s32 	%f358, %r139;
	cvt.f64.f32 	%fd18, %f358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd129;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd344, [retval0+0];
	} // callseq 1
	setp.lt.s32 	%p53, %r39, 0;
	and.pred  	%p3, %p53, %p30;
	not.pred 	%p55, %p3;
	@%p55 bra 	$L__BB0_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd344;
	}
	xor.b32  	%r141, %r140, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd344;
	}
	mov.b64 	%fd344, {%r142, %r141};

$L__BB0_33:
	setp.eq.s32 	%p56, %r531, 1;
	@%p56 bra 	$L__BB0_37;
	bra.uni 	$L__BB0_34;

$L__BB0_37:
	mov.u32 	%r143, 0;
	selp.b32 	%r144, %r39, 0, %p30;
	or.b32  	%r145, %r144, 2146435072;
	selp.b32 	%r146, %r145, %r144, %p31;
	mov.b64 	%fd344, {%r143, %r146};
	bra.uni 	$L__BB0_38;

$L__BB0_34:
	setp.gt.s32 	%p57, %r39, -1;
	@%p57 bra 	$L__BB0_38;

	cvt.rzi.f64.f64 	%fd175, %fd129;
	setp.eq.f64 	%p58, %fd175, 0d4000000000000000;
	@%p58 bra 	$L__BB0_38;

	mov.f64 	%fd344, 0dFFF8000000000000;

$L__BB0_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd25;
	}
	and.b32  	%r148, %r147, 2146435072;
	setp.ne.s32 	%p61, %r148, 2146435072;
	mov.f64 	%fd345, %fd344;
	@%p61 bra 	$L__BB0_44;

	setp.gtu.f64 	%p62, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd345, %fd25;
	@%p62 bra 	$L__BB0_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r149, %temp}, %fd129;
	}
	setp.eq.s32 	%p64, %r149, 0;
	and.pred  	%p65, %p63, %p64;
	@%p65 bra 	$L__BB0_43;
	bra.uni 	$L__BB0_41;

$L__BB0_43:
	mov.u32 	%r154, 0;
	setp.gt.f64 	%p72, %fd19, 0d3FF0000000000000;
	selp.b32 	%r155, 2146435072, 0, %p72;
	xor.b32  	%r156, %r155, 2146435072;
	selp.b32 	%r157, %r156, %r155, %p31;
	setp.eq.s32 	%p73, %r532, -2;
	selp.b32 	%r158, 1072693248, %r157, %p73;
	mov.b64 	%fd345, {%r154, %r158};
	bra.uni 	$L__BB0_44;

$L__BB0_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd18;
	}
	and.b32  	%r151, %r39, 2147483647;
	setp.ne.s32 	%p66, %r151, 2146435072;
	setp.ne.s32 	%p67, %r150, 0;
	or.pred  	%p68, %p66, %p67;
	mov.f64 	%fd345, %fd344;
	@%p68 bra 	$L__BB0_44;

	and.pred  	%p70, %p36, %p3;
	selp.b32 	%r152, %r20, %r19, %p70;
	mov.u32 	%r153, 0;
	mov.b64 	%fd345, {%r153, %r152};

$L__BB0_44:
	mov.f64 	%fd324, 0d3FF0000000000000;
	mov.f64 	%fd323, 0d3FE000000000000B;
	mov.f64 	%fd322, 0d3FC5555555555511;
	mov.f64 	%fd321, 0d3FA55555555502A1;
	mov.f64 	%fd320, 0d3F81111111122322;
	mov.f64 	%fd319, 0d3F56C16C1852B7AF;
	mov.f64 	%fd318, 0d3F2A01A014761F65;
	mov.f64 	%fd317, 0d3EFA01997C89EB71;
	mov.f64 	%fd316, 0d3EC71DEE62401315;
	mov.f64 	%fd315, 0d3E928AF3FCA213EA;
	mov.f64 	%fd314, 0d3E5ADE1569CE2BDF;
	mov.f64 	%fd313, 0dBC7ABC9E3B39803F;
	mov.f64 	%fd312, 0dBFE62E42FEFA39EF;
	mov.f64 	%fd311, 0dC338000000000000;
	mov.f64 	%fd310, 0d4338000000000000;
	mov.f64 	%fd309, 0d3FF71547652B82FE;
	setp.eq.s32 	%p74, %r532, 0;
	selp.f64 	%fd178, 0d3FF0000000000000, %fd345, %p74;
	mul.f64 	%fd29, %fd178, %fd1;
	neg.f64 	%fd180, %fd29;
	fma.rn.f64 	%fd183, %fd180, %fd309, %fd310;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd183;
	}
	add.rn.f64 	%fd185, %fd183, %fd311;
	fma.rn.f64 	%fd187, %fd185, %fd312, %fd180;
	fma.rn.f64 	%fd189, %fd185, %fd313, %fd187;
	fma.rn.f64 	%fd192, %fd314, %fd189, %fd315;
	fma.rn.f64 	%fd194, %fd192, %fd189, %fd316;
	fma.rn.f64 	%fd196, %fd194, %fd189, %fd317;
	fma.rn.f64 	%fd198, %fd196, %fd189, %fd318;
	fma.rn.f64 	%fd200, %fd198, %fd189, %fd319;
	fma.rn.f64 	%fd202, %fd200, %fd189, %fd320;
	fma.rn.f64 	%fd204, %fd202, %fd189, %fd321;
	fma.rn.f64 	%fd206, %fd204, %fd189, %fd322;
	fma.rn.f64 	%fd208, %fd206, %fd189, %fd323;
	fma.rn.f64 	%fd209, %fd208, %fd189, %fd324;
	fma.rn.f64 	%fd210, %fd209, %fd189, %fd324;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd210;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd210;
	}
	shl.b32 	%r159, %r40, 20;
	add.s32 	%r160, %r42, %r159;
	mov.b64 	%fd346, {%r41, %r160};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r161}, %fd180;
	}
	mov.b32 	%f359, %r161;
	abs.f32 	%f44, %f359;
	setp.lt.f32 	%p75, %f44, 0f4086232B;
	@%p75 bra 	$L__BB0_47;

	setp.gt.f64 	%p76, %fd29, 0d8000000000000000;
	mov.f64 	%fd211, 0d7FF0000000000000;
	sub.f64 	%fd212, %fd211, %fd29;
	selp.f64 	%fd346, 0d0000000000000000, %fd212, %p76;
	setp.geu.f32 	%p77, %f44, 0f40874800;
	@%p77 bra 	$L__BB0_47;

	mov.f64 	%fd336, 0d4338000000000000;
	mov.f64 	%fd335, 0d3FF71547652B82FE;
	neg.f64 	%fd334, %fd29;
	fma.rn.f64 	%fd333, %fd334, %fd335, %fd336;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r515, %temp}, %fd333;
	}
	shr.u32 	%r162, %r515, 31;
	add.s32 	%r163, %r515, %r162;
	shr.s32 	%r164, %r163, 1;
	shl.b32 	%r165, %r164, 20;
	add.s32 	%r166, %r42, %r165;
	mov.b64 	%fd213, {%r41, %r166};
	sub.s32 	%r167, %r515, %r164;
	shl.b32 	%r168, %r167, 20;
	add.s32 	%r169, %r168, 1072693248;
	mov.u32 	%r170, 0;
	mov.b64 	%fd214, {%r170, %r169};
	mul.f64 	%fd346, %fd213, %fd214;

$L__BB0_47:
	ld.global.f32 	%f360, [%rd47];
	cvt.f64.f32 	%fd215, %f360;
	mul.f64 	%fd216, %fd342, %fd346;
	cvt.f64.f32 	%fd217, %f1713;
	fma.rn.f64 	%fd218, %fd216, %fd215, %fd217;
	cvt.rn.f32.f64 	%f1713, %fd218;
	cvt.f64.f32 	%fd219, %f1712;
	add.f64 	%fd220, %fd216, %fd219;
	cvt.rn.f32.f64 	%f1712, %fd220;
	add.s32 	%r532, %r532, -1;
	add.s32 	%r531, %r531, 1;
	add.s64 	%rd47, %rd47, 4;
	add.s32 	%r533, %r533, 1;
	setp.lt.s32 	%p78, %r533, %r86;
	@%p78 bra 	$L__BB0_16;

	add.s32 	%r530, %r530, 1;
	setp.lt.s32 	%p79, %r530, %r86;
	@%p79 bra 	$L__BB0_15;

	div.rn.f32 	%f361, %f1713, %f1712;
	max.f32 	%f1709, %f1709, %f361;
	min.f32 	%f1760, %f1760, %f361;
	add.s32 	%r529, %r529, 1;
	setp.lt.s32 	%p80, %r529, %r86;
	@%p80 bra 	$L__BB0_14;

	add.s32 	%r528, %r528, 1;
	setp.lt.s32 	%p81, %r528, %r86;
	@%p81 bra 	$L__BB0_13;

$L__BB0_51:
	ld.param.u32 	%r506, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_3];
	mov.f32 	%f1682, 0f00000000;
	sub.f32 	%f362, %f1709, %f1760;
	add.f32 	%f363, %f362, %f362;
	fma.rn.f32 	%f364, %f362, 0f40000000, %f363;
	mul.f32 	%f365, %f364, 0f40490FD8;
	mul.f32 	%f366, %f365, %f317;
	mul.f32 	%f367, %f366, %f317;
	max.f32 	%f1761, %f1682, %f367;
	setp.lt.s32 	%p82, %r506, 1;
	@%p82 bra 	$L__BB0_205;

	cvt.f64.f32 	%fd34, %f317;
	add.f64 	%fd35, %fd34, 0d4008000000000000;
	mov.u32 	%r171, 0;
	mov.f64 	%fd221, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r198}, %fd221;
	}
	setp.lt.s32 	%p99, %r198, 0;
	setp.eq.f32 	%p103, %f317, 0fBF800000;
	setp.gt.s32 	%p104, %r198, -1;
	mov.u32 	%r534, %r171;

$L__BB0_53:
	mov.f32 	%f1728, 0f00000000;
	mov.f32 	%f1729, %f1728;
	mov.f32 	%f1730, %f1728;
	mov.f32 	%f1731, %f1728;
	mov.f32 	%f1732, %f1728;
	mov.f32 	%f1733, %f1728;
	mov.f32 	%f1734, %f1728;
	mov.f32 	%f1735, %f1728;
	@%p20 bra 	$L__BB0_204;

	mov.f32 	%f1728, 0f00000000;
	div.rn.f32 	%f385, %f1761, 0fC0206C98;
	div.rn.f32 	%f56, %f385, %f317;
	cvt.f64.f32 	%fd36, %f385;
	mov.u32 	%r535, %r171;

$L__BB0_55:
	mov.f32 	%f1627, 0f00000000;
	cvt.rn.f32.s32 	%f386, %r535;
	sub.f32 	%f387, %f386, %f1763;
	add.f32 	%f388, %f387, 0f3F000000;
	sqrt.rn.f32 	%f65, %f34;
	mul.f32 	%f389, %f65, %f388;
	abs.f32 	%f66, %f389;
	setp.ge.f32 	%p84, %f66, 0f3F8060FE;
	mul.f32 	%f390, %f389, %f389;
	selp.f32 	%f391, %f66, %f390, %p84;
	selp.f32 	%f392, 0f3789CA3C, 0f38B1E96A, %p84;
	selp.f32 	%f393, 0fB9F560B9, 0fBA574D20, %p84;
	fma.rn.f32 	%f394, %f392, %f391, %f393;
	selp.f32 	%f395, 0f3BAC840B, 0f3BAAD5EA, %p84;
	fma.rn.f32 	%f396, %f394, %f391, %f395;
	selp.f32 	%f397, 0fBD0C8162, 0fBCDC1BE7, %p84;
	fma.rn.f32 	%f398, %f396, %f391, %f397;
	selp.f32 	%f399, 0f3E1CF906, 0f3DE718AF, %p84;
	fma.rn.f32 	%f400, %f398, %f391, %f399;
	selp.f32 	%f401, 0f3F6A937E, 0fBEC093AC, %p84;
	fma.rn.f32 	%f402, %f400, %f391, %f401;
	selp.f32 	%f403, 0f3F20D842, 0f3E0375D3, %p84;
	fma.rn.f32 	%f404, %f402, %f391, %f403;
	neg.f32 	%f405, %f66;
	selp.f32 	%f406, %f405, %f389, %p84;
	fma.rn.f32 	%f67, %f404, %f406, %f406;
	mov.b32 	%r174, %f389;
	and.b32  	%r51, %r174, -2147483648;
	add.f32 	%f68, %f387, 0fBF000000;
	mul.f32 	%f407, %f65, %f68;
	abs.f32 	%f69, %f407;
	setp.ge.f32 	%p85, %f69, 0f3F8060FE;
	mul.f32 	%f408, %f407, %f407;
	selp.f32 	%f409, %f69, %f408, %p85;
	selp.f32 	%f410, 0f3789CA3C, 0f38B1E96A, %p85;
	selp.f32 	%f411, 0fB9F560B9, 0fBA574D20, %p85;
	fma.rn.f32 	%f412, %f410, %f409, %f411;
	selp.f32 	%f413, 0f3BAC840B, 0f3BAAD5EA, %p85;
	fma.rn.f32 	%f414, %f412, %f409, %f413;
	selp.f32 	%f415, 0fBD0C8162, 0fBCDC1BE7, %p85;
	fma.rn.f32 	%f416, %f414, %f409, %f415;
	selp.f32 	%f417, 0f3E1CF906, 0f3DE718AF, %p85;
	fma.rn.f32 	%f418, %f416, %f409, %f417;
	selp.f32 	%f419, 0f3F6A937E, 0fBEC093AC, %p85;
	fma.rn.f32 	%f420, %f418, %f409, %f419;
	selp.f32 	%f421, 0f3F20D842, 0f3E0375D3, %p85;
	fma.rn.f32 	%f422, %f420, %f409, %f421;
	neg.f32 	%f423, %f69;
	selp.f32 	%f424, %f423, %f407, %p85;
	fma.rn.f32 	%f70, %f422, %f424, %f424;
	mov.b32 	%r175, %f407;
	and.b32  	%r52, %r175, -2147483648;
	add.f32 	%f425, %f386, 0f3F000000;
	sub.f32 	%f71, %f425, %f1763;
	div.rn.f32 	%f72, %f71, %f317;
	mov.f32 	%f426, 0f3F800000;
	cvt.rzi.f32.f32 	%f427, %f426;
	add.f32 	%f428, %f427, %f427;
	mov.f32 	%f429, 0f40000000;
	sub.f32 	%f430, %f429, %f428;
	abs.f32 	%f73, %f430;
	setp.eq.f32 	%p86, %f73, 0f3F800000;
	abs.f32 	%f74, %f72;
	setp.lt.f32 	%p87, %f74, 0f00800000;
	mul.f32 	%f431, %f74, 0f4B800000;
	selp.f32 	%f432, %f431, %f74, %p87;
	selp.f32 	%f433, 0fC3170000, 0fC2FE0000, %p87;
	mov.b32 	%r176, %f432;
	and.b32  	%r177, %r176, 8388607;
	or.b32  	%r178, %r177, 1065353216;
	mov.b32 	%f434, %r178;
	shr.u32 	%r179, %r176, 23;
	cvt.rn.f32.u32 	%f435, %r179;
	add.f32 	%f436, %f433, %f435;
	setp.gt.f32 	%p88, %f434, 0f3FB504F3;
	mul.f32 	%f437, %f434, 0f3F000000;
	add.f32 	%f438, %f436, 0f3F800000;
	selp.f32 	%f439, %f438, %f436, %p88;
	selp.f32 	%f440, %f437, %f434, %p88;
	add.f32 	%f441, %f440, 0fBF800000;
	add.f32 	%f442, %f440, 0f3F800000;
	rcp.approx.ftz.f32 	%f443, %f442;
	add.f32 	%f444, %f441, %f441;
	mul.f32 	%f445, %f444, %f443;
	mul.f32 	%f446, %f445, %f445;
	mov.f32 	%f447, 0f3C4CAF63;
	mov.f32 	%f448, 0f3B18F0FE;
	fma.rn.f32 	%f449, %f448, %f446, %f447;
	mov.f32 	%f450, 0f3DAAAABD;
	fma.rn.f32 	%f451, %f449, %f446, %f450;
	mul.rn.f32 	%f452, %f451, %f446;
	mul.rn.f32 	%f453, %f452, %f445;
	sub.f32 	%f454, %f441, %f445;
	add.f32 	%f455, %f454, %f454;
	neg.f32 	%f456, %f445;
	fma.rn.f32 	%f457, %f456, %f441, %f455;
	mul.rn.f32 	%f458, %f443, %f457;
	add.f32 	%f459, %f453, %f445;
	sub.f32 	%f460, %f445, %f459;
	add.f32 	%f461, %f453, %f460;
	add.f32 	%f462, %f458, %f461;
	add.f32 	%f463, %f459, %f462;
	sub.f32 	%f464, %f459, %f463;
	add.f32 	%f465, %f462, %f464;
	mov.f32 	%f466, 0f3F317200;
	mul.rn.f32 	%f467, %f439, %f466;
	mov.f32 	%f468, 0f35BFBE8E;
	mul.rn.f32 	%f469, %f439, %f468;
	add.f32 	%f470, %f467, %f463;
	sub.f32 	%f471, %f467, %f470;
	add.f32 	%f472, %f463, %f471;
	add.f32 	%f473, %f465, %f472;
	add.f32 	%f474, %f469, %f473;
	add.f32 	%f475, %f470, %f474;
	sub.f32 	%f476, %f470, %f475;
	add.f32 	%f477, %f474, %f476;
	mul.rn.f32 	%f478, %f429, %f475;
	neg.f32 	%f479, %f478;
	fma.rn.f32 	%f480, %f429, %f475, %f479;
	fma.rn.f32 	%f481, %f429, %f477, %f480;
	fma.rn.f32 	%f483, %f1627, %f475, %f481;
	add.rn.f32 	%f484, %f478, %f483;
	neg.f32 	%f485, %f484;
	add.rn.f32 	%f486, %f478, %f485;
	add.rn.f32 	%f487, %f486, %f483;
	mov.b32 	%r180, %f484;
	setp.eq.s32 	%p89, %r180, 1118925336;
	add.s32 	%r181, %r180, -1;
	mov.b32 	%f488, %r181;
	add.f32 	%f489, %f487, 0f37000000;
	selp.f32 	%f75, %f489, %f487, %p89;
	selp.f32 	%f490, %f488, %f484, %p89;
	mov.f32 	%f491, 0f3FB8AA3B;
	mul.rn.f32 	%f492, %f490, %f491;
	cvt.rzi.f32.f32 	%f493, %f492;
	abs.f32 	%f494, %f493;
	setp.gt.f32 	%p90, %f494, 0f42FC0000;
	mov.b32 	%r182, %f493;
	and.b32  	%r183, %r182, -2147483648;
	or.b32  	%r184, %r183, 1123811328;
	mov.b32 	%f495, %r184;
	selp.f32 	%f496, %f495, %f493, %p90;
	mov.f32 	%f497, 0fBF317218;
	fma.rn.f32 	%f498, %f496, %f497, %f490;
	mov.f32 	%f499, 0f3102E308;
	fma.rn.f32 	%f500, %f496, %f499, %f498;
	mul.f32 	%f501, %f500, 0f3FB8AA3B;
	add.f32 	%f502, %f496, 0f4B40007F;
	mov.b32 	%r185, %f502;
	shl.b32 	%r186, %r185, 23;
	mov.b32 	%f503, %r186;
	ex2.approx.ftz.f32 	%f504, %f501;
	mul.f32 	%f76, %f504, %f503;
	setp.lt.f32 	%p91, %f72, 0f00000000;
	and.pred  	%p4, %p91, %p86;
	add.f32 	%f505, %f72, %f72;
	selp.f32 	%f77, %f505, 0f00000000, %p86;
	div.rn.f32 	%f78, %f68, %f317;
	abs.f32 	%f79, %f78;
	setp.lt.f32 	%p92, %f79, 0f00800000;
	mul.f32 	%f507, %f79, 0f4B800000;
	selp.f32 	%f508, %f507, %f79, %p92;
	selp.f32 	%f509, 0fC3170000, 0fC2FE0000, %p92;
	mov.b32 	%r187, %f508;
	and.b32  	%r188, %r187, 8388607;
	or.b32  	%r189, %r188, 1065353216;
	mov.b32 	%f510, %r189;
	shr.u32 	%r190, %r187, 23;
	cvt.rn.f32.u32 	%f511, %r190;
	add.f32 	%f512, %f509, %f511;
	setp.gt.f32 	%p93, %f510, 0f3FB504F3;
	mul.f32 	%f513, %f510, 0f3F000000;
	add.f32 	%f514, %f512, 0f3F800000;
	selp.f32 	%f515, %f514, %f512, %p93;
	selp.f32 	%f516, %f513, %f510, %p93;
	add.f32 	%f517, %f516, 0fBF800000;
	add.f32 	%f518, %f516, 0f3F800000;
	rcp.approx.ftz.f32 	%f519, %f518;
	add.f32 	%f520, %f517, %f517;
	mul.f32 	%f521, %f520, %f519;
	mul.f32 	%f522, %f521, %f521;
	fma.rn.f32 	%f523, %f448, %f522, %f447;
	fma.rn.f32 	%f524, %f523, %f522, %f450;
	mul.rn.f32 	%f525, %f524, %f522;
	mul.rn.f32 	%f526, %f525, %f521;
	sub.f32 	%f527, %f517, %f521;
	add.f32 	%f528, %f527, %f527;
	neg.f32 	%f529, %f521;
	fma.rn.f32 	%f530, %f529, %f517, %f528;
	mul.rn.f32 	%f531, %f519, %f530;
	add.f32 	%f532, %f526, %f521;
	sub.f32 	%f533, %f521, %f532;
	add.f32 	%f534, %f526, %f533;
	add.f32 	%f535, %f531, %f534;
	add.f32 	%f536, %f532, %f535;
	sub.f32 	%f537, %f532, %f536;
	add.f32 	%f538, %f535, %f537;
	mul.rn.f32 	%f539, %f515, %f466;
	mul.rn.f32 	%f540, %f515, %f468;
	add.f32 	%f541, %f539, %f536;
	sub.f32 	%f542, %f539, %f541;
	add.f32 	%f543, %f536, %f542;
	add.f32 	%f544, %f538, %f543;
	add.f32 	%f545, %f540, %f544;
	add.f32 	%f546, %f541, %f545;
	sub.f32 	%f547, %f541, %f546;
	add.f32 	%f548, %f545, %f547;
	mul.rn.f32 	%f549, %f429, %f546;
	neg.f32 	%f550, %f549;
	fma.rn.f32 	%f551, %f429, %f546, %f550;
	fma.rn.f32 	%f552, %f429, %f548, %f551;
	fma.rn.f32 	%f553, %f1627, %f546, %f552;
	add.rn.f32 	%f554, %f549, %f553;
	neg.f32 	%f555, %f554;
	add.rn.f32 	%f556, %f549, %f555;
	add.rn.f32 	%f557, %f556, %f553;
	mov.b32 	%r191, %f554;
	setp.eq.s32 	%p94, %r191, 1118925336;
	add.s32 	%r192, %r191, -1;
	mov.b32 	%f558, %r192;
	add.f32 	%f559, %f557, 0f37000000;
	selp.f32 	%f80, %f559, %f557, %p94;
	selp.f32 	%f560, %f558, %f554, %p94;
	mul.rn.f32 	%f561, %f560, %f491;
	cvt.rzi.f32.f32 	%f562, %f561;
	abs.f32 	%f563, %f562;
	setp.gt.f32 	%p95, %f563, 0f42FC0000;
	mov.b32 	%r193, %f562;
	and.b32  	%r194, %r193, -2147483648;
	or.b32  	%r195, %r194, 1123811328;
	mov.b32 	%f564, %r195;
	selp.f32 	%f565, %f564, %f562, %p95;
	fma.rn.f32 	%f566, %f565, %f497, %f560;
	fma.rn.f32 	%f567, %f565, %f499, %f566;
	mul.f32 	%f568, %f567, 0f3FB8AA3B;
	add.f32 	%f569, %f565, 0f4B40007F;
	mov.b32 	%r196, %f569;
	shl.b32 	%r197, %r196, 23;
	mov.b32 	%f570, %r197;
	ex2.approx.ftz.f32 	%f571, %f568;
	mul.f32 	%f81, %f571, %f570;
	setp.lt.f32 	%p96, %f78, 0f00000000;
	and.pred  	%p5, %p96, %p86;
	add.f32 	%f572, %f78, %f78;
	selp.f32 	%f84, %f572, 0f00000000, %p86;
	and.b32  	%r199, %r198, 2146435072;
	setp.eq.s32 	%p97, %r199, 1073741824;
	abs.f64 	%fd222, %fd34;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd222;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd221;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd37, [retval0+0];
	} // callseq 2
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd34;
	}
	setp.lt.s32 	%p98, %r55, 0;
	and.pred  	%p6, %p98, %p97;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r202}, %fd35;
	}
	and.b32  	%r57, %r202, 2146435072;
	setp.ne.s32 	%p100, %r57, 2146435072;
	setp.gtu.f64 	%p101, %fd222, 0d7FF0000000000000;
	and.b32  	%r58, %r198, 2147483647;
	selp.b32 	%r206, 2146435072, 0, %p104;
	setp.ne.s32 	%p105, %r58, 1071644672;
	and.pred  	%p106, %p105, %p6;
	or.b32  	%r207, %r206, -2147483648;
	selp.b32 	%r61, %r207, %r206, %p106;
	mov.f64 	%fd223, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd223;
	}
	and.b32  	%r64, %r62, 2147483647;
	setp.gt.s32 	%p107, %r62, -1;
	selp.b32 	%r65, 2146435072, 0, %p107;
	or.b32  	%r66, %r65, -2147483648;
	or.pred  	%p9, %p100, %p101;
	mov.u32 	%r536, %r171;

$L__BB0_56:
	cvt.rn.f32.s32 	%f1632, %r535;
	sub.f32 	%f1631, %f1632, %f1763;
	add.f32 	%f1630, %f1631, 0f3F000000;
	mul.f32 	%f1629, %f65, %f1630;
	abs.f32 	%f1628, %f1629;
	setp.ltu.f32 	%p108, %f1628, 0f3F8060FE;
	mov.f32 	%f1736, %f67;
	@%p108 bra 	$L__BB0_58;

	mov.f32 	%f1674, 0f3F800000;
	ex2.approx.ftz.f32 	%f574, %f67;
	sub.f32 	%f576, %f1674, %f574;
	mov.b32 	%r209, %f576;
	or.b32  	%r210, %r51, %r209;
	mov.b32 	%f1736, %r210;

$L__BB0_58:
	cvt.rn.f32.s32 	%f1637, %r535;
	sub.f32 	%f1636, %f1637, %f1763;
	add.f32 	%f1635, %f1636, 0fBF000000;
	mul.f32 	%f1634, %f65, %f1635;
	abs.f32 	%f1633, %f1634;
	setp.ltu.f32 	%p109, %f1633, 0f3F8060FE;
	mov.f32 	%f1737, %f70;
	@%p109 bra 	$L__BB0_60;

	mov.f32 	%f1673, 0f3F800000;
	ex2.approx.ftz.f32 	%f577, %f70;
	sub.f32 	%f579, %f1673, %f577;
	mov.b32 	%r211, %f579;
	or.b32  	%r212, %r52, %r211;
	mov.b32 	%f1737, %r212;

$L__BB0_60:
	sub.f32 	%f580, %f1736, %f1737;
	mul.f32 	%f99, %f580, 0f3F000000;
	cvt.rn.f32.s32 	%f100, %r536;
	sub.f32 	%f101, %f100, %f1762;
	add.f32 	%f581, %f101, 0f3F000000;
	mul.f32 	%f102, %f65, %f581;
	abs.f32 	%f582, %f102;
	setp.ltu.f32 	%p110, %f582, 0f3F8060FE;
	setp.ge.f32 	%p111, %f582, 0f3F8060FE;
	mul.f32 	%f583, %f102, %f102;
	selp.f32 	%f584, %f582, %f583, %p111;
	selp.f32 	%f585, 0f3789CA3C, 0f38B1E96A, %p111;
	selp.f32 	%f586, 0fB9F560B9, 0fBA574D20, %p111;
	fma.rn.f32 	%f587, %f585, %f584, %f586;
	selp.f32 	%f588, 0f3BAC840B, 0f3BAAD5EA, %p111;
	fma.rn.f32 	%f589, %f587, %f584, %f588;
	selp.f32 	%f590, 0fBD0C8162, 0fBCDC1BE7, %p111;
	fma.rn.f32 	%f591, %f589, %f584, %f590;
	selp.f32 	%f592, 0f3E1CF906, 0f3DE718AF, %p111;
	fma.rn.f32 	%f593, %f591, %f584, %f592;
	selp.f32 	%f594, 0f3F6A937E, 0fBEC093AC, %p111;
	fma.rn.f32 	%f595, %f593, %f584, %f594;
	selp.f32 	%f596, 0f3F20D842, 0f3E0375D3, %p111;
	fma.rn.f32 	%f597, %f595, %f584, %f596;
	neg.f32 	%f598, %f582;
	selp.f32 	%f599, %f598, %f102, %p111;
	fma.rn.f32 	%f1738, %f597, %f599, %f599;
	@%p110 bra 	$L__BB0_62;

	mov.f32 	%f1672, 0f3F800000;
	ex2.approx.ftz.f32 	%f600, %f1738;
	sub.f32 	%f602, %f1672, %f600;
	mov.b32 	%r213, %f602;
	mov.b32 	%r214, %f102;
	and.b32  	%r215, %r214, -2147483648;
	or.b32  	%r216, %r215, %r213;
	mov.b32 	%f1738, %r216;

$L__BB0_62:
	cvt.rn.f32.s32 	%f1639, %r536;
	sub.f32 	%f1638, %f1639, %f1762;
	add.f32 	%f106, %f1638, 0fBF000000;
	mul.f32 	%f107, %f65, %f106;
	abs.f32 	%f603, %f107;
	setp.ltu.f32 	%p112, %f603, 0f3F8060FE;
	setp.ge.f32 	%p113, %f603, 0f3F8060FE;
	mul.f32 	%f604, %f107, %f107;
	selp.f32 	%f605, %f603, %f604, %p113;
	selp.f32 	%f606, 0f3789CA3C, 0f38B1E96A, %p113;
	selp.f32 	%f607, 0fB9F560B9, 0fBA574D20, %p113;
	fma.rn.f32 	%f608, %f606, %f605, %f607;
	selp.f32 	%f609, 0f3BAC840B, 0f3BAAD5EA, %p113;
	fma.rn.f32 	%f610, %f608, %f605, %f609;
	selp.f32 	%f611, 0fBD0C8162, 0fBCDC1BE7, %p113;
	fma.rn.f32 	%f612, %f610, %f605, %f611;
	selp.f32 	%f613, 0f3E1CF906, 0f3DE718AF, %p113;
	fma.rn.f32 	%f614, %f612, %f605, %f613;
	selp.f32 	%f615, 0f3F6A937E, 0fBEC093AC, %p113;
	fma.rn.f32 	%f616, %f614, %f605, %f615;
	selp.f32 	%f617, 0f3F20D842, 0f3E0375D3, %p113;
	fma.rn.f32 	%f618, %f616, %f605, %f617;
	neg.f32 	%f619, %f603;
	selp.f32 	%f620, %f619, %f107, %p113;
	fma.rn.f32 	%f1739, %f618, %f620, %f620;
	@%p112 bra 	$L__BB0_64;

	mov.f32 	%f1671, 0f3F800000;
	ex2.approx.ftz.f32 	%f621, %f1739;
	sub.f32 	%f623, %f1671, %f621;
	mov.b32 	%r217, %f623;
	mov.b32 	%r218, %f107;
	and.b32  	%r219, %r218, -2147483648;
	or.b32  	%r220, %r219, %r217;
	mov.b32 	%f1739, %r220;

$L__BB0_64:
	sub.f32 	%f625, %f1738, %f1739;
	mul.f32 	%f111, %f625, 0f3F000000;
	mul.f32 	%f626, %f99, %f1761;
	fma.rn.f32 	%f112, %f111, %f626, %f1760;
	mad.lo.s32 	%r221, %r536, %r86, %r535;
	add.s32 	%r222, %r221, %r2;
	mul.wide.s32 	%rd24, %r222, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.f32 	%f113, [%rd25];
	setp.eq.f32 	%p114, %f76, 0f7F800000;
	mov.f32 	%f1740, 0f7F800000;
	@%p114 bra 	$L__BB0_66;

	fma.rn.f32 	%f1740, %f76, %f75, %f76;

$L__BB0_66:
	setp.geu.f32 	%p377, %f72, 0f00000000;
	mov.b32 	%r223, %f1740;
	xor.b32  	%r224, %r223, -2147483648;
	mov.b32 	%f627, %r224;
	selp.f32 	%f116, %f627, %f1740, %p4;
	setp.eq.f32 	%p115, %f72, 0f00000000;
	selp.f32 	%f1741, %f77, %f116, %p115;
	@%p377 bra 	$L__BB0_69;

	mov.f32 	%f1640, 0f40000000;
	cvt.rzi.f32.f32 	%f629, %f1640;
	setp.eq.f32 	%p116, %f629, 0f40000000;
	mov.f32 	%f1741, %f116;
	@%p116 bra 	$L__BB0_69;

	mov.f32 	%f1741, 0f7FFFFFFF;

$L__BB0_69:
	abs.f32 	%f1645, %f72;
	mov.f32 	%f1644, 0f3FB8AA3B;
	add.f32 	%f1643, %f1645, 0f40000000;
	mov.b32 	%r479, %f1643;
	selp.f32 	%f1642, 0fFF800000, 0f7F800000, %p4;
	add.f32 	%f1641, %f72, 0f40000000;
	setp.gtu.f32 	%p117, %f1645, 0f7F800000;
	mov.f32 	%f1742, 0f7F800000;
	selp.f32 	%f632, %f1641, %f1741, %p117;
	setp.neu.f32 	%p118, %f1645, 0f7F800000;
	selp.f32 	%f633, %f632, %f1642, %p118;
	setp.gt.s32 	%p119, %r479, 2139095039;
	selp.f32 	%f634, %f633, %f1741, %p119;
	mul.f32 	%f635, %f634, 0fBF000000;
	setp.eq.f32 	%p120, %f72, 0f3F800000;
	selp.f32 	%f636, 0fBF000000, %f635, %p120;
	mov.f32 	%f638, 0f3BBB989D;
	fma.rn.f32 	%f639, %f636, %f638, %f350;
	mov.f32 	%f641, 0f437C0000;
	cvt.sat.f32.f32 	%f642, %f639;
	mov.f32 	%f643, 0f4B400001;
	fma.rm.f32 	%f644, %f642, %f641, %f643;
	add.f32 	%f645, %f644, 0fCB40007F;
	neg.f32 	%f646, %f645;
	fma.rn.f32 	%f647, %f636, %f1644, %f646;
	mov.f32 	%f648, 0f32A57060;
	fma.rn.f32 	%f649, %f636, %f648, %f647;
	mov.b32 	%r225, %f644;
	shl.b32 	%r226, %r225, 23;
	mov.b32 	%f650, %r226;
	ex2.approx.ftz.f32 	%f651, %f649;
	mul.f32 	%f119, %f651, %f650;
	setp.eq.f32 	%p121, %f81, 0f7F800000;
	@%p121 bra 	$L__BB0_71;

	fma.rn.f32 	%f1742, %f81, %f80, %f81;

$L__BB0_71:
	setp.geu.f32 	%p378, %f78, 0f00000000;
	mov.b32 	%r227, %f1742;
	xor.b32  	%r228, %r227, -2147483648;
	mov.b32 	%f652, %r228;
	selp.f32 	%f122, %f652, %f1742, %p5;
	setp.eq.f32 	%p122, %f78, 0f00000000;
	selp.f32 	%f1743, %f84, %f122, %p122;
	@%p378 bra 	$L__BB0_74;

	mov.f32 	%f1646, 0f40000000;
	cvt.rzi.f32.f32 	%f654, %f1646;
	setp.eq.f32 	%p123, %f654, 0f40000000;
	mov.f32 	%f1743, %f122;
	@%p123 bra 	$L__BB0_74;

	mov.f32 	%f1743, 0f7FFFFFFF;

$L__BB0_74:
	abs.f32 	%f1655, %f78;
	mov.f32 	%f1654, 0f32A57060;
	mov.f32 	%f1653, 0f4B400001;
	mov.f32 	%f1652, 0f437C0000;
	mov.f32 	%f1651, 0f3BBB989D;
	add.f32 	%f1650, %f1655, 0f40000000;
	mov.b32 	%r480, %f1650;
	selp.f32 	%f1649, 0fFF800000, 0f7F800000, %p5;
	add.f32 	%f1648, %f78, 0f40000000;
	mov.f32 	%f1647, 0f3FB8AA3B;
	setp.gtu.f32 	%p124, %f1655, 0f7F800000;
	selp.f32 	%f656, %f1648, %f1743, %p124;
	setp.neu.f32 	%p125, %f1655, 0f7F800000;
	selp.f32 	%f657, %f656, %f1649, %p125;
	setp.gt.s32 	%p126, %r480, 2139095039;
	selp.f32 	%f658, %f657, %f1743, %p126;
	mul.f32 	%f659, %f658, 0fBF000000;
	setp.eq.f32 	%p127, %f78, 0f3F800000;
	selp.f32 	%f660, 0fBF000000, %f659, %p127;
	fma.rn.f32 	%f663, %f660, %f1651, %f350;
	cvt.sat.f32.f32 	%f666, %f663;
	fma.rm.f32 	%f668, %f666, %f1652, %f1653;
	add.f32 	%f669, %f668, 0fCB40007F;
	neg.f32 	%f670, %f669;
	fma.rn.f32 	%f671, %f660, %f1647, %f670;
	fma.rn.f32 	%f673, %f660, %f1654, %f671;
	mov.b32 	%r229, %f668;
	shl.b32 	%r230, %r229, 23;
	mov.b32 	%f674, %r230;
	ex2.approx.ftz.f32 	%f675, %f673;
	mul.f32 	%f125, %f675, %f674;
	sub.f32 	%f676, %f119, %f125;
	mul.f32 	%f677, %f56, %f676;
	mul.f32 	%f126, %f111, %f677;
	not.pred 	%p128, %p6;
	mov.f64 	%fd348, %fd37;
	@%p128 bra 	$L__BB0_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r231}, %fd37;
	}
	xor.b32  	%r232, %r231, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r233, %temp}, %fd37;
	}
	mov.b64 	%fd348, {%r233, %r232};

$L__BB0_76:
	setp.eq.f32 	%p129, %f317, 0f00000000;
	@%p129 bra 	$L__BB0_80;
	bra.uni 	$L__BB0_77;

$L__BB0_80:
	and.b32  	%r495, %r198, 2146435072;
	setp.eq.s32 	%p381, %r495, 1073741824;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r494}, %fd34;
	}
	selp.b32 	%r493, %r494, 0, %p381;
	or.b32  	%r492, %r493, 2146435072;
	selp.b32 	%r491, %r492, %r493, %p99;
	mov.u32 	%r234, 0;
	mov.b64 	%fd348, {%r234, %r491};
	bra.uni 	$L__BB0_81;

$L__BB0_77:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r481}, %fd34;
	}
	setp.gt.s32 	%p130, %r481, -1;
	@%p130 bra 	$L__BB0_81;

	cvt.rzi.f64.f64 	%fd225, %fd221;
	setp.eq.f64 	%p131, %fd225, 0d4008000000000000;
	@%p131 bra 	$L__BB0_81;

	mov.f64 	%fd348, 0dFFF8000000000000;

$L__BB0_81:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r483}, %fd35;
	}
	and.b32  	%r482, %r483, 2146435072;
	setp.ne.s32 	%p379, %r482, 2146435072;
	selp.f64 	%fd349, %fd348, %fd35, %p379;
	@%p9 bra 	$L__BB0_86;

	and.b32  	%r484, %r198, 2147483647;
	setp.eq.s32 	%p133, %r484, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd221;
	}
	setp.eq.s32 	%p134, %r235, 0;
	and.pred  	%p135, %p133, %p134;
	@%p135 bra 	$L__BB0_85;
	bra.uni 	$L__BB0_83;

$L__BB0_85:
	abs.f64 	%fd307, %fd34;
	setp.gt.f64 	%p380, %fd307, 0d3FF0000000000000;
	selp.b32 	%r490, 2146435072, 0, %p380;
	xor.b32  	%r489, %r490, 2146435072;
	selp.b32 	%r488, %r489, %r490, %p99;
	selp.b32 	%r487, 1072693248, %r488, %p103;
	mov.u32 	%r238, 0;
	mov.b64 	%fd349, {%r238, %r487};
	bra.uni 	$L__BB0_86;

$L__BB0_83:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r486}, %fd34;
	}
	and.b32  	%r485, %r486, 2147483647;
	setp.ne.s32 	%p136, %r485, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r236, %temp}, %fd34;
	}
	setp.ne.s32 	%p137, %r236, 0;
	or.pred  	%p138, %p136, %p137;
	mov.f64 	%fd349, %fd348;
	@%p138 bra 	$L__BB0_86;

	mov.u32 	%r237, 0;
	mov.b64 	%fd349, {%r237, %r61};

$L__BB0_86:
	cvt.rn.f32.s32 	%f1670, %r535;
	cvt.rn.f32.s32 	%f1669, %r536;
	mov.f32 	%f1668, 0f3102E308;
	mov.f32 	%f1667, 0fBF317218;
	mov.f32 	%f1666, 0f35BFBE8E;
	mov.f32 	%f1665, 0f3F317200;
	mov.f32 	%f1664, 0f3DAAAABD;
	mov.f32 	%f1663, 0f3C4CAF63;
	mov.f32 	%f1662, 0f3B18F0FE;
	add.f32 	%f1661, %f1670, 0f3F000000;
	sub.f32 	%f1660, %f1661, %f1763;
	sub.f32 	%f1659, %f1670, %f1763;
	add.f32 	%f1658, %f1659, 0fBF000000;
	mov.f32 	%f1657, 0f3FB8AA3B;
	mov.f32 	%f1656, 0f40000000;
	setp.eq.f32 	%p139, %f317, 0f3F800000;
	selp.f64 	%fd228, 0d3FF0000000000000, %fd349, %p139;
	div.rn.f64 	%fd46, %fd36, %fd228;
	mul.f32 	%f679, %f1658, %f125;
	mul.f32 	%f680, %f1660, %f119;
	sub.f32 	%f681, %f680, %f679;
	cvt.f64.f32 	%fd229, %f681;
	mul.f64 	%fd230, %fd46, %fd229;
	cvt.f64.f32 	%fd231, %f111;
	mul.f64 	%fd232, %fd230, %fd231;
	cvt.rn.f32.f64 	%f127, %fd232;
	add.f32 	%f682, %f1669, 0f3F000000;
	sub.f32 	%f128, %f682, %f1762;
	div.rn.f32 	%f129, %f128, %f317;
	abs.f32 	%f130, %f129;
	setp.lt.f32 	%p140, %f130, 0f00800000;
	mul.f32 	%f683, %f130, 0f4B800000;
	selp.f32 	%f684, %f683, %f130, %p140;
	selp.f32 	%f685, 0fC3170000, 0fC2FE0000, %p140;
	mov.b32 	%r239, %f684;
	and.b32  	%r240, %r239, 8388607;
	or.b32  	%r241, %r240, 1065353216;
	mov.b32 	%f686, %r241;
	shr.u32 	%r242, %r239, 23;
	cvt.rn.f32.u32 	%f687, %r242;
	add.f32 	%f688, %f685, %f687;
	setp.gt.f32 	%p141, %f686, 0f3FB504F3;
	mul.f32 	%f689, %f686, 0f3F000000;
	add.f32 	%f690, %f688, 0f3F800000;
	selp.f32 	%f691, %f690, %f688, %p141;
	selp.f32 	%f692, %f689, %f686, %p141;
	add.f32 	%f693, %f692, 0fBF800000;
	add.f32 	%f694, %f692, 0f3F800000;
	rcp.approx.ftz.f32 	%f695, %f694;
	add.f32 	%f696, %f693, %f693;
	mul.f32 	%f698, %f696, %f695;
	mul.f32 	%f699, %f698, %f698;
	fma.rn.f32 	%f702, %f1662, %f699, %f1663;
	fma.rn.f32 	%f704, %f702, %f699, %f1664;
	mul.rn.f32 	%f705, %f704, %f699;
	mul.rn.f32 	%f706, %f705, %f698;
	sub.f32 	%f707, %f693, %f698;
	add.f32 	%f708, %f707, %f707;
	neg.f32 	%f709, %f698;
	fma.rn.f32 	%f710, %f709, %f693, %f708;
	mul.rn.f32 	%f711, %f695, %f710;
	add.f32 	%f712, %f706, %f698;
	sub.f32 	%f713, %f698, %f712;
	add.f32 	%f714, %f706, %f713;
	add.f32 	%f715, %f711, %f714;
	add.f32 	%f716, %f712, %f715;
	sub.f32 	%f717, %f712, %f716;
	add.f32 	%f718, %f715, %f717;
	mul.rn.f32 	%f720, %f691, %f1665;
	mul.rn.f32 	%f722, %f691, %f1666;
	add.f32 	%f723, %f720, %f716;
	sub.f32 	%f724, %f720, %f723;
	add.f32 	%f725, %f716, %f724;
	add.f32 	%f726, %f718, %f725;
	add.f32 	%f727, %f722, %f726;
	add.f32 	%f728, %f723, %f727;
	sub.f32 	%f729, %f723, %f728;
	add.f32 	%f730, %f727, %f729;
	mul.rn.f32 	%f731, %f1656, %f728;
	neg.f32 	%f732, %f731;
	fma.rn.f32 	%f733, %f1656, %f728, %f732;
	fma.rn.f32 	%f734, %f1656, %f730, %f733;
	mov.f32 	%f735, 0f00000000;
	fma.rn.f32 	%f736, %f735, %f728, %f734;
	add.rn.f32 	%f737, %f731, %f736;
	neg.f32 	%f738, %f737;
	add.rn.f32 	%f739, %f731, %f738;
	add.rn.f32 	%f740, %f739, %f736;
	mov.b32 	%r243, %f737;
	setp.eq.s32 	%p142, %r243, 1118925336;
	add.s32 	%r244, %r243, -1;
	mov.b32 	%f741, %r244;
	add.f32 	%f742, %f740, 0f37000000;
	selp.f32 	%f131, %f742, %f740, %p142;
	selp.f32 	%f743, %f741, %f737, %p142;
	mul.rn.f32 	%f745, %f743, %f1657;
	cvt.rzi.f32.f32 	%f746, %f745;
	abs.f32 	%f747, %f746;
	setp.gt.f32 	%p143, %f747, 0f42FC0000;
	mov.b32 	%r245, %f746;
	and.b32  	%r246, %r245, -2147483648;
	or.b32  	%r247, %r246, 1123811328;
	mov.b32 	%f748, %r247;
	selp.f32 	%f749, %f748, %f746, %p143;
	fma.rn.f32 	%f751, %f749, %f1667, %f743;
	fma.rn.f32 	%f753, %f749, %f1668, %f751;
	mul.f32 	%f754, %f753, 0f3FB8AA3B;
	add.f32 	%f755, %f749, 0f4B40007F;
	mov.b32 	%r248, %f755;
	shl.b32 	%r249, %r248, 23;
	mov.b32 	%f756, %r249;
	ex2.approx.ftz.f32 	%f757, %f754;
	mul.f32 	%f132, %f757, %f756;
	setp.eq.f32 	%p144, %f132, 0f7F800000;
	mov.f32 	%f1744, 0f7F800000;
	@%p144 bra 	$L__BB0_88;

	fma.rn.f32 	%f1744, %f132, %f131, %f132;

$L__BB0_88:
	setp.lt.f32 	%p145, %f129, 0f00000000;
	and.pred  	%p10, %p145, %p86;
	setp.eq.f32 	%p147, %f129, 0f00000000;
	@%p147 bra 	$L__BB0_92;
	bra.uni 	$L__BB0_89;

$L__BB0_92:
	add.f32 	%f762, %f129, %f129;
	selp.f32 	%f1746, %f762, 0f00000000, %p86;
	bra.uni 	$L__BB0_93;

$L__BB0_89:
	mov.b32 	%r250, %f1744;
	xor.b32  	%r251, %r250, -2147483648;
	mov.b32 	%f758, %r251;
	selp.f32 	%f1746, %f758, %f1744, %p10;
	setp.geu.f32 	%p148, %f129, 0f00000000;
	@%p148 bra 	$L__BB0_93;

	mov.f32 	%f1678, 0f40000000;
	cvt.rzi.f32.f32 	%f760, %f1678;
	setp.eq.f32 	%p149, %f760, 0f40000000;
	@%p149 bra 	$L__BB0_93;

	mov.f32 	%f1746, 0f7FFFFFFF;

$L__BB0_93:
	abs.f32 	%f1596, %f129;
	add.f32 	%f763, %f1596, 0f40000000;
	mov.b32 	%r252, %f763;
	setp.lt.s32 	%p151, %r252, 2139095040;
	@%p151 bra 	$L__BB0_98;

	abs.f32 	%f1676, %f129;
	setp.gtu.f32 	%p152, %f1676, 0f7F800000;
	@%p152 bra 	$L__BB0_97;
	bra.uni 	$L__BB0_95;

$L__BB0_97:
	add.f32 	%f1746, %f129, 0f40000000;
	bra.uni 	$L__BB0_98;

$L__BB0_95:
	abs.f32 	%f1677, %f129;
	setp.neu.f32 	%p153, %f1677, 0f7F800000;
	@%p153 bra 	$L__BB0_98;

	selp.f32 	%f1746, 0fFF800000, 0f7F800000, %p10;

$L__BB0_98:
	mov.f32 	%f1613, 0f00000000;
	cvt.rn.f32.s32 	%f1612, %r536;
	sub.f32 	%f1611, %f1612, %f1762;
	add.f32 	%f1610, %f1611, 0fBF000000;
	mov.f32 	%f1609, 0f3102E308;
	mov.f32 	%f1608, 0fBF317218;
	mov.f32 	%f1607, 0f35BFBE8E;
	mov.f32 	%f1606, 0f3F317200;
	mov.f32 	%f1605, 0f3DAAAABD;
	mov.f32 	%f1604, 0f3C4CAF63;
	mov.f32 	%f1603, 0f3B18F0FE;
	mov.f32 	%f1602, 0f32A57060;
	mov.f32 	%f1601, 0f4B400001;
	mov.f32 	%f1600, 0f437C0000;
	mov.f32 	%f1599, 0f3BBB989D;
	mov.f32 	%f1598, 0f3FB8AA3B;
	mov.f32 	%f1597, 0f40000000;
	mul.f32 	%f765, %f1746, 0fBF000000;
	setp.eq.f32 	%p154, %f129, 0f3F800000;
	selp.f32 	%f766, 0fBF000000, %f765, %p154;
	fma.rn.f32 	%f769, %f766, %f1599, %f350;
	cvt.sat.f32.f32 	%f772, %f769;
	fma.rm.f32 	%f774, %f772, %f1600, %f1601;
	add.f32 	%f775, %f774, 0fCB40007F;
	neg.f32 	%f776, %f775;
	fma.rn.f32 	%f777, %f766, %f1598, %f776;
	fma.rn.f32 	%f779, %f766, %f1602, %f777;
	mov.b32 	%r253, %f774;
	shl.b32 	%r254, %r253, 23;
	mov.b32 	%f780, %r254;
	ex2.approx.ftz.f32 	%f781, %f779;
	mul.f32 	%f141, %f781, %f780;
	div.rn.f32 	%f142, %f1610, %f317;
	abs.f32 	%f143, %f142;
	setp.lt.f32 	%p155, %f143, 0f00800000;
	mul.f32 	%f782, %f143, 0f4B800000;
	selp.f32 	%f783, %f782, %f143, %p155;
	selp.f32 	%f784, 0fC3170000, 0fC2FE0000, %p155;
	mov.b32 	%r255, %f783;
	and.b32  	%r256, %r255, 8388607;
	or.b32  	%r257, %r256, 1065353216;
	mov.b32 	%f785, %r257;
	shr.u32 	%r258, %r255, 23;
	cvt.rn.f32.u32 	%f786, %r258;
	add.f32 	%f787, %f784, %f786;
	setp.gt.f32 	%p156, %f785, 0f3FB504F3;
	mul.f32 	%f788, %f785, 0f3F000000;
	add.f32 	%f789, %f787, 0f3F800000;
	selp.f32 	%f790, %f789, %f787, %p156;
	selp.f32 	%f791, %f788, %f785, %p156;
	add.f32 	%f792, %f791, 0fBF800000;
	add.f32 	%f793, %f791, 0f3F800000;
	rcp.approx.ftz.f32 	%f794, %f793;
	add.f32 	%f795, %f792, %f792;
	mul.f32 	%f797, %f795, %f794;
	mul.f32 	%f798, %f797, %f797;
	fma.rn.f32 	%f801, %f1603, %f798, %f1604;
	fma.rn.f32 	%f803, %f801, %f798, %f1605;
	mul.rn.f32 	%f804, %f803, %f798;
	mul.rn.f32 	%f805, %f804, %f797;
	sub.f32 	%f806, %f792, %f797;
	add.f32 	%f807, %f806, %f806;
	neg.f32 	%f808, %f797;
	fma.rn.f32 	%f809, %f808, %f792, %f807;
	mul.rn.f32 	%f810, %f794, %f809;
	add.f32 	%f811, %f805, %f797;
	sub.f32 	%f812, %f797, %f811;
	add.f32 	%f813, %f805, %f812;
	add.f32 	%f814, %f810, %f813;
	add.f32 	%f815, %f811, %f814;
	sub.f32 	%f816, %f811, %f815;
	add.f32 	%f817, %f814, %f816;
	mul.rn.f32 	%f819, %f790, %f1606;
	mul.rn.f32 	%f821, %f790, %f1607;
	add.f32 	%f822, %f819, %f815;
	sub.f32 	%f823, %f819, %f822;
	add.f32 	%f824, %f815, %f823;
	add.f32 	%f825, %f817, %f824;
	add.f32 	%f826, %f821, %f825;
	add.f32 	%f827, %f822, %f826;
	sub.f32 	%f828, %f822, %f827;
	add.f32 	%f829, %f826, %f828;
	mul.rn.f32 	%f830, %f1597, %f827;
	neg.f32 	%f831, %f830;
	fma.rn.f32 	%f832, %f1597, %f827, %f831;
	fma.rn.f32 	%f833, %f1597, %f829, %f832;
	fma.rn.f32 	%f835, %f1613, %f827, %f833;
	add.rn.f32 	%f836, %f830, %f835;
	neg.f32 	%f837, %f836;
	add.rn.f32 	%f838, %f830, %f837;
	add.rn.f32 	%f839, %f838, %f835;
	mov.b32 	%r259, %f836;
	setp.eq.s32 	%p157, %r259, 1118925336;
	add.s32 	%r260, %r259, -1;
	mov.b32 	%f840, %r260;
	add.f32 	%f841, %f839, 0f37000000;
	selp.f32 	%f144, %f841, %f839, %p157;
	selp.f32 	%f842, %f840, %f836, %p157;
	mul.rn.f32 	%f843, %f842, %f1598;
	cvt.rzi.f32.f32 	%f844, %f843;
	abs.f32 	%f845, %f844;
	setp.gt.f32 	%p158, %f845, 0f42FC0000;
	mov.b32 	%r261, %f844;
	and.b32  	%r262, %r261, -2147483648;
	or.b32  	%r263, %r262, 1123811328;
	mov.b32 	%f846, %r263;
	selp.f32 	%f847, %f846, %f844, %p158;
	fma.rn.f32 	%f849, %f847, %f1608, %f842;
	fma.rn.f32 	%f851, %f847, %f1609, %f849;
	mul.f32 	%f852, %f851, 0f3FB8AA3B;
	add.f32 	%f853, %f847, 0f4B40007F;
	mov.b32 	%r264, %f853;
	shl.b32 	%r265, %r264, 23;
	mov.b32 	%f854, %r265;
	ex2.approx.ftz.f32 	%f855, %f852;
	mul.f32 	%f145, %f855, %f854;
	setp.eq.f32 	%p159, %f145, 0f7F800000;
	mov.f32 	%f1747, 0f7F800000;
	@%p159 bra 	$L__BB0_100;

	fma.rn.f32 	%f1747, %f145, %f144, %f145;

$L__BB0_100:
	setp.lt.f32 	%p160, %f142, 0f00000000;
	and.pred  	%p11, %p160, %p86;
	setp.eq.f32 	%p162, %f142, 0f00000000;
	@%p162 bra 	$L__BB0_104;
	bra.uni 	$L__BB0_101;

$L__BB0_104:
	add.f32 	%f860, %f142, %f142;
	selp.f32 	%f1749, %f860, 0f00000000, %p86;
	bra.uni 	$L__BB0_105;

$L__BB0_101:
	mov.b32 	%r266, %f1747;
	xor.b32  	%r267, %r266, -2147483648;
	mov.b32 	%f856, %r267;
	selp.f32 	%f1749, %f856, %f1747, %p11;
	setp.geu.f32 	%p163, %f142, 0f00000000;
	@%p163 bra 	$L__BB0_105;

	mov.f32 	%f1675, 0f40000000;
	cvt.rzi.f32.f32 	%f858, %f1675;
	setp.eq.f32 	%p164, %f858, 0f40000000;
	@%p164 bra 	$L__BB0_105;

	mov.f32 	%f1749, 0f7FFFFFFF;

$L__BB0_105:
	abs.f32 	%f1679, %f142;
	add.f32 	%f861, %f1679, 0f40000000;
	mov.b32 	%r268, %f861;
	setp.lt.s32 	%p166, %r268, 2139095040;
	@%p166 bra 	$L__BB0_110;

	abs.f32 	%f1680, %f142;
	setp.gtu.f32 	%p167, %f1680, 0f7F800000;
	@%p167 bra 	$L__BB0_109;
	bra.uni 	$L__BB0_107;

$L__BB0_109:
	add.f32 	%f1749, %f142, 0f40000000;
	bra.uni 	$L__BB0_110;

$L__BB0_107:
	abs.f32 	%f1681, %f142;
	setp.neu.f32 	%p168, %f1681, 0f7F800000;
	@%p168 bra 	$L__BB0_110;

	selp.f32 	%f1749, 0fFF800000, 0f7F800000, %p11;

$L__BB0_110:
	cvt.rn.f32.s32 	%f1624, %r536;
	add.f32 	%f1623, %f1624, 0f3F000000;
	sub.f32 	%f1622, %f1623, %f1762;
	mov.f32 	%f1750, 0f00000000;
	sub.f32 	%f1620, %f1624, %f1762;
	add.f32 	%f1619, %f1620, 0fBF000000;
	mov.f32 	%f1618, 0f32A57060;
	mov.f32 	%f1617, 0f4B400001;
	mov.f32 	%f1616, 0f437C0000;
	mov.f32 	%f1615, 0f3BBB989D;
	mov.f32 	%f1614, 0f3FB8AA3B;
	mul.f32 	%f863, %f1749, 0fBF000000;
	setp.eq.f32 	%p169, %f142, 0f3F800000;
	selp.f32 	%f864, 0fBF000000, %f863, %p169;
	fma.rn.f32 	%f867, %f864, %f1615, %f350;
	cvt.sat.f32.f32 	%f870, %f867;
	fma.rm.f32 	%f872, %f870, %f1616, %f1617;
	add.f32 	%f873, %f872, 0fCB40007F;
	neg.f32 	%f874, %f873;
	fma.rn.f32 	%f875, %f864, %f1614, %f874;
	fma.rn.f32 	%f877, %f864, %f1618, %f875;
	mov.b32 	%r269, %f872;
	shl.b32 	%r270, %r269, 23;
	mov.b32 	%f878, %r270;
	ex2.approx.ftz.f32 	%f879, %f877;
	mul.f32 	%f880, %f879, %f878;
	sub.f32 	%f881, %f141, %f880;
	mul.f32 	%f882, %f56, %f881;
	mul.f32 	%f154, %f99, %f882;
	mul.f32 	%f883, %f1619, %f880;
	mul.f32 	%f884, %f1622, %f141;
	sub.f32 	%f885, %f884, %f883;
	cvt.f64.f32 	%fd233, %f885;
	mul.f64 	%fd234, %fd46, %fd233;
	cvt.f64.f32 	%fd235, %f99;
	mul.f64 	%fd236, %fd234, %fd235;
	cvt.rn.f32.f64 	%f155, %fd236;
	mul.f32 	%f156, %f99, %f111;
	setp.leu.f32 	%p170, %f112, 0f3C23D70A;
	@%p170 bra 	$L__BB0_112;

	div.rn.f32 	%f886, %f113, %f112;
	add.f32 	%f1750, %f886, 0fBF800000;

$L__BB0_112:
	mov.f32 	%f1751, 0f00000000;
	@%p170 bra 	$L__BB0_127;

	mov.f64 	%fd308, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r503}, %fd308;
	}
	and.b32  	%r502, %r503, 2146435072;
	setp.eq.s32 	%p172, %r502, 1062207488;
	cvt.f64.f32 	%fd47, %f112;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd47;
	}
	abs.f64 	%fd48, %fd47;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd48;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd308;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd351, [retval0+0];
	} // callseq 3
	setp.lt.s32 	%p173, %r69, 0;
	and.pred  	%p12, %p173, %p172;
	not.pred 	%p174, %p12;
	@%p174 bra 	$L__BB0_115;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r271}, %fd351;
	}
	xor.b32  	%r272, %r271, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r273, %temp}, %fd351;
	}
	mov.b64 	%fd351, {%r273, %r272};

$L__BB0_115:
	setp.eq.f32 	%p175, %f112, 0f00000000;
	@%p175 bra 	$L__BB0_119;
	bra.uni 	$L__BB0_116;

$L__BB0_119:
	setp.lt.s32 	%p178, %r62, 0;
	mov.u32 	%r274, 0;
	selp.b32 	%r275, %r69, 0, %p172;
	or.b32  	%r276, %r275, 2146435072;
	selp.b32 	%r277, %r276, %r275, %p178;
	mov.b64 	%fd351, {%r274, %r277};
	bra.uni 	$L__BB0_120;

$L__BB0_116:
	setp.gt.s32 	%p176, %r69, -1;
	@%p176 bra 	$L__BB0_120;

	cvt.rzi.f64.f64 	%fd239, %fd223;
	setp.eq.f64 	%p177, %fd239, 0d4000000000000000;
	@%p177 bra 	$L__BB0_120;

	mov.f64 	%fd351, 0dFFF8000000000000;

$L__BB0_120:
	add.f64 	%fd54, %fd47, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r278}, %fd54;
	}
	and.b32  	%r279, %r278, 2146435072;
	setp.ne.s32 	%p180, %r279, 2146435072;
	mov.f64 	%fd352, %fd351;
	@%p180 bra 	$L__BB0_126;

	setp.gtu.f64 	%p181, %fd48, 0d7FF0000000000000;
	mov.f64 	%fd352, %fd54;
	@%p181 bra 	$L__BB0_126;

	setp.eq.s32 	%p182, %r64, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r280, %temp}, %fd223;
	}
	setp.eq.s32 	%p183, %r280, 0;
	and.pred  	%p184, %p182, %p183;
	@%p184 bra 	$L__BB0_125;
	bra.uni 	$L__BB0_123;

$L__BB0_125:
	setp.lt.s32 	%p190, %r62, 0;
	mov.u32 	%r285, 0;
	setp.gt.f64 	%p191, %fd48, 0d3FF0000000000000;
	selp.b32 	%r286, 2146435072, 0, %p191;
	xor.b32  	%r287, %r286, 2146435072;
	selp.b32 	%r288, %r287, %r286, %p190;
	setp.eq.f32 	%p192, %f112, 0fBF800000;
	selp.b32 	%r289, 1072693248, %r288, %p192;
	mov.b64 	%fd352, {%r285, %r289};
	bra.uni 	$L__BB0_126;

$L__BB0_123:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r281, %temp}, %fd47;
	}
	and.b32  	%r282, %r69, 2147483647;
	setp.ne.s32 	%p185, %r282, 2146435072;
	setp.ne.s32 	%p186, %r281, 0;
	or.pred  	%p187, %p185, %p186;
	mov.f64 	%fd352, %fd351;
	@%p187 bra 	$L__BB0_126;

	setp.ne.s32 	%p188, %r64, 1071644672;
	and.pred  	%p189, %p188, %p12;
	selp.b32 	%r283, %r66, %r65, %p189;
	mov.u32 	%r284, 0;
	mov.b64 	%fd352, {%r284, %r283};

$L__BB0_126:
	setp.eq.f32 	%p193, %f112, 0f3F800000;
	selp.f64 	%fd242, 0d3FF0000000000000, %fd352, %p193;
	cvt.f64.f32 	%fd243, %f113;
	div.rn.f64 	%fd244, %fd243, %fd242;
	cvt.rn.f32.f64 	%f1751, %fd244;

$L__BB0_127:
	mov.f64 	%fd306, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r472}, %fd306;
	}
	and.b32  	%r471, %r472, 2146435072;
	mov.f32 	%f888, 0f47C35000;
	min.f32 	%f889, %f1751, %f888;
	cvt.f64.f32 	%fd58, %f889;
	min.f32 	%f161, %f1750, %f888;
	fma.rn.f32 	%f1731, %f161, %f126, %f1731;
	mul.f32 	%f890, %f161, %f127;
	cvt.f64.f32 	%fd59, %f890;
	cvt.f64.f32 	%fd60, %f126;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd60;
	}
	abs.f64 	%fd61, %fd60;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd61;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd306;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd353, [retval0+0];
	} // callseq 4
	setp.eq.s32 	%p194, %r471, 1062207488;
	@%p194 bra 	$L__BB0_162;
	bra.uni 	$L__BB0_128;

$L__BB0_162:
	setp.gt.s32 	%p240, %r70, -1;
	@%p240 bra 	$L__BB0_164;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r326}, %fd353;
	}
	xor.b32  	%r327, %r326, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r328, %temp}, %fd353;
	}
	mov.b64 	%fd353, {%r328, %r327};

$L__BB0_164:
	setp.eq.f32 	%p241, %f126, 0f00000000;
	@%p241 bra 	$L__BB0_168;
	bra.uni 	$L__BB0_165;

$L__BB0_168:
	setp.lt.s32 	%p244, %r62, 0;
	mov.u32 	%r329, 0;
	or.b32  	%r330, %r70, 2146435072;
	selp.b32 	%r331, %r330, %r70, %p244;
	mov.b64 	%fd353, {%r329, %r331};
	bra.uni 	$L__BB0_169;

$L__BB0_128:
	setp.eq.f32 	%p195, %f126, 0f00000000;
	@%p195 bra 	$L__BB0_132;
	bra.uni 	$L__BB0_129;

$L__BB0_132:
	shr.s32 	%r501, %r62, 31;
	and.b32  	%r500, %r501, 2146435072;
	mov.u32 	%r290, 0;
	mov.b64 	%fd353, {%r290, %r500};
	bra.uni 	$L__BB0_133;

$L__BB0_165:
	@%p240 bra 	$L__BB0_169;

	cvt.rzi.f64.f64 	%fd277, %fd223;
	setp.eq.f64 	%p243, %fd277, 0d4000000000000000;
	@%p243 bra 	$L__BB0_169;

	mov.f64 	%fd353, 0dFFF8000000000000;

$L__BB0_169:
	add.f64 	%fd95, %fd60, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r332}, %fd95;
	}
	and.b32  	%r333, %r332, 2146435072;
	setp.ne.s32 	%p245, %r333, 2146435072;
	mov.f64 	%fd361, %fd353;
	@%p245 bra 	$L__BB0_175;

	setp.gtu.f64 	%p246, %fd61, 0d7FF0000000000000;
	mov.f64 	%fd361, %fd95;
	@%p246 bra 	$L__BB0_175;

	setp.eq.s32 	%p247, %r64, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r334, %temp}, %fd223;
	}
	setp.eq.s32 	%p248, %r334, 0;
	and.pred  	%p249, %p247, %p248;
	@%p249 bra 	$L__BB0_174;
	bra.uni 	$L__BB0_172;

$L__BB0_174:
	setp.lt.s32 	%p256, %r62, 0;
	mov.u32 	%r339, 0;
	setp.gt.f64 	%p257, %fd61, 0d3FF0000000000000;
	selp.b32 	%r340, 2146435072, 0, %p257;
	xor.b32  	%r341, %r340, 2146435072;
	selp.b32 	%r342, %r341, %r340, %p256;
	setp.eq.f32 	%p258, %f126, 0fBF800000;
	selp.b32 	%r343, 1072693248, %r342, %p258;
	mov.b64 	%fd361, {%r339, %r343};
	bra.uni 	$L__BB0_175;

$L__BB0_129:
	setp.gt.s32 	%p196, %r70, -1;
	@%p196 bra 	$L__BB0_133;

	cvt.rzi.f64.f64 	%fd247, %fd223;
	setp.eq.f64 	%p197, %fd247, 0d4000000000000000;
	@%p197 bra 	$L__BB0_133;

	mov.f64 	%fd353, 0dFFF8000000000000;

$L__BB0_133:
	add.f64 	%fd65, %fd60, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r291}, %fd65;
	}
	and.b32  	%r292, %r291, 2146435072;
	setp.ne.s32 	%p198, %r292, 2146435072;
	mov.f64 	%fd354, %fd353;
	@%p198 bra 	$L__BB0_139;

	setp.gtu.f64 	%p199, %fd61, 0d7FF0000000000000;
	mov.f64 	%fd354, %fd65;
	@%p199 bra 	$L__BB0_139;

	setp.eq.s32 	%p200, %r64, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r293, %temp}, %fd223;
	}
	setp.eq.s32 	%p201, %r293, 0;
	and.pred  	%p202, %p200, %p201;
	@%p202 bra 	$L__BB0_138;
	bra.uni 	$L__BB0_136;

$L__BB0_138:
	setp.lt.s32 	%p206, %r62, 0;
	mov.u32 	%r297, 0;
	setp.gt.f64 	%p207, %fd61, 0d3FF0000000000000;
	selp.b32 	%r298, 2146435072, 0, %p207;
	xor.b32  	%r299, %r298, 2146435072;
	selp.b32 	%r300, %r299, %r298, %p206;
	setp.eq.f32 	%p208, %f126, 0fBF800000;
	selp.b32 	%r301, 1072693248, %r300, %p208;
	mov.b64 	%fd354, {%r297, %r301};
	bra.uni 	$L__BB0_139;

$L__BB0_172:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r335, %temp}, %fd60;
	}
	and.b32  	%r336, %r70, 2147483647;
	setp.ne.s32 	%p250, %r336, 2146435072;
	setp.ne.s32 	%p251, %r335, 0;
	or.pred  	%p252, %p250, %p251;
	mov.f64 	%fd361, %fd353;
	@%p252 bra 	$L__BB0_175;

	setp.lt.s32 	%p253, %r70, 0;
	mov.u32 	%r337, 0;
	setp.ne.s32 	%p254, %r64, 1071644672;
	and.pred  	%p255, %p254, %p253;
	selp.b32 	%r338, %r66, %r65, %p255;
	mov.b64 	%fd361, {%r337, %r338};

$L__BB0_175:
	setp.eq.f32 	%p259, %f126, 0f3F800000;
	selp.f64 	%fd280, 0d3FF0000000000000, %fd361, %p259;
	mul.f64 	%fd281, %fd280, %fd58;
	sub.f64 	%fd282, %fd59, %fd281;
	cvt.f64.f32 	%fd283, %f1735;
	add.f64 	%fd371, %fd282, %fd283;
	cvt.f64.f32 	%fd100, %f154;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd100;
	}
	abs.f64 	%fd101, %fd100;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd101;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd223;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd363, [retval0+0];
	} // callseq 7
	setp.gt.s32 	%p260, %r73, -1;
	@%p260 bra 	$L__BB0_177;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r344}, %fd363;
	}
	xor.b32  	%r345, %r344, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r346, %temp}, %fd363;
	}
	mov.b64 	%fd363, {%r346, %r345};

$L__BB0_177:
	setp.eq.f32 	%p261, %f154, 0f00000000;
	@%p261 bra 	$L__BB0_181;
	bra.uni 	$L__BB0_178;

$L__BB0_181:
	setp.lt.s32 	%p264, %r62, 0;
	mov.u32 	%r347, 0;
	or.b32  	%r348, %r73, 2146435072;
	selp.b32 	%r349, %r348, %r73, %p264;
	mov.b64 	%fd363, {%r347, %r349};
	bra.uni 	$L__BB0_182;

$L__BB0_178:
	@%p260 bra 	$L__BB0_182;

	cvt.rzi.f64.f64 	%fd286, %fd223;
	setp.eq.f64 	%p263, %fd286, 0d4000000000000000;
	@%p263 bra 	$L__BB0_182;

	mov.f64 	%fd363, 0dFFF8000000000000;

$L__BB0_182:
	add.f64 	%fd107, %fd100, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r350}, %fd107;
	}
	and.b32  	%r351, %r350, 2146435072;
	setp.ne.s32 	%p265, %r351, 2146435072;
	mov.f64 	%fd364, %fd363;
	@%p265 bra 	$L__BB0_188;

	setp.gtu.f64 	%p266, %fd101, 0d7FF0000000000000;
	mov.f64 	%fd364, %fd107;
	@%p266 bra 	$L__BB0_188;

	setp.eq.s32 	%p267, %r64, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r352, %temp}, %fd223;
	}
	setp.eq.s32 	%p268, %r352, 0;
	and.pred  	%p269, %p267, %p268;
	@%p269 bra 	$L__BB0_187;
	bra.uni 	$L__BB0_185;

$L__BB0_187:
	setp.lt.s32 	%p276, %r62, 0;
	mov.u32 	%r357, 0;
	setp.gt.f64 	%p277, %fd101, 0d3FF0000000000000;
	selp.b32 	%r358, 2146435072, 0, %p277;
	xor.b32  	%r359, %r358, 2146435072;
	selp.b32 	%r360, %r359, %r358, %p276;
	setp.eq.f32 	%p278, %f154, 0fBF800000;
	selp.b32 	%r361, 1072693248, %r360, %p278;
	mov.b64 	%fd364, {%r357, %r361};
	bra.uni 	$L__BB0_188;

$L__BB0_136:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r294, %temp}, %fd60;
	}
	and.b32  	%r295, %r70, 2147483647;
	setp.ne.s32 	%p203, %r295, 2146435072;
	setp.ne.s32 	%p204, %r294, 0;
	or.pred  	%p205, %p203, %p204;
	mov.f64 	%fd354, %fd353;
	@%p205 bra 	$L__BB0_139;

	mov.u32 	%r296, 0;
	mov.b64 	%fd354, {%r296, %r65};

$L__BB0_139:
	setp.eq.f32 	%p209, %f126, 0f3F800000;
	selp.f64 	%fd250, 0d3FF0000000000000, %fd354, %p209;
	mul.f64 	%fd251, %fd250, %fd58;
	sub.f64 	%fd252, %fd59, %fd251;
	cvt.f64.f32 	%fd253, %f1735;
	add.f64 	%fd371, %fd252, %fd253;
	cvt.f64.f32 	%fd70, %f154;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r71}, %fd70;
	}
	abs.f64 	%fd71, %fd70;
	setp.eq.f32 	%p210, %f154, 0f00000000;
	@%p210 bra 	$L__BB0_143;
	bra.uni 	$L__BB0_140;

$L__BB0_143:
	shr.s32 	%r499, %r62, 31;
	and.b32  	%r498, %r499, 2146435072;
	mov.u32 	%r302, 0;
	mov.b64 	%fd355, {%r302, %r498};
	bra.uni 	$L__BB0_144;

$L__BB0_140:
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd223;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd355, [retval0+0];
	} // callseq 5
	setp.gt.s32 	%p211, %r71, -1;
	@%p211 bra 	$L__BB0_144;

	cvt.rzi.f64.f64 	%fd256, %fd223;
	setp.eq.f64 	%p212, %fd256, 0d4000000000000000;
	@%p212 bra 	$L__BB0_144;

	mov.f64 	%fd355, 0dFFF8000000000000;

$L__BB0_144:
	add.f64 	%fd75, %fd70, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r303}, %fd75;
	}
	and.b32  	%r304, %r303, 2146435072;
	setp.ne.s32 	%p213, %r304, 2146435072;
	mov.f64 	%fd356, %fd355;
	@%p213 bra 	$L__BB0_150;

	setp.gtu.f64 	%p214, %fd71, 0d7FF0000000000000;
	mov.f64 	%fd356, %fd75;
	@%p214 bra 	$L__BB0_150;

	setp.eq.s32 	%p215, %r64, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r305, %temp}, %fd223;
	}
	setp.eq.s32 	%p216, %r305, 0;
	and.pred  	%p217, %p215, %p216;
	@%p217 bra 	$L__BB0_149;
	bra.uni 	$L__BB0_147;

$L__BB0_149:
	setp.lt.s32 	%p221, %r62, 0;
	mov.u32 	%r309, 0;
	setp.gt.f64 	%p222, %fd71, 0d3FF0000000000000;
	selp.b32 	%r310, 2146435072, 0, %p222;
	xor.b32  	%r311, %r310, 2146435072;
	selp.b32 	%r312, %r311, %r310, %p221;
	setp.eq.f32 	%p223, %f154, 0fBF800000;
	selp.b32 	%r313, 1072693248, %r312, %p223;
	mov.b64 	%fd356, {%r309, %r313};
	bra.uni 	$L__BB0_150;

$L__BB0_185:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r353, %temp}, %fd100;
	}
	and.b32  	%r354, %r73, 2147483647;
	setp.ne.s32 	%p270, %r354, 2146435072;
	setp.ne.s32 	%p271, %r353, 0;
	or.pred  	%p272, %p270, %p271;
	mov.f64 	%fd364, %fd363;
	@%p272 bra 	$L__BB0_188;

	setp.lt.s32 	%p273, %r73, 0;
	mov.u32 	%r355, 0;
	setp.ne.s32 	%p274, %r64, 1071644672;
	and.pred  	%p275, %p274, %p273;
	selp.b32 	%r356, %r66, %r65, %p275;
	mov.b64 	%fd364, {%r355, %r356};

$L__BB0_188:
	setp.eq.f32 	%p279, %f154, 0f3F800000;
	selp.f64 	%fd289, 0d3FF0000000000000, %fd364, %p279;
	mul.f64 	%fd290, %fd289, %fd58;
	mul.f32 	%f893, %f161, %f155;
	cvt.f64.f32 	%fd291, %f893;
	sub.f64 	%fd292, %fd291, %fd290;
	cvt.f64.f32 	%fd293, %f1734;
	add.f64 	%fd370, %fd292, %fd293;
	cvt.f64.f32 	%fd112, %f156;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd112;
	}
	abs.f64 	%fd113, %fd112;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd113;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd223;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd366, [retval0+0];
	} // callseq 8
	setp.gt.s32 	%p280, %r74, -1;
	@%p280 bra 	$L__BB0_190;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r362}, %fd366;
	}
	xor.b32  	%r363, %r362, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r364, %temp}, %fd366;
	}
	mov.b64 	%fd366, {%r364, %r363};

$L__BB0_190:
	setp.eq.f32 	%p281, %f156, 0f00000000;
	@%p281 bra 	$L__BB0_194;
	bra.uni 	$L__BB0_191;

$L__BB0_194:
	setp.lt.s32 	%p284, %r62, 0;
	mov.u32 	%r365, 0;
	or.b32  	%r366, %r74, 2146435072;
	selp.b32 	%r367, %r366, %r74, %p284;
	mov.b64 	%fd366, {%r365, %r367};
	bra.uni 	$L__BB0_195;

$L__BB0_191:
	@%p280 bra 	$L__BB0_195;

	cvt.rzi.f64.f64 	%fd296, %fd223;
	setp.eq.f64 	%p283, %fd296, 0d4000000000000000;
	@%p283 bra 	$L__BB0_195;

	mov.f64 	%fd366, 0dFFF8000000000000;

$L__BB0_195:
	add.f64 	%fd119, %fd112, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r368}, %fd119;
	}
	and.b32  	%r369, %r368, 2146435072;
	setp.ne.s32 	%p285, %r369, 2146435072;
	mov.f64 	%fd367, %fd366;
	@%p285 bra 	$L__BB0_201;

	setp.gtu.f64 	%p286, %fd113, 0d7FF0000000000000;
	mov.f64 	%fd367, %fd119;
	@%p286 bra 	$L__BB0_201;

	setp.eq.s32 	%p287, %r64, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r370, %temp}, %fd223;
	}
	setp.eq.s32 	%p288, %r370, 0;
	and.pred  	%p289, %p287, %p288;
	@%p289 bra 	$L__BB0_200;
	bra.uni 	$L__BB0_198;

$L__BB0_200:
	setp.lt.s32 	%p296, %r62, 0;
	mov.u32 	%r375, 0;
	setp.gt.f64 	%p297, %fd113, 0d3FF0000000000000;
	selp.b32 	%r376, 2146435072, 0, %p297;
	xor.b32  	%r377, %r376, 2146435072;
	selp.b32 	%r378, %r377, %r376, %p296;
	setp.eq.f32 	%p298, %f156, 0fBF800000;
	selp.b32 	%r379, 1072693248, %r378, %p298;
	mov.b64 	%fd367, {%r375, %r379};
	bra.uni 	$L__BB0_201;

$L__BB0_147:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r306, %temp}, %fd70;
	}
	and.b32  	%r307, %r71, 2147483647;
	setp.ne.s32 	%p218, %r307, 2146435072;
	setp.ne.s32 	%p219, %r306, 0;
	or.pred  	%p220, %p218, %p219;
	mov.f64 	%fd356, %fd355;
	@%p220 bra 	$L__BB0_150;

	mov.u32 	%r308, 0;
	mov.b64 	%fd356, {%r308, %r65};

$L__BB0_150:
	setp.eq.f32 	%p224, %f154, 0f3F800000;
	selp.f64 	%fd259, 0d3FF0000000000000, %fd356, %p224;
	mul.f64 	%fd260, %fd259, %fd58;
	mul.f32 	%f891, %f161, %f155;
	cvt.f64.f32 	%fd261, %f891;
	sub.f64 	%fd262, %fd261, %fd260;
	cvt.f64.f32 	%fd263, %f1734;
	add.f64 	%fd370, %fd262, %fd263;
	cvt.f64.f32 	%fd80, %f156;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r72}, %fd80;
	}
	abs.f64 	%fd81, %fd80;
	setp.eq.f32 	%p225, %f156, 0f00000000;
	@%p225 bra 	$L__BB0_154;
	bra.uni 	$L__BB0_151;

$L__BB0_154:
	shr.s32 	%r497, %r62, 31;
	and.b32  	%r496, %r497, 2146435072;
	mov.u32 	%r314, 0;
	mov.b64 	%fd357, {%r314, %r496};
	bra.uni 	$L__BB0_155;

$L__BB0_151:
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd81;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd223;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd357, [retval0+0];
	} // callseq 6
	setp.gt.s32 	%p226, %r72, -1;
	@%p226 bra 	$L__BB0_155;

	cvt.rzi.f64.f64 	%fd266, %fd223;
	setp.eq.f64 	%p227, %fd266, 0d4000000000000000;
	@%p227 bra 	$L__BB0_155;

	mov.f64 	%fd357, 0dFFF8000000000000;

$L__BB0_155:
	add.f64 	%fd85, %fd80, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r315}, %fd85;
	}
	and.b32  	%r316, %r315, 2146435072;
	setp.ne.s32 	%p228, %r316, 2146435072;
	mov.f64 	%fd358, %fd357;
	@%p228 bra 	$L__BB0_161;

	setp.gtu.f64 	%p229, %fd81, 0d7FF0000000000000;
	mov.f64 	%fd358, %fd85;
	@%p229 bra 	$L__BB0_161;

	setp.eq.s32 	%p230, %r64, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r317, %temp}, %fd223;
	}
	setp.eq.s32 	%p231, %r317, 0;
	and.pred  	%p232, %p230, %p231;
	@%p232 bra 	$L__BB0_160;
	bra.uni 	$L__BB0_158;

$L__BB0_160:
	setp.lt.s32 	%p236, %r62, 0;
	mov.u32 	%r321, 0;
	setp.gt.f64 	%p237, %fd81, 0d3FF0000000000000;
	selp.b32 	%r322, 2146435072, 0, %p237;
	xor.b32  	%r323, %r322, 2146435072;
	selp.b32 	%r324, %r323, %r322, %p236;
	setp.eq.f32 	%p238, %f156, 0fBF800000;
	selp.b32 	%r325, 1072693248, %r324, %p238;
	mov.b64 	%fd358, {%r321, %r325};
	bra.uni 	$L__BB0_161;

$L__BB0_198:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r371, %temp}, %fd112;
	}
	and.b32  	%r372, %r74, 2147483647;
	setp.ne.s32 	%p290, %r372, 2146435072;
	setp.ne.s32 	%p291, %r371, 0;
	or.pred  	%p292, %p290, %p291;
	mov.f64 	%fd367, %fd366;
	@%p292 bra 	$L__BB0_201;

	setp.lt.s32 	%p293, %r74, 0;
	mov.u32 	%r373, 0;
	setp.ne.s32 	%p294, %r64, 1071644672;
	and.pred  	%p295, %p294, %p293;
	selp.b32 	%r374, %r66, %r65, %p295;
	mov.b64 	%fd367, {%r373, %r374};

$L__BB0_201:
	mul.f32 	%f894, %f161, 0f00000000;
	cvt.f64.f32 	%fd299, %f894;
	setp.eq.f32 	%p299, %f156, 0f3F800000;
	selp.f64 	%fd300, 0d3FF0000000000000, %fd367, %p299;
	mul.f64 	%fd301, %fd300, %fd58;
	sub.f64 	%fd302, %fd299, %fd301;
	cvt.f64.f32 	%fd303, %f1733;
	add.f64 	%fd369, %fd302, %fd303;
	cvt.f64.f32 	%fd304, %f1732;
	sub.f64 	%fd305, %fd299, %fd58;
	add.f64 	%fd368, %fd305, %fd304;
	bra.uni 	$L__BB0_202;

$L__BB0_158:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r318, %temp}, %fd80;
	}
	and.b32  	%r319, %r72, 2147483647;
	setp.ne.s32 	%p233, %r319, 2146435072;
	setp.ne.s32 	%p234, %r318, 0;
	or.pred  	%p235, %p233, %p234;
	mov.f64 	%fd358, %fd357;
	@%p235 bra 	$L__BB0_161;

	mov.u32 	%r320, 0;
	mov.b64 	%fd358, {%r320, %r65};

$L__BB0_161:
	mul.f32 	%f892, %f161, 0f00000000;
	cvt.f64.f32 	%fd269, %f892;
	setp.eq.f32 	%p239, %f156, 0f3F800000;
	selp.f64 	%fd270, 0d3FF0000000000000, %fd358, %p239;
	mul.f64 	%fd271, %fd270, %fd58;
	sub.f64 	%fd272, %fd269, %fd271;
	cvt.f64.f32 	%fd273, %f1733;
	add.f64 	%fd369, %fd272, %fd273;
	cvt.f64.f32 	%fd274, %f1732;
	sub.f64 	%fd275, %fd269, %fd58;
	add.f64 	%fd368, %fd275, %fd274;

$L__BB0_202:
	cvt.rn.f32.f64 	%f1735, %fd371;
	cvt.rn.f32.f64 	%f1734, %fd370;
	cvt.rn.f32.f64 	%f1733, %fd369;
	cvt.rn.f32.f64 	%f1732, %fd368;
	fma.rn.f32 	%f1730, %f161, %f154, %f1730;
	fma.rn.f32 	%f1729, %f161, %f156, %f1729;
	add.f32 	%f1728, %f1728, %f161;
	add.s32 	%r536, %r536, 1;
	setp.lt.s32 	%p300, %r536, %r86;
	@%p300 bra 	$L__BB0_56;

	add.s32 	%r535, %r535, 1;
	setp.lt.s32 	%p301, %r535, %r86;
	@%p301 bra 	$L__BB0_55;

$L__BB0_204:
	ld.param.u32 	%r473, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_3];
	div.rn.f32 	%f895, %f1731, %f1735;
	mov.f32 	%f896, 0fBF800000;
	max.f32 	%f897, %f895, %f896;
	mov.f32 	%f898, 0f3F800000;
	min.f32 	%f899, %f897, %f898;
	sub.f32 	%f1763, %f1763, %f899;
	div.rn.f32 	%f900, %f1730, %f1734;
	max.f32 	%f901, %f900, %f896;
	min.f32 	%f902, %f901, %f898;
	sub.f32 	%f1762, %f1762, %f902;
	neg.f32 	%f903, %f1761;
	div.rn.f32 	%f904, %f1729, %f1733;
	max.f32 	%f905, %f904, %f903;
	min.f32 	%f906, %f905, %f1761;
	sub.f32 	%f907, %f1761, %f906;
	neg.f32 	%f908, %f1760;
	div.rn.f32 	%f909, %f1728, %f1732;
	max.f32 	%f910, %f909, %f908;
	min.f32 	%f911, %f910, %f1760;
	sub.f32 	%f912, %f1760, %f911;
	max.f32 	%f1761, %f907, %f898;
	mov.f32 	%f913, 0f3C23D70A;
	max.f32 	%f1760, %f912, %f913;
	add.s32 	%r534, %r534, 1;
	setp.lt.s32 	%p302, %r534, %r473;
	@%p302 bra 	$L__BB0_53;

$L__BB0_205:
	mov.f32 	%f924, 0f00000000;
	mov.f32 	%f1775, %f924;
	mov.f32 	%f1776, %f924;
	mov.f32 	%f1777, %f924;
	mov.f32 	%f1780, %f924;
	mov.f32 	%f1778, %f924;
	mov.f32 	%f1779, %f924;
	mov.f32 	%f1781, %f924;
	mov.f32 	%f1782, %f924;
	mov.f32 	%f1783, %f924;
	mov.f32 	%f1784, %f924;
	mov.f32 	%f1802, %f924;
	@%p20 bra 	$L__BB0_260;

	div.rn.f32 	%f936, %f1761, 0fC0206C98;
	div.rn.f32 	%f186, %f936, %f317;
	sqrt.rn.f32 	%f187, %f34;
	mov.f32 	%f937, 0f3F800000;
	cvt.rzi.f32.f32 	%f938, %f937;
	add.f32 	%f939, %f938, %f938;
	mov.f32 	%f940, 0f40000000;
	sub.f32 	%f941, %f940, %f939;
	abs.f32 	%f188, %f941;
	mov.u32 	%r380, 0;
	setp.eq.f32 	%p311, %f188, 0f3F800000;
	mov.u32 	%r537, %r380;

$L__BB0_207:
	cvt.rn.f32.s32 	%f942, %r537;
	sub.f32 	%f943, %f942, %f1763;
	add.f32 	%f944, %f943, 0f3F000000;
	mul.f32 	%f945, %f187, %f944;
	abs.f32 	%f200, %f945;
	setp.ge.f32 	%p304, %f200, 0f3F8060FE;
	mul.f32 	%f946, %f945, %f945;
	selp.f32 	%f947, %f200, %f946, %p304;
	selp.f32 	%f948, 0f3789CA3C, 0f38B1E96A, %p304;
	selp.f32 	%f949, 0fB9F560B9, 0fBA574D20, %p304;
	fma.rn.f32 	%f950, %f948, %f947, %f949;
	selp.f32 	%f951, 0f3BAC840B, 0f3BAAD5EA, %p304;
	fma.rn.f32 	%f952, %f950, %f947, %f951;
	selp.f32 	%f953, 0fBD0C8162, 0fBCDC1BE7, %p304;
	fma.rn.f32 	%f954, %f952, %f947, %f953;
	selp.f32 	%f955, 0f3E1CF906, 0f3DE718AF, %p304;
	fma.rn.f32 	%f956, %f954, %f947, %f955;
	selp.f32 	%f957, 0f3F6A937E, 0fBEC093AC, %p304;
	fma.rn.f32 	%f958, %f956, %f947, %f957;
	selp.f32 	%f959, 0f3F20D842, 0f3E0375D3, %p304;
	fma.rn.f32 	%f960, %f958, %f947, %f959;
	neg.f32 	%f961, %f200;
	selp.f32 	%f962, %f961, %f945, %p304;
	fma.rn.f32 	%f201, %f960, %f962, %f962;
	mov.b32 	%r382, %f945;
	and.b32  	%r79, %r382, -2147483648;
	add.f32 	%f963, %f943, 0fBF000000;
	mul.f32 	%f964, %f187, %f963;
	abs.f32 	%f202, %f964;
	setp.ge.f32 	%p305, %f202, 0f3F8060FE;
	mul.f32 	%f965, %f964, %f964;
	selp.f32 	%f966, %f202, %f965, %p305;
	selp.f32 	%f967, 0f3789CA3C, 0f38B1E96A, %p305;
	selp.f32 	%f968, 0fB9F560B9, 0fBA574D20, %p305;
	fma.rn.f32 	%f969, %f967, %f966, %f968;
	selp.f32 	%f970, 0f3BAC840B, 0f3BAAD5EA, %p305;
	fma.rn.f32 	%f971, %f969, %f966, %f970;
	selp.f32 	%f972, 0fBD0C8162, 0fBCDC1BE7, %p305;
	fma.rn.f32 	%f973, %f971, %f966, %f972;
	selp.f32 	%f974, 0f3E1CF906, 0f3DE718AF, %p305;
	fma.rn.f32 	%f975, %f973, %f966, %f974;
	selp.f32 	%f976, 0f3F6A937E, 0fBEC093AC, %p305;
	fma.rn.f32 	%f977, %f975, %f966, %f976;
	selp.f32 	%f978, 0f3F20D842, 0f3E0375D3, %p305;
	fma.rn.f32 	%f979, %f977, %f966, %f978;
	neg.f32 	%f980, %f202;
	selp.f32 	%f981, %f980, %f964, %p305;
	fma.rn.f32 	%f203, %f979, %f981, %f981;
	mov.b32 	%r383, %f964;
	and.b32  	%r80, %r383, -2147483648;
	add.f32 	%f982, %f942, 0f3F000000;
	sub.f32 	%f983, %f982, %f1763;
	div.rn.f32 	%f204, %f983, %f317;
	abs.f32 	%f205, %f204;
	setp.lt.f32 	%p306, %f205, 0f00800000;
	mul.f32 	%f984, %f205, 0f4B800000;
	selp.f32 	%f985, %f984, %f205, %p306;
	selp.f32 	%f986, 0fC3170000, 0fC2FE0000, %p306;
	mov.b32 	%r384, %f985;
	and.b32  	%r385, %r384, 8388607;
	or.b32  	%r386, %r385, 1065353216;
	mov.b32 	%f987, %r386;
	shr.u32 	%r387, %r384, 23;
	cvt.rn.f32.u32 	%f988, %r387;
	add.f32 	%f989, %f986, %f988;
	setp.gt.f32 	%p307, %f987, 0f3FB504F3;
	mul.f32 	%f990, %f987, 0f3F000000;
	add.f32 	%f991, %f989, 0f3F800000;
	selp.f32 	%f992, %f991, %f989, %p307;
	selp.f32 	%f993, %f990, %f987, %p307;
	add.f32 	%f994, %f993, 0fBF800000;
	add.f32 	%f995, %f993, 0f3F800000;
	rcp.approx.ftz.f32 	%f996, %f995;
	add.f32 	%f997, %f994, %f994;
	mul.f32 	%f999, %f997, %f996;
	mul.f32 	%f1000, %f999, %f999;
	mov.f32 	%f1001, 0f3C4CAF63;
	mov.f32 	%f1002, 0f3B18F0FE;
	fma.rn.f32 	%f1003, %f1002, %f1000, %f1001;
	mov.f32 	%f1004, 0f3DAAAABD;
	fma.rn.f32 	%f1005, %f1003, %f1000, %f1004;
	mul.rn.f32 	%f1006, %f1005, %f1000;
	mul.rn.f32 	%f1007, %f1006, %f999;
	sub.f32 	%f1008, %f994, %f999;
	add.f32 	%f1009, %f1008, %f1008;
	neg.f32 	%f1010, %f999;
	fma.rn.f32 	%f1011, %f1010, %f994, %f1009;
	mul.rn.f32 	%f1012, %f996, %f1011;
	add.f32 	%f1013, %f1007, %f999;
	sub.f32 	%f1014, %f999, %f1013;
	add.f32 	%f1015, %f1007, %f1014;
	add.f32 	%f1016, %f1012, %f1015;
	add.f32 	%f1017, %f1013, %f1016;
	sub.f32 	%f1018, %f1013, %f1017;
	add.f32 	%f1019, %f1016, %f1018;
	mov.f32 	%f1020, 0f3F317200;
	mul.rn.f32 	%f1021, %f992, %f1020;
	mov.f32 	%f1022, 0f35BFBE8E;
	mul.rn.f32 	%f1023, %f992, %f1022;
	add.f32 	%f1024, %f1021, %f1017;
	sub.f32 	%f1025, %f1021, %f1024;
	add.f32 	%f1026, %f1017, %f1025;
	add.f32 	%f1027, %f1019, %f1026;
	add.f32 	%f1028, %f1023, %f1027;
	add.f32 	%f1029, %f1024, %f1028;
	sub.f32 	%f1030, %f1024, %f1029;
	add.f32 	%f1031, %f1028, %f1030;
	mul.rn.f32 	%f1032, %f940, %f1029;
	neg.f32 	%f1033, %f1032;
	fma.rn.f32 	%f1034, %f940, %f1029, %f1033;
	fma.rn.f32 	%f1035, %f940, %f1031, %f1034;
	fma.rn.f32 	%f1037, %f924, %f1029, %f1035;
	add.rn.f32 	%f1038, %f1032, %f1037;
	neg.f32 	%f1039, %f1038;
	add.rn.f32 	%f1040, %f1032, %f1039;
	add.rn.f32 	%f1041, %f1040, %f1037;
	mov.b32 	%r388, %f1038;
	setp.eq.s32 	%p308, %r388, 1118925336;
	add.s32 	%r389, %r388, -1;
	mov.b32 	%f1042, %r389;
	add.f32 	%f1043, %f1041, 0f37000000;
	selp.f32 	%f206, %f1043, %f1041, %p308;
	selp.f32 	%f1044, %f1042, %f1038, %p308;
	mov.f32 	%f1045, 0f3FB8AA3B;
	mul.rn.f32 	%f1046, %f1044, %f1045;
	cvt.rzi.f32.f32 	%f1047, %f1046;
	abs.f32 	%f1048, %f1047;
	setp.gt.f32 	%p309, %f1048, 0f42FC0000;
	mov.b32 	%r390, %f1047;
	and.b32  	%r391, %r390, -2147483648;
	or.b32  	%r392, %r391, 1123811328;
	mov.b32 	%f1049, %r392;
	selp.f32 	%f1050, %f1049, %f1047, %p309;
	mov.f32 	%f1051, 0fBF317218;
	fma.rn.f32 	%f1052, %f1050, %f1051, %f1044;
	mov.f32 	%f1053, 0f3102E308;
	fma.rn.f32 	%f1054, %f1050, %f1053, %f1052;
	mul.f32 	%f1055, %f1054, 0f3FB8AA3B;
	add.f32 	%f1056, %f1050, 0f4B40007F;
	mov.b32 	%r393, %f1056;
	shl.b32 	%r394, %r393, 23;
	mov.b32 	%f1057, %r394;
	ex2.approx.ftz.f32 	%f1058, %f1055;
	mul.f32 	%f207, %f1058, %f1057;
	setp.lt.f32 	%p310, %f204, 0f00000000;
	and.pred  	%p13, %p310, %p311;
	add.f32 	%f1059, %f204, %f204;
	selp.f32 	%f208, %f1059, 0f00000000, %p311;
	add.f32 	%f1060, %f205, 0f40000000;
	mov.b32 	%r81, %f1060;
	div.rn.f32 	%f209, %f963, %f317;
	abs.f32 	%f210, %f209;
	setp.lt.f32 	%p312, %f210, 0f00800000;
	mul.f32 	%f1061, %f210, 0f4B800000;
	selp.f32 	%f1062, %f1061, %f210, %p312;
	selp.f32 	%f1063, 0fC3170000, 0fC2FE0000, %p312;
	mov.b32 	%r395, %f1062;
	and.b32  	%r396, %r395, 8388607;
	or.b32  	%r397, %r396, 1065353216;
	mov.b32 	%f1064, %r397;
	shr.u32 	%r398, %r395, 23;
	cvt.rn.f32.u32 	%f1065, %r398;
	add.f32 	%f1066, %f1063, %f1065;
	setp.gt.f32 	%p313, %f1064, 0f3FB504F3;
	mul.f32 	%f1067, %f1064, 0f3F000000;
	add.f32 	%f1068, %f1066, 0f3F800000;
	selp.f32 	%f1069, %f1068, %f1066, %p313;
	selp.f32 	%f1070, %f1067, %f1064, %p313;
	add.f32 	%f1071, %f1070, 0fBF800000;
	add.f32 	%f1072, %f1070, 0f3F800000;
	rcp.approx.ftz.f32 	%f1073, %f1072;
	add.f32 	%f1074, %f1071, %f1071;
	mul.f32 	%f1075, %f1074, %f1073;
	mul.f32 	%f1076, %f1075, %f1075;
	fma.rn.f32 	%f1077, %f1002, %f1076, %f1001;
	fma.rn.f32 	%f1078, %f1077, %f1076, %f1004;
	mul.rn.f32 	%f1079, %f1078, %f1076;
	mul.rn.f32 	%f1080, %f1079, %f1075;
	sub.f32 	%f1081, %f1071, %f1075;
	add.f32 	%f1082, %f1081, %f1081;
	neg.f32 	%f1083, %f1075;
	fma.rn.f32 	%f1084, %f1083, %f1071, %f1082;
	mul.rn.f32 	%f1085, %f1073, %f1084;
	add.f32 	%f1086, %f1080, %f1075;
	sub.f32 	%f1087, %f1075, %f1086;
	add.f32 	%f1088, %f1080, %f1087;
	add.f32 	%f1089, %f1085, %f1088;
	add.f32 	%f1090, %f1086, %f1089;
	sub.f32 	%f1091, %f1086, %f1090;
	add.f32 	%f1092, %f1089, %f1091;
	mul.rn.f32 	%f1093, %f1069, %f1020;
	mul.rn.f32 	%f1094, %f1069, %f1022;
	add.f32 	%f1095, %f1093, %f1090;
	sub.f32 	%f1096, %f1093, %f1095;
	add.f32 	%f1097, %f1090, %f1096;
	add.f32 	%f1098, %f1092, %f1097;
	add.f32 	%f1099, %f1094, %f1098;
	add.f32 	%f1100, %f1095, %f1099;
	sub.f32 	%f1101, %f1095, %f1100;
	add.f32 	%f1102, %f1099, %f1101;
	mul.rn.f32 	%f1103, %f940, %f1100;
	neg.f32 	%f1104, %f1103;
	fma.rn.f32 	%f1105, %f940, %f1100, %f1104;
	fma.rn.f32 	%f1106, %f940, %f1102, %f1105;
	fma.rn.f32 	%f1107, %f924, %f1100, %f1106;
	add.rn.f32 	%f1108, %f1103, %f1107;
	neg.f32 	%f1109, %f1108;
	add.rn.f32 	%f1110, %f1103, %f1109;
	add.rn.f32 	%f1111, %f1110, %f1107;
	mov.b32 	%r399, %f1108;
	setp.eq.s32 	%p314, %r399, 1118925336;
	add.s32 	%r400, %r399, -1;
	mov.b32 	%f1112, %r400;
	add.f32 	%f1113, %f1111, 0f37000000;
	selp.f32 	%f211, %f1113, %f1111, %p314;
	selp.f32 	%f1114, %f1112, %f1108, %p314;
	mul.rn.f32 	%f1115, %f1114, %f1045;
	cvt.rzi.f32.f32 	%f1116, %f1115;
	abs.f32 	%f1117, %f1116;
	setp.gt.f32 	%p315, %f1117, 0f42FC0000;
	mov.b32 	%r401, %f1116;
	and.b32  	%r402, %r401, -2147483648;
	or.b32  	%r403, %r402, 1123811328;
	mov.b32 	%f1118, %r403;
	selp.f32 	%f1119, %f1118, %f1116, %p315;
	fma.rn.f32 	%f1120, %f1119, %f1051, %f1114;
	fma.rn.f32 	%f1121, %f1119, %f1053, %f1120;
	mul.f32 	%f1122, %f1121, 0f3FB8AA3B;
	add.f32 	%f1123, %f1119, 0f4B40007F;
	mov.b32 	%r404, %f1123;
	shl.b32 	%r405, %r404, 23;
	mov.b32 	%f1124, %r405;
	ex2.approx.ftz.f32 	%f1125, %f1122;
	mul.f32 	%f212, %f1125, %f1124;
	add.f32 	%f213, %f204, 0f40000000;
	setp.lt.f32 	%p316, %f209, 0f00000000;
	and.pred  	%p14, %p316, %p311;
	selp.f32 	%f214, 0fFF800000, 0f7F800000, %p13;
	add.f32 	%f1126, %f209, %f209;
	selp.f32 	%f215, %f1126, 0f00000000, %p311;
	add.f32 	%f1127, %f210, 0f40000000;
	mov.b32 	%r82, %f1127;
	add.f32 	%f216, %f209, 0f40000000;
	selp.f32 	%f217, 0fFF800000, 0f7F800000, %p14;
	setp.geu.f32 	%p15, %f204, 0f00000000;
	setp.geu.f32 	%p16, %f209, 0f00000000;
	mov.u32 	%r538, %r380;

$L__BB0_208:
	setp.ltu.f32 	%p317, %f200, 0f3F8060FE;
	mov.f32 	%f1786, %f201;
	@%p317 bra 	$L__BB0_210;

	ex2.approx.ftz.f32 	%f1128, %f201;
	sub.f32 	%f1130, %f937, %f1128;
	mov.b32 	%r406, %f1130;
	or.b32  	%r407, %r79, %r406;
	mov.b32 	%f1786, %r407;

$L__BB0_210:
	setp.ltu.f32 	%p318, %f202, 0f3F8060FE;
	mov.f32 	%f1787, %f203;
	@%p318 bra 	$L__BB0_212;

	ex2.approx.ftz.f32 	%f1131, %f203;
	sub.f32 	%f1133, %f937, %f1131;
	mov.b32 	%r408, %f1133;
	or.b32  	%r409, %r80, %r408;
	mov.b32 	%f1787, %r409;

$L__BB0_212:
	sub.f32 	%f1134, %f1786, %f1787;
	mul.f32 	%f233, %f1134, 0f3F000000;
	cvt.rn.f32.s32 	%f234, %r538;
	sub.f32 	%f235, %f234, %f1762;
	add.f32 	%f1135, %f235, 0f3F000000;
	mul.f32 	%f236, %f187, %f1135;
	abs.f32 	%f1136, %f236;
	setp.ltu.f32 	%p319, %f1136, 0f3F8060FE;
	setp.ge.f32 	%p320, %f1136, 0f3F8060FE;
	mul.f32 	%f1137, %f236, %f236;
	selp.f32 	%f1138, %f1136, %f1137, %p320;
	selp.f32 	%f1139, 0f3789CA3C, 0f38B1E96A, %p320;
	selp.f32 	%f1140, 0fB9F560B9, 0fBA574D20, %p320;
	fma.rn.f32 	%f1141, %f1139, %f1138, %f1140;
	selp.f32 	%f1142, 0f3BAC840B, 0f3BAAD5EA, %p320;
	fma.rn.f32 	%f1143, %f1141, %f1138, %f1142;
	selp.f32 	%f1144, 0fBD0C8162, 0fBCDC1BE7, %p320;
	fma.rn.f32 	%f1145, %f1143, %f1138, %f1144;
	selp.f32 	%f1146, 0f3E1CF906, 0f3DE718AF, %p320;
	fma.rn.f32 	%f1147, %f1145, %f1138, %f1146;
	selp.f32 	%f1148, 0f3F6A937E, 0fBEC093AC, %p320;
	fma.rn.f32 	%f1149, %f1147, %f1138, %f1148;
	selp.f32 	%f1150, 0f3F20D842, 0f3E0375D3, %p320;
	fma.rn.f32 	%f1151, %f1149, %f1138, %f1150;
	neg.f32 	%f1152, %f1136;
	selp.f32 	%f1153, %f1152, %f236, %p320;
	fma.rn.f32 	%f1788, %f1151, %f1153, %f1153;
	@%p319 bra 	$L__BB0_214;

	ex2.approx.ftz.f32 	%f1154, %f1788;
	sub.f32 	%f1156, %f937, %f1154;
	mov.b32 	%r410, %f1156;
	mov.b32 	%r411, %f236;
	and.b32  	%r412, %r411, -2147483648;
	or.b32  	%r413, %r412, %r410;
	mov.b32 	%f1788, %r413;

$L__BB0_214:
	add.f32 	%f240, %f235, 0fBF000000;
	mul.f32 	%f241, %f187, %f240;
	abs.f32 	%f1157, %f241;
	setp.ltu.f32 	%p321, %f1157, 0f3F8060FE;
	setp.ge.f32 	%p322, %f1157, 0f3F8060FE;
	mul.f32 	%f1158, %f241, %f241;
	selp.f32 	%f1159, %f1157, %f1158, %p322;
	selp.f32 	%f1160, 0f3789CA3C, 0f38B1E96A, %p322;
	selp.f32 	%f1161, 0fB9F560B9, 0fBA574D20, %p322;
	fma.rn.f32 	%f1162, %f1160, %f1159, %f1161;
	selp.f32 	%f1163, 0f3BAC840B, 0f3BAAD5EA, %p322;
	fma.rn.f32 	%f1164, %f1162, %f1159, %f1163;
	selp.f32 	%f1165, 0fBD0C8162, 0fBCDC1BE7, %p322;
	fma.rn.f32 	%f1166, %f1164, %f1159, %f1165;
	selp.f32 	%f1167, 0f3E1CF906, 0f3DE718AF, %p322;
	fma.rn.f32 	%f1168, %f1166, %f1159, %f1167;
	selp.f32 	%f1169, 0f3F6A937E, 0fBEC093AC, %p322;
	fma.rn.f32 	%f1170, %f1168, %f1159, %f1169;
	selp.f32 	%f1171, 0f3F20D842, 0f3E0375D3, %p322;
	fma.rn.f32 	%f1172, %f1170, %f1159, %f1171;
	neg.f32 	%f1173, %f1157;
	selp.f32 	%f1174, %f1173, %f241, %p322;
	fma.rn.f32 	%f1789, %f1172, %f1174, %f1174;
	@%p321 bra 	$L__BB0_216;

	ex2.approx.ftz.f32 	%f1175, %f1789;
	sub.f32 	%f1177, %f937, %f1175;
	mov.b32 	%r414, %f1177;
	mov.b32 	%r415, %f241;
	and.b32  	%r416, %r415, -2147483648;
	or.b32  	%r417, %r416, %r414;
	mov.b32 	%f1789, %r417;

$L__BB0_216:
	sub.f32 	%f1179, %f1788, %f1789;
	mul.f32 	%f245, %f1179, 0f3F000000;
	mul.f32 	%f1180, %f233, %f1761;
	fma.rn.f32 	%f246, %f245, %f1180, %f1760;
	mad.lo.s32 	%r418, %r538, %r86, %r537;
	add.s32 	%r419, %r418, %r2;
	mul.wide.s32 	%rd26, %r419, 4;
	add.s64 	%rd27, %rd1, %rd26;
	ld.global.f32 	%f247, [%rd27];
	setp.eq.f32 	%p323, %f207, 0f7F800000;
	mov.f32 	%f1790, 0f7F800000;
	@%p323 bra 	$L__BB0_218;

	fma.rn.f32 	%f1790, %f207, %f206, %f207;

$L__BB0_218:
	mov.b32 	%r420, %f1790;
	xor.b32  	%r421, %r420, -2147483648;
	mov.b32 	%f1181, %r421;
	selp.f32 	%f250, %f1181, %f1790, %p13;
	setp.eq.f32 	%p324, %f204, 0f00000000;
	selp.f32 	%f1791, %f208, %f250, %p324;
	@%p15 bra 	$L__BB0_221;

	cvt.rzi.f32.f32 	%f1183, %f940;
	setp.eq.f32 	%p325, %f1183, 0f40000000;
	mov.f32 	%f1791, %f250;
	@%p325 bra 	$L__BB0_221;

	mov.f32 	%f1791, 0f7FFFFFFF;

$L__BB0_221:
	setp.eq.f32 	%p326, %f212, 0f7F800000;
	mov.f32 	%f1792, 0f7F800000;
	@%p326 bra 	$L__BB0_223;

	fma.rn.f32 	%f1792, %f212, %f211, %f212;

$L__BB0_223:
	mov.b32 	%r422, %f1792;
	xor.b32  	%r423, %r422, -2147483648;
	mov.b32 	%f1186, %r423;
	selp.f32 	%f255, %f1186, %f1792, %p14;
	setp.eq.f32 	%p327, %f209, 0f00000000;
	selp.f32 	%f1793, %f215, %f255, %p327;
	@%p16 bra 	$L__BB0_226;

	cvt.rzi.f32.f32 	%f1188, %f940;
	setp.eq.f32 	%p328, %f1188, 0f40000000;
	mov.f32 	%f1793, %f255;
	@%p328 bra 	$L__BB0_226;

	mov.f32 	%f1793, 0f7FFFFFFF;

$L__BB0_226:
	setp.gtu.f32 	%p329, %f205, 0f7F800000;
	mov.f32 	%f1794, 0f7F800000;
	selp.f32 	%f1191, %f213, %f1791, %p329;
	setp.neu.f32 	%p330, %f205, 0f7F800000;
	selp.f32 	%f1192, %f1191, %f214, %p330;
	setp.gt.s32 	%p331, %r81, 2139095039;
	selp.f32 	%f1193, %f1192, %f1791, %p331;
	mul.f32 	%f1194, %f1193, 0fBF000000;
	setp.eq.f32 	%p332, %f204, 0f3F800000;
	selp.f32 	%f1195, 0fBF000000, %f1194, %p332;
	mov.f32 	%f1197, 0f3BBB989D;
	fma.rn.f32 	%f1198, %f1195, %f1197, %f350;
	mov.f32 	%f1200, 0f437C0000;
	cvt.sat.f32.f32 	%f1201, %f1198;
	mov.f32 	%f1202, 0f4B400001;
	fma.rm.f32 	%f1203, %f1201, %f1200, %f1202;
	setp.gtu.f32 	%p333, %f210, 0f7F800000;
	selp.f32 	%f1204, %f216, %f1793, %p333;
	setp.neu.f32 	%p334, %f210, 0f7F800000;
	selp.f32 	%f1205, %f1204, %f217, %p334;
	setp.gt.s32 	%p335, %r82, 2139095039;
	selp.f32 	%f1206, %f1205, %f1793, %p335;
	mul.f32 	%f1207, %f1206, 0fBF000000;
	setp.eq.f32 	%p336, %f209, 0f3F800000;
	selp.f32 	%f1208, 0fBF000000, %f1207, %p336;
	fma.rn.f32 	%f1209, %f1208, %f1197, %f350;
	cvt.sat.f32.f32 	%f1210, %f1209;
	fma.rm.f32 	%f1211, %f1210, %f1200, %f1202;
	add.f32 	%f1212, %f1211, 0fCB40007F;
	neg.f32 	%f1213, %f1212;
	fma.rn.f32 	%f1214, %f1208, %f1045, %f1213;
	mov.f32 	%f1215, 0f32A57060;
	fma.rn.f32 	%f1216, %f1208, %f1215, %f1214;
	mov.b32 	%r424, %f1211;
	shl.b32 	%r425, %r424, 23;
	mov.b32 	%f1217, %r425;
	ex2.approx.ftz.f32 	%f1218, %f1216;
	mul.f32 	%f1219, %f1218, %f1217;
	mov.b32 	%r426, %f1203;
	shl.b32 	%r427, %r426, 23;
	mov.b32 	%f1220, %r427;
	add.f32 	%f1221, %f1203, 0fCB40007F;
	neg.f32 	%f1222, %f1221;
	fma.rn.f32 	%f1223, %f1195, %f1045, %f1222;
	fma.rn.f32 	%f1224, %f1195, %f1215, %f1223;
	ex2.approx.ftz.f32 	%f1225, %f1224;
	mul.f32 	%f1226, %f1225, %f1220;
	sub.f32 	%f1227, %f1226, %f1219;
	mul.f32 	%f1228, %f186, %f1227;
	mul.f32 	%f258, %f245, %f1228;
	add.f32 	%f1229, %f234, 0f3F000000;
	sub.f32 	%f1230, %f1229, %f1762;
	div.rn.f32 	%f259, %f1230, %f317;
	abs.f32 	%f260, %f259;
	setp.lt.f32 	%p337, %f260, 0f00800000;
	mul.f32 	%f1231, %f260, 0f4B800000;
	selp.f32 	%f1232, %f1231, %f260, %p337;
	selp.f32 	%f1233, 0fC3170000, 0fC2FE0000, %p337;
	mov.b32 	%r428, %f1232;
	and.b32  	%r429, %r428, 8388607;
	or.b32  	%r430, %r429, 1065353216;
	mov.b32 	%f1234, %r430;
	shr.u32 	%r431, %r428, 23;
	cvt.rn.f32.u32 	%f1235, %r431;
	add.f32 	%f1236, %f1233, %f1235;
	setp.gt.f32 	%p338, %f1234, 0f3FB504F3;
	mul.f32 	%f1237, %f1234, 0f3F000000;
	add.f32 	%f1238, %f1236, 0f3F800000;
	selp.f32 	%f1239, %f1238, %f1236, %p338;
	selp.f32 	%f1240, %f1237, %f1234, %p338;
	add.f32 	%f1241, %f1240, 0fBF800000;
	add.f32 	%f1242, %f1240, 0f3F800000;
	rcp.approx.ftz.f32 	%f1243, %f1242;
	add.f32 	%f1244, %f1241, %f1241;
	mul.f32 	%f1246, %f1244, %f1243;
	mul.f32 	%f1247, %f1246, %f1246;
	fma.rn.f32 	%f1250, %f1002, %f1247, %f1001;
	fma.rn.f32 	%f1252, %f1250, %f1247, %f1004;
	mul.rn.f32 	%f1253, %f1252, %f1247;
	mul.rn.f32 	%f1254, %f1253, %f1246;
	sub.f32 	%f1255, %f1241, %f1246;
	add.f32 	%f1256, %f1255, %f1255;
	neg.f32 	%f1257, %f1246;
	fma.rn.f32 	%f1258, %f1257, %f1241, %f1256;
	mul.rn.f32 	%f1259, %f1243, %f1258;
	add.f32 	%f1260, %f1254, %f1246;
	sub.f32 	%f1261, %f1246, %f1260;
	add.f32 	%f1262, %f1254, %f1261;
	add.f32 	%f1263, %f1259, %f1262;
	add.f32 	%f1264, %f1260, %f1263;
	sub.f32 	%f1265, %f1260, %f1264;
	add.f32 	%f1266, %f1263, %f1265;
	mul.rn.f32 	%f1268, %f1239, %f1020;
	mul.rn.f32 	%f1270, %f1239, %f1022;
	add.f32 	%f1271, %f1268, %f1264;
	sub.f32 	%f1272, %f1268, %f1271;
	add.f32 	%f1273, %f1264, %f1272;
	add.f32 	%f1274, %f1266, %f1273;
	add.f32 	%f1275, %f1270, %f1274;
	add.f32 	%f1276, %f1271, %f1275;
	sub.f32 	%f1277, %f1271, %f1276;
	add.f32 	%f1278, %f1275, %f1277;
	mul.rn.f32 	%f1279, %f940, %f1276;
	neg.f32 	%f1280, %f1279;
	fma.rn.f32 	%f1281, %f940, %f1276, %f1280;
	fma.rn.f32 	%f1282, %f940, %f1278, %f1281;
	mov.f32 	%f1283, 0f00000000;
	fma.rn.f32 	%f1284, %f1283, %f1276, %f1282;
	add.rn.f32 	%f1285, %f1279, %f1284;
	neg.f32 	%f1286, %f1285;
	add.rn.f32 	%f1287, %f1279, %f1286;
	add.rn.f32 	%f1288, %f1287, %f1284;
	mov.b32 	%r432, %f1285;
	setp.eq.s32 	%p339, %r432, 1118925336;
	add.s32 	%r433, %r432, -1;
	mov.b32 	%f1289, %r433;
	add.f32 	%f1290, %f1288, 0f37000000;
	selp.f32 	%f261, %f1290, %f1288, %p339;
	selp.f32 	%f1291, %f1289, %f1285, %p339;
	mul.rn.f32 	%f1292, %f1291, %f1045;
	cvt.rzi.f32.f32 	%f1293, %f1292;
	abs.f32 	%f1294, %f1293;
	setp.gt.f32 	%p340, %f1294, 0f42FC0000;
	mov.b32 	%r434, %f1293;
	and.b32  	%r435, %r434, -2147483648;
	or.b32  	%r436, %r435, 1123811328;
	mov.b32 	%f1295, %r436;
	selp.f32 	%f1296, %f1295, %f1293, %p340;
	fma.rn.f32 	%f1298, %f1296, %f1051, %f1291;
	fma.rn.f32 	%f1300, %f1296, %f1053, %f1298;
	mul.f32 	%f1301, %f1300, 0f3FB8AA3B;
	add.f32 	%f1302, %f1296, 0f4B40007F;
	mov.b32 	%r437, %f1302;
	shl.b32 	%r438, %r437, 23;
	mov.b32 	%f1303, %r438;
	ex2.approx.ftz.f32 	%f1304, %f1301;
	mul.f32 	%f262, %f1304, %f1303;
	setp.eq.f32 	%p341, %f262, 0f7F800000;
	@%p341 bra 	$L__BB0_228;

	fma.rn.f32 	%f1794, %f262, %f261, %f262;

$L__BB0_228:
	setp.lt.f32 	%p342, %f259, 0f00000000;
	and.pred  	%p17, %p342, %p311;
	setp.eq.f32 	%p344, %f259, 0f00000000;
	@%p344 bra 	$L__BB0_232;
	bra.uni 	$L__BB0_229;

$L__BB0_232:
	add.f32 	%f1309, %f259, %f259;
	selp.f32 	%f1796, %f1309, 0f00000000, %p311;
	bra.uni 	$L__BB0_233;

$L__BB0_229:
	mov.b32 	%r439, %f1794;
	xor.b32  	%r440, %r439, -2147483648;
	mov.b32 	%f1305, %r440;
	selp.f32 	%f1796, %f1305, %f1794, %p17;
	setp.geu.f32 	%p345, %f259, 0f00000000;
	@%p345 bra 	$L__BB0_233;

	cvt.rzi.f32.f32 	%f1307, %f940;
	setp.eq.f32 	%p346, %f1307, 0f40000000;
	@%p346 bra 	$L__BB0_233;

	mov.f32 	%f1796, 0f7FFFFFFF;

$L__BB0_233:
	add.f32 	%f1310, %f260, 0f40000000;
	mov.b32 	%r441, %f1310;
	setp.lt.s32 	%p348, %r441, 2139095040;
	@%p348 bra 	$L__BB0_238;

	setp.gtu.f32 	%p349, %f260, 0f7F800000;
	@%p349 bra 	$L__BB0_237;
	bra.uni 	$L__BB0_235;

$L__BB0_237:
	add.f32 	%f1796, %f259, 0f40000000;
	bra.uni 	$L__BB0_238;

$L__BB0_235:
	setp.neu.f32 	%p350, %f260, 0f7F800000;
	@%p350 bra 	$L__BB0_238;

	selp.f32 	%f1796, 0fFF800000, 0f7F800000, %p17;

$L__BB0_238:
	mul.f32 	%f1312, %f1796, 0fBF000000;
	setp.eq.f32 	%p351, %f259, 0f3F800000;
	selp.f32 	%f1313, 0fBF000000, %f1312, %p351;
	fma.rn.f32 	%f1316, %f1313, %f1197, %f350;
	cvt.sat.f32.f32 	%f1319, %f1316;
	fma.rm.f32 	%f1321, %f1319, %f1200, %f1202;
	add.f32 	%f1322, %f1321, 0fCB40007F;
	neg.f32 	%f1323, %f1322;
	fma.rn.f32 	%f1324, %f1313, %f1045, %f1323;
	fma.rn.f32 	%f1326, %f1313, %f1215, %f1324;
	mov.b32 	%r442, %f1321;
	shl.b32 	%r443, %r442, 23;
	mov.b32 	%f1327, %r443;
	ex2.approx.ftz.f32 	%f1328, %f1326;
	mul.f32 	%f271, %f1328, %f1327;
	div.rn.f32 	%f272, %f240, %f317;
	abs.f32 	%f273, %f272;
	setp.lt.f32 	%p352, %f273, 0f00800000;
	mul.f32 	%f1329, %f273, 0f4B800000;
	selp.f32 	%f1330, %f1329, %f273, %p352;
	selp.f32 	%f1331, 0fC3170000, 0fC2FE0000, %p352;
	mov.b32 	%r444, %f1330;
	and.b32  	%r445, %r444, 8388607;
	or.b32  	%r446, %r445, 1065353216;
	mov.b32 	%f1332, %r446;
	shr.u32 	%r447, %r444, 23;
	cvt.rn.f32.u32 	%f1333, %r447;
	add.f32 	%f1334, %f1331, %f1333;
	setp.gt.f32 	%p353, %f1332, 0f3FB504F3;
	mul.f32 	%f1335, %f1332, 0f3F000000;
	add.f32 	%f1336, %f1334, 0f3F800000;
	selp.f32 	%f1337, %f1336, %f1334, %p353;
	selp.f32 	%f1338, %f1335, %f1332, %p353;
	add.f32 	%f1339, %f1338, 0fBF800000;
	add.f32 	%f1340, %f1338, 0f3F800000;
	rcp.approx.ftz.f32 	%f1341, %f1340;
	add.f32 	%f1342, %f1339, %f1339;
	mul.f32 	%f1344, %f1342, %f1341;
	mul.f32 	%f1345, %f1344, %f1344;
	fma.rn.f32 	%f1348, %f1002, %f1345, %f1001;
	fma.rn.f32 	%f1350, %f1348, %f1345, %f1004;
	mul.rn.f32 	%f1351, %f1350, %f1345;
	mul.rn.f32 	%f1352, %f1351, %f1344;
	sub.f32 	%f1353, %f1339, %f1344;
	add.f32 	%f1354, %f1353, %f1353;
	neg.f32 	%f1355, %f1344;
	fma.rn.f32 	%f1356, %f1355, %f1339, %f1354;
	mul.rn.f32 	%f1357, %f1341, %f1356;
	add.f32 	%f1358, %f1352, %f1344;
	sub.f32 	%f1359, %f1344, %f1358;
	add.f32 	%f1360, %f1352, %f1359;
	add.f32 	%f1361, %f1357, %f1360;
	add.f32 	%f1362, %f1358, %f1361;
	sub.f32 	%f1363, %f1358, %f1362;
	add.f32 	%f1364, %f1361, %f1363;
	mul.rn.f32 	%f1366, %f1337, %f1020;
	mul.rn.f32 	%f1368, %f1337, %f1022;
	add.f32 	%f1369, %f1366, %f1362;
	sub.f32 	%f1370, %f1366, %f1369;
	add.f32 	%f1371, %f1362, %f1370;
	add.f32 	%f1372, %f1364, %f1371;
	add.f32 	%f1373, %f1368, %f1372;
	add.f32 	%f1374, %f1369, %f1373;
	sub.f32 	%f1375, %f1369, %f1374;
	add.f32 	%f1376, %f1373, %f1375;
	mul.rn.f32 	%f1377, %f940, %f1374;
	neg.f32 	%f1378, %f1377;
	fma.rn.f32 	%f1379, %f940, %f1374, %f1378;
	fma.rn.f32 	%f1380, %f940, %f1376, %f1379;
	fma.rn.f32 	%f1382, %f1283, %f1374, %f1380;
	add.rn.f32 	%f1383, %f1377, %f1382;
	neg.f32 	%f1384, %f1383;
	add.rn.f32 	%f1385, %f1377, %f1384;
	add.rn.f32 	%f1386, %f1385, %f1382;
	mov.b32 	%r448, %f1383;
	setp.eq.s32 	%p354, %r448, 1118925336;
	add.s32 	%r449, %r448, -1;
	mov.b32 	%f1387, %r449;
	add.f32 	%f1388, %f1386, 0f37000000;
	selp.f32 	%f274, %f1388, %f1386, %p354;
	selp.f32 	%f1389, %f1387, %f1383, %p354;
	mul.rn.f32 	%f1390, %f1389, %f1045;
	cvt.rzi.f32.f32 	%f1391, %f1390;
	abs.f32 	%f1392, %f1391;
	setp.gt.f32 	%p355, %f1392, 0f42FC0000;
	mov.b32 	%r450, %f1391;
	and.b32  	%r451, %r450, -2147483648;
	or.b32  	%r452, %r451, 1123811328;
	mov.b32 	%f1393, %r452;
	selp.f32 	%f1394, %f1393, %f1391, %p355;
	fma.rn.f32 	%f1396, %f1394, %f1051, %f1389;
	fma.rn.f32 	%f1398, %f1394, %f1053, %f1396;
	mul.f32 	%f1399, %f1398, 0f3FB8AA3B;
	add.f32 	%f1400, %f1394, 0f4B40007F;
	mov.b32 	%r453, %f1400;
	shl.b32 	%r454, %r453, 23;
	mov.b32 	%f1401, %r454;
	ex2.approx.ftz.f32 	%f1402, %f1399;
	mul.f32 	%f275, %f1402, %f1401;
	setp.eq.f32 	%p356, %f275, 0f7F800000;
	mov.f32 	%f1797, 0f7F800000;
	@%p356 bra 	$L__BB0_240;

	fma.rn.f32 	%f1797, %f275, %f274, %f275;

$L__BB0_240:
	setp.lt.f32 	%p357, %f272, 0f00000000;
	and.pred  	%p18, %p357, %p311;
	setp.eq.f32 	%p359, %f272, 0f00000000;
	@%p359 bra 	$L__BB0_244;
	bra.uni 	$L__BB0_241;

$L__BB0_244:
	add.f32 	%f1407, %f272, %f272;
	selp.f32 	%f1799, %f1407, 0f00000000, %p311;
	bra.uni 	$L__BB0_245;

$L__BB0_241:
	mov.b32 	%r455, %f1797;
	xor.b32  	%r456, %r455, -2147483648;
	mov.b32 	%f1403, %r456;
	selp.f32 	%f1799, %f1403, %f1797, %p18;
	setp.geu.f32 	%p360, %f272, 0f00000000;
	@%p360 bra 	$L__BB0_245;

	cvt.rzi.f32.f32 	%f1405, %f940;
	setp.eq.f32 	%p361, %f1405, 0f40000000;
	@%p361 bra 	$L__BB0_245;

	mov.f32 	%f1799, 0f7FFFFFFF;

$L__BB0_245:
	add.f32 	%f1408, %f273, 0f40000000;
	mov.b32 	%r457, %f1408;
	setp.lt.s32 	%p363, %r457, 2139095040;
	@%p363 bra 	$L__BB0_250;

	setp.gtu.f32 	%p364, %f273, 0f7F800000;
	@%p364 bra 	$L__BB0_249;
	bra.uni 	$L__BB0_247;

$L__BB0_249:
	add.f32 	%f1799, %f272, 0f40000000;
	bra.uni 	$L__BB0_250;

$L__BB0_247:
	setp.neu.f32 	%p365, %f273, 0f7F800000;
	@%p365 bra 	$L__BB0_250;

	selp.f32 	%f1799, 0fFF800000, 0f7F800000, %p18;

$L__BB0_250:
	mul.f32 	%f1409, %f1799, 0fBF000000;
	setp.eq.f32 	%p366, %f272, 0f3F800000;
	selp.f32 	%f1410, 0fBF000000, %f1409, %p366;
	fma.rn.f32 	%f1413, %f1410, %f1197, %f350;
	cvt.sat.f32.f32 	%f1416, %f1413;
	fma.rm.f32 	%f1418, %f1416, %f1200, %f1202;
	add.f32 	%f1419, %f1418, 0fCB40007F;
	neg.f32 	%f1420, %f1419;
	fma.rn.f32 	%f1421, %f1410, %f1045, %f1420;
	fma.rn.f32 	%f1423, %f1410, %f1215, %f1421;
	mov.b32 	%r458, %f1418;
	shl.b32 	%r459, %r458, 23;
	mov.b32 	%f1424, %r459;
	ex2.approx.ftz.f32 	%f1425, %f1423;
	mul.f32 	%f1426, %f1425, %f1424;
	sub.f32 	%f1427, %f271, %f1426;
	mul.f32 	%f1428, %f186, %f1427;
	mul.f32 	%f1429, %f233, %f1428;
	mul.f32 	%f1430, %f258, %f258;
	div.rn.f32 	%f1431, %f1430, %f246;
	add.f32 	%f1781, %f1781, %f1431;
	mul.f32 	%f1432, %f1429, %f258;
	div.rn.f32 	%f1433, %f1432, %f246;
	add.f32 	%f1780, %f1780, %f1433;
	mul.f32 	%f1434, %f233, %f245;
	mul.f32 	%f1435, %f1434, %f258;
	div.rn.f32 	%f1436, %f1435, %f246;
	add.f32 	%f1779, %f1779, %f1436;
	div.rn.f32 	%f1437, %f258, %f246;
	add.f32 	%f1778, %f1778, %f1437;
	mul.f32 	%f1438, %f1429, %f1429;
	div.rn.f32 	%f1439, %f1438, %f246;
	add.f32 	%f1777, %f1777, %f1439;
	mul.f32 	%f1440, %f1434, %f1429;
	div.rn.f32 	%f1441, %f1440, %f246;
	add.f32 	%f1776, %f1776, %f1441;
	div.rn.f32 	%f1442, %f1429, %f246;
	add.f32 	%f1775, %f1775, %f1442;
	mul.f32 	%f1443, %f1434, %f1434;
	div.rn.f32 	%f1444, %f1443, %f246;
	add.f32 	%f1782, %f1782, %f1444;
	div.rn.f32 	%f1445, %f1434, %f246;
	add.f32 	%f1783, %f1783, %f1445;
	rcp.rn.f32 	%f1446, %f246;
	add.f32 	%f1784, %f1784, %f1446;
	setp.leu.f32 	%p367, %f246, 0f00000000;
	@%p367 bra 	$L__BB0_258;

	setp.gt.f32 	%p368, %f247, 0f00000000;
	@%p368 bra 	$L__BB0_253;
	bra.uni 	$L__BB0_252;

$L__BB0_253:
	setp.lt.f32 	%p369, %f246, 0f00800000;
	mul.f32 	%f1447, %f246, 0f4B000000;
	selp.f32 	%f295, %f1447, %f246, %p369;
	selp.f32 	%f1448, 0fC1B80000, 0f00000000, %p369;
	mov.b32 	%r460, %f295;
	add.s32 	%r461, %r460, -1059760811;
	and.b32  	%r462, %r461, -8388608;
	sub.s32 	%r463, %r460, %r462;
	mov.b32 	%f1449, %r463;
	cvt.rn.f32.s32 	%f1450, %r462;
	mov.f32 	%f1451, 0f34000000;
	fma.rn.f32 	%f1452, %f1450, %f1451, %f1448;
	add.f32 	%f1453, %f1449, 0fBF800000;
	mov.f32 	%f1454, 0f3E1039F6;
	mov.f32 	%f1455, 0fBE055027;
	fma.rn.f32 	%f1456, %f1455, %f1453, %f1454;
	mov.f32 	%f1457, 0fBDF8CDCC;
	fma.rn.f32 	%f1458, %f1456, %f1453, %f1457;
	mov.f32 	%f1459, 0f3E0F2955;
	fma.rn.f32 	%f1460, %f1458, %f1453, %f1459;
	mov.f32 	%f1461, 0fBE2AD8B9;
	fma.rn.f32 	%f1462, %f1460, %f1453, %f1461;
	mov.f32 	%f1463, 0f3E4CED0B;
	fma.rn.f32 	%f1464, %f1462, %f1453, %f1463;
	mov.f32 	%f1465, 0fBE7FFF22;
	fma.rn.f32 	%f1466, %f1464, %f1453, %f1465;
	mov.f32 	%f1467, 0f3EAAAA78;
	fma.rn.f32 	%f1468, %f1466, %f1453, %f1467;
	mov.f32 	%f1469, 0fBF000000;
	fma.rn.f32 	%f1470, %f1468, %f1453, %f1469;
	mul.f32 	%f1471, %f1453, %f1470;
	fma.rn.f32 	%f1472, %f1471, %f1453, %f1453;
	mov.f32 	%f1473, 0f3F317218;
	fma.rn.f32 	%f1800, %f1452, %f1473, %f1472;
	setp.lt.u32 	%p370, %r460, 2139095040;
	@%p370 bra 	$L__BB0_255;

	mov.f32 	%f1474, 0f7F800000;
	fma.rn.f32 	%f1800, %f295, %f1474, %f1474;

$L__BB0_255:
	setp.eq.f32 	%p371, %f295, 0f00000000;
	selp.f32 	%f1475, 0fFF800000, %f1800, %p371;
	mul.f32 	%f1476, %f247, %f1475;
	sub.f32 	%f299, %f1476, %f246;
	mul.f32 	%f1477, %f247, 0f4B000000;
	setp.lt.f32 	%p372, %f247, 0f00800000;
	selp.f32 	%f300, %f1477, %f247, %p372;
	selp.f32 	%f1478, 0fC1B80000, 0f00000000, %p372;
	mov.b32 	%r464, %f300;
	add.s32 	%r465, %r464, -1059760811;
	and.b32  	%r466, %r465, -8388608;
	sub.s32 	%r467, %r464, %r466;
	mov.b32 	%f1479, %r467;
	cvt.rn.f32.s32 	%f1480, %r466;
	fma.rn.f32 	%f1482, %f1480, %f1451, %f1478;
	add.f32 	%f1483, %f1479, 0fBF800000;
	fma.rn.f32 	%f1486, %f1455, %f1483, %f1454;
	fma.rn.f32 	%f1488, %f1486, %f1483, %f1457;
	fma.rn.f32 	%f1490, %f1488, %f1483, %f1459;
	fma.rn.f32 	%f1492, %f1490, %f1483, %f1461;
	fma.rn.f32 	%f1494, %f1492, %f1483, %f1463;
	fma.rn.f32 	%f1496, %f1494, %f1483, %f1465;
	fma.rn.f32 	%f1498, %f1496, %f1483, %f1467;
	fma.rn.f32 	%f1500, %f1498, %f1483, %f1469;
	mul.f32 	%f1501, %f1483, %f1500;
	fma.rn.f32 	%f1502, %f1501, %f1483, %f1483;
	fma.rn.f32 	%f1801, %f1482, %f1473, %f1502;
	setp.lt.u32 	%p373, %r464, 2139095040;
	@%p373 bra 	$L__BB0_257;

	mov.f32 	%f1504, 0f7F800000;
	fma.rn.f32 	%f1801, %f300, %f1504, %f1504;

$L__BB0_257:
	setp.eq.f32 	%p374, %f300, 0f00000000;
	selp.f32 	%f1505, 0fFF800000, %f1801, %p374;
	mul.f32 	%f1506, %f247, %f1505;
	sub.f32 	%f1507, %f299, %f1506;
	add.f32 	%f1508, %f247, %f1507;
	add.f32 	%f1802, %f1802, %f1508;
	bra.uni 	$L__BB0_258;

$L__BB0_252:
	sub.f32 	%f1802, %f1802, %f246;

$L__BB0_258:
	add.s32 	%r538, %r538, 1;
	setp.lt.s32 	%p375, %r538, %r86;
	@%p375 bra 	$L__BB0_208;

	add.s32 	%r537, %r537, 1;
	setp.lt.s32 	%p376, %r537, %r86;
	@%p376 bra 	$L__BB0_207;

$L__BB0_260:
	ld.param.u64 	%rd46, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_5];
	ld.param.u32 	%r478, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_7];
	ld.param.u64 	%rd45, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_4];
	ld.param.u64 	%rd44, [_Z19kernel_MLEFit_XYNB_PKffiiPfS1_S1_i_param_6];
	mov.u32 	%r477, %tid.x;
	mov.u32 	%r476, %ntid.x;
	mov.u32 	%r475, %ctaid.x;
	mad.lo.s32 	%r474, %r475, %r476, %r477;
	cvta.to.global.u64 	%rd28, %rd44;
	rcp.rn.f32 	%f1509, %f1781;
	mov.f32 	%f1510, 0f3F800000;
	mul.f32 	%f1511, %f1509, %f1780;
	mul.f32 	%f1512, %f1509, %f1779;
	mul.f32 	%f1513, %f1509, %f1778;
	fma.rn.f32 	%f1514, %f1511, %f1780, 0f00000000;
	sub.f32 	%f1516, %f1777, %f1514;
	fma.rn.f32 	%f1517, %f1512, %f1780, 0f00000000;
	rcp.rn.f32 	%f1518, %f1516;
	sub.f32 	%f1519, %f1776, %f1517;
	mul.f32 	%f1520, %f1518, %f1519;
	fma.rn.f32 	%f1521, %f1513, %f1780, 0f00000000;
	sub.f32 	%f1522, %f1775, %f1521;
	mul.f32 	%f1523, %f1518, %f1522;
	fma.rn.f32 	%f1524, %f1511, %f1779, 0f00000000;
	sub.f32 	%f1525, %f1776, %f1524;
	fma.rn.f32 	%f1526, %f1512, %f1779, 0f00000000;
	fma.rn.f32 	%f1527, %f1520, %f1525, %f1526;
	sub.f32 	%f1528, %f1782, %f1527;
	fma.rn.f32 	%f1529, %f1513, %f1779, 0f00000000;
	fma.rn.f32 	%f1530, %f1523, %f1525, %f1529;
	rcp.rn.f32 	%f1531, %f1528;
	sub.f32 	%f1532, %f1783, %f1530;
	mul.f32 	%f1533, %f1531, %f1532;
	fma.rn.f32 	%f1534, %f1511, %f1778, 0f00000000;
	sub.f32 	%f1535, %f1775, %f1534;
	fma.rn.f32 	%f1536, %f1512, %f1778, 0f00000000;
	fma.rn.f32 	%f1537, %f1520, %f1535, %f1536;
	sub.f32 	%f1538, %f1783, %f1537;
	fma.rn.f32 	%f1539, %f1513, %f1778, 0f00000000;
	fma.rn.f32 	%f1540, %f1523, %f1535, %f1539;
	fma.rn.f32 	%f1541, %f1533, %f1538, %f1540;
	sub.f32 	%f1542, %f1784, %f1541;
	add.f32 	%f1543, %f1511, 0f00000000;
	sub.f32 	%f1544, %f924, %f1543;
	add.f32 	%f1545, %f1512, 0f00000000;
	fma.rn.f32 	%f1546, %f1520, %f1544, %f1545;
	sub.f32 	%f1547, %f924, %f1546;
	add.f32 	%f1548, %f1513, 0f00000000;
	fma.rn.f32 	%f1549, %f1523, %f1544, %f1548;
	fma.rn.f32 	%f1550, %f1533, %f1547, %f1549;
	sub.f32 	%f1551, %f924, %f1550;
	div.rn.f32 	%f1552, %f1551, %f1542;
	fma.rn.f32 	%f1553, %f1538, %f1552, 0f00000000;
	sub.f32 	%f1554, %f1547, %f1553;
	mul.f32 	%f1555, %f1531, %f1554;
	fma.rn.f32 	%f1556, %f1525, %f1555, 0f00000000;
	fma.rn.f32 	%f1557, %f1535, %f1552, %f1556;
	sub.f32 	%f1558, %f1544, %f1557;
	mul.f32 	%f1559, %f1518, %f1558;
	fma.rn.f32 	%f1560, %f1780, %f1559, 0f00000000;
	fma.rn.f32 	%f1561, %f1779, %f1555, %f1560;
	fma.rn.f32 	%f1562, %f1778, %f1552, %f1561;
	sub.f32 	%f1563, %f1510, %f1562;
	mul.f32 	%f1564, %f1509, %f1563;
	fma.rn.f32 	%f1565, %f1511, 0f00000000, 0f00000000;
	sub.f32 	%f1566, %f1510, %f1565;
	fma.rn.f32 	%f1567, %f1512, 0f00000000, 0f00000000;
	fma.rn.f32 	%f1568, %f1520, %f1566, %f1567;
	sub.f32 	%f1569, %f924, %f1568;
	fma.rn.f32 	%f1570, %f1513, 0f00000000, 0f00000000;
	fma.rn.f32 	%f1571, %f1523, %f1566, %f1570;
	fma.rn.f32 	%f1572, %f1533, %f1569, %f1571;
	sub.f32 	%f1573, %f924, %f1572;
	div.rn.f32 	%f1574, %f1573, %f1542;
	fma.rn.f32 	%f1575, %f1538, %f1574, 0f00000000;
	sub.f32 	%f1576, %f1569, %f1575;
	mul.f32 	%f1577, %f1531, %f1576;
	fma.rn.f32 	%f1578, %f1525, %f1577, 0f00000000;
	fma.rn.f32 	%f1579, %f1535, %f1574, %f1578;
	sub.f32 	%f1580, %f1566, %f1579;
	mul.f32 	%f1581, %f1518, %f1580;
	sub.f32 	%f1582, %f924, %f1565;
	fma.rn.f32 	%f1583, %f1520, %f1582, %f1567;
	sub.f32 	%f1584, %f1510, %f1583;
	fma.rn.f32 	%f1585, %f1523, %f1582, %f1570;
	fma.rn.f32 	%f1586, %f1533, %f1584, %f1585;
	sub.f32 	%f1587, %f924, %f1586;
	div.rn.f32 	%f1588, %f1587, %f1542;
	fma.rn.f32 	%f1589, %f1538, %f1588, 0f00000000;
	sub.f32 	%f1590, %f1584, %f1589;
	mul.f32 	%f1591, %f1531, %f1590;
	sub.f32 	%f1592, %f924, %f1583;
	fma.rn.f32 	%f1593, %f1533, %f1592, %f1585;
	sub.f32 	%f1594, %f1510, %f1593;
	div.rn.f32 	%f1595, %f1594, %f1542;
	cvta.to.global.u64 	%rd29, %rd45;
	mul.wide.s32 	%rd30, %r474, 4;
	add.s64 	%rd31, %rd29, %rd30;
	st.global.f32 	[%rd31], %f1763;
	mul.wide.s32 	%rd32, %r478, 4;
	add.s64 	%rd33, %rd31, %rd32;
	st.global.f32 	[%rd33], %f1762;
	add.s32 	%r468, %r474, %r478;
	add.s32 	%r469, %r468, %r478;
	mul.wide.s32 	%rd34, %r469, 4;
	add.s64 	%rd35, %rd29, %rd34;
	st.global.f32 	[%rd35], %f1761;
	add.s32 	%r470, %r469, %r478;
	mul.wide.s32 	%rd36, %r470, 4;
	add.s64 	%rd37, %rd29, %rd36;
	st.global.f32 	[%rd37], %f1760;
	cvta.to.global.u64 	%rd38, %rd46;
	add.s64 	%rd39, %rd38, %rd30;
	st.global.f32 	[%rd39], %f1564;
	add.s64 	%rd40, %rd39, %rd32;
	st.global.f32 	[%rd40], %f1581;
	add.s64 	%rd41, %rd38, %rd34;
	st.global.f32 	[%rd41], %f1591;
	add.s64 	%rd42, %rd38, %rd36;
	st.global.f32 	[%rd42], %f1595;
	add.s64 	%rd43, %rd28, %rd30;
	st.global.f32 	[%rd43], %f1802;

$L__BB0_261:
	ret;

}
	// .globl	_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i
.visible .entry _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i(
	.param .u64 _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_0,
	.param .f32 _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_1,
	.param .u32 _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_2,
	.param .u32 _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_3,
	.param .u64 _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_4,
	.param .u64 _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_5,
	.param .u64 _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_6,
	.param .u32 _Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_7
)
{
	.reg .pred 	%p<680>;
	.reg .f32 	%f<2944>;
	.reg .b32 	%r<785>;
	.reg .f64 	%fd<558>;
	.reg .b64 	%rd<52>;


	ld.param.u64 	%rd7, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_0];
	ld.param.f32 	%f2864, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_1];
	ld.param.u32 	%r102, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_2];
	ld.param.u32 	%r104, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_7];
	cvta.to.global.u64 	%rd1, %rd7;
	mov.u32 	%r105, %ntid.x;
	mov.u32 	%r106, %ctaid.x;
	mov.u32 	%r107, %tid.x;
	mad.lo.s32 	%r1, %r106, %r105, %r107;
	setp.ge.s32 	%p39, %r1, %r104;
	@%p39 bra 	$L__BB1_427;

	mul.lo.s32 	%r108, %r102, %r102;
	mul.lo.s32 	%r2, %r108, %r1;
	setp.lt.s32 	%p40, %r102, 1;
	mov.f32 	%f2796, 0f00000000;
	mov.f32 	%f2787, %f2796;
	mov.f32 	%f2788, %f2796;
	mov.f32 	%f2789, %f2796;
	@%p40 bra 	$L__BB1_11;

	add.s32 	%r3, %r102, -1;
	and.b32  	%r4, %r102, 3;
	sub.s32 	%r5, %r102, %r4;
	shl.b32 	%r6, %r102, 2;
	mov.u32 	%r109, 0;
	setp.lt.u32 	%p41, %r3, 3;
	setp.eq.s32 	%p43, %r4, 0;
	setp.eq.s32 	%p44, %r4, 1;
	setp.eq.s32 	%p45, %r4, 2;
	cvt.s64.s32 	%rd13, %r6;
	mov.u32 	%r770, %r109;

$L__BB1_3:
	cvt.rn.f32.s32 	%f4, %r770;
	mov.u32 	%r773, %r109;
	@%p41 bra 	$L__BB1_6;

	mov.u32 	%r773, %r109;
	mov.u32 	%r772, %r5;

$L__BB1_5:
	mad.lo.s32 	%r112, %r773, %r102, %r770;
	add.s32 	%r113, %r112, %r2;
	mul.wide.s32 	%rd11, %r113, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.f32 	%f464, [%rd12];
	fma.rn.f32 	%f465, %f464, %f4, %f2787;
	cvt.rn.f32.s32 	%f466, %r773;
	fma.rn.f32 	%f467, %f464, %f466, %f2788;
	add.f32 	%f468, %f2789, %f464;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.f32 	%f469, [%rd14];
	fma.rn.f32 	%f470, %f469, %f4, %f465;
	add.s32 	%r114, %r773, 1;
	cvt.rn.f32.s32 	%f471, %r114;
	fma.rn.f32 	%f472, %f469, %f471, %f467;
	add.f32 	%f473, %f468, %f469;
	add.s64 	%rd15, %rd14, %rd13;
	ld.global.f32 	%f474, [%rd15];
	fma.rn.f32 	%f475, %f474, %f4, %f470;
	add.s32 	%r115, %r773, 2;
	cvt.rn.f32.s32 	%f476, %r115;
	fma.rn.f32 	%f477, %f474, %f476, %f472;
	add.f32 	%f478, %f473, %f474;
	add.s64 	%rd16, %rd15, %rd13;
	ld.global.f32 	%f479, [%rd16];
	fma.rn.f32 	%f2787, %f479, %f4, %f475;
	add.s32 	%r116, %r773, 3;
	cvt.rn.f32.s32 	%f480, %r116;
	fma.rn.f32 	%f2788, %f479, %f480, %f477;
	add.f32 	%f2789, %f478, %f479;
	add.s32 	%r773, %r773, 4;
	add.s32 	%r772, %r772, -4;
	setp.ne.s32 	%p42, %r772, 0;
	@%p42 bra 	$L__BB1_5;

$L__BB1_6:
	@%p43 bra 	$L__BB1_10;

	mad.lo.s32 	%r13, %r773, %r102, %r770;
	add.s32 	%r117, %r13, %r2;
	mul.wide.s32 	%rd17, %r117, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.f32 	%f481, [%rd18];
	fma.rn.f32 	%f2787, %f481, %f4, %f2787;
	cvt.rn.f32.s32 	%f482, %r773;
	fma.rn.f32 	%f2788, %f481, %f482, %f2788;
	add.f32 	%f2789, %f2789, %f481;
	@%p44 bra 	$L__BB1_10;

	add.s32 	%r14, %r13, %r102;
	add.s32 	%r118, %r14, %r2;
	mul.wide.s32 	%rd19, %r118, 4;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.f32 	%f483, [%rd20];
	fma.rn.f32 	%f2787, %f483, %f4, %f2787;
	add.s32 	%r119, %r773, 1;
	cvt.rn.f32.s32 	%f484, %r119;
	fma.rn.f32 	%f2788, %f483, %f484, %f2788;
	add.f32 	%f2789, %f2789, %f483;
	@%p45 bra 	$L__BB1_10;

	add.s32 	%r120, %r773, 2;
	add.s32 	%r121, %r14, %r102;
	add.s32 	%r122, %r121, %r2;
	mul.wide.s32 	%rd21, %r122, 4;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.f32 	%f485, [%rd22];
	fma.rn.f32 	%f2787, %f485, %f4, %f2787;
	cvt.rn.f32.s32 	%f486, %r120;
	fma.rn.f32 	%f2788, %f485, %f486, %f2788;
	add.f32 	%f2789, %f2789, %f485;

$L__BB1_10:
	add.s32 	%r770, %r770, 1;
	setp.lt.s32 	%p46, %r770, %r102;
	@%p46 bra 	$L__BB1_3;

$L__BB1_11:
	div.rn.f32 	%f2868, %f2787, %f2789;
	div.rn.f32 	%f2867, %f2788, %f2789;
	mov.f32 	%f2865, 0f51BA43B7;
	@%p40 bra 	$L__BB1_51;

	mov.f32 	%f491, 0f3F000000;
	div.rn.f32 	%f492, %f491, %f2864;
	div.rn.f32 	%f493, %f492, %f2864;
	cvt.f64.f32 	%fd1, %f493;
	mov.f64 	%fd215, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd215;
	}
	and.b32  	%r17, %r16, 2146435072;
	and.b32  	%r18, %r16, 2147483647;
	setp.gt.s32 	%p48, %r16, -1;
	selp.b32 	%r19, 2146435072, 0, %p48;
	mov.u32 	%r123, 0;
	or.b32  	%r20, %r19, -2147483648;
	mul.wide.s32 	%rd23, %r2, 4;
	add.s64 	%rd2, %rd1, %rd23;
	setp.eq.s32 	%p50, %r17, 1062207488;
	setp.lt.s32 	%p51, %r16, 0;
	setp.ne.s32 	%p56, %r18, 1071644672;
	setp.eq.s32 	%p83, %r18, 2146435072;
	mov.u32 	%r774, %r123;

$L__BB1_13:
	mov.u32 	%r775, %r123;

$L__BB1_14:
	mov.u32 	%r126, 1;
	sub.s32 	%r24, %r126, %r775;
	mov.f32 	%f2799, 0f00000000;
	mov.f32 	%f2800, %f2799;
	mov.u32 	%r776, %r123;

$L__BB1_15:
	add.s32 	%r778, %r775, -1;
	sub.s32 	%r26, %r776, %r774;
	cvt.rn.f32.s32 	%f496, %r26;
	cvt.f64.f32 	%fd2, %f496;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd2;
	}
	abs.f64 	%fd216, %fd2;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd216;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd215;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 9
	setp.lt.s32 	%p49, %r27, 0;
	and.pred  	%p1, %p49, %p50;
	selp.b32 	%r128, %r27, 0, %p50;
	or.b32  	%r129, %r128, 2146435072;
	selp.b32 	%r28, %r129, %r128, %p51;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd4;
	}
	and.b32  	%r29, %r130, 2146435072;
	setp.ne.s32 	%p52, %r29, 2146435072;
	setp.gtu.f64 	%p53, %fd216, 0d7FF0000000000000;
	setp.gt.f64 	%p54, %fd216, 0d3FF0000000000000;
	selp.b32 	%r131, 2146435072, 0, %p54;
	xor.b32  	%r132, %r131, 2146435072;
	selp.b32 	%r133, %r132, %r131, %p51;
	setp.eq.s32 	%p55, %r26, -1;
	selp.b32 	%r30, 1072693248, %r133, %p55;
	and.b32  	%r31, %r27, 2147483647;
	and.pred  	%p57, %p56, %p1;
	selp.b32 	%r32, %r20, %r19, %p57;
	or.pred  	%p2, %p52, %p53;
	mul.lo.s32 	%r134, %r102, %r776;
	mul.wide.s32 	%rd24, %r134, 4;
	add.s64 	%rd51, %rd2, %rd24;
	mov.u32 	%r777, %r24;
	mov.u32 	%r779, %r123;

$L__BB1_16:
	not.pred 	%p58, %p1;
	mov.f64 	%fd502, %fd3;
	@%p58 bra 	$L__BB1_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r135}, %fd3;
	}
	xor.b32  	%r136, %r135, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r137, %temp}, %fd3;
	}
	mov.b64 	%fd502, {%r137, %r136};

$L__BB1_18:
	setp.eq.s32 	%p59, %r26, 0;
	@%p59 bra 	$L__BB1_22;

	setp.gt.s32 	%p60, %r27, -1;
	@%p60 bra 	$L__BB1_23;

	cvt.rzi.f64.f64 	%fd219, %fd215;
	setp.eq.f64 	%p61, %fd219, 0d4000000000000000;
	@%p61 bra 	$L__BB1_23;

	mov.f64 	%fd502, 0dFFF8000000000000;
	bra.uni 	$L__BB1_23;

$L__BB1_22:
	mov.u32 	%r138, 0;
	mov.b64 	%fd502, {%r138, %r28};

$L__BB1_23:
	selp.f64 	%fd503, %fd502, %fd4, %p52;
	@%p2 bra 	$L__BB1_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd215;
	}
	setp.eq.s32 	%p64, %r139, 0;
	and.pred  	%p65, %p83, %p64;
	@%p65 bra 	$L__BB1_27;
	bra.uni 	$L__BB1_25;

$L__BB1_27:
	mov.u32 	%r142, 0;
	mov.b64 	%fd503, {%r142, %r30};
	bra.uni 	$L__BB1_28;

$L__BB1_25:
	setp.ne.s32 	%p66, %r31, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd2;
	}
	setp.ne.s32 	%p67, %r140, 0;
	or.pred  	%p68, %p66, %p67;
	mov.f64 	%fd503, %fd502;
	@%p68 bra 	$L__BB1_28;

	mov.u32 	%r141, 0;
	mov.b64 	%fd503, {%r141, %r32};

$L__BB1_28:
	setp.eq.s32 	%p69, %r26, 1;
	selp.f64 	%fd222, 0d3FF0000000000000, %fd503, %p69;
	mov.f64 	%fd223, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd222, %fd1;
	neg.f64 	%fd224, %fd13;
	mov.f64 	%fd225, 0d4338000000000000;
	mov.f64 	%fd226, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd227, %fd224, %fd226, %fd225;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd227;
	}
	mov.f64 	%fd228, 0dC338000000000000;
	add.rn.f64 	%fd229, %fd227, %fd228;
	mov.f64 	%fd230, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd231, %fd229, %fd230, %fd224;
	mov.f64 	%fd232, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd233, %fd229, %fd232, %fd231;
	mov.f64 	%fd234, 0d3E928AF3FCA213EA;
	mov.f64 	%fd235, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd236, %fd235, %fd233, %fd234;
	mov.f64 	%fd237, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd238, %fd236, %fd233, %fd237;
	mov.f64 	%fd239, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd240, %fd238, %fd233, %fd239;
	mov.f64 	%fd241, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd242, %fd240, %fd233, %fd241;
	mov.f64 	%fd243, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd244, %fd242, %fd233, %fd243;
	mov.f64 	%fd245, 0d3F81111111122322;
	fma.rn.f64 	%fd246, %fd244, %fd233, %fd245;
	mov.f64 	%fd247, 0d3FA55555555502A1;
	fma.rn.f64 	%fd248, %fd246, %fd233, %fd247;
	mov.f64 	%fd249, 0d3FC5555555555511;
	fma.rn.f64 	%fd250, %fd248, %fd233, %fd249;
	mov.f64 	%fd251, 0d3FE000000000000B;
	fma.rn.f64 	%fd252, %fd250, %fd233, %fd251;
	fma.rn.f64 	%fd253, %fd252, %fd233, %fd223;
	fma.rn.f64 	%fd254, %fd253, %fd233, %fd223;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd254;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd254;
	}
	shl.b32 	%r143, %r36, 20;
	add.s32 	%r144, %r38, %r143;
	mov.b64 	%fd504, {%r37, %r144};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r145}, %fd224;
	}
	mov.b32 	%f497, %r145;
	abs.f32 	%f42, %f497;
	setp.lt.f32 	%p70, %f42, 0f4086232B;
	@%p70 bra 	$L__BB1_31;

	setp.gt.f64 	%p71, %fd13, 0d8000000000000000;
	mov.f64 	%fd255, 0d7FF0000000000000;
	sub.f64 	%fd256, %fd255, %fd13;
	selp.f64 	%fd504, 0d0000000000000000, %fd256, %p71;
	setp.geu.f32 	%p72, %f42, 0f40874800;
	@%p72 bra 	$L__BB1_31;

	shr.u32 	%r146, %r36, 31;
	add.s32 	%r147, %r36, %r146;
	shr.s32 	%r148, %r147, 1;
	shl.b32 	%r149, %r148, 20;
	add.s32 	%r150, %r38, %r149;
	mov.b64 	%fd257, {%r37, %r150};
	sub.s32 	%r151, %r36, %r148;
	shl.b32 	%r152, %r151, 20;
	add.s32 	%r153, %r152, 1072693248;
	mov.u32 	%r154, 0;
	mov.b64 	%fd258, {%r154, %r153};
	mul.f64 	%fd504, %fd257, %fd258;

$L__BB1_31:
	add.s32 	%r155, %r778, 1;
	cvt.rn.f32.s32 	%f498, %r155;
	cvt.f64.f32 	%fd18, %f498;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd215;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd506, [retval0+0];
	} // callseq 10
	setp.lt.s32 	%p73, %r39, 0;
	and.pred  	%p3, %p73, %p50;
	not.pred 	%p75, %p3;
	@%p75 bra 	$L__BB1_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r156}, %fd506;
	}
	xor.b32  	%r157, %r156, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r158, %temp}, %fd506;
	}
	mov.b64 	%fd506, {%r158, %r157};

$L__BB1_33:
	setp.eq.s32 	%p76, %r777, 1;
	@%p76 bra 	$L__BB1_37;
	bra.uni 	$L__BB1_34;

$L__BB1_37:
	mov.u32 	%r159, 0;
	selp.b32 	%r160, %r39, 0, %p50;
	or.b32  	%r161, %r160, 2146435072;
	selp.b32 	%r162, %r161, %r160, %p51;
	mov.b64 	%fd506, {%r159, %r162};
	bra.uni 	$L__BB1_38;

$L__BB1_34:
	setp.gt.s32 	%p77, %r39, -1;
	@%p77 bra 	$L__BB1_38;

	cvt.rzi.f64.f64 	%fd261, %fd215;
	setp.eq.f64 	%p78, %fd261, 0d4000000000000000;
	@%p78 bra 	$L__BB1_38;

	mov.f64 	%fd506, 0dFFF8000000000000;

$L__BB1_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r163}, %fd25;
	}
	and.b32  	%r164, %r163, 2146435072;
	setp.ne.s32 	%p81, %r164, 2146435072;
	mov.f64 	%fd507, %fd506;
	@%p81 bra 	$L__BB1_44;

	setp.gtu.f64 	%p82, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd507, %fd25;
	@%p82 bra 	$L__BB1_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r165, %temp}, %fd215;
	}
	setp.eq.s32 	%p84, %r165, 0;
	and.pred  	%p85, %p83, %p84;
	@%p85 bra 	$L__BB1_43;
	bra.uni 	$L__BB1_41;

$L__BB1_43:
	mov.u32 	%r170, 0;
	setp.gt.f64 	%p92, %fd19, 0d3FF0000000000000;
	selp.b32 	%r171, 2146435072, 0, %p92;
	xor.b32  	%r172, %r171, 2146435072;
	selp.b32 	%r173, %r172, %r171, %p51;
	setp.eq.s32 	%p93, %r778, -2;
	selp.b32 	%r174, 1072693248, %r173, %p93;
	mov.b64 	%fd507, {%r170, %r174};
	bra.uni 	$L__BB1_44;

$L__BB1_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r166, %temp}, %fd18;
	}
	and.b32  	%r167, %r39, 2147483647;
	setp.ne.s32 	%p86, %r167, 2146435072;
	setp.ne.s32 	%p87, %r166, 0;
	or.pred  	%p88, %p86, %p87;
	mov.f64 	%fd507, %fd506;
	@%p88 bra 	$L__BB1_44;

	and.pred  	%p90, %p56, %p3;
	selp.b32 	%r168, %r20, %r19, %p90;
	mov.u32 	%r169, 0;
	mov.b64 	%fd507, {%r169, %r168};

$L__BB1_44:
	mov.f64 	%fd500, 0d3FF0000000000000;
	mov.f64 	%fd499, 0d3FE000000000000B;
	mov.f64 	%fd498, 0d3FC5555555555511;
	mov.f64 	%fd497, 0d3FA55555555502A1;
	mov.f64 	%fd496, 0d3F81111111122322;
	mov.f64 	%fd495, 0d3F56C16C1852B7AF;
	mov.f64 	%fd494, 0d3F2A01A014761F65;
	mov.f64 	%fd493, 0d3EFA01997C89EB71;
	mov.f64 	%fd492, 0d3EC71DEE62401315;
	mov.f64 	%fd491, 0d3E928AF3FCA213EA;
	mov.f64 	%fd490, 0d3E5ADE1569CE2BDF;
	mov.f64 	%fd489, 0dBC7ABC9E3B39803F;
	mov.f64 	%fd488, 0dBFE62E42FEFA39EF;
	mov.f64 	%fd487, 0dC338000000000000;
	mov.f64 	%fd486, 0d4338000000000000;
	mov.f64 	%fd485, 0d3FF71547652B82FE;
	setp.eq.s32 	%p94, %r778, 0;
	selp.f64 	%fd264, 0d3FF0000000000000, %fd507, %p94;
	mul.f64 	%fd29, %fd264, %fd1;
	neg.f64 	%fd266, %fd29;
	fma.rn.f64 	%fd269, %fd266, %fd485, %fd486;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd269;
	}
	add.rn.f64 	%fd271, %fd269, %fd487;
	fma.rn.f64 	%fd273, %fd271, %fd488, %fd266;
	fma.rn.f64 	%fd275, %fd271, %fd489, %fd273;
	fma.rn.f64 	%fd278, %fd490, %fd275, %fd491;
	fma.rn.f64 	%fd280, %fd278, %fd275, %fd492;
	fma.rn.f64 	%fd282, %fd280, %fd275, %fd493;
	fma.rn.f64 	%fd284, %fd282, %fd275, %fd494;
	fma.rn.f64 	%fd286, %fd284, %fd275, %fd495;
	fma.rn.f64 	%fd288, %fd286, %fd275, %fd496;
	fma.rn.f64 	%fd290, %fd288, %fd275, %fd497;
	fma.rn.f64 	%fd292, %fd290, %fd275, %fd498;
	fma.rn.f64 	%fd294, %fd292, %fd275, %fd499;
	fma.rn.f64 	%fd295, %fd294, %fd275, %fd500;
	fma.rn.f64 	%fd296, %fd295, %fd275, %fd500;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd296;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd296;
	}
	shl.b32 	%r175, %r40, 20;
	add.s32 	%r176, %r42, %r175;
	mov.b64 	%fd508, {%r41, %r176};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r177}, %fd266;
	}
	mov.b32 	%f499, %r177;
	abs.f32 	%f43, %f499;
	setp.lt.f32 	%p95, %f43, 0f4086232B;
	@%p95 bra 	$L__BB1_47;

	setp.gt.f64 	%p96, %fd29, 0d8000000000000000;
	mov.f64 	%fd297, 0d7FF0000000000000;
	sub.f64 	%fd298, %fd297, %fd29;
	selp.f64 	%fd508, 0d0000000000000000, %fd298, %p96;
	setp.geu.f32 	%p97, %f43, 0f40874800;
	@%p97 bra 	$L__BB1_47;

	shr.u32 	%r178, %r40, 31;
	add.s32 	%r179, %r40, %r178;
	shr.s32 	%r180, %r179, 1;
	shl.b32 	%r181, %r180, 20;
	add.s32 	%r182, %r42, %r181;
	mov.b64 	%fd299, {%r41, %r182};
	sub.s32 	%r183, %r40, %r180;
	shl.b32 	%r184, %r183, 20;
	add.s32 	%r185, %r184, 1072693248;
	mov.u32 	%r186, 0;
	mov.b64 	%fd300, {%r186, %r185};
	mul.f64 	%fd508, %fd299, %fd300;

$L__BB1_47:
	ld.global.f32 	%f500, [%rd51];
	cvt.f64.f32 	%fd301, %f500;
	mul.f64 	%fd302, %fd504, %fd508;
	cvt.f64.f32 	%fd303, %f2800;
	fma.rn.f64 	%fd304, %fd302, %fd301, %fd303;
	cvt.rn.f32.f64 	%f2800, %fd304;
	cvt.f64.f32 	%fd305, %f2799;
	add.f64 	%fd306, %fd302, %fd305;
	cvt.rn.f32.f64 	%f2799, %fd306;
	add.s32 	%r778, %r778, -1;
	add.s32 	%r777, %r777, 1;
	add.s64 	%rd51, %rd51, 4;
	add.s32 	%r779, %r779, 1;
	setp.lt.s32 	%p98, %r779, %r102;
	@%p98 bra 	$L__BB1_16;

	add.s32 	%r776, %r776, 1;
	setp.lt.s32 	%p99, %r776, %r102;
	@%p99 bra 	$L__BB1_15;

	div.rn.f32 	%f501, %f2800, %f2799;
	max.f32 	%f2796, %f2796, %f501;
	min.f32 	%f2865, %f2865, %f501;
	add.s32 	%r775, %r775, 1;
	setp.lt.s32 	%p100, %r775, %r102;
	@%p100 bra 	$L__BB1_14;

	add.s32 	%r774, %r774, 1;
	setp.lt.s32 	%p101, %r774, %r102;
	@%p101 bra 	$L__BB1_13;

$L__BB1_51:
	ld.param.u32 	%r768, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_3];
	mov.f32 	%f2774, 0f00000000;
	sub.f32 	%f502, %f2796, %f2865;
	add.f32 	%f503, %f502, %f502;
	fma.rn.f32 	%f504, %f502, 0f40000000, %f503;
	mul.f32 	%f505, %f504, 0f40490FD8;
	mul.f32 	%f506, %f505, %f2864;
	mul.f32 	%f507, %f506, %f2864;
	max.f32 	%f2866, %f2774, %f507;
	setp.lt.s32 	%p102, %r768, 1;
	@%p102 bra 	$L__BB1_337;

	cvt.rn.f32.s32 	%f509, %r102;
	mul.f32 	%f51, %f509, 0f3F000000;
	mov.u32 	%r780, 0;
	mov.f64 	%fd309, 0d4008000000000000;

$L__BB1_53:
	mov.f32 	%f2818, 0f00000000;
	mov.f32 	%f2819, %f2818;
	mov.f32 	%f2820, %f2818;
	mov.f32 	%f2821, %f2818;
	mov.f32 	%f2822, %f2818;
	mov.f32 	%f2823, %f2818;
	mov.f32 	%f2824, %f2818;
	mov.f32 	%f2825, %f2818;
	mov.f32 	%f2826, %f2818;
	mov.f32 	%f2827, %f2818;
	@%p40 bra 	$L__BB1_336;

	mov.f32 	%f2818, 0f00000000;
	mov.f32 	%f530, 0f3F000000;
	div.rn.f32 	%f531, %f530, %f2864;
	div.rn.f32 	%f57, %f531, %f2864;
	div.rn.f32 	%f532, %f2866, 0fC0206C98;
	div.rn.f32 	%f58, %f532, %f2864;
	cvt.f64.f32 	%fd34, %f532;
	cvt.f64.f32 	%fd307, %f2864;
	add.f64 	%fd35, %fd307, 0d4008000000000000;
	div.rn.f32 	%f59, %f58, %f2864;
	mov.f32 	%f533, 0fC0000000;
	div.rn.f32 	%f60, %f533, %f2864;
	div.rn.f32 	%f534, %f2866, 0f40206C98;
	cvt.f64.f32 	%fd36, %f534;
	mov.u32 	%r781, 0;

$L__BB1_55:
	cvt.f64.f32 	%fd477, %f2864;
	mov.u32 	%r782, 0;
	mov.f32 	%f2648, 0f00000000;
	cvt.rn.f32.s32 	%f535, %r781;
	sub.f32 	%f71, %f535, %f2868;
	add.f32 	%f72, %f71, 0f3F000000;
	sqrt.rn.f32 	%f73, %f57;
	mul.f32 	%f536, %f72, %f73;
	abs.f32 	%f74, %f536;
	setp.ge.f32 	%p104, %f74, 0f3F8060FE;
	mul.f32 	%f537, %f536, %f536;
	selp.f32 	%f538, %f74, %f537, %p104;
	selp.f32 	%f539, 0f3789CA3C, 0f38B1E96A, %p104;
	selp.f32 	%f540, 0fB9F560B9, 0fBA574D20, %p104;
	fma.rn.f32 	%f541, %f539, %f538, %f540;
	selp.f32 	%f542, 0f3BAC840B, 0f3BAAD5EA, %p104;
	fma.rn.f32 	%f543, %f541, %f538, %f542;
	selp.f32 	%f544, 0fBD0C8162, 0fBCDC1BE7, %p104;
	fma.rn.f32 	%f545, %f543, %f538, %f544;
	selp.f32 	%f546, 0f3E1CF906, 0f3DE718AF, %p104;
	fma.rn.f32 	%f547, %f545, %f538, %f546;
	selp.f32 	%f548, 0f3F6A937E, 0fBEC093AC, %p104;
	fma.rn.f32 	%f549, %f547, %f538, %f548;
	selp.f32 	%f550, 0f3F20D842, 0f3E0375D3, %p104;
	fma.rn.f32 	%f551, %f549, %f538, %f550;
	neg.f32 	%f552, %f74;
	selp.f32 	%f553, %f552, %f536, %p104;
	fma.rn.f32 	%f75, %f551, %f553, %f553;
	mov.b32 	%r190, %f536;
	and.b32  	%r51, %r190, -2147483648;
	add.f32 	%f76, %f71, 0fBF000000;
	mul.f32 	%f554, %f76, %f73;
	abs.f32 	%f77, %f554;
	setp.ge.f32 	%p105, %f77, 0f3F8060FE;
	mul.f32 	%f555, %f554, %f554;
	selp.f32 	%f556, %f77, %f555, %p105;
	selp.f32 	%f557, 0f3789CA3C, 0f38B1E96A, %p105;
	selp.f32 	%f558, 0fB9F560B9, 0fBA574D20, %p105;
	fma.rn.f32 	%f559, %f557, %f556, %f558;
	selp.f32 	%f560, 0f3BAC840B, 0f3BAAD5EA, %p105;
	fma.rn.f32 	%f561, %f559, %f556, %f560;
	selp.f32 	%f562, 0fBD0C8162, 0fBCDC1BE7, %p105;
	fma.rn.f32 	%f563, %f561, %f556, %f562;
	selp.f32 	%f564, 0f3E1CF906, 0f3DE718AF, %p105;
	fma.rn.f32 	%f565, %f563, %f556, %f564;
	selp.f32 	%f566, 0f3F6A937E, 0fBEC093AC, %p105;
	fma.rn.f32 	%f567, %f565, %f556, %f566;
	selp.f32 	%f568, 0f3F20D842, 0f3E0375D3, %p105;
	fma.rn.f32 	%f569, %f567, %f556, %f568;
	neg.f32 	%f570, %f77;
	selp.f32 	%f571, %f570, %f554, %p105;
	fma.rn.f32 	%f78, %f569, %f571, %f571;
	mov.b32 	%r191, %f554;
	and.b32  	%r52, %r191, -2147483648;
	add.f32 	%f572, %f535, 0f3F000000;
	sub.f32 	%f79, %f572, %f2868;
	div.rn.f32 	%f80, %f79, %f2864;
	mov.f32 	%f573, 0f3F800000;
	cvt.rzi.f32.f32 	%f574, %f573;
	add.f32 	%f575, %f574, %f574;
	mov.f32 	%f576, 0f40000000;
	sub.f32 	%f577, %f576, %f575;
	abs.f32 	%f81, %f577;
	setp.eq.f32 	%p106, %f81, 0f3F800000;
	abs.f32 	%f82, %f80;
	setp.lt.f32 	%p107, %f82, 0f00800000;
	mul.f32 	%f578, %f82, 0f4B800000;
	selp.f32 	%f579, %f578, %f82, %p107;
	selp.f32 	%f580, 0fC3170000, 0fC2FE0000, %p107;
	mov.b32 	%r192, %f579;
	and.b32  	%r193, %r192, 8388607;
	or.b32  	%r194, %r193, 1065353216;
	mov.b32 	%f581, %r194;
	shr.u32 	%r195, %r192, 23;
	cvt.rn.f32.u32 	%f582, %r195;
	add.f32 	%f583, %f580, %f582;
	setp.gt.f32 	%p108, %f581, 0f3FB504F3;
	mul.f32 	%f584, %f581, 0f3F000000;
	add.f32 	%f585, %f583, 0f3F800000;
	selp.f32 	%f586, %f585, %f583, %p108;
	selp.f32 	%f587, %f584, %f581, %p108;
	add.f32 	%f588, %f587, 0fBF800000;
	add.f32 	%f589, %f587, 0f3F800000;
	rcp.approx.ftz.f32 	%f590, %f589;
	add.f32 	%f591, %f588, %f588;
	mul.f32 	%f592, %f591, %f590;
	mul.f32 	%f593, %f592, %f592;
	mov.f32 	%f594, 0f3C4CAF63;
	mov.f32 	%f595, 0f3B18F0FE;
	fma.rn.f32 	%f596, %f595, %f593, %f594;
	mov.f32 	%f597, 0f3DAAAABD;
	fma.rn.f32 	%f598, %f596, %f593, %f597;
	mul.rn.f32 	%f599, %f598, %f593;
	mul.rn.f32 	%f600, %f599, %f592;
	sub.f32 	%f601, %f588, %f592;
	add.f32 	%f602, %f601, %f601;
	neg.f32 	%f603, %f592;
	fma.rn.f32 	%f604, %f603, %f588, %f602;
	mul.rn.f32 	%f605, %f590, %f604;
	add.f32 	%f606, %f600, %f592;
	sub.f32 	%f607, %f592, %f606;
	add.f32 	%f608, %f600, %f607;
	add.f32 	%f609, %f605, %f608;
	add.f32 	%f610, %f606, %f609;
	sub.f32 	%f611, %f606, %f610;
	add.f32 	%f612, %f609, %f611;
	mov.f32 	%f613, 0f3F317200;
	mul.rn.f32 	%f614, %f586, %f613;
	mov.f32 	%f615, 0f35BFBE8E;
	mul.rn.f32 	%f616, %f586, %f615;
	add.f32 	%f617, %f614, %f610;
	sub.f32 	%f618, %f614, %f617;
	add.f32 	%f619, %f610, %f618;
	add.f32 	%f620, %f612, %f619;
	add.f32 	%f621, %f616, %f620;
	add.f32 	%f622, %f617, %f621;
	sub.f32 	%f623, %f617, %f622;
	add.f32 	%f624, %f621, %f623;
	mul.rn.f32 	%f625, %f576, %f622;
	neg.f32 	%f626, %f625;
	fma.rn.f32 	%f627, %f576, %f622, %f626;
	fma.rn.f32 	%f628, %f576, %f624, %f627;
	fma.rn.f32 	%f630, %f2648, %f622, %f628;
	add.rn.f32 	%f631, %f625, %f630;
	neg.f32 	%f632, %f631;
	add.rn.f32 	%f633, %f625, %f632;
	add.rn.f32 	%f634, %f633, %f630;
	mov.b32 	%r196, %f631;
	setp.eq.s32 	%p109, %r196, 1118925336;
	add.s32 	%r197, %r196, -1;
	mov.b32 	%f635, %r197;
	add.f32 	%f636, %f634, 0f37000000;
	selp.f32 	%f83, %f636, %f634, %p109;
	selp.f32 	%f637, %f635, %f631, %p109;
	mov.f32 	%f638, 0f3FB8AA3B;
	mul.rn.f32 	%f639, %f637, %f638;
	cvt.rzi.f32.f32 	%f640, %f639;
	abs.f32 	%f641, %f640;
	setp.gt.f32 	%p110, %f641, 0f42FC0000;
	mov.b32 	%r198, %f640;
	and.b32  	%r199, %r198, -2147483648;
	or.b32  	%r200, %r199, 1123811328;
	mov.b32 	%f642, %r200;
	selp.f32 	%f643, %f642, %f640, %p110;
	mov.f32 	%f644, 0fBF317218;
	fma.rn.f32 	%f645, %f643, %f644, %f637;
	mov.f32 	%f646, 0f3102E308;
	fma.rn.f32 	%f647, %f643, %f646, %f645;
	mul.f32 	%f648, %f647, 0f3FB8AA3B;
	add.f32 	%f649, %f643, 0f4B40007F;
	mov.b32 	%r201, %f649;
	shl.b32 	%r202, %r201, 23;
	mov.b32 	%f650, %r202;
	ex2.approx.ftz.f32 	%f651, %f648;
	mul.f32 	%f84, %f651, %f650;
	setp.lt.f32 	%p111, %f80, 0f00000000;
	and.pred  	%p4, %p111, %p106;
	div.rn.f32 	%f85, %f76, %f2864;
	abs.f32 	%f86, %f85;
	setp.lt.f32 	%p112, %f86, 0f00800000;
	mul.f32 	%f652, %f86, 0f4B800000;
	selp.f32 	%f653, %f652, %f86, %p112;
	selp.f32 	%f654, 0fC3170000, 0fC2FE0000, %p112;
	mov.b32 	%r203, %f653;
	and.b32  	%r204, %r203, 8388607;
	or.b32  	%r205, %r204, 1065353216;
	mov.b32 	%f655, %r205;
	shr.u32 	%r206, %r203, 23;
	cvt.rn.f32.u32 	%f656, %r206;
	add.f32 	%f657, %f654, %f656;
	setp.gt.f32 	%p113, %f655, 0f3FB504F3;
	mul.f32 	%f658, %f655, 0f3F000000;
	add.f32 	%f659, %f657, 0f3F800000;
	selp.f32 	%f660, %f659, %f657, %p113;
	selp.f32 	%f661, %f658, %f655, %p113;
	add.f32 	%f662, %f661, 0fBF800000;
	add.f32 	%f663, %f661, 0f3F800000;
	rcp.approx.ftz.f32 	%f664, %f663;
	add.f32 	%f665, %f662, %f662;
	mul.f32 	%f666, %f665, %f664;
	mul.f32 	%f667, %f666, %f666;
	fma.rn.f32 	%f668, %f595, %f667, %f594;
	fma.rn.f32 	%f669, %f668, %f667, %f597;
	mul.rn.f32 	%f670, %f669, %f667;
	mul.rn.f32 	%f671, %f670, %f666;
	sub.f32 	%f672, %f662, %f666;
	add.f32 	%f673, %f672, %f672;
	neg.f32 	%f674, %f666;
	fma.rn.f32 	%f675, %f674, %f662, %f673;
	mul.rn.f32 	%f676, %f664, %f675;
	add.f32 	%f677, %f671, %f666;
	sub.f32 	%f678, %f666, %f677;
	add.f32 	%f679, %f671, %f678;
	add.f32 	%f680, %f676, %f679;
	add.f32 	%f681, %f677, %f680;
	sub.f32 	%f682, %f677, %f681;
	add.f32 	%f683, %f680, %f682;
	mul.rn.f32 	%f684, %f660, %f613;
	mul.rn.f32 	%f685, %f660, %f615;
	add.f32 	%f686, %f684, %f681;
	sub.f32 	%f687, %f684, %f686;
	add.f32 	%f688, %f681, %f687;
	add.f32 	%f689, %f683, %f688;
	add.f32 	%f690, %f685, %f689;
	add.f32 	%f691, %f686, %f690;
	sub.f32 	%f692, %f686, %f691;
	add.f32 	%f693, %f690, %f692;
	mul.rn.f32 	%f694, %f576, %f691;
	neg.f32 	%f695, %f694;
	fma.rn.f32 	%f696, %f576, %f691, %f695;
	fma.rn.f32 	%f697, %f576, %f693, %f696;
	fma.rn.f32 	%f698, %f2648, %f691, %f697;
	add.rn.f32 	%f699, %f694, %f698;
	neg.f32 	%f700, %f699;
	add.rn.f32 	%f701, %f694, %f700;
	add.rn.f32 	%f702, %f701, %f698;
	mov.b32 	%r207, %f699;
	setp.eq.s32 	%p114, %r207, 1118925336;
	add.s32 	%r208, %r207, -1;
	mov.b32 	%f703, %r208;
	add.f32 	%f704, %f702, 0f37000000;
	selp.f32 	%f87, %f704, %f702, %p114;
	selp.f32 	%f705, %f703, %f699, %p114;
	mul.rn.f32 	%f706, %f705, %f638;
	cvt.rzi.f32.f32 	%f707, %f706;
	abs.f32 	%f708, %f707;
	setp.gt.f32 	%p115, %f708, 0f42FC0000;
	mov.b32 	%r209, %f707;
	and.b32  	%r210, %r209, -2147483648;
	or.b32  	%r211, %r210, 1123811328;
	mov.b32 	%f709, %r211;
	selp.f32 	%f710, %f709, %f707, %p115;
	fma.rn.f32 	%f711, %f710, %f644, %f705;
	fma.rn.f32 	%f712, %f710, %f646, %f711;
	mul.f32 	%f713, %f712, 0f3FB8AA3B;
	add.f32 	%f714, %f710, 0f4B40007F;
	mov.b32 	%r212, %f714;
	shl.b32 	%r213, %r212, 23;
	mov.b32 	%f715, %r213;
	ex2.approx.ftz.f32 	%f716, %f713;
	mul.f32 	%f88, %f716, %f715;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd477;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd309;
	}
	and.b32  	%r55, %r54, 2146435072;
	setp.eq.s32 	%p117, %r55, 1073741824;
	abs.f64 	%fd310, %fd477;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd310;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd37, [retval0+0];
	} // callseq 11
	setp.lt.s32 	%p118, %r53, 0;
	and.pred  	%p6, %p118, %p117;
	selp.b32 	%r214, %r53, 0, %p117;
	setp.lt.s32 	%p119, %r54, 0;
	or.b32  	%r215, %r214, 2146435072;
	selp.b32 	%r56, %r215, %r214, %p119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r216}, %fd35;
	}
	and.b32  	%r57, %r216, 2146435072;
	setp.ne.s32 	%p120, %r57, 2146435072;
	setp.gtu.f64 	%p121, %fd310, 0d7FF0000000000000;
	and.b32  	%r58, %r54, 2147483647;
	setp.gt.f64 	%p122, %fd310, 0d3FF0000000000000;
	selp.b32 	%r217, 2146435072, 0, %p122;
	xor.b32  	%r218, %r217, 2146435072;
	selp.b32 	%r219, %r218, %r217, %p119;
	setp.eq.f32 	%p123, %f2864, 0fBF800000;
	selp.b32 	%r59, 1072693248, %r219, %p123;
	setp.gt.s32 	%p124, %r54, -1;
	selp.b32 	%r60, 2146435072, 0, %p124;
	setp.ne.s32 	%p125, %r58, 1071644672;
	and.pred  	%p126, %p125, %p6;
	or.b32  	%r61, %r60, -2147483648;
	selp.b32 	%r62, %r61, %r60, %p126;
	add.f32 	%f717, %f535, 0f3F800000;
	sub.f32 	%f718, %f717, %f2868;
	div.rn.f32 	%f89, %f718, %f2864;
	abs.f32 	%f90, %f89;
	setp.lt.f32 	%p127, %f90, 0f00800000;
	mul.f32 	%f719, %f90, 0f4B800000;
	selp.f32 	%f720, %f719, %f90, %p127;
	selp.f32 	%f721, 0fC3170000, 0fC2FE0000, %p127;
	mov.b32 	%r220, %f720;
	and.b32  	%r221, %r220, 8388607;
	or.b32  	%r222, %r221, 1065353216;
	mov.b32 	%f722, %r222;
	shr.u32 	%r223, %r220, 23;
	cvt.rn.f32.u32 	%f723, %r223;
	add.f32 	%f724, %f721, %f723;
	setp.gt.f32 	%p128, %f722, 0f3FB504F3;
	mul.f32 	%f725, %f722, 0f3F000000;
	add.f32 	%f726, %f724, 0f3F800000;
	selp.f32 	%f727, %f726, %f724, %p128;
	selp.f32 	%f728, %f725, %f722, %p128;
	add.f32 	%f729, %f728, 0fBF800000;
	add.f32 	%f730, %f728, 0f3F800000;
	rcp.approx.ftz.f32 	%f731, %f730;
	add.f32 	%f732, %f729, %f729;
	mul.f32 	%f733, %f732, %f731;
	mul.f32 	%f734, %f733, %f733;
	fma.rn.f32 	%f735, %f595, %f734, %f594;
	fma.rn.f32 	%f736, %f735, %f734, %f597;
	mul.rn.f32 	%f737, %f736, %f734;
	mul.rn.f32 	%f738, %f737, %f733;
	sub.f32 	%f739, %f729, %f733;
	add.f32 	%f740, %f739, %f739;
	neg.f32 	%f741, %f733;
	fma.rn.f32 	%f742, %f741, %f729, %f740;
	mul.rn.f32 	%f743, %f731, %f742;
	add.f32 	%f744, %f738, %f733;
	sub.f32 	%f745, %f733, %f744;
	add.f32 	%f746, %f738, %f745;
	add.f32 	%f747, %f743, %f746;
	add.f32 	%f748, %f744, %f747;
	sub.f32 	%f749, %f744, %f748;
	add.f32 	%f750, %f747, %f749;
	mul.rn.f32 	%f751, %f727, %f613;
	mul.rn.f32 	%f752, %f727, %f615;
	add.f32 	%f753, %f751, %f748;
	sub.f32 	%f754, %f751, %f753;
	add.f32 	%f755, %f748, %f754;
	add.f32 	%f756, %f750, %f755;
	add.f32 	%f757, %f752, %f756;
	add.f32 	%f758, %f753, %f757;
	sub.f32 	%f759, %f753, %f758;
	add.f32 	%f760, %f757, %f759;
	mul.rn.f32 	%f761, %f576, %f758;
	neg.f32 	%f762, %f761;
	fma.rn.f32 	%f763, %f576, %f758, %f762;
	fma.rn.f32 	%f764, %f576, %f760, %f763;
	fma.rn.f32 	%f765, %f2648, %f758, %f764;
	add.rn.f32 	%f766, %f761, %f765;
	neg.f32 	%f767, %f766;
	add.rn.f32 	%f768, %f761, %f767;
	add.rn.f32 	%f769, %f768, %f765;
	mov.b32 	%r224, %f766;
	setp.eq.s32 	%p129, %r224, 1118925336;
	add.s32 	%r225, %r224, -1;
	mov.b32 	%f770, %r225;
	add.f32 	%f771, %f769, 0f37000000;
	selp.f32 	%f91, %f771, %f769, %p129;
	selp.f32 	%f772, %f770, %f766, %p129;
	mul.rn.f32 	%f773, %f772, %f638;
	cvt.rzi.f32.f32 	%f774, %f773;
	abs.f32 	%f775, %f774;
	setp.gt.f32 	%p130, %f775, 0f42FC0000;
	mov.b32 	%r226, %f774;
	and.b32  	%r227, %r226, -2147483648;
	or.b32  	%r228, %r227, 1123811328;
	mov.b32 	%f776, %r228;
	selp.f32 	%f777, %f776, %f774, %p130;
	fma.rn.f32 	%f778, %f777, %f644, %f772;
	fma.rn.f32 	%f779, %f777, %f646, %f778;
	mul.f32 	%f780, %f779, 0f3FB8AA3B;
	add.f32 	%f781, %f777, 0f4B40007F;
	mov.b32 	%r229, %f781;
	shl.b32 	%r230, %r229, 23;
	mov.b32 	%f782, %r230;
	ex2.approx.ftz.f32 	%f783, %f780;
	mul.f32 	%f92, %f783, %f782;
	div.rn.f32 	%f93, %f71, %f2864;
	abs.f32 	%f94, %f93;
	setp.lt.f32 	%p132, %f94, 0f00800000;
	mul.f32 	%f784, %f94, 0f4B800000;
	selp.f32 	%f785, %f784, %f94, %p132;
	selp.f32 	%f786, 0fC3170000, 0fC2FE0000, %p132;
	mov.b32 	%r231, %f785;
	and.b32  	%r232, %r231, 8388607;
	or.b32  	%r233, %r232, 1065353216;
	mov.b32 	%f787, %r233;
	shr.u32 	%r234, %r231, 23;
	cvt.rn.f32.u32 	%f788, %r234;
	add.f32 	%f789, %f786, %f788;
	setp.gt.f32 	%p133, %f787, 0f3FB504F3;
	mul.f32 	%f790, %f787, 0f3F000000;
	add.f32 	%f791, %f789, 0f3F800000;
	selp.f32 	%f792, %f791, %f789, %p133;
	selp.f32 	%f793, %f790, %f787, %p133;
	add.f32 	%f794, %f793, 0fBF800000;
	add.f32 	%f795, %f793, 0f3F800000;
	rcp.approx.ftz.f32 	%f796, %f795;
	add.f32 	%f797, %f794, %f794;
	mul.f32 	%f798, %f797, %f796;
	mul.f32 	%f799, %f798, %f798;
	fma.rn.f32 	%f800, %f595, %f799, %f594;
	fma.rn.f32 	%f801, %f800, %f799, %f597;
	mul.rn.f32 	%f802, %f801, %f799;
	mul.rn.f32 	%f803, %f802, %f798;
	sub.f32 	%f804, %f794, %f798;
	add.f32 	%f805, %f804, %f804;
	neg.f32 	%f806, %f798;
	fma.rn.f32 	%f807, %f806, %f794, %f805;
	mul.rn.f32 	%f808, %f796, %f807;
	add.f32 	%f809, %f803, %f798;
	sub.f32 	%f810, %f798, %f809;
	add.f32 	%f811, %f803, %f810;
	add.f32 	%f812, %f808, %f811;
	add.f32 	%f813, %f809, %f812;
	sub.f32 	%f814, %f809, %f813;
	add.f32 	%f815, %f812, %f814;
	mul.rn.f32 	%f816, %f792, %f613;
	mul.rn.f32 	%f817, %f792, %f615;
	add.f32 	%f818, %f816, %f813;
	sub.f32 	%f819, %f816, %f818;
	add.f32 	%f820, %f813, %f819;
	add.f32 	%f821, %f815, %f820;
	add.f32 	%f822, %f817, %f821;
	add.f32 	%f823, %f818, %f822;
	sub.f32 	%f824, %f818, %f823;
	add.f32 	%f825, %f822, %f824;
	mul.rn.f32 	%f826, %f576, %f823;
	neg.f32 	%f827, %f826;
	fma.rn.f32 	%f828, %f576, %f823, %f827;
	fma.rn.f32 	%f829, %f576, %f825, %f828;
	fma.rn.f32 	%f830, %f2648, %f823, %f829;
	add.rn.f32 	%f831, %f826, %f830;
	neg.f32 	%f832, %f831;
	add.rn.f32 	%f833, %f826, %f832;
	add.rn.f32 	%f834, %f833, %f830;
	mov.b32 	%r235, %f831;
	setp.eq.s32 	%p134, %r235, 1118925336;
	add.s32 	%r236, %r235, -1;
	mov.b32 	%f835, %r236;
	add.f32 	%f836, %f834, 0f37000000;
	selp.f32 	%f95, %f836, %f834, %p134;
	selp.f32 	%f837, %f835, %f831, %p134;
	mul.rn.f32 	%f838, %f837, %f638;
	cvt.rzi.f32.f32 	%f839, %f838;
	abs.f32 	%f840, %f839;
	setp.gt.f32 	%p135, %f840, 0f42FC0000;
	mov.b32 	%r237, %f839;
	and.b32  	%r238, %r237, -2147483648;
	or.b32  	%r239, %r238, 1123811328;
	mov.b32 	%f841, %r239;
	selp.f32 	%f842, %f841, %f839, %p135;
	fma.rn.f32 	%f843, %f842, %f644, %f837;
	fma.rn.f32 	%f844, %f842, %f646, %f843;
	mul.f32 	%f845, %f844, 0f3FB8AA3B;
	add.f32 	%f846, %f842, 0f4B40007F;
	mov.b32 	%r240, %f846;
	shl.b32 	%r241, %r240, 23;
	mov.b32 	%f847, %r241;
	ex2.approx.ftz.f32 	%f848, %f845;
	mul.f32 	%f96, %f848, %f847;
	mov.f64 	%fd311, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r242}, %fd311;
	}
	and.b32  	%r243, %r242, 2146435072;
	setp.eq.s32 	%p137, %r243, 1074790400;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd310;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd311;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd38, [retval0+0];
	} // callseq 12
	and.pred  	%p9, %p118, %p137;
	selp.b32 	%r244, %r53, 0, %p137;
	setp.lt.s32 	%p138, %r242, 0;
	or.b32  	%r245, %r244, 2146435072;
	selp.b32 	%r63, %r245, %r244, %p138;
	add.f64 	%fd312, %fd477, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r246}, %fd312;
	}
	and.b32  	%r64, %r246, 2146435072;
	setp.ne.s32 	%p139, %r64, 2146435072;
	cvt.f64.f32 	%fd39, %f72;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd39;
	}
	abs.f64 	%fd313, %fd39;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd313;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd40, [retval0+0];
	} // callseq 13
	setp.lt.s32 	%p140, %r65, 0;
	and.pred  	%p10, %p140, %p117;
	and.b32  	%r66, %r242, 2147483647;
	selp.b32 	%r247, %r218, %r217, %p138;
	selp.b32 	%r67, 1072693248, %r247, %p123;
	add.f64 	%fd41, %fd39, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r248}, %fd41;
	}
	and.b32  	%r68, %r248, 2146435072;
	setp.ne.s32 	%p141, %r68, 2146435072;
	setp.gt.s32 	%p142, %r242, -1;
	selp.b32 	%r249, 2146435072, 0, %p142;
	setp.ne.s32 	%p143, %r66, 1071644672;
	and.pred  	%p144, %p143, %p9;
	or.b32  	%r250, %r249, -2147483648;
	selp.b32 	%r69, %r250, %r249, %p144;
	setp.gtu.f64 	%p145, %fd313, 0d7FF0000000000000;
	cvt.f64.f32 	%fd42, %f76;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd42;
	}
	abs.f64 	%fd314, %fd42;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd314;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd43, [retval0+0];
	} // callseq 14
	setp.lt.s32 	%p146, %r70, 0;
	and.pred  	%p11, %p146, %p117;
	setp.gt.f64 	%p147, %fd313, 0d3FF0000000000000;
	selp.b32 	%r251, 2146435072, 0, %p147;
	xor.b32  	%r252, %r251, 2146435072;
	selp.b32 	%r253, %r252, %r251, %p119;
	setp.eq.f32 	%p148, %f72, 0fBF800000;
	selp.b32 	%r71, 1072693248, %r253, %p148;
	add.f64 	%fd44, %fd42, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r254}, %fd44;
	}
	and.b32  	%r72, %r254, 2146435072;
	setp.ne.s32 	%p149, %r72, 2146435072;
	setp.gtu.f64 	%p150, %fd314, 0d7FF0000000000000;
	setp.gt.f64 	%p151, %fd314, 0d3FF0000000000000;
	selp.b32 	%r255, 2146435072, 0, %p151;
	xor.b32  	%r256, %r255, 2146435072;
	selp.b32 	%r257, %r256, %r255, %p119;
	setp.eq.f32 	%p152, %f76, 0fBF800000;
	selp.b32 	%r73, 1072693248, %r257, %p152;
	mov.f64 	%fd315, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd315;
	}
	and.b32  	%r75, %r74, 2147483647;
	setp.gt.s32 	%p153, %r74, -1;
	selp.b32 	%r76, 2146435072, 0, %p153;
	or.pred  	%p14, %p120, %p121;
	or.pred  	%p17, %p139, %p121;
	or.pred  	%p18, %p141, %p145;
	or.pred  	%p19, %p149, %p150;
	shr.s32 	%r258, %r74, 31;
	and.b32  	%r77, %r258, 2146435072;

$L__BB1_56:
	cvt.rn.f32.s32 	%f2653, %r781;
	sub.f32 	%f2652, %f2653, %f2868;
	add.f32 	%f2651, %f2652, 0f3F000000;
	mul.f32 	%f2650, %f2651, %f73;
	abs.f32 	%f2649, %f2650;
	setp.ltu.f32 	%p154, %f2649, 0f3F8060FE;
	mov.f32 	%f2828, %f75;
	@%p154 bra 	$L__BB1_58;

	mov.f32 	%f2758, 0f3F800000;
	ex2.approx.ftz.f32 	%f849, %f75;
	sub.f32 	%f851, %f2758, %f849;
	mov.b32 	%r259, %f851;
	or.b32  	%r260, %r51, %r259;
	mov.b32 	%f2828, %r260;

$L__BB1_58:
	cvt.rn.f32.s32 	%f2658, %r781;
	sub.f32 	%f2657, %f2658, %f2868;
	add.f32 	%f2656, %f2657, 0fBF000000;
	mul.f32 	%f2655, %f2656, %f73;
	abs.f32 	%f2654, %f2655;
	setp.ltu.f32 	%p155, %f2654, 0f3F8060FE;
	mov.f32 	%f2829, %f78;
	@%p155 bra 	$L__BB1_60;

	mov.f32 	%f2757, 0f3F800000;
	ex2.approx.ftz.f32 	%f852, %f78;
	sub.f32 	%f854, %f2757, %f852;
	mov.b32 	%r261, %f854;
	or.b32  	%r262, %r52, %r261;
	mov.b32 	%f2829, %r262;

$L__BB1_60:
	sub.f32 	%f855, %f2828, %f2829;
	mul.f32 	%f111, %f855, 0f3F000000;
	cvt.rn.f32.s32 	%f112, %r782;
	sub.f32 	%f113, %f112, %f2867;
	add.f32 	%f114, %f113, 0f3F000000;
	mul.f32 	%f115, %f73, %f114;
	abs.f32 	%f856, %f115;
	setp.ltu.f32 	%p156, %f856, 0f3F8060FE;
	setp.ge.f32 	%p157, %f856, 0f3F8060FE;
	mul.f32 	%f857, %f115, %f115;
	selp.f32 	%f858, %f856, %f857, %p157;
	selp.f32 	%f859, 0f3789CA3C, 0f38B1E96A, %p157;
	selp.f32 	%f860, 0fB9F560B9, 0fBA574D20, %p157;
	fma.rn.f32 	%f861, %f859, %f858, %f860;
	selp.f32 	%f862, 0f3BAC840B, 0f3BAAD5EA, %p157;
	fma.rn.f32 	%f863, %f861, %f858, %f862;
	selp.f32 	%f864, 0fBD0C8162, 0fBCDC1BE7, %p157;
	fma.rn.f32 	%f865, %f863, %f858, %f864;
	selp.f32 	%f866, 0f3E1CF906, 0f3DE718AF, %p157;
	fma.rn.f32 	%f867, %f865, %f858, %f866;
	selp.f32 	%f868, 0f3F6A937E, 0fBEC093AC, %p157;
	fma.rn.f32 	%f869, %f867, %f858, %f868;
	selp.f32 	%f870, 0f3F20D842, 0f3E0375D3, %p157;
	fma.rn.f32 	%f871, %f869, %f858, %f870;
	neg.f32 	%f872, %f856;
	selp.f32 	%f873, %f872, %f115, %p157;
	fma.rn.f32 	%f2830, %f871, %f873, %f873;
	@%p156 bra 	$L__BB1_62;

	mov.f32 	%f2756, 0f3F800000;
	ex2.approx.ftz.f32 	%f874, %f2830;
	sub.f32 	%f876, %f2756, %f874;
	mov.b32 	%r263, %f876;
	mov.b32 	%r264, %f115;
	and.b32  	%r265, %r264, -2147483648;
	or.b32  	%r266, %r265, %r263;
	mov.b32 	%f2830, %r266;

$L__BB1_62:
	cvt.rn.f32.s32 	%f2660, %r782;
	sub.f32 	%f2659, %f2660, %f2867;
	add.f32 	%f119, %f2659, 0fBF000000;
	mul.f32 	%f120, %f73, %f119;
	abs.f32 	%f877, %f120;
	setp.ltu.f32 	%p158, %f877, 0f3F8060FE;
	setp.ge.f32 	%p159, %f877, 0f3F8060FE;
	mul.f32 	%f878, %f120, %f120;
	selp.f32 	%f879, %f877, %f878, %p159;
	selp.f32 	%f880, 0f3789CA3C, 0f38B1E96A, %p159;
	selp.f32 	%f881, 0fB9F560B9, 0fBA574D20, %p159;
	fma.rn.f32 	%f882, %f880, %f879, %f881;
	selp.f32 	%f883, 0f3BAC840B, 0f3BAAD5EA, %p159;
	fma.rn.f32 	%f884, %f882, %f879, %f883;
	selp.f32 	%f885, 0fBD0C8162, 0fBCDC1BE7, %p159;
	fma.rn.f32 	%f886, %f884, %f879, %f885;
	selp.f32 	%f887, 0f3E1CF906, 0f3DE718AF, %p159;
	fma.rn.f32 	%f888, %f886, %f879, %f887;
	selp.f32 	%f889, 0f3F6A937E, 0fBEC093AC, %p159;
	fma.rn.f32 	%f890, %f888, %f879, %f889;
	selp.f32 	%f891, 0f3F20D842, 0f3E0375D3, %p159;
	fma.rn.f32 	%f892, %f890, %f879, %f891;
	neg.f32 	%f893, %f877;
	selp.f32 	%f894, %f893, %f120, %p159;
	fma.rn.f32 	%f2831, %f892, %f894, %f894;
	@%p158 bra 	$L__BB1_64;

	mov.f32 	%f2755, 0f3F800000;
	ex2.approx.ftz.f32 	%f895, %f2831;
	sub.f32 	%f897, %f2755, %f895;
	mov.b32 	%r267, %f897;
	mov.b32 	%r268, %f120;
	and.b32  	%r269, %r268, -2147483648;
	or.b32  	%r270, %r269, %r267;
	mov.b32 	%f2831, %r270;

$L__BB1_64:
	sub.f32 	%f899, %f2830, %f2831;
	mul.f32 	%f124, %f899, 0f3F000000;
	mul.f32 	%f900, %f111, %f2866;
	fma.rn.f32 	%f125, %f124, %f900, %f2865;
	mad.lo.s32 	%r271, %r782, %r102, %r781;
	add.s32 	%r272, %r271, %r2;
	mul.wide.s32 	%rd26, %r272, 4;
	add.s64 	%rd27, %rd1, %rd26;
	ld.global.f32 	%f126, [%rd27];
	setp.eq.f32 	%p160, %f84, 0f7F800000;
	mov.f32 	%f2832, 0f7F800000;
	@%p160 bra 	$L__BB1_66;

	fma.rn.f32 	%f2832, %f84, %f83, %f84;

$L__BB1_66:
	setp.geu.f32 	%p660, %f80, 0f00000000;
	mov.b32 	%r273, %f2832;
	xor.b32  	%r274, %r273, -2147483648;
	mov.b32 	%f901, %r274;
	selp.f32 	%f129, %f901, %f2832, %p4;
	add.f32 	%f902, %f80, %f80;
	selp.f32 	%f903, %f902, 0f00000000, %p106;
	setp.eq.f32 	%p162, %f80, 0f00000000;
	selp.f32 	%f2833, %f903, %f129, %p162;
	@%p660 bra 	$L__BB1_69;

	cvt.rzi.f32.f32 	%f905, %f576;
	setp.eq.f32 	%p163, %f905, 0f40000000;
	mov.f32 	%f2833, %f129;
	@%p163 bra 	$L__BB1_69;

	mov.f32 	%f2833, 0f7FFFFFFF;

$L__BB1_69:
	mov.f32 	%f2663, 0f3FB8AA3B;
	mov.f32 	%f2662, 0f3F000000;
	abs.f32 	%f2661, %f80;
	add.f32 	%f908, %f2661, 0f40000000;
	mov.b32 	%r275, %f908;
	setp.gt.s32 	%p164, %r275, 2139095039;
	add.f32 	%f909, %f80, 0f40000000;
	setp.gtu.f32 	%p165, %f2661, 0f7F800000;
	mov.f32 	%f2834, 0f7F800000;
	selp.f32 	%f910, %f909, %f2833, %p165;
	selp.f32 	%f911, 0fFF800000, 0f7F800000, %p4;
	setp.neu.f32 	%p166, %f2661, 0f7F800000;
	selp.f32 	%f912, %f910, %f911, %p166;
	selp.f32 	%f913, %f912, %f2833, %p164;
	mul.f32 	%f914, %f913, 0fBF000000;
	setp.eq.f32 	%p167, %f80, 0f3F800000;
	selp.f32 	%f915, 0fBF000000, %f914, %p167;
	mov.f32 	%f917, 0f3BBB989D;
	fma.rn.f32 	%f918, %f915, %f917, %f2662;
	mov.f32 	%f920, 0f437C0000;
	cvt.sat.f32.f32 	%f921, %f918;
	mov.f32 	%f922, 0f4B400001;
	fma.rm.f32 	%f923, %f921, %f920, %f922;
	add.f32 	%f924, %f923, 0fCB40007F;
	neg.f32 	%f925, %f924;
	fma.rn.f32 	%f926, %f915, %f2663, %f925;
	mov.f32 	%f927, 0f32A57060;
	fma.rn.f32 	%f928, %f915, %f927, %f926;
	mov.b32 	%r276, %f923;
	shl.b32 	%r277, %r276, 23;
	mov.b32 	%f929, %r277;
	ex2.approx.ftz.f32 	%f930, %f928;
	mul.f32 	%f132, %f930, %f929;
	setp.eq.f32 	%p168, %f88, 0f7F800000;
	@%p168 bra 	$L__BB1_71;

	fma.rn.f32 	%f2834, %f88, %f87, %f88;

$L__BB1_71:
	setp.geu.f32 	%p663, %f85, 0f00000000;
	setp.lt.f32 	%p662, %f85, 0f00000000;
	and.pred  	%p661, %p662, %p106;
	mov.b32 	%r278, %f2834;
	xor.b32  	%r279, %r278, -2147483648;
	mov.b32 	%f931, %r279;
	selp.f32 	%f135, %f931, %f2834, %p661;
	add.f32 	%f932, %f85, %f85;
	selp.f32 	%f933, %f932, 0f00000000, %p106;
	setp.eq.f32 	%p170, %f85, 0f00000000;
	selp.f32 	%f2835, %f933, %f135, %p170;
	@%p663 bra 	$L__BB1_74;

	cvt.rzi.f32.f32 	%f935, %f576;
	setp.eq.f32 	%p171, %f935, 0f40000000;
	mov.f32 	%f2835, %f135;
	@%p171 bra 	$L__BB1_74;

	mov.f32 	%f2835, 0f7FFFFFFF;

$L__BB1_74:
	mov.f32 	%f2670, 0f32A57060;
	mov.f32 	%f2669, 0f4B400001;
	mov.f32 	%f2668, 0f437C0000;
	mov.f32 	%f2667, 0f3BBB989D;
	abs.f32 	%f2666, %f85;
	setp.lt.f32 	%p665, %f85, 0f00000000;
	and.pred  	%p664, %p665, %p106;
	mov.f32 	%f2665, 0f3FB8AA3B;
	mov.f32 	%f2664, 0f3F000000;
	add.f32 	%f937, %f2666, 0f40000000;
	mov.b32 	%r280, %f937;
	setp.gt.s32 	%p172, %r280, 2139095039;
	add.f32 	%f938, %f85, 0f40000000;
	setp.gtu.f32 	%p173, %f2666, 0f7F800000;
	selp.f32 	%f939, %f938, %f2835, %p173;
	selp.f32 	%f940, 0fFF800000, 0f7F800000, %p664;
	setp.neu.f32 	%p174, %f2666, 0f7F800000;
	selp.f32 	%f941, %f939, %f940, %p174;
	selp.f32 	%f942, %f941, %f2835, %p172;
	mul.f32 	%f943, %f942, 0fBF000000;
	setp.eq.f32 	%p175, %f85, 0f3F800000;
	selp.f32 	%f944, 0fBF000000, %f943, %p175;
	fma.rn.f32 	%f947, %f944, %f2667, %f2664;
	cvt.sat.f32.f32 	%f950, %f947;
	fma.rm.f32 	%f952, %f950, %f2668, %f2669;
	add.f32 	%f953, %f952, 0fCB40007F;
	neg.f32 	%f954, %f953;
	fma.rn.f32 	%f955, %f944, %f2665, %f954;
	fma.rn.f32 	%f957, %f944, %f2670, %f955;
	mov.b32 	%r281, %f952;
	shl.b32 	%r282, %r281, 23;
	mov.b32 	%f958, %r282;
	ex2.approx.ftz.f32 	%f959, %f957;
	mul.f32 	%f138, %f959, %f958;
	sub.f32 	%f960, %f132, %f138;
	mul.f32 	%f961, %f58, %f960;
	mul.f32 	%f139, %f124, %f961;
	not.pred 	%p176, %p6;
	mov.f64 	%fd510, %fd37;
	@%p176 bra 	$L__BB1_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r283}, %fd37;
	}
	xor.b32  	%r284, %r283, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r285, %temp}, %fd37;
	}
	mov.b64 	%fd510, {%r285, %r284};

$L__BB1_76:
	setp.eq.f32 	%p177, %f2864, 0f00000000;
	@%p177 bra 	$L__BB1_80;
	bra.uni 	$L__BB1_77;

$L__BB1_80:
	mov.u32 	%r286, 0;
	mov.b64 	%fd510, {%r286, %r56};
	bra.uni 	$L__BB1_81;

$L__BB1_77:
	setp.gt.s32 	%p178, %r53, -1;
	@%p178 bra 	$L__BB1_81;

	cvt.rzi.f64.f64 	%fd317, %fd309;
	setp.eq.f64 	%p179, %fd317, 0d4008000000000000;
	@%p179 bra 	$L__BB1_81;

	mov.f64 	%fd510, 0dFFF8000000000000;

$L__BB1_81:
	selp.f64 	%fd511, %fd510, %fd35, %p120;
	@%p14 bra 	$L__BB1_86;

	setp.eq.s32 	%p181, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r287, %temp}, %fd309;
	}
	setp.eq.s32 	%p182, %r287, 0;
	and.pred  	%p183, %p181, %p182;
	@%p183 bra 	$L__BB1_85;
	bra.uni 	$L__BB1_83;

$L__BB1_85:
	mov.u32 	%r291, 0;
	mov.b64 	%fd511, {%r291, %r59};
	bra.uni 	$L__BB1_86;

$L__BB1_83:
	and.b32  	%r288, %r53, 2147483647;
	setp.ne.s32 	%p184, %r288, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r289, %temp}, %fd307;
	}
	setp.ne.s32 	%p185, %r289, 0;
	or.pred  	%p186, %p184, %p185;
	mov.f64 	%fd511, %fd510;
	@%p186 bra 	$L__BB1_86;

	mov.u32 	%r290, 0;
	mov.b64 	%fd511, {%r290, %r62};

$L__BB1_86:
	mov.f32 	%f2681, 0f3102E308;
	mov.f32 	%f2680, 0fBF317218;
	mov.f32 	%f2679, 0f35BFBE8E;
	mov.f32 	%f2678, 0f3F317200;
	mov.f32 	%f2677, 0f3DAAAABD;
	mov.f32 	%f2676, 0f3C4CAF63;
	mov.f32 	%f2675, 0f3B18F0FE;
	cvt.rn.f32.s32 	%f2674, %r781;
	add.f32 	%f2673, %f2674, 0f3F000000;
	sub.f32 	%f2672, %f2673, %f2868;
	mov.f32 	%f2671, 0f3FB8AA3B;
	setp.eq.f32 	%p187, %f2864, 0f3F800000;
	selp.f64 	%fd321, 0d3FF0000000000000, %fd511, %p187;
	div.rn.f64 	%fd322, %fd34, %fd321;
	mul.f32 	%f963, %f76, %f138;
	mul.f32 	%f964, %f2672, %f132;
	sub.f32 	%f965, %f964, %f963;
	cvt.f64.f32 	%fd323, %f965;
	mul.f64 	%fd324, %fd322, %fd323;
	cvt.f64.f32 	%fd53, %f124;
	mul.f64 	%fd325, %fd324, %fd53;
	cvt.rn.f32.f64 	%f140, %fd325;
	add.f32 	%f966, %f112, 0f3F000000;
	sub.f32 	%f141, %f966, %f2867;
	div.rn.f32 	%f142, %f141, %f2864;
	abs.f32 	%f143, %f142;
	setp.lt.f32 	%p188, %f143, 0f00800000;
	mul.f32 	%f967, %f143, 0f4B800000;
	selp.f32 	%f968, %f967, %f143, %p188;
	selp.f32 	%f969, 0fC3170000, 0fC2FE0000, %p188;
	mov.b32 	%r292, %f968;
	and.b32  	%r293, %r292, 8388607;
	or.b32  	%r294, %r293, 1065353216;
	mov.b32 	%f970, %r294;
	shr.u32 	%r295, %r292, 23;
	cvt.rn.f32.u32 	%f971, %r295;
	add.f32 	%f972, %f969, %f971;
	setp.gt.f32 	%p189, %f970, 0f3FB504F3;
	mul.f32 	%f973, %f970, 0f3F000000;
	add.f32 	%f974, %f972, 0f3F800000;
	selp.f32 	%f975, %f974, %f972, %p189;
	selp.f32 	%f976, %f973, %f970, %p189;
	add.f32 	%f977, %f976, 0fBF800000;
	add.f32 	%f978, %f976, 0f3F800000;
	rcp.approx.ftz.f32 	%f979, %f978;
	add.f32 	%f980, %f977, %f977;
	mul.f32 	%f982, %f980, %f979;
	mul.f32 	%f983, %f982, %f982;
	fma.rn.f32 	%f986, %f2675, %f983, %f2676;
	fma.rn.f32 	%f988, %f986, %f983, %f2677;
	mul.rn.f32 	%f989, %f988, %f983;
	mul.rn.f32 	%f990, %f989, %f982;
	sub.f32 	%f991, %f977, %f982;
	add.f32 	%f992, %f991, %f991;
	neg.f32 	%f993, %f982;
	fma.rn.f32 	%f994, %f993, %f977, %f992;
	mul.rn.f32 	%f995, %f979, %f994;
	add.f32 	%f996, %f990, %f982;
	sub.f32 	%f997, %f982, %f996;
	add.f32 	%f998, %f990, %f997;
	add.f32 	%f999, %f995, %f998;
	add.f32 	%f1000, %f996, %f999;
	sub.f32 	%f1001, %f996, %f1000;
	add.f32 	%f1002, %f999, %f1001;
	mul.rn.f32 	%f1004, %f975, %f2678;
	mul.rn.f32 	%f1006, %f975, %f2679;
	add.f32 	%f1007, %f1004, %f1000;
	sub.f32 	%f1008, %f1004, %f1007;
	add.f32 	%f1009, %f1000, %f1008;
	add.f32 	%f1010, %f1002, %f1009;
	add.f32 	%f1011, %f1006, %f1010;
	add.f32 	%f1012, %f1007, %f1011;
	sub.f32 	%f1013, %f1007, %f1012;
	add.f32 	%f1014, %f1011, %f1013;
	mul.rn.f32 	%f1015, %f576, %f1012;
	neg.f32 	%f1016, %f1015;
	fma.rn.f32 	%f1017, %f576, %f1012, %f1016;
	fma.rn.f32 	%f1018, %f576, %f1014, %f1017;
	mov.f32 	%f1019, 0f00000000;
	fma.rn.f32 	%f1020, %f1019, %f1012, %f1018;
	add.rn.f32 	%f1021, %f1015, %f1020;
	neg.f32 	%f1022, %f1021;
	add.rn.f32 	%f1023, %f1015, %f1022;
	add.rn.f32 	%f1024, %f1023, %f1020;
	mov.b32 	%r296, %f1021;
	setp.eq.s32 	%p190, %r296, 1118925336;
	add.s32 	%r297, %r296, -1;
	mov.b32 	%f1025, %r297;
	add.f32 	%f1026, %f1024, 0f37000000;
	selp.f32 	%f144, %f1026, %f1024, %p190;
	selp.f32 	%f1027, %f1025, %f1021, %p190;
	mul.rn.f32 	%f1029, %f1027, %f2671;
	cvt.rzi.f32.f32 	%f1030, %f1029;
	abs.f32 	%f1031, %f1030;
	setp.gt.f32 	%p191, %f1031, 0f42FC0000;
	mov.b32 	%r298, %f1030;
	and.b32  	%r299, %r298, -2147483648;
	or.b32  	%r300, %r299, 1123811328;
	mov.b32 	%f1032, %r300;
	selp.f32 	%f1033, %f1032, %f1030, %p191;
	fma.rn.f32 	%f1035, %f1033, %f2680, %f1027;
	fma.rn.f32 	%f1037, %f1033, %f2681, %f1035;
	mul.f32 	%f1038, %f1037, 0f3FB8AA3B;
	add.f32 	%f1039, %f1033, 0f4B40007F;
	mov.b32 	%r301, %f1039;
	shl.b32 	%r302, %r301, 23;
	mov.b32 	%f1040, %r302;
	ex2.approx.ftz.f32 	%f1041, %f1038;
	mul.f32 	%f145, %f1041, %f1040;
	setp.eq.f32 	%p192, %f145, 0f7F800000;
	mov.f32 	%f2836, 0f7F800000;
	@%p192 bra 	$L__BB1_88;

	fma.rn.f32 	%f2836, %f145, %f144, %f145;

$L__BB1_88:
	setp.lt.f32 	%p193, %f142, 0f00000000;
	and.pred  	%p20, %p193, %p106;
	setp.eq.f32 	%p195, %f142, 0f00000000;
	@%p195 bra 	$L__BB1_92;
	bra.uni 	$L__BB1_89;

$L__BB1_92:
	add.f32 	%f1046, %f142, %f142;
	selp.f32 	%f2838, %f1046, 0f00000000, %p106;
	bra.uni 	$L__BB1_93;

$L__BB1_89:
	mov.b32 	%r303, %f2836;
	xor.b32  	%r304, %r303, -2147483648;
	mov.b32 	%f1042, %r304;
	selp.f32 	%f2838, %f1042, %f2836, %p20;
	setp.geu.f32 	%p196, %f142, 0f00000000;
	@%p196 bra 	$L__BB1_93;

	cvt.rzi.f32.f32 	%f1044, %f576;
	setp.eq.f32 	%p197, %f1044, 0f40000000;
	@%p197 bra 	$L__BB1_93;

	mov.f32 	%f2838, 0f7FFFFFFF;

$L__BB1_93:
	abs.f32 	%f2761, %f142;
	add.f32 	%f1047, %f2761, 0f40000000;
	mov.b32 	%r305, %f1047;
	setp.lt.s32 	%p199, %r305, 2139095040;
	@%p199 bra 	$L__BB1_98;

	abs.f32 	%f2766, %f142;
	setp.gtu.f32 	%p200, %f2766, 0f7F800000;
	@%p200 bra 	$L__BB1_97;
	bra.uni 	$L__BB1_95;

$L__BB1_97:
	add.f32 	%f2838, %f142, 0f40000000;
	bra.uni 	$L__BB1_98;

$L__BB1_95:
	abs.f32 	%f2767, %f142;
	setp.neu.f32 	%p201, %f2767, 0f7F800000;
	@%p201 bra 	$L__BB1_98;

	selp.f32 	%f2838, 0fFF800000, 0f7F800000, %p20;

$L__BB1_98:
	mov.f32 	%f2695, 0f00000000;
	mov.f32 	%f2694, 0f3102E308;
	mov.f32 	%f2693, 0fBF317218;
	mov.f32 	%f2692, 0f35BFBE8E;
	mov.f32 	%f2691, 0f3F317200;
	mov.f32 	%f2690, 0f3DAAAABD;
	mov.f32 	%f2689, 0f3C4CAF63;
	mov.f32 	%f2688, 0f3B18F0FE;
	mov.f32 	%f2687, 0f32A57060;
	mov.f32 	%f2686, 0f4B400001;
	mov.f32 	%f2685, 0f437C0000;
	mov.f32 	%f2684, 0f3BBB989D;
	mov.f32 	%f2683, 0f3FB8AA3B;
	mov.f32 	%f2682, 0f3F000000;
	mul.f32 	%f1049, %f2838, 0fBF000000;
	setp.eq.f32 	%p202, %f142, 0f3F800000;
	selp.f32 	%f1050, 0fBF000000, %f1049, %p202;
	fma.rn.f32 	%f1053, %f1050, %f2684, %f2682;
	cvt.sat.f32.f32 	%f1056, %f1053;
	fma.rm.f32 	%f1058, %f1056, %f2685, %f2686;
	add.f32 	%f1059, %f1058, 0fCB40007F;
	neg.f32 	%f1060, %f1059;
	fma.rn.f32 	%f1061, %f1050, %f2683, %f1060;
	fma.rn.f32 	%f1063, %f1050, %f2687, %f1061;
	mov.b32 	%r306, %f1058;
	shl.b32 	%r307, %r306, 23;
	mov.b32 	%f1064, %r307;
	ex2.approx.ftz.f32 	%f1065, %f1063;
	mul.f32 	%f154, %f1065, %f1064;
	div.rn.f32 	%f155, %f119, %f2864;
	abs.f32 	%f156, %f155;
	setp.lt.f32 	%p203, %f156, 0f00800000;
	mul.f32 	%f1066, %f156, 0f4B800000;
	selp.f32 	%f1067, %f1066, %f156, %p203;
	selp.f32 	%f1068, 0fC3170000, 0fC2FE0000, %p203;
	mov.b32 	%r308, %f1067;
	and.b32  	%r309, %r308, 8388607;
	or.b32  	%r310, %r309, 1065353216;
	mov.b32 	%f1069, %r310;
	shr.u32 	%r311, %r308, 23;
	cvt.rn.f32.u32 	%f1070, %r311;
	add.f32 	%f1071, %f1068, %f1070;
	setp.gt.f32 	%p204, %f1069, 0f3FB504F3;
	mul.f32 	%f1072, %f1069, 0f3F000000;
	add.f32 	%f1073, %f1071, 0f3F800000;
	selp.f32 	%f1074, %f1073, %f1071, %p204;
	selp.f32 	%f1075, %f1072, %f1069, %p204;
	add.f32 	%f1076, %f1075, 0fBF800000;
	add.f32 	%f1077, %f1075, 0f3F800000;
	rcp.approx.ftz.f32 	%f1078, %f1077;
	add.f32 	%f1079, %f1076, %f1076;
	mul.f32 	%f1081, %f1079, %f1078;
	mul.f32 	%f1082, %f1081, %f1081;
	fma.rn.f32 	%f1085, %f2688, %f1082, %f2689;
	fma.rn.f32 	%f1087, %f1085, %f1082, %f2690;
	mul.rn.f32 	%f1088, %f1087, %f1082;
	mul.rn.f32 	%f1089, %f1088, %f1081;
	sub.f32 	%f1090, %f1076, %f1081;
	add.f32 	%f1091, %f1090, %f1090;
	neg.f32 	%f1092, %f1081;
	fma.rn.f32 	%f1093, %f1092, %f1076, %f1091;
	mul.rn.f32 	%f1094, %f1078, %f1093;
	add.f32 	%f1095, %f1089, %f1081;
	sub.f32 	%f1096, %f1081, %f1095;
	add.f32 	%f1097, %f1089, %f1096;
	add.f32 	%f1098, %f1094, %f1097;
	add.f32 	%f1099, %f1095, %f1098;
	sub.f32 	%f1100, %f1095, %f1099;
	add.f32 	%f1101, %f1098, %f1100;
	mul.rn.f32 	%f1103, %f1074, %f2691;
	mul.rn.f32 	%f1105, %f1074, %f2692;
	add.f32 	%f1106, %f1103, %f1099;
	sub.f32 	%f1107, %f1103, %f1106;
	add.f32 	%f1108, %f1099, %f1107;
	add.f32 	%f1109, %f1101, %f1108;
	add.f32 	%f1110, %f1105, %f1109;
	add.f32 	%f1111, %f1106, %f1110;
	sub.f32 	%f1112, %f1106, %f1111;
	add.f32 	%f1113, %f1110, %f1112;
	mul.rn.f32 	%f1114, %f576, %f1111;
	neg.f32 	%f1115, %f1114;
	fma.rn.f32 	%f1116, %f576, %f1111, %f1115;
	fma.rn.f32 	%f1117, %f576, %f1113, %f1116;
	fma.rn.f32 	%f1119, %f2695, %f1111, %f1117;
	add.rn.f32 	%f1120, %f1114, %f1119;
	neg.f32 	%f1121, %f1120;
	add.rn.f32 	%f1122, %f1114, %f1121;
	add.rn.f32 	%f1123, %f1122, %f1119;
	mov.b32 	%r312, %f1120;
	setp.eq.s32 	%p205, %r312, 1118925336;
	add.s32 	%r313, %r312, -1;
	mov.b32 	%f1124, %r313;
	add.f32 	%f1125, %f1123, 0f37000000;
	selp.f32 	%f157, %f1125, %f1123, %p205;
	selp.f32 	%f1126, %f1124, %f1120, %p205;
	mul.rn.f32 	%f1127, %f1126, %f2683;
	cvt.rzi.f32.f32 	%f1128, %f1127;
	abs.f32 	%f1129, %f1128;
	setp.gt.f32 	%p206, %f1129, 0f42FC0000;
	mov.b32 	%r314, %f1128;
	and.b32  	%r315, %r314, -2147483648;
	or.b32  	%r316, %r315, 1123811328;
	mov.b32 	%f1130, %r316;
	selp.f32 	%f1131, %f1130, %f1128, %p206;
	fma.rn.f32 	%f1133, %f1131, %f2693, %f1126;
	fma.rn.f32 	%f1135, %f1131, %f2694, %f1133;
	mul.f32 	%f1136, %f1135, 0f3FB8AA3B;
	add.f32 	%f1137, %f1131, 0f4B40007F;
	mov.b32 	%r317, %f1137;
	shl.b32 	%r318, %r317, 23;
	mov.b32 	%f1138, %r318;
	ex2.approx.ftz.f32 	%f1139, %f1136;
	mul.f32 	%f158, %f1139, %f1138;
	setp.eq.f32 	%p207, %f158, 0f7F800000;
	mov.f32 	%f2839, 0f7F800000;
	@%p207 bra 	$L__BB1_100;

	fma.rn.f32 	%f2839, %f158, %f157, %f158;

$L__BB1_100:
	setp.lt.f32 	%p208, %f155, 0f00000000;
	and.pred  	%p21, %p208, %p106;
	setp.eq.f32 	%p210, %f155, 0f00000000;
	@%p210 bra 	$L__BB1_104;
	bra.uni 	$L__BB1_101;

$L__BB1_104:
	add.f32 	%f1144, %f155, %f155;
	selp.f32 	%f2841, %f1144, 0f00000000, %p106;
	bra.uni 	$L__BB1_105;

$L__BB1_101:
	mov.b32 	%r319, %f2839;
	xor.b32  	%r320, %r319, -2147483648;
	mov.b32 	%f1140, %r320;
	selp.f32 	%f2841, %f1140, %f2839, %p21;
	setp.geu.f32 	%p211, %f155, 0f00000000;
	@%p211 bra 	$L__BB1_105;

	cvt.rzi.f32.f32 	%f1142, %f576;
	setp.eq.f32 	%p212, %f1142, 0f40000000;
	@%p212 bra 	$L__BB1_105;

	mov.f32 	%f2841, 0f7FFFFFFF;

$L__BB1_105:
	abs.f32 	%f2768, %f155;
	add.f32 	%f1145, %f2768, 0f40000000;
	mov.b32 	%r321, %f1145;
	setp.lt.s32 	%p214, %r321, 2139095040;
	@%p214 bra 	$L__BB1_110;

	abs.f32 	%f2769, %f155;
	setp.gtu.f32 	%p215, %f2769, 0f7F800000;
	@%p215 bra 	$L__BB1_109;
	bra.uni 	$L__BB1_107;

$L__BB1_109:
	add.f32 	%f2841, %f155, 0f40000000;
	bra.uni 	$L__BB1_110;

$L__BB1_107:
	abs.f32 	%f2770, %f155;
	setp.neu.f32 	%p216, %f2770, 0f7F800000;
	@%p216 bra 	$L__BB1_110;

	selp.f32 	%f2841, 0fFF800000, 0f7F800000, %p21;

$L__BB1_110:
	mov.f32 	%f2701, 0f32A57060;
	mov.f32 	%f2700, 0f4B400001;
	mov.f32 	%f2699, 0f437C0000;
	mov.f32 	%f2698, 0f3BBB989D;
	mov.f32 	%f2697, 0f3FB8AA3B;
	mov.f32 	%f2696, 0f3F000000;
	mul.f32 	%f1146, %f2841, 0fBF000000;
	setp.eq.f32 	%p217, %f155, 0f3F800000;
	selp.f32 	%f1147, 0fBF000000, %f1146, %p217;
	fma.rn.f32 	%f1150, %f1147, %f2698, %f2696;
	cvt.sat.f32.f32 	%f1153, %f1150;
	fma.rm.f32 	%f1155, %f1153, %f2699, %f2700;
	add.f32 	%f1156, %f1155, 0fCB40007F;
	neg.f32 	%f1157, %f1156;
	fma.rn.f32 	%f1158, %f1147, %f2697, %f1157;
	fma.rn.f32 	%f1160, %f1147, %f2701, %f1158;
	mov.b32 	%r322, %f1155;
	shl.b32 	%r323, %r322, 23;
	mov.b32 	%f1161, %r323;
	ex2.approx.ftz.f32 	%f1162, %f1160;
	mul.f32 	%f167, %f1162, %f1161;
	sub.f32 	%f1163, %f154, %f167;
	mul.f32 	%f1164, %f58, %f1163;
	mul.f32 	%f168, %f111, %f1164;
	mov.f64 	%fd513, %fd37;
	@%p176 bra 	$L__BB1_112;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r324}, %fd37;
	}
	xor.b32  	%r325, %r324, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r326, %temp}, %fd37;
	}
	mov.b64 	%fd513, {%r326, %r325};

$L__BB1_112:
	setp.eq.f32 	%p676, %f2864, 0f00000000;
	@%p676 bra 	$L__BB1_116;
	bra.uni 	$L__BB1_113;

$L__BB1_116:
	mov.u32 	%r327, 0;
	mov.b64 	%fd513, {%r327, %r56};
	bra.uni 	$L__BB1_117;

$L__BB1_113:
	setp.gt.s32 	%p220, %r53, -1;
	@%p220 bra 	$L__BB1_117;

	cvt.rzi.f64.f64 	%fd327, %fd309;
	setp.eq.f64 	%p221, %fd327, 0d4008000000000000;
	@%p221 bra 	$L__BB1_117;

	mov.f64 	%fd513, 0dFFF8000000000000;

$L__BB1_117:
	selp.f64 	%fd514, %fd513, %fd35, %p120;
	@%p14 bra 	$L__BB1_122;

	setp.eq.s32 	%p223, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r328, %temp}, %fd309;
	}
	setp.eq.s32 	%p224, %r328, 0;
	and.pred  	%p225, %p223, %p224;
	@%p225 bra 	$L__BB1_121;
	bra.uni 	$L__BB1_119;

$L__BB1_121:
	mov.u32 	%r332, 0;
	mov.b64 	%fd514, {%r332, %r59};
	bra.uni 	$L__BB1_122;

$L__BB1_119:
	and.b32  	%r329, %r53, 2147483647;
	setp.ne.s32 	%p226, %r329, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r330, %temp}, %fd307;
	}
	setp.ne.s32 	%p227, %r330, 0;
	or.pred  	%p228, %p226, %p227;
	mov.f64 	%fd514, %fd513;
	@%p228 bra 	$L__BB1_122;

	mov.u32 	%r331, 0;
	mov.b64 	%fd514, {%r331, %r62};

$L__BB1_122:
	cvt.rn.f32.s32 	%f2764, %r782;
	add.f32 	%f2763, %f2764, 0f3F000000;
	sub.f32 	%f2762, %f2763, %f2867;
	setp.eq.f32 	%p677, %f2864, 0f3F800000;
	selp.f64 	%fd331, 0d3FF0000000000000, %fd514, %p677;
	div.rn.f64 	%fd332, %fd34, %fd331;
	mul.f32 	%f1166, %f119, %f167;
	mul.f32 	%f1167, %f2762, %f154;
	sub.f32 	%f1168, %f1167, %f1166;
	cvt.f64.f32 	%fd333, %f1168;
	mul.f64 	%fd334, %fd332, %fd333;
	cvt.f64.f32 	%fd335, %f111;
	mul.f64 	%fd336, %fd334, %fd335;
	cvt.rn.f32.f64 	%f169, %fd336;
	setp.eq.f32 	%p230, %f92, 0f7F800000;
	mov.f32 	%f2842, 0f7F800000;
	@%p230 bra 	$L__BB1_124;

	fma.rn.f32 	%f2842, %f92, %f91, %f92;

$L__BB1_124:
	setp.geu.f32 	%p668, %f89, 0f00000000;
	setp.lt.f32 	%p667, %f89, 0f00000000;
	and.pred  	%p666, %p667, %p106;
	mov.b32 	%r333, %f2842;
	xor.b32  	%r334, %r333, -2147483648;
	mov.b32 	%f1169, %r334;
	selp.f32 	%f172, %f1169, %f2842, %p666;
	add.f32 	%f1170, %f89, %f89;
	selp.f32 	%f1171, %f1170, 0f00000000, %p106;
	setp.eq.f32 	%p232, %f89, 0f00000000;
	selp.f32 	%f2843, %f1171, %f172, %p232;
	@%p668 bra 	$L__BB1_127;

	cvt.rzi.f32.f32 	%f1173, %f576;
	setp.eq.f32 	%p233, %f1173, 0f40000000;
	mov.f32 	%f2843, %f172;
	@%p233 bra 	$L__BB1_127;

	mov.f32 	%f2843, 0f7FFFFFFF;

$L__BB1_127:
	abs.f32 	%f2708, %f89;
	setp.lt.f32 	%p670, %f89, 0f00000000;
	and.pred  	%p669, %p670, %p106;
	mov.f32 	%f2707, 0f32A57060;
	mov.f32 	%f2706, 0f4B400001;
	mov.f32 	%f2705, 0f437C0000;
	mov.f32 	%f2704, 0f3BBB989D;
	mov.f32 	%f2703, 0f3FB8AA3B;
	mov.f32 	%f2702, 0f3F000000;
	add.f32 	%f1176, %f2708, 0f40000000;
	mov.b32 	%r335, %f1176;
	setp.gt.s32 	%p234, %r335, 2139095039;
	add.f32 	%f1177, %f89, 0f40000000;
	setp.gtu.f32 	%p235, %f2708, 0f7F800000;
	mov.f32 	%f2844, 0f7F800000;
	selp.f32 	%f1178, %f1177, %f2843, %p235;
	selp.f32 	%f1179, 0fFF800000, 0f7F800000, %p669;
	setp.neu.f32 	%p236, %f2708, 0f7F800000;
	selp.f32 	%f1180, %f1178, %f1179, %p236;
	selp.f32 	%f1181, %f1180, %f2843, %p234;
	mul.f32 	%f1182, %f1181, 0fBF000000;
	setp.eq.f32 	%p237, %f89, 0f3F800000;
	selp.f32 	%f1183, 0fBF000000, %f1182, %p237;
	fma.rn.f32 	%f1186, %f1183, %f2704, %f2702;
	cvt.sat.f32.f32 	%f1189, %f1186;
	fma.rm.f32 	%f1191, %f1189, %f2705, %f2706;
	add.f32 	%f1192, %f1191, 0fCB40007F;
	neg.f32 	%f1193, %f1192;
	fma.rn.f32 	%f1194, %f1183, %f2703, %f1193;
	fma.rn.f32 	%f1196, %f1183, %f2707, %f1194;
	mov.b32 	%r336, %f1191;
	shl.b32 	%r337, %r336, 23;
	mov.b32 	%f1197, %r337;
	ex2.approx.ftz.f32 	%f1198, %f1196;
	mul.f32 	%f175, %f1198, %f1197;
	setp.eq.f32 	%p238, %f96, 0f7F800000;
	@%p238 bra 	$L__BB1_129;

	fma.rn.f32 	%f2844, %f96, %f95, %f96;

$L__BB1_129:
	setp.geu.f32 	%p673, %f93, 0f00000000;
	setp.lt.f32 	%p672, %f93, 0f00000000;
	and.pred  	%p671, %p672, %p106;
	mov.b32 	%r338, %f2844;
	xor.b32  	%r339, %r338, -2147483648;
	mov.b32 	%f1199, %r339;
	selp.f32 	%f178, %f1199, %f2844, %p671;
	add.f32 	%f1200, %f93, %f93;
	selp.f32 	%f1201, %f1200, 0f00000000, %p106;
	setp.eq.f32 	%p240, %f93, 0f00000000;
	selp.f32 	%f2845, %f1201, %f178, %p240;
	@%p673 bra 	$L__BB1_132;

	cvt.rzi.f32.f32 	%f1203, %f576;
	setp.eq.f32 	%p241, %f1203, 0f40000000;
	mov.f32 	%f2845, %f178;
	@%p241 bra 	$L__BB1_132;

	mov.f32 	%f2845, 0f7FFFFFFF;

$L__BB1_132:
	cvt.rn.f32.s32 	%f2717, %r781;
	sub.f32 	%f2716, %f2717, %f2868;
	abs.f32 	%f2715, %f93;
	setp.lt.f32 	%p675, %f93, 0f00000000;
	and.pred  	%p674, %p675, %p106;
	mov.f32 	%f2714, 0f32A57060;
	mov.f32 	%f2713, 0f4B400001;
	mov.f32 	%f2712, 0f437C0000;
	mov.f32 	%f2711, 0f3BBB989D;
	mov.f32 	%f2710, 0f3FB8AA3B;
	mov.f32 	%f2709, 0f3F000000;
	add.f32 	%f1205, %f2715, 0f40000000;
	mov.b32 	%r340, %f1205;
	setp.gt.s32 	%p242, %r340, 2139095039;
	add.f32 	%f1206, %f93, 0f40000000;
	setp.gtu.f32 	%p243, %f2715, 0f7F800000;
	selp.f32 	%f1207, %f1206, %f2845, %p243;
	selp.f32 	%f1208, 0fFF800000, 0f7F800000, %p674;
	setp.neu.f32 	%p244, %f2715, 0f7F800000;
	selp.f32 	%f1209, %f1207, %f1208, %p244;
	selp.f32 	%f1210, %f1209, %f2845, %p242;
	mul.f32 	%f1211, %f1210, 0fBF000000;
	setp.eq.f32 	%p245, %f93, 0f3F800000;
	selp.f32 	%f1212, 0fBF000000, %f1211, %p245;
	fma.rn.f32 	%f1215, %f1212, %f2711, %f2709;
	cvt.sat.f32.f32 	%f1218, %f1215;
	fma.rm.f32 	%f1220, %f1218, %f2712, %f2713;
	add.f32 	%f1221, %f1220, 0fCB40007F;
	neg.f32 	%f1222, %f1221;
	fma.rn.f32 	%f1223, %f1212, %f2710, %f1222;
	fma.rn.f32 	%f1225, %f1212, %f2714, %f1223;
	mov.b32 	%r341, %f1220;
	shl.b32 	%r342, %r341, 23;
	mov.b32 	%f1226, %r342;
	ex2.approx.ftz.f32 	%f1227, %f1225;
	mul.f32 	%f181, %f1227, %f1226;
	add.f32 	%f1228, %f2716, 0f3F800000;
	mul.f32 	%f1229, %f1228, %f175;
	mul.f32 	%f1230, %f2716, %f181;
	sub.f32 	%f1231, %f1229, %f1230;
	mul.f32 	%f1232, %f59, %f1231;
	mul.f32 	%f182, %f124, %f1232;
	not.pred 	%p246, %p9;
	mov.f64 	%fd516, %fd38;
	@%p246 bra 	$L__BB1_134;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r343}, %fd38;
	}
	xor.b32  	%r344, %r343, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r345, %temp}, %fd38;
	}
	mov.b64 	%fd516, {%r345, %r344};

$L__BB1_134:
	setp.eq.f32 	%p678, %f2864, 0f00000000;
	@%p678 bra 	$L__BB1_138;
	bra.uni 	$L__BB1_135;

$L__BB1_138:
	mov.u32 	%r346, 0;
	mov.b64 	%fd516, {%r346, %r63};
	bra.uni 	$L__BB1_139;

$L__BB1_135:
	setp.gt.s32 	%p248, %r53, -1;
	@%p248 bra 	$L__BB1_139;

	mov.f64 	%fd483, 0d4014000000000000;
	cvt.rzi.f64.f64 	%fd338, %fd483;
	setp.eq.f64 	%p249, %fd338, 0d4014000000000000;
	@%p249 bra 	$L__BB1_139;

	mov.f64 	%fd516, 0dFFF8000000000000;

$L__BB1_139:
	cvt.f64.f32 	%fd479, %f2864;
	add.f64 	%fd478, %fd477, 0d4014000000000000;
	selp.f64 	%fd517, %fd516, %fd478, %p139;
	@%p17 bra 	$L__BB1_144;

	mov.f64 	%fd480, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r767}, %fd480;
	}
	and.b32  	%r766, %r767, 2147483647;
	setp.eq.s32 	%p251, %r766, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r347, %temp}, %fd480;
	}
	setp.eq.s32 	%p252, %r347, 0;
	and.pred  	%p253, %p251, %p252;
	@%p253 bra 	$L__BB1_143;
	bra.uni 	$L__BB1_141;

$L__BB1_143:
	mov.u32 	%r351, 0;
	mov.b64 	%fd517, {%r351, %r67};
	bra.uni 	$L__BB1_144;

$L__BB1_141:
	and.b32  	%r348, %r53, 2147483647;
	setp.ne.s32 	%p254, %r348, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r349, %temp}, %fd307;
	}
	setp.ne.s32 	%p255, %r349, 0;
	or.pred  	%p256, %p254, %p255;
	mov.f64 	%fd517, %fd516;
	@%p256 bra 	$L__BB1_144;

	mov.u32 	%r350, 0;
	mov.b64 	%fd517, {%r350, %r69};

$L__BB1_144:
	setp.eq.f32 	%p679, %f2864, 0f3F800000;
	selp.f64 	%fd344, 0d3FF0000000000000, %fd517, %p679;
	div.rn.f64 	%fd70, %fd36, %fd344;
	not.pred 	%p258, %p10;
	mov.f64 	%fd519, %fd40;
	@%p258 bra 	$L__BB1_146;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r352}, %fd40;
	}
	xor.b32  	%r353, %r352, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r354, %temp}, %fd40;
	}
	mov.b64 	%fd519, {%r354, %r353};

$L__BB1_146:
	cvt.rn.f32.s32 	%f2720, %r781;
	sub.f32 	%f2719, %f2720, %f2868;
	add.f32 	%f2718, %f2719, 0f3F000000;
	setp.eq.f32 	%p259, %f2718, 0f00000000;
	@%p259 bra 	$L__BB1_150;
	bra.uni 	$L__BB1_147;

$L__BB1_150:
	mov.u32 	%r355, 0;
	selp.b32 	%r357, %r65, 0, %p117;
	or.b32  	%r358, %r357, 2146435072;
	selp.b32 	%r359, %r358, %r357, %p119;
	mov.b64 	%fd519, {%r355, %r359};
	bra.uni 	$L__BB1_151;

$L__BB1_147:
	setp.gt.s32 	%p260, %r65, -1;
	@%p260 bra 	$L__BB1_151;

	cvt.rzi.f64.f64 	%fd346, %fd309;
	setp.eq.f64 	%p261, %fd346, 0d4008000000000000;
	@%p261 bra 	$L__BB1_151;

	mov.f64 	%fd519, 0dFFF8000000000000;

$L__BB1_151:
	selp.f64 	%fd520, %fd519, %fd41, %p141;
	@%p18 bra 	$L__BB1_156;

	setp.eq.s32 	%p265, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r360, %temp}, %fd309;
	}
	setp.eq.s32 	%p266, %r360, 0;
	and.pred  	%p267, %p265, %p266;
	@%p267 bra 	$L__BB1_155;
	bra.uni 	$L__BB1_153;

$L__BB1_155:
	mov.u32 	%r367, 0;
	mov.b64 	%fd520, {%r367, %r71};
	bra.uni 	$L__BB1_156;

$L__BB1_153:
	cvt.rn.f32.s32 	%f2723, %r781;
	sub.f32 	%f2722, %f2723, %f2868;
	add.f32 	%f2721, %f2722, 0f3F000000;
	cvt.f64.f32 	%fd481, %f2721;
	and.b32  	%r361, %r65, 2147483647;
	setp.ne.s32 	%p268, %r361, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r362, %temp}, %fd481;
	}
	setp.ne.s32 	%p269, %r362, 0;
	or.pred  	%p270, %p268, %p269;
	mov.f64 	%fd520, %fd519;
	@%p270 bra 	$L__BB1_156;

	and.pred  	%p272, %p125, %p10;
	selp.b32 	%r365, %r61, %r60, %p272;
	mov.u32 	%r366, 0;
	mov.b64 	%fd520, {%r366, %r365};

$L__BB1_156:
	cvt.rn.f32.s32 	%f2726, %r781;
	sub.f32 	%f2725, %f2726, %f2868;
	add.f32 	%f2724, %f2725, 0f3F000000;
	setp.eq.f32 	%p273, %f2724, 0f3F800000;
	selp.f64 	%fd349, 0d3FF0000000000000, %fd520, %p273;
	cvt.f64.f32 	%fd350, %f175;
	mul.f64 	%fd79, %fd349, %fd350;
	not.pred 	%p274, %p11;
	mov.f64 	%fd522, %fd43;
	@%p274 bra 	$L__BB1_158;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r368}, %fd43;
	}
	xor.b32  	%r369, %r368, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r370, %temp}, %fd43;
	}
	mov.b64 	%fd522, {%r370, %r369};

$L__BB1_158:
	setp.eq.f32 	%p275, %f76, 0f00000000;
	@%p275 bra 	$L__BB1_162;
	bra.uni 	$L__BB1_159;

$L__BB1_162:
	mov.u32 	%r371, 0;
	selp.b32 	%r373, %r70, 0, %p117;
	or.b32  	%r374, %r373, 2146435072;
	selp.b32 	%r375, %r374, %r373, %p119;
	mov.b64 	%fd522, {%r371, %r375};
	bra.uni 	$L__BB1_163;

$L__BB1_159:
	setp.gt.s32 	%p276, %r70, -1;
	@%p276 bra 	$L__BB1_163;

	cvt.rzi.f64.f64 	%fd352, %fd309;
	setp.eq.f64 	%p277, %fd352, 0d4008000000000000;
	@%p277 bra 	$L__BB1_163;

	mov.f64 	%fd522, 0dFFF8000000000000;

$L__BB1_163:
	selp.f64 	%fd523, %fd522, %fd44, %p149;
	@%p19 bra 	$L__BB1_168;

	setp.eq.s32 	%p281, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r376, %temp}, %fd309;
	}
	setp.eq.s32 	%p282, %r376, 0;
	and.pred  	%p283, %p281, %p282;
	@%p283 bra 	$L__BB1_167;
	bra.uni 	$L__BB1_165;

$L__BB1_167:
	mov.u32 	%r383, 0;
	mov.b64 	%fd523, {%r383, %r73};
	bra.uni 	$L__BB1_168;

$L__BB1_165:
	cvt.rn.f32.s32 	%f2729, %r781;
	sub.f32 	%f2728, %f2729, %f2868;
	add.f32 	%f2727, %f2728, 0fBF000000;
	cvt.f64.f32 	%fd482, %f2727;
	and.b32  	%r377, %r70, 2147483647;
	setp.ne.s32 	%p284, %r377, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r378, %temp}, %fd482;
	}
	setp.ne.s32 	%p285, %r378, 0;
	or.pred  	%p286, %p284, %p285;
	mov.f64 	%fd523, %fd522;
	@%p286 bra 	$L__BB1_168;

	and.pred  	%p288, %p125, %p11;
	selp.b32 	%r381, %r61, %r60, %p288;
	mov.u32 	%r382, 0;
	mov.b64 	%fd523, {%r382, %r381};

$L__BB1_168:
	cvt.f64.f32 	%fd484, %f124;
	cvt.rn.f32.s32 	%f2765, %r782;
	mov.f32 	%f2738, 0f00000000;
	mov.f32 	%f2737, 0f3102E308;
	mov.f32 	%f2736, 0fBF317218;
	mov.f32 	%f2735, 0f35BFBE8E;
	mov.f32 	%f2734, 0f3F317200;
	mov.f32 	%f2733, 0f3DAAAABD;
	mov.f32 	%f2732, 0f3C4CAF63;
	mov.f32 	%f2731, 0f3B18F0FE;
	mov.f32 	%f2730, 0f3FB8AA3B;
	setp.eq.f32 	%p289, %f76, 0f3F800000;
	selp.f64 	%fd355, 0d3FF0000000000000, %fd523, %p289;
	cvt.f64.f32 	%fd356, %f181;
	mul.f64 	%fd357, %fd355, %fd356;
	sub.f64 	%fd358, %fd79, %fd357;
	mul.f64 	%fd359, %fd70, %fd358;
	mul.f64 	%fd360, %fd359, %fd484;
	mul.f32 	%f1234, %f60, %f182;
	cvt.f64.f32 	%fd361, %f1234;
	sub.f64 	%fd362, %fd361, %fd360;
	cvt.rn.f32.f64 	%f183, %fd362;
	add.f32 	%f1235, %f2765, 0f3F800000;
	sub.f32 	%f1236, %f1235, %f2867;
	div.rn.f32 	%f184, %f1236, %f2864;
	abs.f32 	%f185, %f184;
	setp.lt.f32 	%p290, %f185, 0f00800000;
	mul.f32 	%f1237, %f185, 0f4B800000;
	selp.f32 	%f1238, %f1237, %f185, %p290;
	selp.f32 	%f1239, 0fC3170000, 0fC2FE0000, %p290;
	mov.b32 	%r384, %f1238;
	and.b32  	%r385, %r384, 8388607;
	or.b32  	%r386, %r385, 1065353216;
	mov.b32 	%f1240, %r386;
	shr.u32 	%r387, %r384, 23;
	cvt.rn.f32.u32 	%f1241, %r387;
	add.f32 	%f1242, %f1239, %f1241;
	setp.gt.f32 	%p291, %f1240, 0f3FB504F3;
	mul.f32 	%f1243, %f1240, 0f3F000000;
	add.f32 	%f1244, %f1242, 0f3F800000;
	selp.f32 	%f1245, %f1244, %f1242, %p291;
	selp.f32 	%f1246, %f1243, %f1240, %p291;
	add.f32 	%f1247, %f1246, 0fBF800000;
	add.f32 	%f1248, %f1246, 0f3F800000;
	rcp.approx.ftz.f32 	%f1249, %f1248;
	add.f32 	%f1250, %f1247, %f1247;
	mul.f32 	%f1252, %f1250, %f1249;
	mul.f32 	%f1253, %f1252, %f1252;
	fma.rn.f32 	%f1256, %f2731, %f1253, %f2732;
	fma.rn.f32 	%f1258, %f1256, %f1253, %f2733;
	mul.rn.f32 	%f1259, %f1258, %f1253;
	mul.rn.f32 	%f1260, %f1259, %f1252;
	sub.f32 	%f1261, %f1247, %f1252;
	add.f32 	%f1262, %f1261, %f1261;
	neg.f32 	%f1263, %f1252;
	fma.rn.f32 	%f1264, %f1263, %f1247, %f1262;
	mul.rn.f32 	%f1265, %f1249, %f1264;
	add.f32 	%f1266, %f1260, %f1252;
	sub.f32 	%f1267, %f1252, %f1266;
	add.f32 	%f1268, %f1260, %f1267;
	add.f32 	%f1269, %f1265, %f1268;
	add.f32 	%f1270, %f1266, %f1269;
	sub.f32 	%f1271, %f1266, %f1270;
	add.f32 	%f1272, %f1269, %f1271;
	mul.rn.f32 	%f1274, %f1245, %f2734;
	mul.rn.f32 	%f1276, %f1245, %f2735;
	add.f32 	%f1277, %f1274, %f1270;
	sub.f32 	%f1278, %f1274, %f1277;
	add.f32 	%f1279, %f1270, %f1278;
	add.f32 	%f1280, %f1272, %f1279;
	add.f32 	%f1281, %f1276, %f1280;
	add.f32 	%f1282, %f1277, %f1281;
	sub.f32 	%f1283, %f1277, %f1282;
	add.f32 	%f1284, %f1281, %f1283;
	mul.rn.f32 	%f1285, %f576, %f1282;
	neg.f32 	%f1286, %f1285;
	fma.rn.f32 	%f1287, %f576, %f1282, %f1286;
	fma.rn.f32 	%f1288, %f576, %f1284, %f1287;
	fma.rn.f32 	%f1290, %f2738, %f1282, %f1288;
	add.rn.f32 	%f1291, %f1285, %f1290;
	neg.f32 	%f1292, %f1291;
	add.rn.f32 	%f1293, %f1285, %f1292;
	add.rn.f32 	%f1294, %f1293, %f1290;
	mov.b32 	%r388, %f1291;
	setp.eq.s32 	%p292, %r388, 1118925336;
	add.s32 	%r389, %r388, -1;
	mov.b32 	%f1295, %r389;
	add.f32 	%f1296, %f1294, 0f37000000;
	selp.f32 	%f186, %f1296, %f1294, %p292;
	selp.f32 	%f1297, %f1295, %f1291, %p292;
	mul.rn.f32 	%f1299, %f1297, %f2730;
	cvt.rzi.f32.f32 	%f1300, %f1299;
	abs.f32 	%f1301, %f1300;
	setp.gt.f32 	%p293, %f1301, 0f42FC0000;
	mov.b32 	%r390, %f1300;
	and.b32  	%r391, %r390, -2147483648;
	or.b32  	%r392, %r391, 1123811328;
	mov.b32 	%f1302, %r392;
	selp.f32 	%f1303, %f1302, %f1300, %p293;
	fma.rn.f32 	%f1305, %f1303, %f2736, %f1297;
	fma.rn.f32 	%f1307, %f1303, %f2737, %f1305;
	mul.f32 	%f1308, %f1307, 0f3FB8AA3B;
	add.f32 	%f1309, %f1303, 0f4B40007F;
	mov.b32 	%r393, %f1309;
	shl.b32 	%r394, %r393, 23;
	mov.b32 	%f1310, %r394;
	ex2.approx.ftz.f32 	%f1311, %f1308;
	mul.f32 	%f187, %f1311, %f1310;
	setp.eq.f32 	%p294, %f187, 0f7F800000;
	mov.f32 	%f2846, 0f7F800000;
	@%p294 bra 	$L__BB1_170;

	fma.rn.f32 	%f2846, %f187, %f186, %f187;

$L__BB1_170:
	setp.lt.f32 	%p295, %f184, 0f00000000;
	and.pred  	%p22, %p295, %p106;
	setp.eq.f32 	%p297, %f184, 0f00000000;
	@%p297 bra 	$L__BB1_174;
	bra.uni 	$L__BB1_171;

$L__BB1_174:
	add.f32 	%f1316, %f184, %f184;
	selp.f32 	%f2848, %f1316, 0f00000000, %p106;
	bra.uni 	$L__BB1_175;

$L__BB1_171:
	mov.b32 	%r395, %f2846;
	xor.b32  	%r396, %r395, -2147483648;
	mov.b32 	%f1312, %r396;
	selp.f32 	%f2848, %f1312, %f2846, %p22;
	setp.geu.f32 	%p298, %f184, 0f00000000;
	@%p298 bra 	$L__BB1_175;

	cvt.rzi.f32.f32 	%f1314, %f576;
	setp.eq.f32 	%p299, %f1314, 0f40000000;
	@%p299 bra 	$L__BB1_175;

	mov.f32 	%f2848, 0f7FFFFFFF;

$L__BB1_175:
	abs.f32 	%f2771, %f184;
	add.f32 	%f1317, %f2771, 0f40000000;
	mov.b32 	%r397, %f1317;
	setp.lt.s32 	%p301, %r397, 2139095040;
	@%p301 bra 	$L__BB1_180;

	abs.f32 	%f2772, %f184;
	setp.gtu.f32 	%p302, %f2772, 0f7F800000;
	@%p302 bra 	$L__BB1_179;
	bra.uni 	$L__BB1_177;

$L__BB1_179:
	add.f32 	%f2848, %f184, 0f40000000;
	bra.uni 	$L__BB1_180;

$L__BB1_177:
	abs.f32 	%f2773, %f184;
	setp.neu.f32 	%p303, %f2773, 0f7F800000;
	@%p303 bra 	$L__BB1_180;

	selp.f32 	%f2848, 0fFF800000, 0f7F800000, %p22;

$L__BB1_180:
	mov.f32 	%f2754, 0f00000000;
	mov.f32 	%f2753, 0f3102E308;
	mov.f32 	%f2752, 0fBF317218;
	mov.f32 	%f2751, 0f35BFBE8E;
	mov.f32 	%f2750, 0f3F317200;
	mov.f32 	%f2749, 0f3DAAAABD;
	mov.f32 	%f2748, 0f3C4CAF63;
	mov.f32 	%f2747, 0f3B18F0FE;
	mov.f32 	%f2746, 0f32A57060;
	mov.f32 	%f2745, 0f4B400001;
	mov.f32 	%f2744, 0f437C0000;
	mov.f32 	%f2743, 0f3BBB989D;
	mov.f32 	%f2742, 0f3FB8AA3B;
	mov.f32 	%f2741, 0f3F000000;
	cvt.rn.f32.s32 	%f2740, %r782;
	sub.f32 	%f2739, %f2740, %f2867;
	mul.f32 	%f1319, %f2848, 0fBF000000;
	setp.eq.f32 	%p304, %f184, 0f3F800000;
	selp.f32 	%f1320, 0fBF000000, %f1319, %p304;
	fma.rn.f32 	%f1323, %f1320, %f2743, %f2741;
	cvt.sat.f32.f32 	%f1326, %f1323;
	fma.rm.f32 	%f1328, %f1326, %f2744, %f2745;
	add.f32 	%f1329, %f1328, 0fCB40007F;
	neg.f32 	%f1330, %f1329;
	fma.rn.f32 	%f1331, %f1320, %f2742, %f1330;
	fma.rn.f32 	%f1333, %f1320, %f2746, %f1331;
	mov.b32 	%r398, %f1328;
	shl.b32 	%r399, %r398, 23;
	mov.b32 	%f1334, %r399;
	ex2.approx.ftz.f32 	%f1335, %f1333;
	mul.f32 	%f196, %f1335, %f1334;
	div.rn.f32 	%f197, %f2739, %f2864;
	abs.f32 	%f198, %f197;
	setp.lt.f32 	%p305, %f198, 0f00800000;
	mul.f32 	%f1336, %f198, 0f4B800000;
	selp.f32 	%f1337, %f1336, %f198, %p305;
	selp.f32 	%f1338, 0fC3170000, 0fC2FE0000, %p305;
	mov.b32 	%r400, %f1337;
	and.b32  	%r401, %r400, 8388607;
	or.b32  	%r402, %r401, 1065353216;
	mov.b32 	%f1339, %r402;
	shr.u32 	%r403, %r400, 23;
	cvt.rn.f32.u32 	%f1340, %r403;
	add.f32 	%f1341, %f1338, %f1340;
	setp.gt.f32 	%p306, %f1339, 0f3FB504F3;
	mul.f32 	%f1342, %f1339, 0f3F000000;
	add.f32 	%f1343, %f1341, 0f3F800000;
	selp.f32 	%f1344, %f1343, %f1341, %p306;
	selp.f32 	%f1345, %f1342, %f1339, %p306;
	add.f32 	%f1346, %f1345, 0fBF800000;
	add.f32 	%f1347, %f1345, 0f3F800000;
	rcp.approx.ftz.f32 	%f1348, %f1347;
	add.f32 	%f1349, %f1346, %f1346;
	mul.f32 	%f1351, %f1349, %f1348;
	mul.f32 	%f1352, %f1351, %f1351;
	fma.rn.f32 	%f1355, %f2747, %f1352, %f2748;
	fma.rn.f32 	%f1357, %f1355, %f1352, %f2749;
	mul.rn.f32 	%f1358, %f1357, %f1352;
	mul.rn.f32 	%f1359, %f1358, %f1351;
	sub.f32 	%f1360, %f1346, %f1351;
	add.f32 	%f1361, %f1360, %f1360;
	neg.f32 	%f1362, %f1351;
	fma.rn.f32 	%f1363, %f1362, %f1346, %f1361;
	mul.rn.f32 	%f1364, %f1348, %f1363;
	add.f32 	%f1365, %f1359, %f1351;
	sub.f32 	%f1366, %f1351, %f1365;
	add.f32 	%f1367, %f1359, %f1366;
	add.f32 	%f1368, %f1364, %f1367;
	add.f32 	%f1369, %f1365, %f1368;
	sub.f32 	%f1370, %f1365, %f1369;
	add.f32 	%f1371, %f1368, %f1370;
	mul.rn.f32 	%f1373, %f1344, %f2750;
	mul.rn.f32 	%f1375, %f1344, %f2751;
	add.f32 	%f1376, %f1373, %f1369;
	sub.f32 	%f1377, %f1373, %f1376;
	add.f32 	%f1378, %f1369, %f1377;
	add.f32 	%f1379, %f1371, %f1378;
	add.f32 	%f1380, %f1375, %f1379;
	add.f32 	%f1381, %f1376, %f1380;
	sub.f32 	%f1382, %f1376, %f1381;
	add.f32 	%f1383, %f1380, %f1382;
	mul.rn.f32 	%f1384, %f576, %f1381;
	neg.f32 	%f1385, %f1384;
	fma.rn.f32 	%f1386, %f576, %f1381, %f1385;
	fma.rn.f32 	%f1387, %f576, %f1383, %f1386;
	fma.rn.f32 	%f1389, %f2754, %f1381, %f1387;
	add.rn.f32 	%f1390, %f1384, %f1389;
	neg.f32 	%f1391, %f1390;
	add.rn.f32 	%f1392, %f1384, %f1391;
	add.rn.f32 	%f1393, %f1392, %f1389;
	mov.b32 	%r404, %f1390;
	setp.eq.s32 	%p307, %r404, 1118925336;
	add.s32 	%r405, %r404, -1;
	mov.b32 	%f1394, %r405;
	add.f32 	%f1395, %f1393, 0f37000000;
	selp.f32 	%f199, %f1395, %f1393, %p307;
	selp.f32 	%f1396, %f1394, %f1390, %p307;
	mul.rn.f32 	%f1397, %f1396, %f2742;
	cvt.rzi.f32.f32 	%f1398, %f1397;
	abs.f32 	%f1399, %f1398;
	setp.gt.f32 	%p308, %f1399, 0f42FC0000;
	mov.b32 	%r406, %f1398;
	and.b32  	%r407, %r406, -2147483648;
	or.b32  	%r408, %r407, 1123811328;
	mov.b32 	%f1400, %r408;
	selp.f32 	%f1401, %f1400, %f1398, %p308;
	fma.rn.f32 	%f1403, %f1401, %f2752, %f1396;
	fma.rn.f32 	%f1405, %f1401, %f2753, %f1403;
	mul.f32 	%f1406, %f1405, 0f3FB8AA3B;
	add.f32 	%f1407, %f1401, 0f4B40007F;
	mov.b32 	%r409, %f1407;
	shl.b32 	%r410, %r409, 23;
	mov.b32 	%f1408, %r410;
	ex2.approx.ftz.f32 	%f1409, %f1406;
	mul.f32 	%f200, %f1409, %f1408;
	setp.eq.f32 	%p309, %f200, 0f7F800000;
	mov.f32 	%f2849, 0f7F800000;
	@%p309 bra 	$L__BB1_182;

	fma.rn.f32 	%f2849, %f200, %f199, %f200;

$L__BB1_182:
	setp.lt.f32 	%p310, %f197, 0f00000000;
	and.pred  	%p23, %p310, %p106;
	setp.eq.f32 	%p312, %f197, 0f00000000;
	@%p312 bra 	$L__BB1_186;
	bra.uni 	$L__BB1_183;

$L__BB1_186:
	add.f32 	%f1414, %f197, %f197;
	selp.f32 	%f2851, %f1414, 0f00000000, %p106;
	bra.uni 	$L__BB1_187;

$L__BB1_183:
	mov.b32 	%r411, %f2849;
	xor.b32  	%r412, %r411, -2147483648;
	mov.b32 	%f1410, %r412;
	selp.f32 	%f2851, %f1410, %f2849, %p23;
	setp.geu.f32 	%p313, %f197, 0f00000000;
	@%p313 bra 	$L__BB1_187;

	cvt.rzi.f32.f32 	%f1412, %f576;
	setp.eq.f32 	%p314, %f1412, 0f40000000;
	@%p314 bra 	$L__BB1_187;

	mov.f32 	%f2851, 0f7FFFFFFF;

$L__BB1_187:
	abs.f32 	%f2636, %f197;
	add.f32 	%f1415, %f2636, 0f40000000;
	mov.b32 	%r413, %f1415;
	setp.lt.s32 	%p316, %r413, 2139095040;
	@%p316 bra 	$L__BB1_192;

	abs.f32 	%f2759, %f197;
	setp.gtu.f32 	%p317, %f2759, 0f7F800000;
	@%p317 bra 	$L__BB1_191;
	bra.uni 	$L__BB1_189;

$L__BB1_191:
	add.f32 	%f2851, %f197, 0f40000000;
	bra.uni 	$L__BB1_192;

$L__BB1_189:
	abs.f32 	%f2760, %f197;
	setp.neu.f32 	%p318, %f2760, 0f7F800000;
	@%p318 bra 	$L__BB1_192;

	selp.f32 	%f2851, 0fFF800000, 0f7F800000, %p23;

$L__BB1_192:
	mov.f32 	%f2644, 0f32A57060;
	mov.f32 	%f2643, 0f4B400001;
	mov.f32 	%f2642, 0f437C0000;
	mov.f32 	%f2641, 0f3BBB989D;
	mov.f32 	%f2640, 0f3FB8AA3B;
	mov.f32 	%f2639, 0f3F000000;
	cvt.rn.f32.s32 	%f2638, %r782;
	sub.f32 	%f2637, %f2638, %f2867;
	mul.f32 	%f1416, %f2851, 0fBF000000;
	setp.eq.f32 	%p319, %f197, 0f3F800000;
	selp.f32 	%f1417, 0fBF000000, %f1416, %p319;
	fma.rn.f32 	%f1420, %f1417, %f2641, %f2639;
	cvt.sat.f32.f32 	%f1423, %f1420;
	fma.rm.f32 	%f1425, %f1423, %f2642, %f2643;
	add.f32 	%f1426, %f1425, 0fCB40007F;
	neg.f32 	%f1427, %f1426;
	fma.rn.f32 	%f1428, %f1417, %f2640, %f1427;
	fma.rn.f32 	%f1430, %f1417, %f2644, %f1428;
	mov.b32 	%r414, %f1425;
	shl.b32 	%r415, %r414, 23;
	mov.b32 	%f1431, %r415;
	ex2.approx.ftz.f32 	%f1432, %f1430;
	mul.f32 	%f209, %f1432, %f1431;
	add.f32 	%f1433, %f2637, 0f3F800000;
	mul.f32 	%f1434, %f1433, %f196;
	mul.f32 	%f1435, %f2637, %f209;
	sub.f32 	%f210, %f1434, %f1435;
	cvt.f64.f32 	%fd363, %f114;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd363;
	}
	abs.f64 	%fd88, %fd363;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd88;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd525, [retval0+0];
	} // callseq 15
	setp.lt.s32 	%p320, %r79, 0;
	and.pred  	%p24, %p320, %p117;
	not.pred 	%p322, %p24;
	@%p322 bra 	$L__BB1_194;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r416}, %fd525;
	}
	xor.b32  	%r417, %r416, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r418, %temp}, %fd525;
	}
	mov.b64 	%fd525, {%r418, %r417};

$L__BB1_194:
	setp.eq.f32 	%p323, %f114, 0f00000000;
	@%p323 bra 	$L__BB1_198;
	bra.uni 	$L__BB1_195;

$L__BB1_198:
	mov.u32 	%r419, 0;
	selp.b32 	%r420, %r79, 0, %p117;
	or.b32  	%r421, %r420, 2146435072;
	selp.b32 	%r422, %r421, %r420, %p119;
	mov.b64 	%fd525, {%r419, %r422};
	bra.uni 	$L__BB1_199;

$L__BB1_195:
	setp.gt.s32 	%p324, %r79, -1;
	@%p324 bra 	$L__BB1_199;

	cvt.rzi.f64.f64 	%fd366, %fd309;
	setp.eq.f64 	%p325, %fd366, 0d4008000000000000;
	@%p325 bra 	$L__BB1_199;

	mov.f64 	%fd525, 0dFFF8000000000000;

$L__BB1_199:
	add.f64 	%fd94, %fd363, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r423}, %fd94;
	}
	and.b32  	%r424, %r423, 2146435072;
	setp.ne.s32 	%p328, %r424, 2146435072;
	mov.f64 	%fd526, %fd525;
	@%p328 bra 	$L__BB1_205;

	setp.gtu.f64 	%p329, %fd88, 0d7FF0000000000000;
	mov.f64 	%fd526, %fd94;
	@%p329 bra 	$L__BB1_205;

	setp.eq.s32 	%p330, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r425, %temp}, %fd309;
	}
	setp.eq.s32 	%p331, %r425, 0;
	and.pred  	%p332, %p330, %p331;
	@%p332 bra 	$L__BB1_204;
	bra.uni 	$L__BB1_202;

$L__BB1_204:
	mov.u32 	%r430, 0;
	setp.gt.f64 	%p339, %fd88, 0d3FF0000000000000;
	selp.b32 	%r431, 2146435072, 0, %p339;
	xor.b32  	%r432, %r431, 2146435072;
	selp.b32 	%r433, %r432, %r431, %p119;
	setp.eq.f32 	%p340, %f114, 0fBF800000;
	selp.b32 	%r434, 1072693248, %r433, %p340;
	mov.b64 	%fd526, {%r430, %r434};
	bra.uni 	$L__BB1_205;

$L__BB1_202:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r426, %temp}, %fd363;
	}
	and.b32  	%r427, %r79, 2147483647;
	setp.ne.s32 	%p333, %r427, 2146435072;
	setp.ne.s32 	%p334, %r426, 0;
	or.pred  	%p335, %p333, %p334;
	mov.f64 	%fd526, %fd525;
	@%p335 bra 	$L__BB1_205;

	and.pred  	%p337, %p125, %p24;
	selp.b32 	%r428, %r61, %r60, %p337;
	mov.u32 	%r429, 0;
	mov.b64 	%fd526, {%r429, %r428};

$L__BB1_205:
	mul.f32 	%f1436, %f59, %f210;
	mul.f32 	%f211, %f111, %f1436;
	setp.eq.f32 	%p341, %f114, 0f3F800000;
	selp.f64 	%fd371, 0d3FF0000000000000, %fd526, %p341;
	cvt.f64.f32 	%fd372, %f196;
	mul.f64 	%fd98, %fd371, %fd372;
	cvt.f64.f32 	%fd99, %f119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd99;
	}
	abs.f64 	%fd100, %fd99;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd100;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd528, [retval0+0];
	} // callseq 16
	setp.lt.s32 	%p342, %r80, 0;
	and.pred  	%p25, %p342, %p117;
	not.pred 	%p344, %p25;
	@%p344 bra 	$L__BB1_207;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r435}, %fd528;
	}
	xor.b32  	%r436, %r435, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r437, %temp}, %fd528;
	}
	mov.b64 	%fd528, {%r437, %r436};

$L__BB1_207:
	setp.eq.f32 	%p345, %f119, 0f00000000;
	@%p345 bra 	$L__BB1_211;
	bra.uni 	$L__BB1_208;

$L__BB1_211:
	mov.u32 	%r438, 0;
	selp.b32 	%r439, %r80, 0, %p117;
	or.b32  	%r440, %r439, 2146435072;
	selp.b32 	%r441, %r440, %r439, %p119;
	mov.b64 	%fd528, {%r438, %r441};
	bra.uni 	$L__BB1_212;

$L__BB1_208:
	setp.gt.s32 	%p346, %r80, -1;
	@%p346 bra 	$L__BB1_212;

	cvt.rzi.f64.f64 	%fd375, %fd309;
	setp.eq.f64 	%p347, %fd375, 0d4008000000000000;
	@%p347 bra 	$L__BB1_212;

	mov.f64 	%fd528, 0dFFF8000000000000;

$L__BB1_212:
	add.f64 	%fd106, %fd99, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r442}, %fd106;
	}
	and.b32  	%r443, %r442, 2146435072;
	setp.ne.s32 	%p350, %r443, 2146435072;
	mov.f64 	%fd529, %fd528;
	@%p350 bra 	$L__BB1_218;

	setp.gtu.f64 	%p351, %fd100, 0d7FF0000000000000;
	mov.f64 	%fd529, %fd106;
	@%p351 bra 	$L__BB1_218;

	setp.eq.s32 	%p352, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r444, %temp}, %fd309;
	}
	setp.eq.s32 	%p353, %r444, 0;
	and.pred  	%p354, %p352, %p353;
	@%p354 bra 	$L__BB1_217;
	bra.uni 	$L__BB1_215;

$L__BB1_217:
	mov.u32 	%r449, 0;
	setp.gt.f64 	%p361, %fd100, 0d3FF0000000000000;
	selp.b32 	%r450, 2146435072, 0, %p361;
	xor.b32  	%r451, %r450, 2146435072;
	selp.b32 	%r452, %r451, %r450, %p119;
	setp.eq.f32 	%p362, %f119, 0fBF800000;
	selp.b32 	%r453, 1072693248, %r452, %p362;
	mov.b64 	%fd529, {%r449, %r453};
	bra.uni 	$L__BB1_218;

$L__BB1_215:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r445, %temp}, %fd99;
	}
	and.b32  	%r446, %r80, 2147483647;
	setp.ne.s32 	%p355, %r446, 2146435072;
	setp.ne.s32 	%p356, %r445, 0;
	or.pred  	%p357, %p355, %p356;
	mov.f64 	%fd529, %fd528;
	@%p357 bra 	$L__BB1_218;

	and.pred  	%p359, %p125, %p25;
	selp.b32 	%r447, %r61, %r60, %p359;
	mov.u32 	%r448, 0;
	mov.b64 	%fd529, {%r448, %r447};

$L__BB1_218:
	cvt.f64.f32 	%fd476, %f111;
	mov.f32 	%f2852, 0f00000000;
	setp.eq.f32 	%p363, %f119, 0f3F800000;
	selp.f64 	%fd378, 0d3FF0000000000000, %fd529, %p363;
	cvt.f64.f32 	%fd379, %f209;
	mul.f64 	%fd380, %fd378, %fd379;
	sub.f64 	%fd381, %fd98, %fd380;
	mul.f64 	%fd382, %fd70, %fd381;
	mul.f64 	%fd384, %fd382, %fd476;
	mul.f32 	%f1438, %f60, %f211;
	cvt.f64.f32 	%fd385, %f1438;
	sub.f64 	%fd386, %fd385, %fd384;
	cvt.rn.f32.f64 	%f1439, %fd386;
	add.f32 	%f212, %f182, %f211;
	add.f32 	%f213, %f183, %f1439;
	mul.f32 	%f214, %f111, %f124;
	setp.leu.f32 	%p364, %f125, 0f3C23D70A;
	@%p364 bra 	$L__BB1_220;

	div.rn.f32 	%f1440, %f126, %f125;
	add.f32 	%f2852, %f1440, 0fBF800000;

$L__BB1_220:
	mov.f32 	%f2853, 0f00000000;
	@%p364 bra 	$L__BB1_235;

	and.b32  	%r454, %r74, 2146435072;
	setp.eq.s32 	%p366, %r454, 1062207488;
	cvt.f64.f32 	%fd110, %f125;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r81}, %fd110;
	}
	abs.f64 	%fd111, %fd110;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd531, [retval0+0];
	} // callseq 17
	setp.lt.s32 	%p367, %r81, 0;
	and.pred  	%p26, %p367, %p366;
	not.pred 	%p368, %p26;
	@%p368 bra 	$L__BB1_223;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r455}, %fd531;
	}
	xor.b32  	%r456, %r455, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r457, %temp}, %fd531;
	}
	mov.b64 	%fd531, {%r457, %r456};

$L__BB1_223:
	setp.eq.f32 	%p369, %f125, 0f00000000;
	@%p369 bra 	$L__BB1_227;
	bra.uni 	$L__BB1_224;

$L__BB1_227:
	setp.lt.s32 	%p372, %r74, 0;
	mov.u32 	%r458, 0;
	selp.b32 	%r460, %r81, 0, %p366;
	or.b32  	%r461, %r460, 2146435072;
	selp.b32 	%r462, %r461, %r460, %p372;
	mov.b64 	%fd531, {%r458, %r462};
	bra.uni 	$L__BB1_228;

$L__BB1_224:
	setp.gt.s32 	%p370, %r81, -1;
	@%p370 bra 	$L__BB1_228;

	cvt.rzi.f64.f64 	%fd389, %fd315;
	setp.eq.f64 	%p371, %fd389, 0d4000000000000000;
	@%p371 bra 	$L__BB1_228;

	mov.f64 	%fd531, 0dFFF8000000000000;

$L__BB1_228:
	add.f64 	%fd117, %fd110, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r463}, %fd117;
	}
	and.b32  	%r464, %r463, 2146435072;
	setp.ne.s32 	%p374, %r464, 2146435072;
	mov.f64 	%fd532, %fd531;
	@%p374 bra 	$L__BB1_234;

	setp.gtu.f64 	%p375, %fd111, 0d7FF0000000000000;
	mov.f64 	%fd532, %fd117;
	@%p375 bra 	$L__BB1_234;

	setp.eq.s32 	%p376, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r465, %temp}, %fd315;
	}
	setp.eq.s32 	%p377, %r465, 0;
	and.pred  	%p378, %p376, %p377;
	@%p378 bra 	$L__BB1_233;
	bra.uni 	$L__BB1_231;

$L__BB1_233:
	setp.lt.s32 	%p384, %r74, 0;
	mov.u32 	%r471, 0;
	setp.gt.f64 	%p385, %fd111, 0d3FF0000000000000;
	selp.b32 	%r472, 2146435072, 0, %p385;
	xor.b32  	%r473, %r472, 2146435072;
	selp.b32 	%r474, %r473, %r472, %p384;
	setp.eq.f32 	%p386, %f125, 0fBF800000;
	selp.b32 	%r475, 1072693248, %r474, %p386;
	mov.b64 	%fd532, {%r471, %r475};
	bra.uni 	$L__BB1_234;

$L__BB1_231:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r466, %temp}, %fd110;
	}
	and.b32  	%r467, %r81, 2147483647;
	setp.ne.s32 	%p379, %r467, 2146435072;
	setp.ne.s32 	%p380, %r466, 0;
	or.pred  	%p381, %p379, %p380;
	mov.f64 	%fd532, %fd531;
	@%p381 bra 	$L__BB1_234;

	setp.ne.s32 	%p382, %r75, 1071644672;
	and.pred  	%p383, %p382, %p26;
	or.b32  	%r468, %r76, -2147483648;
	selp.b32 	%r469, %r468, %r76, %p383;
	mov.u32 	%r470, 0;
	mov.b64 	%fd532, {%r470, %r469};

$L__BB1_234:
	setp.eq.f32 	%p387, %f125, 0f3F800000;
	selp.f64 	%fd392, 0d3FF0000000000000, %fd532, %p387;
	cvt.f64.f32 	%fd393, %f126;
	div.rn.f64 	%fd394, %fd393, %fd392;
	cvt.rn.f32.f64 	%f2853, %fd394;

$L__BB1_235:
	and.b32  	%r476, %r74, 2146435072;
	setp.eq.s32 	%p388, %r476, 1062207488;
	mov.f32 	%f1442, 0f47C35000;
	min.f32 	%f1443, %f2853, %f1442;
	cvt.f64.f32 	%fd121, %f1443;
	min.f32 	%f219, %f2852, %f1442;
	fma.rn.f32 	%f2822, %f219, %f139, %f2822;
	mul.f32 	%f1444, %f219, %f140;
	cvt.f64.f32 	%fd122, %f1444;
	cvt.f64.f32 	%fd123, %f139;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd123;
	}
	abs.f64 	%fd124, %fd123;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd124;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd533, [retval0+0];
	} // callseq 18
	@%p388 bra 	$L__BB1_281;
	bra.uni 	$L__BB1_236;

$L__BB1_281:
	setp.gt.s32 	%p449, %r82, -1;
	@%p449 bra 	$L__BB1_283;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r525}, %fd533;
	}
	xor.b32  	%r526, %r525, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r527, %temp}, %fd533;
	}
	mov.b64 	%fd533, {%r527, %r526};

$L__BB1_283:
	setp.eq.f32 	%p450, %f139, 0f00000000;
	@%p450 bra 	$L__BB1_287;
	bra.uni 	$L__BB1_284;

$L__BB1_287:
	setp.lt.s32 	%p453, %r74, 0;
	mov.u32 	%r528, 0;
	or.b32  	%r529, %r82, 2146435072;
	selp.b32 	%r530, %r529, %r82, %p453;
	mov.b64 	%fd533, {%r528, %r530};
	bra.uni 	$L__BB1_288;

$L__BB1_236:
	setp.eq.f32 	%p389, %f139, 0f00000000;
	@%p389 bra 	$L__BB1_240;
	bra.uni 	$L__BB1_237;

$L__BB1_240:
	mov.u32 	%r477, 0;
	mov.b64 	%fd533, {%r477, %r77};
	bra.uni 	$L__BB1_241;

$L__BB1_284:
	@%p449 bra 	$L__BB1_288;

	cvt.rzi.f64.f64 	%fd437, %fd315;
	setp.eq.f64 	%p452, %fd437, 0d4000000000000000;
	@%p452 bra 	$L__BB1_288;

	mov.f64 	%fd533, 0dFFF8000000000000;

$L__BB1_288:
	add.f64 	%fd168, %fd123, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r531}, %fd168;
	}
	and.b32  	%r532, %r531, 2146435072;
	setp.ne.s32 	%p454, %r532, 2146435072;
	mov.f64 	%fd543, %fd533;
	@%p454 bra 	$L__BB1_294;

	setp.gtu.f64 	%p455, %fd124, 0d7FF0000000000000;
	mov.f64 	%fd543, %fd168;
	@%p455 bra 	$L__BB1_294;

	setp.eq.s32 	%p456, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r533, %temp}, %fd315;
	}
	setp.eq.s32 	%p457, %r533, 0;
	and.pred  	%p458, %p456, %p457;
	@%p458 bra 	$L__BB1_293;
	bra.uni 	$L__BB1_291;

$L__BB1_293:
	setp.lt.s32 	%p465, %r74, 0;
	mov.u32 	%r539, 0;
	setp.gt.f64 	%p466, %fd124, 0d3FF0000000000000;
	selp.b32 	%r540, 2146435072, 0, %p466;
	xor.b32  	%r541, %r540, 2146435072;
	selp.b32 	%r542, %r541, %r540, %p465;
	setp.eq.f32 	%p467, %f139, 0fBF800000;
	selp.b32 	%r543, 1072693248, %r542, %p467;
	mov.b64 	%fd543, {%r539, %r543};
	bra.uni 	$L__BB1_294;

$L__BB1_237:
	setp.gt.s32 	%p390, %r82, -1;
	@%p390 bra 	$L__BB1_241;

	cvt.rzi.f64.f64 	%fd397, %fd315;
	setp.eq.f64 	%p391, %fd397, 0d4000000000000000;
	@%p391 bra 	$L__BB1_241;

	mov.f64 	%fd533, 0dFFF8000000000000;

$L__BB1_241:
	add.f64 	%fd128, %fd123, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r478}, %fd128;
	}
	and.b32  	%r479, %r478, 2146435072;
	setp.ne.s32 	%p392, %r479, 2146435072;
	mov.f64 	%fd534, %fd533;
	@%p392 bra 	$L__BB1_247;

	setp.gtu.f64 	%p393, %fd124, 0d7FF0000000000000;
	mov.f64 	%fd534, %fd128;
	@%p393 bra 	$L__BB1_247;

	setp.eq.s32 	%p394, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r480, %temp}, %fd315;
	}
	setp.eq.s32 	%p395, %r480, 0;
	and.pred  	%p396, %p394, %p395;
	@%p396 bra 	$L__BB1_246;
	bra.uni 	$L__BB1_244;

$L__BB1_246:
	setp.lt.s32 	%p400, %r74, 0;
	mov.u32 	%r484, 0;
	setp.gt.f64 	%p401, %fd124, 0d3FF0000000000000;
	selp.b32 	%r485, 2146435072, 0, %p401;
	xor.b32  	%r486, %r485, 2146435072;
	selp.b32 	%r487, %r486, %r485, %p400;
	setp.eq.f32 	%p402, %f139, 0fBF800000;
	selp.b32 	%r488, 1072693248, %r487, %p402;
	mov.b64 	%fd534, {%r484, %r488};
	bra.uni 	$L__BB1_247;

$L__BB1_291:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r534, %temp}, %fd123;
	}
	and.b32  	%r535, %r82, 2147483647;
	setp.ne.s32 	%p459, %r535, 2146435072;
	setp.ne.s32 	%p460, %r534, 0;
	or.pred  	%p461, %p459, %p460;
	mov.f64 	%fd543, %fd533;
	@%p461 bra 	$L__BB1_294;

	setp.lt.s32 	%p462, %r82, 0;
	mov.u32 	%r536, 0;
	setp.ne.s32 	%p463, %r75, 1071644672;
	and.pred  	%p464, %p463, %p462;
	or.b32  	%r537, %r76, -2147483648;
	selp.b32 	%r538, %r537, %r76, %p464;
	mov.b64 	%fd543, {%r536, %r538};

$L__BB1_294:
	setp.eq.f32 	%p468, %f139, 0f3F800000;
	selp.f64 	%fd440, 0d3FF0000000000000, %fd543, %p468;
	mul.f64 	%fd441, %fd440, %fd121;
	sub.f64 	%fd442, %fd122, %fd441;
	cvt.f64.f32 	%fd443, %f2827;
	add.f64 	%fd557, %fd442, %fd443;
	cvt.f64.f32 	%fd173, %f168;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd173;
	}
	abs.f64 	%fd174, %fd173;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd174;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd545, [retval0+0];
	} // callseq 22
	setp.gt.s32 	%p469, %r86, -1;
	@%p469 bra 	$L__BB1_296;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r544}, %fd545;
	}
	xor.b32  	%r545, %r544, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r546, %temp}, %fd545;
	}
	mov.b64 	%fd545, {%r546, %r545};

$L__BB1_296:
	setp.eq.f32 	%p470, %f168, 0f00000000;
	@%p470 bra 	$L__BB1_300;
	bra.uni 	$L__BB1_297;

$L__BB1_300:
	setp.lt.s32 	%p473, %r74, 0;
	mov.u32 	%r547, 0;
	or.b32  	%r548, %r86, 2146435072;
	selp.b32 	%r549, %r548, %r86, %p473;
	mov.b64 	%fd545, {%r547, %r549};
	bra.uni 	$L__BB1_301;

$L__BB1_297:
	@%p469 bra 	$L__BB1_301;

	cvt.rzi.f64.f64 	%fd446, %fd315;
	setp.eq.f64 	%p472, %fd446, 0d4000000000000000;
	@%p472 bra 	$L__BB1_301;

	mov.f64 	%fd545, 0dFFF8000000000000;

$L__BB1_301:
	add.f64 	%fd180, %fd173, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r550}, %fd180;
	}
	and.b32  	%r551, %r550, 2146435072;
	setp.ne.s32 	%p474, %r551, 2146435072;
	mov.f64 	%fd546, %fd545;
	@%p474 bra 	$L__BB1_307;

	setp.gtu.f64 	%p475, %fd174, 0d7FF0000000000000;
	mov.f64 	%fd546, %fd180;
	@%p475 bra 	$L__BB1_307;

	setp.eq.s32 	%p476, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r552, %temp}, %fd315;
	}
	setp.eq.s32 	%p477, %r552, 0;
	and.pred  	%p478, %p476, %p477;
	@%p478 bra 	$L__BB1_306;
	bra.uni 	$L__BB1_304;

$L__BB1_306:
	setp.lt.s32 	%p485, %r74, 0;
	mov.u32 	%r558, 0;
	setp.gt.f64 	%p486, %fd174, 0d3FF0000000000000;
	selp.b32 	%r559, 2146435072, 0, %p486;
	xor.b32  	%r560, %r559, 2146435072;
	selp.b32 	%r561, %r560, %r559, %p485;
	setp.eq.f32 	%p487, %f168, 0fBF800000;
	selp.b32 	%r562, 1072693248, %r561, %p487;
	mov.b64 	%fd546, {%r558, %r562};
	bra.uni 	$L__BB1_307;

$L__BB1_244:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r481, %temp}, %fd123;
	}
	and.b32  	%r482, %r82, 2147483647;
	setp.ne.s32 	%p397, %r482, 2146435072;
	setp.ne.s32 	%p398, %r481, 0;
	or.pred  	%p399, %p397, %p398;
	mov.f64 	%fd534, %fd533;
	@%p399 bra 	$L__BB1_247;

	mov.u32 	%r483, 0;
	mov.b64 	%fd534, {%r483, %r76};

$L__BB1_247:
	setp.eq.f32 	%p403, %f139, 0f3F800000;
	selp.f64 	%fd400, 0d3FF0000000000000, %fd534, %p403;
	mul.f64 	%fd401, %fd400, %fd121;
	sub.f64 	%fd402, %fd122, %fd401;
	cvt.f64.f32 	%fd403, %f2827;
	add.f64 	%fd557, %fd402, %fd403;
	cvt.f64.f32 	%fd133, %f168;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd133;
	}
	abs.f64 	%fd134, %fd133;
	setp.eq.f32 	%p404, %f168, 0f00000000;
	@%p404 bra 	$L__BB1_251;
	bra.uni 	$L__BB1_248;

$L__BB1_251:
	mov.u32 	%r489, 0;
	mov.b64 	%fd535, {%r489, %r77};
	bra.uni 	$L__BB1_252;

$L__BB1_248:
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd134;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd535, [retval0+0];
	} // callseq 19
	setp.gt.s32 	%p405, %r83, -1;
	@%p405 bra 	$L__BB1_252;

	cvt.rzi.f64.f64 	%fd406, %fd315;
	setp.eq.f64 	%p406, %fd406, 0d4000000000000000;
	@%p406 bra 	$L__BB1_252;

	mov.f64 	%fd535, 0dFFF8000000000000;

$L__BB1_252:
	add.f64 	%fd138, %fd133, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r490}, %fd138;
	}
	and.b32  	%r491, %r490, 2146435072;
	setp.ne.s32 	%p407, %r491, 2146435072;
	mov.f64 	%fd536, %fd535;
	@%p407 bra 	$L__BB1_258;

	setp.gtu.f64 	%p408, %fd134, 0d7FF0000000000000;
	mov.f64 	%fd536, %fd138;
	@%p408 bra 	$L__BB1_258;

	setp.eq.s32 	%p409, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r492, %temp}, %fd315;
	}
	setp.eq.s32 	%p410, %r492, 0;
	and.pred  	%p411, %p409, %p410;
	@%p411 bra 	$L__BB1_257;
	bra.uni 	$L__BB1_255;

$L__BB1_257:
	setp.lt.s32 	%p415, %r74, 0;
	mov.u32 	%r496, 0;
	setp.gt.f64 	%p416, %fd134, 0d3FF0000000000000;
	selp.b32 	%r497, 2146435072, 0, %p416;
	xor.b32  	%r498, %r497, 2146435072;
	selp.b32 	%r499, %r498, %r497, %p415;
	setp.eq.f32 	%p417, %f168, 0fBF800000;
	selp.b32 	%r500, 1072693248, %r499, %p417;
	mov.b64 	%fd536, {%r496, %r500};
	bra.uni 	$L__BB1_258;

$L__BB1_304:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r553, %temp}, %fd173;
	}
	and.b32  	%r554, %r86, 2147483647;
	setp.ne.s32 	%p479, %r554, 2146435072;
	setp.ne.s32 	%p480, %r553, 0;
	or.pred  	%p481, %p479, %p480;
	mov.f64 	%fd546, %fd545;
	@%p481 bra 	$L__BB1_307;

	setp.lt.s32 	%p482, %r86, 0;
	mov.u32 	%r555, 0;
	setp.ne.s32 	%p483, %r75, 1071644672;
	and.pred  	%p484, %p483, %p482;
	or.b32  	%r556, %r76, -2147483648;
	selp.b32 	%r557, %r556, %r76, %p484;
	mov.b64 	%fd546, {%r555, %r557};

$L__BB1_307:
	setp.eq.f32 	%p488, %f168, 0f3F800000;
	selp.f64 	%fd449, 0d3FF0000000000000, %fd546, %p488;
	mul.f64 	%fd450, %fd449, %fd121;
	mul.f32 	%f1448, %f219, %f169;
	cvt.f64.f32 	%fd451, %f1448;
	sub.f64 	%fd452, %fd451, %fd450;
	cvt.f64.f32 	%fd453, %f2826;
	add.f64 	%fd556, %fd452, %fd453;
	cvt.f64.f32 	%fd185, %f214;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd185;
	}
	abs.f64 	%fd186, %fd185;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd186;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd548, [retval0+0];
	} // callseq 23
	setp.gt.s32 	%p489, %r87, -1;
	@%p489 bra 	$L__BB1_309;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r563}, %fd548;
	}
	xor.b32  	%r564, %r563, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r565, %temp}, %fd548;
	}
	mov.b64 	%fd548, {%r565, %r564};

$L__BB1_309:
	setp.eq.f32 	%p490, %f214, 0f00000000;
	@%p490 bra 	$L__BB1_313;
	bra.uni 	$L__BB1_310;

$L__BB1_313:
	setp.lt.s32 	%p493, %r74, 0;
	mov.u32 	%r566, 0;
	or.b32  	%r567, %r87, 2146435072;
	selp.b32 	%r568, %r567, %r87, %p493;
	mov.b64 	%fd548, {%r566, %r568};
	bra.uni 	$L__BB1_314;

$L__BB1_310:
	@%p489 bra 	$L__BB1_314;

	cvt.rzi.f64.f64 	%fd456, %fd315;
	setp.eq.f64 	%p492, %fd456, 0d4000000000000000;
	@%p492 bra 	$L__BB1_314;

	mov.f64 	%fd548, 0dFFF8000000000000;

$L__BB1_314:
	add.f64 	%fd192, %fd185, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r569}, %fd192;
	}
	and.b32  	%r570, %r569, 2146435072;
	setp.ne.s32 	%p494, %r570, 2146435072;
	mov.f64 	%fd549, %fd548;
	@%p494 bra 	$L__BB1_320;

	setp.gtu.f64 	%p495, %fd186, 0d7FF0000000000000;
	mov.f64 	%fd549, %fd192;
	@%p495 bra 	$L__BB1_320;

	setp.eq.s32 	%p496, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r571, %temp}, %fd315;
	}
	setp.eq.s32 	%p497, %r571, 0;
	and.pred  	%p498, %p496, %p497;
	@%p498 bra 	$L__BB1_319;
	bra.uni 	$L__BB1_317;

$L__BB1_319:
	setp.lt.s32 	%p505, %r74, 0;
	mov.u32 	%r577, 0;
	setp.gt.f64 	%p506, %fd186, 0d3FF0000000000000;
	selp.b32 	%r578, 2146435072, 0, %p506;
	xor.b32  	%r579, %r578, 2146435072;
	selp.b32 	%r580, %r579, %r578, %p505;
	setp.eq.f32 	%p507, %f214, 0fBF800000;
	selp.b32 	%r581, 1072693248, %r580, %p507;
	mov.b64 	%fd549, {%r577, %r581};
	bra.uni 	$L__BB1_320;

$L__BB1_255:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r493, %temp}, %fd133;
	}
	and.b32  	%r494, %r83, 2147483647;
	setp.ne.s32 	%p412, %r494, 2146435072;
	setp.ne.s32 	%p413, %r493, 0;
	or.pred  	%p414, %p412, %p413;
	mov.f64 	%fd536, %fd535;
	@%p414 bra 	$L__BB1_258;

	mov.u32 	%r495, 0;
	mov.b64 	%fd536, {%r495, %r76};

$L__BB1_258:
	setp.eq.f32 	%p418, %f168, 0f3F800000;
	selp.f64 	%fd409, 0d3FF0000000000000, %fd536, %p418;
	mul.f64 	%fd410, %fd409, %fd121;
	mul.f32 	%f1445, %f219, %f169;
	cvt.f64.f32 	%fd411, %f1445;
	sub.f64 	%fd412, %fd411, %fd410;
	cvt.f64.f32 	%fd413, %f2826;
	add.f64 	%fd556, %fd412, %fd413;
	cvt.f64.f32 	%fd143, %f214;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd143;
	}
	abs.f64 	%fd144, %fd143;
	setp.eq.f32 	%p419, %f214, 0f00000000;
	@%p419 bra 	$L__BB1_262;
	bra.uni 	$L__BB1_259;

$L__BB1_262:
	mov.u32 	%r501, 0;
	mov.b64 	%fd537, {%r501, %r77};
	bra.uni 	$L__BB1_263;

$L__BB1_259:
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd144;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd537, [retval0+0];
	} // callseq 20
	setp.gt.s32 	%p420, %r84, -1;
	@%p420 bra 	$L__BB1_263;

	cvt.rzi.f64.f64 	%fd416, %fd315;
	setp.eq.f64 	%p421, %fd416, 0d4000000000000000;
	@%p421 bra 	$L__BB1_263;

	mov.f64 	%fd537, 0dFFF8000000000000;

$L__BB1_263:
	add.f64 	%fd148, %fd143, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r502}, %fd148;
	}
	and.b32  	%r503, %r502, 2146435072;
	setp.ne.s32 	%p422, %r503, 2146435072;
	mov.f64 	%fd538, %fd537;
	@%p422 bra 	$L__BB1_269;

	setp.gtu.f64 	%p423, %fd144, 0d7FF0000000000000;
	mov.f64 	%fd538, %fd148;
	@%p423 bra 	$L__BB1_269;

	setp.eq.s32 	%p424, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r504, %temp}, %fd315;
	}
	setp.eq.s32 	%p425, %r504, 0;
	and.pred  	%p426, %p424, %p425;
	@%p426 bra 	$L__BB1_268;
	bra.uni 	$L__BB1_266;

$L__BB1_268:
	setp.lt.s32 	%p430, %r74, 0;
	mov.u32 	%r508, 0;
	setp.gt.f64 	%p431, %fd144, 0d3FF0000000000000;
	selp.b32 	%r509, 2146435072, 0, %p431;
	xor.b32  	%r510, %r509, 2146435072;
	selp.b32 	%r511, %r510, %r509, %p430;
	setp.eq.f32 	%p432, %f214, 0fBF800000;
	selp.b32 	%r512, 1072693248, %r511, %p432;
	mov.b64 	%fd538, {%r508, %r512};
	bra.uni 	$L__BB1_269;

$L__BB1_317:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r572, %temp}, %fd185;
	}
	and.b32  	%r573, %r87, 2147483647;
	setp.ne.s32 	%p499, %r573, 2146435072;
	setp.ne.s32 	%p500, %r572, 0;
	or.pred  	%p501, %p499, %p500;
	mov.f64 	%fd549, %fd548;
	@%p501 bra 	$L__BB1_320;

	setp.lt.s32 	%p502, %r87, 0;
	mov.u32 	%r574, 0;
	setp.ne.s32 	%p503, %r75, 1071644672;
	and.pred  	%p504, %p503, %p502;
	or.b32  	%r575, %r76, -2147483648;
	selp.b32 	%r576, %r575, %r76, %p504;
	mov.b64 	%fd549, {%r574, %r576};

$L__BB1_320:
	mul.f32 	%f1449, %f219, 0f00000000;
	cvt.f64.f32 	%fd459, %f1449;
	setp.eq.f32 	%p508, %f214, 0f3F800000;
	selp.f64 	%fd460, 0d3FF0000000000000, %fd549, %p508;
	mul.f64 	%fd461, %fd460, %fd121;
	sub.f64 	%fd462, %fd459, %fd461;
	cvt.f64.f32 	%fd463, %f2825;
	add.f64 	%fd555, %fd462, %fd463;
	cvt.f64.f32 	%fd464, %f2824;
	sub.f64 	%fd465, %fd459, %fd121;
	add.f64 	%fd554, %fd465, %fd464;
	cvt.f64.f32 	%fd198, %f212;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd198;
	}
	abs.f64 	%fd199, %fd198;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd199;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd551, [retval0+0];
	} // callseq 24
	setp.gt.s32 	%p509, %r88, -1;
	@%p509 bra 	$L__BB1_322;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r582}, %fd551;
	}
	xor.b32  	%r583, %r582, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r584, %temp}, %fd551;
	}
	mov.b64 	%fd551, {%r584, %r583};

$L__BB1_322:
	setp.eq.f32 	%p510, %f212, 0f00000000;
	@%p510 bra 	$L__BB1_326;
	bra.uni 	$L__BB1_323;

$L__BB1_326:
	setp.lt.s32 	%p513, %r74, 0;
	mov.u32 	%r585, 0;
	or.b32  	%r586, %r88, 2146435072;
	selp.b32 	%r587, %r586, %r88, %p513;
	mov.b64 	%fd551, {%r585, %r587};
	bra.uni 	$L__BB1_327;

$L__BB1_323:
	@%p509 bra 	$L__BB1_327;

	cvt.rzi.f64.f64 	%fd468, %fd315;
	setp.eq.f64 	%p512, %fd468, 0d4000000000000000;
	@%p512 bra 	$L__BB1_327;

	mov.f64 	%fd551, 0dFFF8000000000000;

$L__BB1_327:
	add.f64 	%fd205, %fd198, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r588}, %fd205;
	}
	and.b32  	%r589, %r588, 2146435072;
	setp.ne.s32 	%p514, %r589, 2146435072;
	mov.f64 	%fd552, %fd551;
	@%p514 bra 	$L__BB1_333;

	setp.gtu.f64 	%p515, %fd199, 0d7FF0000000000000;
	mov.f64 	%fd552, %fd205;
	@%p515 bra 	$L__BB1_333;

	setp.eq.s32 	%p516, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r590, %temp}, %fd315;
	}
	setp.eq.s32 	%p517, %r590, 0;
	and.pred  	%p518, %p516, %p517;
	@%p518 bra 	$L__BB1_332;
	bra.uni 	$L__BB1_330;

$L__BB1_332:
	setp.lt.s32 	%p525, %r74, 0;
	mov.u32 	%r596, 0;
	setp.gt.f64 	%p526, %fd199, 0d3FF0000000000000;
	selp.b32 	%r597, 2146435072, 0, %p526;
	xor.b32  	%r598, %r597, 2146435072;
	selp.b32 	%r599, %r598, %r597, %p525;
	setp.eq.f32 	%p527, %f212, 0fBF800000;
	selp.b32 	%r600, 1072693248, %r599, %p527;
	mov.b64 	%fd552, {%r596, %r600};
	bra.uni 	$L__BB1_333;

$L__BB1_266:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r505, %temp}, %fd143;
	}
	and.b32  	%r506, %r84, 2147483647;
	setp.ne.s32 	%p427, %r506, 2146435072;
	setp.ne.s32 	%p428, %r505, 0;
	or.pred  	%p429, %p427, %p428;
	mov.f64 	%fd538, %fd537;
	@%p429 bra 	$L__BB1_269;

	mov.u32 	%r507, 0;
	mov.b64 	%fd538, {%r507, %r76};

$L__BB1_269:
	mul.f32 	%f1446, %f219, 0f00000000;
	cvt.f64.f32 	%fd419, %f1446;
	setp.eq.f32 	%p433, %f214, 0f3F800000;
	selp.f64 	%fd420, 0d3FF0000000000000, %fd538, %p433;
	mul.f64 	%fd421, %fd420, %fd121;
	sub.f64 	%fd422, %fd419, %fd421;
	cvt.f64.f32 	%fd423, %f2825;
	add.f64 	%fd555, %fd422, %fd423;
	cvt.f64.f32 	%fd424, %f2824;
	sub.f64 	%fd425, %fd419, %fd121;
	add.f64 	%fd554, %fd425, %fd424;
	cvt.f64.f32 	%fd154, %f212;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd154;
	}
	abs.f64 	%fd155, %fd154;
	setp.eq.f32 	%p434, %f212, 0f00000000;
	@%p434 bra 	$L__BB1_273;
	bra.uni 	$L__BB1_270;

$L__BB1_273:
	mov.u32 	%r513, 0;
	mov.b64 	%fd539, {%r513, %r77};
	bra.uni 	$L__BB1_274;

$L__BB1_270:
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd155;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd539, [retval0+0];
	} // callseq 21
	setp.gt.s32 	%p435, %r85, -1;
	@%p435 bra 	$L__BB1_274;

	cvt.rzi.f64.f64 	%fd428, %fd315;
	setp.eq.f64 	%p436, %fd428, 0d4000000000000000;
	@%p436 bra 	$L__BB1_274;

	mov.f64 	%fd539, 0dFFF8000000000000;

$L__BB1_274:
	add.f64 	%fd159, %fd154, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r514}, %fd159;
	}
	and.b32  	%r515, %r514, 2146435072;
	setp.ne.s32 	%p437, %r515, 2146435072;
	mov.f64 	%fd540, %fd539;
	@%p437 bra 	$L__BB1_280;

	setp.gtu.f64 	%p438, %fd155, 0d7FF0000000000000;
	mov.f64 	%fd540, %fd159;
	@%p438 bra 	$L__BB1_280;

	setp.eq.s32 	%p439, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r516, %temp}, %fd315;
	}
	setp.eq.s32 	%p440, %r516, 0;
	and.pred  	%p441, %p439, %p440;
	@%p441 bra 	$L__BB1_279;
	bra.uni 	$L__BB1_277;

$L__BB1_279:
	setp.lt.s32 	%p445, %r74, 0;
	mov.u32 	%r520, 0;
	setp.gt.f64 	%p446, %fd155, 0d3FF0000000000000;
	selp.b32 	%r521, 2146435072, 0, %p446;
	xor.b32  	%r522, %r521, 2146435072;
	selp.b32 	%r523, %r522, %r521, %p445;
	setp.eq.f32 	%p447, %f212, 0fBF800000;
	selp.b32 	%r524, 1072693248, %r523, %p447;
	mov.b64 	%fd540, {%r520, %r524};
	bra.uni 	$L__BB1_280;

$L__BB1_330:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r591, %temp}, %fd198;
	}
	and.b32  	%r592, %r88, 2147483647;
	setp.ne.s32 	%p519, %r592, 2146435072;
	setp.ne.s32 	%p520, %r591, 0;
	or.pred  	%p521, %p519, %p520;
	mov.f64 	%fd552, %fd551;
	@%p521 bra 	$L__BB1_333;

	setp.lt.s32 	%p522, %r88, 0;
	mov.u32 	%r593, 0;
	setp.ne.s32 	%p523, %r75, 1071644672;
	and.pred  	%p524, %p523, %p522;
	or.b32  	%r594, %r76, -2147483648;
	selp.b32 	%r595, %r594, %r76, %p524;
	mov.b64 	%fd552, {%r593, %r595};

$L__BB1_333:
	setp.eq.f32 	%p528, %f212, 0f3F800000;
	selp.f64 	%fd471, 0d3FF0000000000000, %fd552, %p528;
	mul.f64 	%fd472, %fd471, %fd121;
	mul.f32 	%f1450, %f219, %f213;
	cvt.f64.f32 	%fd473, %f1450;
	sub.f64 	%fd474, %fd473, %fd472;
	cvt.f64.f32 	%fd475, %f2823;
	add.f64 	%fd553, %fd474, %fd475;
	bra.uni 	$L__BB1_334;

$L__BB1_277:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r517, %temp}, %fd154;
	}
	and.b32  	%r518, %r85, 2147483647;
	setp.ne.s32 	%p442, %r518, 2146435072;
	setp.ne.s32 	%p443, %r517, 0;
	or.pred  	%p444, %p442, %p443;
	mov.f64 	%fd540, %fd539;
	@%p444 bra 	$L__BB1_280;

	mov.u32 	%r519, 0;
	mov.b64 	%fd540, {%r519, %r76};

$L__BB1_280:
	setp.eq.f32 	%p448, %f212, 0f3F800000;
	selp.f64 	%fd431, 0d3FF0000000000000, %fd540, %p448;
	mul.f64 	%fd432, %fd431, %fd121;
	mul.f32 	%f1447, %f219, %f213;
	cvt.f64.f32 	%fd433, %f1447;
	sub.f64 	%fd434, %fd433, %fd432;
	cvt.f64.f32 	%fd435, %f2823;
	add.f64 	%fd553, %fd434, %fd435;

$L__BB1_334:
	cvt.rn.f32.f64 	%f2827, %fd557;
	cvt.rn.f32.f64 	%f2826, %fd556;
	cvt.rn.f32.f64 	%f2825, %fd555;
	cvt.rn.f32.f64 	%f2824, %fd554;
	cvt.rn.f32.f64 	%f2823, %fd553;
	fma.rn.f32 	%f2821, %f219, %f168, %f2821;
	fma.rn.f32 	%f2820, %f219, %f214, %f2820;
	add.f32 	%f2819, %f2819, %f219;
	fma.rn.f32 	%f2818, %f219, %f212, %f2818;
	add.s32 	%r782, %r782, 1;
	setp.lt.s32 	%p529, %r782, %r102;
	@%p529 bra 	$L__BB1_56;

	add.s32 	%r781, %r781, 1;
	setp.lt.s32 	%p530, %r781, %r102;
	@%p530 bra 	$L__BB1_55;

$L__BB1_336:
	ld.param.u32 	%r759, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_3];
	div.rn.f32 	%f1451, %f2822, %f2827;
	mov.f32 	%f1452, 0fBF800000;
	max.f32 	%f1453, %f1451, %f1452;
	mov.f32 	%f1454, 0f3F800000;
	min.f32 	%f1455, %f1453, %f1454;
	sub.f32 	%f2868, %f2868, %f1455;
	div.rn.f32 	%f1456, %f2821, %f2826;
	max.f32 	%f1457, %f1456, %f1452;
	min.f32 	%f1458, %f1457, %f1454;
	sub.f32 	%f2867, %f2867, %f1458;
	neg.f32 	%f1459, %f2866;
	div.rn.f32 	%f1460, %f2820, %f2825;
	max.f32 	%f1461, %f1460, %f1459;
	min.f32 	%f1462, %f1461, %f2866;
	sub.f32 	%f1463, %f2866, %f1462;
	neg.f32 	%f1464, %f2865;
	div.rn.f32 	%f1465, %f2819, %f2824;
	max.f32 	%f1466, %f1465, %f1464;
	min.f32 	%f1467, %f1466, %f2865;
	sub.f32 	%f1468, %f2865, %f1467;
	neg.f32 	%f1469, %f2864;
	div.rn.f32 	%f1470, %f2818, %f2823;
	max.f32 	%f1471, %f1470, %f1469;
	min.f32 	%f1472, %f1471, %f2864;
	sub.f32 	%f1473, %f2864, %f1472;
	max.f32 	%f2866, %f1463, %f1454;
	mov.f32 	%f1474, 0f3C23D70A;
	max.f32 	%f2865, %f1468, %f1474;
	mov.f32 	%f1475, 0f3F000000;
	max.f32 	%f1476, %f1473, %f1475;
	min.f32 	%f2864, %f1476, %f51;
	add.s32 	%r780, %r780, 1;
	setp.lt.s32 	%p531, %r780, %r759;
	@%p531 bra 	$L__BB1_53;

$L__BB1_337:
	mov.f32 	%f1492, 0f00000000;
	mov.f32 	%f2885, %f1492;
	mov.f32 	%f2886, %f1492;
	mov.f32 	%f2887, %f1492;
	mov.f32 	%f2890, %f1492;
	mov.f32 	%f2894, %f1492;
	mov.f32 	%f2888, %f1492;
	mov.f32 	%f2889, %f1492;
	mov.f32 	%f2891, %f1492;
	mov.f32 	%f2895, %f1492;
	mov.f32 	%f2892, %f1492;
	mov.f32 	%f2893, %f1492;
	mov.f32 	%f2896, %f1492;
	mov.f32 	%f2897, %f1492;
	mov.f32 	%f2898, %f1492;
	mov.f32 	%f2899, %f1492;
	mov.f32 	%f2927, %f1492;
	@%p40 bra 	$L__BB1_426;

	mov.f32 	%f1509, 0f3F000000;
	div.rn.f32 	%f1510, %f1509, %f2864;
	div.rn.f32 	%f1511, %f1510, %f2864;
	div.rn.f32 	%f1512, %f2866, 0fC0206C98;
	div.rn.f32 	%f250, %f1512, %f2864;
	div.rn.f32 	%f251, %f250, %f2864;
	sqrt.rn.f32 	%f252, %f1511;
	mov.f32 	%f1513, 0f3F800000;
	cvt.rzi.f32.f32 	%f1514, %f1513;
	add.f32 	%f1515, %f1514, %f1514;
	mov.f32 	%f1516, 0f40000000;
	sub.f32 	%f1517, %f1516, %f1515;
	abs.f32 	%f253, %f1517;
	mov.u32 	%r601, 0;
	setp.eq.f32 	%p540, %f253, 0f3F800000;
	mov.u32 	%r783, %r601;

$L__BB1_339:
	cvt.rn.f32.s32 	%f1518, %r783;
	sub.f32 	%f270, %f1518, %f2868;
	add.f32 	%f1519, %f270, 0f3F000000;
	mul.f32 	%f1520, %f1519, %f252;
	abs.f32 	%f271, %f1520;
	setp.ge.f32 	%p533, %f271, 0f3F8060FE;
	mul.f32 	%f1521, %f1520, %f1520;
	selp.f32 	%f1522, %f271, %f1521, %p533;
	selp.f32 	%f1523, 0f3789CA3C, 0f38B1E96A, %p533;
	selp.f32 	%f1524, 0fB9F560B9, 0fBA574D20, %p533;
	fma.rn.f32 	%f1525, %f1523, %f1522, %f1524;
	selp.f32 	%f1526, 0f3BAC840B, 0f3BAAD5EA, %p533;
	fma.rn.f32 	%f1527, %f1525, %f1522, %f1526;
	selp.f32 	%f1528, 0fBD0C8162, 0fBCDC1BE7, %p533;
	fma.rn.f32 	%f1529, %f1527, %f1522, %f1528;
	selp.f32 	%f1530, 0f3E1CF906, 0f3DE718AF, %p533;
	fma.rn.f32 	%f1531, %f1529, %f1522, %f1530;
	selp.f32 	%f1532, 0f3F6A937E, 0fBEC093AC, %p533;
	fma.rn.f32 	%f1533, %f1531, %f1522, %f1532;
	selp.f32 	%f1534, 0f3F20D842, 0f3E0375D3, %p533;
	fma.rn.f32 	%f1535, %f1533, %f1522, %f1534;
	neg.f32 	%f1536, %f271;
	selp.f32 	%f1537, %f1536, %f1520, %p533;
	fma.rn.f32 	%f272, %f1535, %f1537, %f1537;
	mov.b32 	%r603, %f1520;
	and.b32  	%r93, %r603, -2147483648;
	add.f32 	%f1538, %f270, 0fBF000000;
	mul.f32 	%f1539, %f1538, %f252;
	abs.f32 	%f273, %f1539;
	setp.ge.f32 	%p534, %f273, 0f3F8060FE;
	mul.f32 	%f1540, %f1539, %f1539;
	selp.f32 	%f1541, %f273, %f1540, %p534;
	selp.f32 	%f1542, 0f3789CA3C, 0f38B1E96A, %p534;
	selp.f32 	%f1543, 0fB9F560B9, 0fBA574D20, %p534;
	fma.rn.f32 	%f1544, %f1542, %f1541, %f1543;
	selp.f32 	%f1545, 0f3BAC840B, 0f3BAAD5EA, %p534;
	fma.rn.f32 	%f1546, %f1544, %f1541, %f1545;
	selp.f32 	%f1547, 0fBD0C8162, 0fBCDC1BE7, %p534;
	fma.rn.f32 	%f1548, %f1546, %f1541, %f1547;
	selp.f32 	%f1549, 0f3E1CF906, 0f3DE718AF, %p534;
	fma.rn.f32 	%f1550, %f1548, %f1541, %f1549;
	selp.f32 	%f1551, 0f3F6A937E, 0fBEC093AC, %p534;
	fma.rn.f32 	%f1552, %f1550, %f1541, %f1551;
	selp.f32 	%f1553, 0f3F20D842, 0f3E0375D3, %p534;
	fma.rn.f32 	%f1554, %f1552, %f1541, %f1553;
	neg.f32 	%f1555, %f273;
	selp.f32 	%f1556, %f1555, %f1539, %p534;
	fma.rn.f32 	%f274, %f1554, %f1556, %f1556;
	mov.b32 	%r604, %f1539;
	and.b32  	%r94, %r604, -2147483648;
	add.f32 	%f1557, %f1518, 0f3F000000;
	sub.f32 	%f1558, %f1557, %f2868;
	div.rn.f32 	%f275, %f1558, %f2864;
	abs.f32 	%f276, %f275;
	setp.lt.f32 	%p535, %f276, 0f00800000;
	mul.f32 	%f1559, %f276, 0f4B800000;
	selp.f32 	%f1560, %f1559, %f276, %p535;
	selp.f32 	%f1561, 0fC3170000, 0fC2FE0000, %p535;
	mov.b32 	%r605, %f1560;
	and.b32  	%r606, %r605, 8388607;
	or.b32  	%r607, %r606, 1065353216;
	mov.b32 	%f1562, %r607;
	shr.u32 	%r608, %r605, 23;
	cvt.rn.f32.u32 	%f1563, %r608;
	add.f32 	%f1564, %f1561, %f1563;
	setp.gt.f32 	%p536, %f1562, 0f3FB504F3;
	mul.f32 	%f1565, %f1562, 0f3F000000;
	add.f32 	%f1566, %f1564, 0f3F800000;
	selp.f32 	%f1567, %f1566, %f1564, %p536;
	selp.f32 	%f1568, %f1565, %f1562, %p536;
	add.f32 	%f1569, %f1568, 0fBF800000;
	add.f32 	%f1570, %f1568, 0f3F800000;
	rcp.approx.ftz.f32 	%f1571, %f1570;
	add.f32 	%f1572, %f1569, %f1569;
	mul.f32 	%f1574, %f1572, %f1571;
	mul.f32 	%f1575, %f1574, %f1574;
	mov.f32 	%f1576, 0f3C4CAF63;
	mov.f32 	%f1577, 0f3B18F0FE;
	fma.rn.f32 	%f1578, %f1577, %f1575, %f1576;
	mov.f32 	%f1579, 0f3DAAAABD;
	fma.rn.f32 	%f1580, %f1578, %f1575, %f1579;
	mul.rn.f32 	%f1581, %f1580, %f1575;
	mul.rn.f32 	%f1582, %f1581, %f1574;
	sub.f32 	%f1583, %f1569, %f1574;
	add.f32 	%f1584, %f1583, %f1583;
	neg.f32 	%f1585, %f1574;
	fma.rn.f32 	%f1586, %f1585, %f1569, %f1584;
	mul.rn.f32 	%f1587, %f1571, %f1586;
	add.f32 	%f1588, %f1582, %f1574;
	sub.f32 	%f1589, %f1574, %f1588;
	add.f32 	%f1590, %f1582, %f1589;
	add.f32 	%f1591, %f1587, %f1590;
	add.f32 	%f1592, %f1588, %f1591;
	sub.f32 	%f1593, %f1588, %f1592;
	add.f32 	%f1594, %f1591, %f1593;
	mov.f32 	%f1595, 0f3F317200;
	mul.rn.f32 	%f1596, %f1567, %f1595;
	mov.f32 	%f1597, 0f35BFBE8E;
	mul.rn.f32 	%f1598, %f1567, %f1597;
	add.f32 	%f1599, %f1596, %f1592;
	sub.f32 	%f1600, %f1596, %f1599;
	add.f32 	%f1601, %f1592, %f1600;
	add.f32 	%f1602, %f1594, %f1601;
	add.f32 	%f1603, %f1598, %f1602;
	add.f32 	%f1604, %f1599, %f1603;
	sub.f32 	%f1605, %f1599, %f1604;
	add.f32 	%f1606, %f1603, %f1605;
	mul.rn.f32 	%f1607, %f1516, %f1604;
	neg.f32 	%f1608, %f1607;
	fma.rn.f32 	%f1609, %f1516, %f1604, %f1608;
	fma.rn.f32 	%f1610, %f1516, %f1606, %f1609;
	fma.rn.f32 	%f1612, %f1492, %f1604, %f1610;
	add.rn.f32 	%f1613, %f1607, %f1612;
	neg.f32 	%f1614, %f1613;
	add.rn.f32 	%f1615, %f1607, %f1614;
	add.rn.f32 	%f1616, %f1615, %f1612;
	mov.b32 	%r609, %f1613;
	setp.eq.s32 	%p537, %r609, 1118925336;
	add.s32 	%r610, %r609, -1;
	mov.b32 	%f1617, %r610;
	add.f32 	%f1618, %f1616, 0f37000000;
	selp.f32 	%f277, %f1618, %f1616, %p537;
	selp.f32 	%f1619, %f1617, %f1613, %p537;
	mov.f32 	%f1620, 0f3FB8AA3B;
	mul.rn.f32 	%f1621, %f1619, %f1620;
	cvt.rzi.f32.f32 	%f1622, %f1621;
	abs.f32 	%f1623, %f1622;
	setp.gt.f32 	%p538, %f1623, 0f42FC0000;
	mov.b32 	%r611, %f1622;
	and.b32  	%r612, %r611, -2147483648;
	or.b32  	%r613, %r612, 1123811328;
	mov.b32 	%f1624, %r613;
	selp.f32 	%f1625, %f1624, %f1622, %p538;
	mov.f32 	%f1626, 0fBF317218;
	fma.rn.f32 	%f1627, %f1625, %f1626, %f1619;
	mov.f32 	%f1628, 0f3102E308;
	fma.rn.f32 	%f1629, %f1625, %f1628, %f1627;
	mul.f32 	%f1630, %f1629, 0f3FB8AA3B;
	add.f32 	%f1631, %f1625, 0f4B40007F;
	mov.b32 	%r614, %f1631;
	shl.b32 	%r615, %r614, 23;
	mov.b32 	%f1632, %r615;
	ex2.approx.ftz.f32 	%f1633, %f1630;
	mul.f32 	%f278, %f1633, %f1632;
	setp.lt.f32 	%p539, %f275, 0f00000000;
	and.pred  	%p27, %p539, %p540;
	add.f32 	%f1634, %f275, %f275;
	selp.f32 	%f279, %f1634, 0f00000000, %p540;
	add.f32 	%f1635, %f276, 0f40000000;
	mov.b32 	%r95, %f1635;
	div.rn.f32 	%f280, %f1538, %f2864;
	abs.f32 	%f281, %f280;
	setp.lt.f32 	%p541, %f281, 0f00800000;
	mul.f32 	%f1636, %f281, 0f4B800000;
	selp.f32 	%f1637, %f1636, %f281, %p541;
	selp.f32 	%f1638, 0fC3170000, 0fC2FE0000, %p541;
	mov.b32 	%r616, %f1637;
	and.b32  	%r617, %r616, 8388607;
	or.b32  	%r618, %r617, 1065353216;
	mov.b32 	%f1639, %r618;
	shr.u32 	%r619, %r616, 23;
	cvt.rn.f32.u32 	%f1640, %r619;
	add.f32 	%f1641, %f1638, %f1640;
	setp.gt.f32 	%p542, %f1639, 0f3FB504F3;
	mul.f32 	%f1642, %f1639, 0f3F000000;
	add.f32 	%f1643, %f1641, 0f3F800000;
	selp.f32 	%f1644, %f1643, %f1641, %p542;
	selp.f32 	%f1645, %f1642, %f1639, %p542;
	add.f32 	%f1646, %f1645, 0fBF800000;
	add.f32 	%f1647, %f1645, 0f3F800000;
	rcp.approx.ftz.f32 	%f1648, %f1647;
	add.f32 	%f1649, %f1646, %f1646;
	mul.f32 	%f1650, %f1649, %f1648;
	mul.f32 	%f1651, %f1650, %f1650;
	fma.rn.f32 	%f1652, %f1577, %f1651, %f1576;
	fma.rn.f32 	%f1653, %f1652, %f1651, %f1579;
	mul.rn.f32 	%f1654, %f1653, %f1651;
	mul.rn.f32 	%f1655, %f1654, %f1650;
	sub.f32 	%f1656, %f1646, %f1650;
	add.f32 	%f1657, %f1656, %f1656;
	neg.f32 	%f1658, %f1650;
	fma.rn.f32 	%f1659, %f1658, %f1646, %f1657;
	mul.rn.f32 	%f1660, %f1648, %f1659;
	add.f32 	%f1661, %f1655, %f1650;
	sub.f32 	%f1662, %f1650, %f1661;
	add.f32 	%f1663, %f1655, %f1662;
	add.f32 	%f1664, %f1660, %f1663;
	add.f32 	%f1665, %f1661, %f1664;
	sub.f32 	%f1666, %f1661, %f1665;
	add.f32 	%f1667, %f1664, %f1666;
	mul.rn.f32 	%f1668, %f1644, %f1595;
	mul.rn.f32 	%f1669, %f1644, %f1597;
	add.f32 	%f1670, %f1668, %f1665;
	sub.f32 	%f1671, %f1668, %f1670;
	add.f32 	%f1672, %f1665, %f1671;
	add.f32 	%f1673, %f1667, %f1672;
	add.f32 	%f1674, %f1669, %f1673;
	add.f32 	%f1675, %f1670, %f1674;
	sub.f32 	%f1676, %f1670, %f1675;
	add.f32 	%f1677, %f1674, %f1676;
	mul.rn.f32 	%f1678, %f1516, %f1675;
	neg.f32 	%f1679, %f1678;
	fma.rn.f32 	%f1680, %f1516, %f1675, %f1679;
	fma.rn.f32 	%f1681, %f1516, %f1677, %f1680;
	fma.rn.f32 	%f1682, %f1492, %f1675, %f1681;
	add.rn.f32 	%f1683, %f1678, %f1682;
	neg.f32 	%f1684, %f1683;
	add.rn.f32 	%f1685, %f1678, %f1684;
	add.rn.f32 	%f1686, %f1685, %f1682;
	mov.b32 	%r620, %f1683;
	setp.eq.s32 	%p543, %r620, 1118925336;
	add.s32 	%r621, %r620, -1;
	mov.b32 	%f1687, %r621;
	add.f32 	%f1688, %f1686, 0f37000000;
	selp.f32 	%f282, %f1688, %f1686, %p543;
	selp.f32 	%f1689, %f1687, %f1683, %p543;
	mul.rn.f32 	%f1690, %f1689, %f1620;
	cvt.rzi.f32.f32 	%f1691, %f1690;
	abs.f32 	%f1692, %f1691;
	setp.gt.f32 	%p544, %f1692, 0f42FC0000;
	mov.b32 	%r622, %f1691;
	and.b32  	%r623, %r622, -2147483648;
	or.b32  	%r624, %r623, 1123811328;
	mov.b32 	%f1693, %r624;
	selp.f32 	%f1694, %f1693, %f1691, %p544;
	fma.rn.f32 	%f1695, %f1694, %f1626, %f1689;
	fma.rn.f32 	%f1696, %f1694, %f1628, %f1695;
	mul.f32 	%f1697, %f1696, 0f3FB8AA3B;
	add.f32 	%f1698, %f1694, 0f4B40007F;
	mov.b32 	%r625, %f1698;
	shl.b32 	%r626, %r625, 23;
	mov.b32 	%f1699, %r626;
	ex2.approx.ftz.f32 	%f1700, %f1697;
	mul.f32 	%f283, %f1700, %f1699;
	add.f32 	%f284, %f275, 0f40000000;
	setp.lt.f32 	%p545, %f280, 0f00000000;
	and.pred  	%p28, %p545, %p540;
	selp.f32 	%f285, 0fFF800000, 0f7F800000, %p27;
	add.f32 	%f1701, %f280, %f280;
	selp.f32 	%f286, %f1701, 0f00000000, %p540;
	add.f32 	%f1702, %f281, 0f40000000;
	mov.b32 	%r96, %f1702;
	add.f32 	%f287, %f280, 0f40000000;
	selp.f32 	%f288, 0fFF800000, 0f7F800000, %p28;
	add.f32 	%f1703, %f1518, 0f3F800000;
	sub.f32 	%f1704, %f1703, %f2868;
	div.rn.f32 	%f289, %f1704, %f2864;
	abs.f32 	%f290, %f289;
	setp.lt.f32 	%p546, %f290, 0f00800000;
	mul.f32 	%f1705, %f290, 0f4B800000;
	selp.f32 	%f1706, %f1705, %f290, %p546;
	selp.f32 	%f1707, 0fC3170000, 0fC2FE0000, %p546;
	mov.b32 	%r627, %f1706;
	and.b32  	%r628, %r627, 8388607;
	or.b32  	%r629, %r628, 1065353216;
	mov.b32 	%f1708, %r629;
	shr.u32 	%r630, %r627, 23;
	cvt.rn.f32.u32 	%f1709, %r630;
	add.f32 	%f1710, %f1707, %f1709;
	setp.gt.f32 	%p547, %f1708, 0f3FB504F3;
	mul.f32 	%f1711, %f1708, 0f3F000000;
	add.f32 	%f1712, %f1710, 0f3F800000;
	selp.f32 	%f1713, %f1712, %f1710, %p547;
	selp.f32 	%f1714, %f1711, %f1708, %p547;
	add.f32 	%f1715, %f1714, 0fBF800000;
	add.f32 	%f1716, %f1714, 0f3F800000;
	rcp.approx.ftz.f32 	%f1717, %f1716;
	add.f32 	%f1718, %f1715, %f1715;
	mul.f32 	%f1719, %f1718, %f1717;
	mul.f32 	%f1720, %f1719, %f1719;
	fma.rn.f32 	%f1721, %f1577, %f1720, %f1576;
	fma.rn.f32 	%f1722, %f1721, %f1720, %f1579;
	mul.rn.f32 	%f1723, %f1722, %f1720;
	mul.rn.f32 	%f1724, %f1723, %f1719;
	sub.f32 	%f1725, %f1715, %f1719;
	add.f32 	%f1726, %f1725, %f1725;
	neg.f32 	%f1727, %f1719;
	fma.rn.f32 	%f1728, %f1727, %f1715, %f1726;
	mul.rn.f32 	%f1729, %f1717, %f1728;
	add.f32 	%f1730, %f1724, %f1719;
	sub.f32 	%f1731, %f1719, %f1730;
	add.f32 	%f1732, %f1724, %f1731;
	add.f32 	%f1733, %f1729, %f1732;
	add.f32 	%f1734, %f1730, %f1733;
	sub.f32 	%f1735, %f1730, %f1734;
	add.f32 	%f1736, %f1733, %f1735;
	mul.rn.f32 	%f1737, %f1713, %f1595;
	mul.rn.f32 	%f1738, %f1713, %f1597;
	add.f32 	%f1739, %f1737, %f1734;
	sub.f32 	%f1740, %f1737, %f1739;
	add.f32 	%f1741, %f1734, %f1740;
	add.f32 	%f1742, %f1736, %f1741;
	add.f32 	%f1743, %f1738, %f1742;
	add.f32 	%f1744, %f1739, %f1743;
	sub.f32 	%f1745, %f1739, %f1744;
	add.f32 	%f1746, %f1743, %f1745;
	mul.rn.f32 	%f1747, %f1516, %f1744;
	neg.f32 	%f1748, %f1747;
	fma.rn.f32 	%f1749, %f1516, %f1744, %f1748;
	fma.rn.f32 	%f1750, %f1516, %f1746, %f1749;
	fma.rn.f32 	%f1751, %f1492, %f1744, %f1750;
	add.rn.f32 	%f1752, %f1747, %f1751;
	neg.f32 	%f1753, %f1752;
	add.rn.f32 	%f1754, %f1747, %f1753;
	add.rn.f32 	%f1755, %f1754, %f1751;
	mov.b32 	%r631, %f1752;
	setp.eq.s32 	%p548, %r631, 1118925336;
	add.s32 	%r632, %r631, -1;
	mov.b32 	%f1756, %r632;
	add.f32 	%f1757, %f1755, 0f37000000;
	selp.f32 	%f291, %f1757, %f1755, %p548;
	selp.f32 	%f1758, %f1756, %f1752, %p548;
	mul.rn.f32 	%f1759, %f1758, %f1620;
	cvt.rzi.f32.f32 	%f1760, %f1759;
	abs.f32 	%f1761, %f1760;
	setp.gt.f32 	%p549, %f1761, 0f42FC0000;
	mov.b32 	%r633, %f1760;
	and.b32  	%r634, %r633, -2147483648;
	or.b32  	%r635, %r634, 1123811328;
	mov.b32 	%f1762, %r635;
	selp.f32 	%f1763, %f1762, %f1760, %p549;
	fma.rn.f32 	%f1764, %f1763, %f1626, %f1758;
	fma.rn.f32 	%f1765, %f1763, %f1628, %f1764;
	mul.f32 	%f1766, %f1765, 0f3FB8AA3B;
	add.f32 	%f1767, %f1763, 0f4B40007F;
	mov.b32 	%r636, %f1767;
	shl.b32 	%r637, %r636, 23;
	mov.b32 	%f1768, %r637;
	ex2.approx.ftz.f32 	%f1769, %f1766;
	mul.f32 	%f292, %f1769, %f1768;
	setp.lt.f32 	%p550, %f289, 0f00000000;
	and.pred  	%p29, %p550, %p540;
	add.f32 	%f1770, %f289, %f289;
	selp.f32 	%f293, %f1770, 0f00000000, %p540;
	add.f32 	%f1771, %f290, 0f40000000;
	mov.b32 	%r97, %f1771;
	div.rn.f32 	%f294, %f270, %f2864;
	abs.f32 	%f295, %f294;
	setp.lt.f32 	%p551, %f295, 0f00800000;
	mul.f32 	%f1772, %f295, 0f4B800000;
	selp.f32 	%f1773, %f1772, %f295, %p551;
	selp.f32 	%f1774, 0fC3170000, 0fC2FE0000, %p551;
	mov.b32 	%r638, %f1773;
	and.b32  	%r639, %r638, 8388607;
	or.b32  	%r640, %r639, 1065353216;
	mov.b32 	%f1775, %r640;
	shr.u32 	%r641, %r638, 23;
	cvt.rn.f32.u32 	%f1776, %r641;
	add.f32 	%f1777, %f1774, %f1776;
	setp.gt.f32 	%p552, %f1775, 0f3FB504F3;
	mul.f32 	%f1778, %f1775, 0f3F000000;
	add.f32 	%f1779, %f1777, 0f3F800000;
	selp.f32 	%f1780, %f1779, %f1777, %p552;
	selp.f32 	%f1781, %f1778, %f1775, %p552;
	add.f32 	%f1782, %f1781, 0fBF800000;
	add.f32 	%f1783, %f1781, 0f3F800000;
	rcp.approx.ftz.f32 	%f1784, %f1783;
	add.f32 	%f1785, %f1782, %f1782;
	mul.f32 	%f1786, %f1785, %f1784;
	mul.f32 	%f1787, %f1786, %f1786;
	fma.rn.f32 	%f1788, %f1577, %f1787, %f1576;
	fma.rn.f32 	%f1789, %f1788, %f1787, %f1579;
	mul.rn.f32 	%f1790, %f1789, %f1787;
	mul.rn.f32 	%f1791, %f1790, %f1786;
	sub.f32 	%f1792, %f1782, %f1786;
	add.f32 	%f1793, %f1792, %f1792;
	neg.f32 	%f1794, %f1786;
	fma.rn.f32 	%f1795, %f1794, %f1782, %f1793;
	mul.rn.f32 	%f1796, %f1784, %f1795;
	add.f32 	%f1797, %f1791, %f1786;
	sub.f32 	%f1798, %f1786, %f1797;
	add.f32 	%f1799, %f1791, %f1798;
	add.f32 	%f1800, %f1796, %f1799;
	add.f32 	%f1801, %f1797, %f1800;
	sub.f32 	%f1802, %f1797, %f1801;
	add.f32 	%f1803, %f1800, %f1802;
	mul.rn.f32 	%f1804, %f1780, %f1595;
	mul.rn.f32 	%f1805, %f1780, %f1597;
	add.f32 	%f1806, %f1804, %f1801;
	sub.f32 	%f1807, %f1804, %f1806;
	add.f32 	%f1808, %f1801, %f1807;
	add.f32 	%f1809, %f1803, %f1808;
	add.f32 	%f1810, %f1805, %f1809;
	add.f32 	%f1811, %f1806, %f1810;
	sub.f32 	%f1812, %f1806, %f1811;
	add.f32 	%f1813, %f1810, %f1812;
	mul.rn.f32 	%f1814, %f1516, %f1811;
	neg.f32 	%f1815, %f1814;
	fma.rn.f32 	%f1816, %f1516, %f1811, %f1815;
	fma.rn.f32 	%f1817, %f1516, %f1813, %f1816;
	fma.rn.f32 	%f1818, %f1492, %f1811, %f1817;
	add.rn.f32 	%f1819, %f1814, %f1818;
	neg.f32 	%f1820, %f1819;
	add.rn.f32 	%f1821, %f1814, %f1820;
	add.rn.f32 	%f1822, %f1821, %f1818;
	mov.b32 	%r642, %f1819;
	setp.eq.s32 	%p553, %r642, 1118925336;
	add.s32 	%r643, %r642, -1;
	mov.b32 	%f1823, %r643;
	add.f32 	%f1824, %f1822, 0f37000000;
	selp.f32 	%f296, %f1824, %f1822, %p553;
	selp.f32 	%f1825, %f1823, %f1819, %p553;
	mul.rn.f32 	%f1826, %f1825, %f1620;
	cvt.rzi.f32.f32 	%f1827, %f1826;
	abs.f32 	%f1828, %f1827;
	setp.gt.f32 	%p554, %f1828, 0f42FC0000;
	mov.b32 	%r644, %f1827;
	and.b32  	%r645, %r644, -2147483648;
	or.b32  	%r646, %r645, 1123811328;
	mov.b32 	%f1829, %r646;
	selp.f32 	%f1830, %f1829, %f1827, %p554;
	fma.rn.f32 	%f1831, %f1830, %f1626, %f1825;
	fma.rn.f32 	%f1832, %f1830, %f1628, %f1831;
	mul.f32 	%f1833, %f1832, 0f3FB8AA3B;
	add.f32 	%f1834, %f1830, 0f4B40007F;
	mov.b32 	%r647, %f1834;
	shl.b32 	%r648, %r647, 23;
	mov.b32 	%f1835, %r648;
	ex2.approx.ftz.f32 	%f1836, %f1833;
	mul.f32 	%f297, %f1836, %f1835;
	add.f32 	%f298, %f289, 0f40000000;
	setp.lt.f32 	%p555, %f294, 0f00000000;
	and.pred  	%p30, %p555, %p540;
	selp.f32 	%f299, 0fFF800000, 0f7F800000, %p29;
	add.f32 	%f1837, %f294, %f294;
	selp.f32 	%f300, %f1837, 0f00000000, %p540;
	add.f32 	%f1838, %f295, 0f40000000;
	mov.b32 	%r98, %f1838;
	add.f32 	%f301, %f270, 0f3F800000;
	add.f32 	%f302, %f294, 0f40000000;
	selp.f32 	%f303, 0fFF800000, 0f7F800000, %p30;
	setp.geu.f32 	%p31, %f275, 0f00000000;
	setp.geu.f32 	%p32, %f280, 0f00000000;
	setp.geu.f32 	%p33, %f289, 0f00000000;
	setp.geu.f32 	%p34, %f294, 0f00000000;
	mov.u32 	%r784, %r601;

$L__BB1_340:
	setp.ltu.f32 	%p556, %f271, 0f3F8060FE;
	mov.f32 	%f2901, %f272;
	@%p556 bra 	$L__BB1_342;

	ex2.approx.ftz.f32 	%f1839, %f272;
	sub.f32 	%f1841, %f1513, %f1839;
	mov.b32 	%r649, %f1841;
	or.b32  	%r650, %r93, %r649;
	mov.b32 	%f2901, %r650;

$L__BB1_342:
	setp.ltu.f32 	%p557, %f273, 0f3F8060FE;
	mov.f32 	%f2902, %f274;
	@%p557 bra 	$L__BB1_344;

	ex2.approx.ftz.f32 	%f1842, %f274;
	sub.f32 	%f1844, %f1513, %f1842;
	mov.b32 	%r651, %f1844;
	or.b32  	%r652, %r94, %r651;
	mov.b32 	%f2902, %r652;

$L__BB1_344:
	sub.f32 	%f1845, %f2901, %f2902;
	mul.f32 	%f324, %f1845, 0f3F000000;
	cvt.rn.f32.s32 	%f325, %r784;
	sub.f32 	%f326, %f325, %f2867;
	add.f32 	%f1846, %f326, 0f3F000000;
	mul.f32 	%f327, %f252, %f1846;
	abs.f32 	%f1847, %f327;
	setp.ltu.f32 	%p558, %f1847, 0f3F8060FE;
	setp.ge.f32 	%p559, %f1847, 0f3F8060FE;
	mul.f32 	%f1848, %f327, %f327;
	selp.f32 	%f1849, %f1847, %f1848, %p559;
	selp.f32 	%f1850, 0f3789CA3C, 0f38B1E96A, %p559;
	selp.f32 	%f1851, 0fB9F560B9, 0fBA574D20, %p559;
	fma.rn.f32 	%f1852, %f1850, %f1849, %f1851;
	selp.f32 	%f1853, 0f3BAC840B, 0f3BAAD5EA, %p559;
	fma.rn.f32 	%f1854, %f1852, %f1849, %f1853;
	selp.f32 	%f1855, 0fBD0C8162, 0fBCDC1BE7, %p559;
	fma.rn.f32 	%f1856, %f1854, %f1849, %f1855;
	selp.f32 	%f1857, 0f3E1CF906, 0f3DE718AF, %p559;
	fma.rn.f32 	%f1858, %f1856, %f1849, %f1857;
	selp.f32 	%f1859, 0f3F6A937E, 0fBEC093AC, %p559;
	fma.rn.f32 	%f1860, %f1858, %f1849, %f1859;
	selp.f32 	%f1861, 0f3F20D842, 0f3E0375D3, %p559;
	fma.rn.f32 	%f1862, %f1860, %f1849, %f1861;
	neg.f32 	%f1863, %f1847;
	selp.f32 	%f1864, %f1863, %f327, %p559;
	fma.rn.f32 	%f2903, %f1862, %f1864, %f1864;
	@%p558 bra 	$L__BB1_346;

	ex2.approx.ftz.f32 	%f1865, %f2903;
	sub.f32 	%f1867, %f1513, %f1865;
	mov.b32 	%r653, %f1867;
	mov.b32 	%r654, %f327;
	and.b32  	%r655, %r654, -2147483648;
	or.b32  	%r656, %r655, %r653;
	mov.b32 	%f2903, %r656;

$L__BB1_346:
	add.f32 	%f331, %f326, 0fBF000000;
	mul.f32 	%f332, %f252, %f331;
	abs.f32 	%f1868, %f332;
	setp.ltu.f32 	%p560, %f1868, 0f3F8060FE;
	setp.ge.f32 	%p561, %f1868, 0f3F8060FE;
	mul.f32 	%f1869, %f332, %f332;
	selp.f32 	%f1870, %f1868, %f1869, %p561;
	selp.f32 	%f1871, 0f3789CA3C, 0f38B1E96A, %p561;
	selp.f32 	%f1872, 0fB9F560B9, 0fBA574D20, %p561;
	fma.rn.f32 	%f1873, %f1871, %f1870, %f1872;
	selp.f32 	%f1874, 0f3BAC840B, 0f3BAAD5EA, %p561;
	fma.rn.f32 	%f1875, %f1873, %f1870, %f1874;
	selp.f32 	%f1876, 0fBD0C8162, 0fBCDC1BE7, %p561;
	fma.rn.f32 	%f1877, %f1875, %f1870, %f1876;
	selp.f32 	%f1878, 0f3E1CF906, 0f3DE718AF, %p561;
	fma.rn.f32 	%f1879, %f1877, %f1870, %f1878;
	selp.f32 	%f1880, 0f3F6A937E, 0fBEC093AC, %p561;
	fma.rn.f32 	%f1881, %f1879, %f1870, %f1880;
	selp.f32 	%f1882, 0f3F20D842, 0f3E0375D3, %p561;
	fma.rn.f32 	%f1883, %f1881, %f1870, %f1882;
	neg.f32 	%f1884, %f1868;
	selp.f32 	%f1885, %f1884, %f332, %p561;
	fma.rn.f32 	%f2904, %f1883, %f1885, %f1885;
	@%p560 bra 	$L__BB1_348;

	ex2.approx.ftz.f32 	%f1886, %f2904;
	sub.f32 	%f1888, %f1513, %f1886;
	mov.b32 	%r657, %f1888;
	mov.b32 	%r658, %f332;
	and.b32  	%r659, %r658, -2147483648;
	or.b32  	%r660, %r659, %r657;
	mov.b32 	%f2904, %r660;

$L__BB1_348:
	sub.f32 	%f1890, %f2903, %f2904;
	mul.f32 	%f336, %f1890, 0f3F000000;
	mul.f32 	%f1891, %f324, %f2866;
	fma.rn.f32 	%f337, %f336, %f1891, %f2865;
	mad.lo.s32 	%r661, %r784, %r102, %r783;
	add.s32 	%r662, %r661, %r2;
	mul.wide.s32 	%rd28, %r662, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.f32 	%f338, [%rd29];
	setp.eq.f32 	%p562, %f278, 0f7F800000;
	mov.f32 	%f2905, 0f7F800000;
	@%p562 bra 	$L__BB1_350;

	fma.rn.f32 	%f2905, %f278, %f277, %f278;

$L__BB1_350:
	mov.b32 	%r663, %f2905;
	xor.b32  	%r664, %r663, -2147483648;
	mov.b32 	%f1892, %r664;
	selp.f32 	%f341, %f1892, %f2905, %p27;
	setp.eq.f32 	%p563, %f275, 0f00000000;
	selp.f32 	%f2906, %f279, %f341, %p563;
	@%p31 bra 	$L__BB1_353;

	cvt.rzi.f32.f32 	%f1894, %f1516;
	setp.eq.f32 	%p564, %f1894, 0f40000000;
	mov.f32 	%f2906, %f341;
	@%p564 bra 	$L__BB1_353;

	mov.f32 	%f2906, 0f7FFFFFFF;

$L__BB1_353:
	setp.eq.f32 	%p565, %f283, 0f7F800000;
	mov.f32 	%f2907, 0f7F800000;
	@%p565 bra 	$L__BB1_355;

	fma.rn.f32 	%f2907, %f283, %f282, %f283;

$L__BB1_355:
	mov.b32 	%r665, %f2907;
	xor.b32  	%r666, %r665, -2147483648;
	mov.b32 	%f1897, %r666;
	selp.f32 	%f346, %f1897, %f2907, %p28;
	setp.eq.f32 	%p566, %f280, 0f00000000;
	selp.f32 	%f2908, %f286, %f346, %p566;
	@%p32 bra 	$L__BB1_358;

	cvt.rzi.f32.f32 	%f1899, %f1516;
	setp.eq.f32 	%p567, %f1899, 0f40000000;
	mov.f32 	%f2908, %f346;
	@%p567 bra 	$L__BB1_358;

	mov.f32 	%f2908, 0f7FFFFFFF;

$L__BB1_358:
	setp.gtu.f32 	%p568, %f276, 0f7F800000;
	mov.f32 	%f2909, 0f7F800000;
	selp.f32 	%f1902, %f284, %f2906, %p568;
	setp.neu.f32 	%p569, %f276, 0f7F800000;
	selp.f32 	%f1903, %f1902, %f285, %p569;
	setp.gt.s32 	%p570, %r95, 2139095039;
	selp.f32 	%f1904, %f1903, %f2906, %p570;
	mul.f32 	%f1905, %f1904, 0fBF000000;
	setp.eq.f32 	%p571, %f275, 0f3F800000;
	selp.f32 	%f1906, 0fBF000000, %f1905, %p571;
	mov.f32 	%f1908, 0f3BBB989D;
	fma.rn.f32 	%f1909, %f1906, %f1908, %f1509;
	mov.f32 	%f1911, 0f437C0000;
	cvt.sat.f32.f32 	%f1912, %f1909;
	mov.f32 	%f1913, 0f4B400001;
	fma.rm.f32 	%f1914, %f1912, %f1911, %f1913;
	setp.gtu.f32 	%p572, %f281, 0f7F800000;
	selp.f32 	%f1915, %f287, %f2908, %p572;
	setp.neu.f32 	%p573, %f281, 0f7F800000;
	selp.f32 	%f1916, %f1915, %f288, %p573;
	setp.gt.s32 	%p574, %r96, 2139095039;
	selp.f32 	%f1917, %f1916, %f2908, %p574;
	mul.f32 	%f1918, %f1917, 0fBF000000;
	setp.eq.f32 	%p575, %f280, 0f3F800000;
	selp.f32 	%f1919, 0fBF000000, %f1918, %p575;
	fma.rn.f32 	%f1920, %f1919, %f1908, %f1509;
	cvt.sat.f32.f32 	%f1921, %f1920;
	fma.rm.f32 	%f1922, %f1921, %f1911, %f1913;
	add.f32 	%f1923, %f1922, 0fCB40007F;
	neg.f32 	%f1924, %f1923;
	fma.rn.f32 	%f1925, %f1919, %f1620, %f1924;
	mov.f32 	%f1926, 0f32A57060;
	fma.rn.f32 	%f1927, %f1919, %f1926, %f1925;
	mov.b32 	%r667, %f1922;
	shl.b32 	%r668, %r667, 23;
	mov.b32 	%f1928, %r668;
	ex2.approx.ftz.f32 	%f1929, %f1927;
	mul.f32 	%f1930, %f1929, %f1928;
	mov.b32 	%r669, %f1914;
	shl.b32 	%r670, %r669, 23;
	mov.b32 	%f1931, %r670;
	add.f32 	%f1932, %f1914, 0fCB40007F;
	neg.f32 	%f1933, %f1932;
	fma.rn.f32 	%f1934, %f1906, %f1620, %f1933;
	fma.rn.f32 	%f1935, %f1906, %f1926, %f1934;
	ex2.approx.ftz.f32 	%f1936, %f1935;
	mul.f32 	%f1937, %f1936, %f1931;
	sub.f32 	%f1938, %f1937, %f1930;
	mul.f32 	%f1939, %f250, %f1938;
	mul.f32 	%f349, %f336, %f1939;
	add.f32 	%f1940, %f325, 0f3F000000;
	sub.f32 	%f1941, %f1940, %f2867;
	div.rn.f32 	%f350, %f1941, %f2864;
	abs.f32 	%f351, %f350;
	setp.lt.f32 	%p576, %f351, 0f00800000;
	mul.f32 	%f1942, %f351, 0f4B800000;
	selp.f32 	%f1943, %f1942, %f351, %p576;
	selp.f32 	%f1944, 0fC3170000, 0fC2FE0000, %p576;
	mov.b32 	%r671, %f1943;
	and.b32  	%r672, %r671, 8388607;
	or.b32  	%r673, %r672, 1065353216;
	mov.b32 	%f1945, %r673;
	shr.u32 	%r674, %r671, 23;
	cvt.rn.f32.u32 	%f1946, %r674;
	add.f32 	%f1947, %f1944, %f1946;
	setp.gt.f32 	%p577, %f1945, 0f3FB504F3;
	mul.f32 	%f1948, %f1945, 0f3F000000;
	add.f32 	%f1949, %f1947, 0f3F800000;
	selp.f32 	%f1950, %f1949, %f1947, %p577;
	selp.f32 	%f1951, %f1948, %f1945, %p577;
	add.f32 	%f1952, %f1951, 0fBF800000;
	add.f32 	%f1953, %f1951, 0f3F800000;
	rcp.approx.ftz.f32 	%f1954, %f1953;
	add.f32 	%f1955, %f1952, %f1952;
	mul.f32 	%f1957, %f1955, %f1954;
	mul.f32 	%f1958, %f1957, %f1957;
	fma.rn.f32 	%f1961, %f1577, %f1958, %f1576;
	fma.rn.f32 	%f1963, %f1961, %f1958, %f1579;
	mul.rn.f32 	%f1964, %f1963, %f1958;
	mul.rn.f32 	%f1965, %f1964, %f1957;
	sub.f32 	%f1966, %f1952, %f1957;
	add.f32 	%f1967, %f1966, %f1966;
	neg.f32 	%f1968, %f1957;
	fma.rn.f32 	%f1969, %f1968, %f1952, %f1967;
	mul.rn.f32 	%f1970, %f1954, %f1969;
	add.f32 	%f1971, %f1965, %f1957;
	sub.f32 	%f1972, %f1957, %f1971;
	add.f32 	%f1973, %f1965, %f1972;
	add.f32 	%f1974, %f1970, %f1973;
	add.f32 	%f1975, %f1971, %f1974;
	sub.f32 	%f1976, %f1971, %f1975;
	add.f32 	%f1977, %f1974, %f1976;
	mul.rn.f32 	%f1979, %f1950, %f1595;
	mul.rn.f32 	%f1981, %f1950, %f1597;
	add.f32 	%f1982, %f1979, %f1975;
	sub.f32 	%f1983, %f1979, %f1982;
	add.f32 	%f1984, %f1975, %f1983;
	add.f32 	%f1985, %f1977, %f1984;
	add.f32 	%f1986, %f1981, %f1985;
	add.f32 	%f1987, %f1982, %f1986;
	sub.f32 	%f1988, %f1982, %f1987;
	add.f32 	%f1989, %f1986, %f1988;
	mul.rn.f32 	%f1990, %f1516, %f1987;
	neg.f32 	%f1991, %f1990;
	fma.rn.f32 	%f1992, %f1516, %f1987, %f1991;
	fma.rn.f32 	%f1993, %f1516, %f1989, %f1992;
	mov.f32 	%f1994, 0f00000000;
	fma.rn.f32 	%f1995, %f1994, %f1987, %f1993;
	add.rn.f32 	%f1996, %f1990, %f1995;
	neg.f32 	%f1997, %f1996;
	add.rn.f32 	%f1998, %f1990, %f1997;
	add.rn.f32 	%f1999, %f1998, %f1995;
	mov.b32 	%r675, %f1996;
	setp.eq.s32 	%p578, %r675, 1118925336;
	add.s32 	%r676, %r675, -1;
	mov.b32 	%f2000, %r676;
	add.f32 	%f2001, %f1999, 0f37000000;
	selp.f32 	%f352, %f2001, %f1999, %p578;
	selp.f32 	%f2002, %f2000, %f1996, %p578;
	mul.rn.f32 	%f2003, %f2002, %f1620;
	cvt.rzi.f32.f32 	%f2004, %f2003;
	abs.f32 	%f2005, %f2004;
	setp.gt.f32 	%p579, %f2005, 0f42FC0000;
	mov.b32 	%r677, %f2004;
	and.b32  	%r678, %r677, -2147483648;
	or.b32  	%r679, %r678, 1123811328;
	mov.b32 	%f2006, %r679;
	selp.f32 	%f2007, %f2006, %f2004, %p579;
	fma.rn.f32 	%f2009, %f2007, %f1626, %f2002;
	fma.rn.f32 	%f2011, %f2007, %f1628, %f2009;
	mul.f32 	%f2012, %f2011, 0f3FB8AA3B;
	add.f32 	%f2013, %f2007, 0f4B40007F;
	mov.b32 	%r680, %f2013;
	shl.b32 	%r681, %r680, 23;
	mov.b32 	%f2014, %r681;
	ex2.approx.ftz.f32 	%f2015, %f2012;
	mul.f32 	%f353, %f2015, %f2014;
	setp.eq.f32 	%p580, %f353, 0f7F800000;
	@%p580 bra 	$L__BB1_360;

	fma.rn.f32 	%f2909, %f353, %f352, %f353;

$L__BB1_360:
	setp.lt.f32 	%p581, %f350, 0f00000000;
	and.pred  	%p35, %p581, %p540;
	setp.eq.f32 	%p583, %f350, 0f00000000;
	@%p583 bra 	$L__BB1_364;
	bra.uni 	$L__BB1_361;

$L__BB1_364:
	add.f32 	%f2020, %f350, %f350;
	selp.f32 	%f2911, %f2020, 0f00000000, %p540;
	bra.uni 	$L__BB1_365;

$L__BB1_361:
	mov.b32 	%r682, %f2909;
	xor.b32  	%r683, %r682, -2147483648;
	mov.b32 	%f2016, %r683;
	selp.f32 	%f2911, %f2016, %f2909, %p35;
	setp.geu.f32 	%p584, %f350, 0f00000000;
	@%p584 bra 	$L__BB1_365;

	cvt.rzi.f32.f32 	%f2018, %f1516;
	setp.eq.f32 	%p585, %f2018, 0f40000000;
	@%p585 bra 	$L__BB1_365;

	mov.f32 	%f2911, 0f7FFFFFFF;

$L__BB1_365:
	add.f32 	%f2021, %f351, 0f40000000;
	mov.b32 	%r684, %f2021;
	setp.lt.s32 	%p587, %r684, 2139095040;
	@%p587 bra 	$L__BB1_370;

	setp.gtu.f32 	%p588, %f351, 0f7F800000;
	@%p588 bra 	$L__BB1_369;
	bra.uni 	$L__BB1_367;

$L__BB1_369:
	add.f32 	%f2911, %f350, 0f40000000;
	bra.uni 	$L__BB1_370;

$L__BB1_367:
	setp.neu.f32 	%p589, %f351, 0f7F800000;
	@%p589 bra 	$L__BB1_370;

	selp.f32 	%f2911, 0fFF800000, 0f7F800000, %p35;

$L__BB1_370:
	mul.f32 	%f2023, %f2911, 0fBF000000;
	setp.eq.f32 	%p590, %f350, 0f3F800000;
	selp.f32 	%f2024, 0fBF000000, %f2023, %p590;
	fma.rn.f32 	%f2027, %f2024, %f1908, %f1509;
	cvt.sat.f32.f32 	%f2030, %f2027;
	fma.rm.f32 	%f2032, %f2030, %f1911, %f1913;
	add.f32 	%f2033, %f2032, 0fCB40007F;
	neg.f32 	%f2034, %f2033;
	fma.rn.f32 	%f2035, %f2024, %f1620, %f2034;
	fma.rn.f32 	%f2037, %f2024, %f1926, %f2035;
	mov.b32 	%r685, %f2032;
	shl.b32 	%r686, %r685, 23;
	mov.b32 	%f2038, %r686;
	ex2.approx.ftz.f32 	%f2039, %f2037;
	mul.f32 	%f362, %f2039, %f2038;
	div.rn.f32 	%f363, %f331, %f2864;
	abs.f32 	%f364, %f363;
	setp.lt.f32 	%p591, %f364, 0f00800000;
	mul.f32 	%f2040, %f364, 0f4B800000;
	selp.f32 	%f2041, %f2040, %f364, %p591;
	selp.f32 	%f2042, 0fC3170000, 0fC2FE0000, %p591;
	mov.b32 	%r687, %f2041;
	and.b32  	%r688, %r687, 8388607;
	or.b32  	%r689, %r688, 1065353216;
	mov.b32 	%f2043, %r689;
	shr.u32 	%r690, %r687, 23;
	cvt.rn.f32.u32 	%f2044, %r690;
	add.f32 	%f2045, %f2042, %f2044;
	setp.gt.f32 	%p592, %f2043, 0f3FB504F3;
	mul.f32 	%f2046, %f2043, 0f3F000000;
	add.f32 	%f2047, %f2045, 0f3F800000;
	selp.f32 	%f2048, %f2047, %f2045, %p592;
	selp.f32 	%f2049, %f2046, %f2043, %p592;
	add.f32 	%f2050, %f2049, 0fBF800000;
	add.f32 	%f2051, %f2049, 0f3F800000;
	rcp.approx.ftz.f32 	%f2052, %f2051;
	add.f32 	%f2053, %f2050, %f2050;
	mul.f32 	%f2055, %f2053, %f2052;
	mul.f32 	%f2056, %f2055, %f2055;
	fma.rn.f32 	%f2059, %f1577, %f2056, %f1576;
	fma.rn.f32 	%f2061, %f2059, %f2056, %f1579;
	mul.rn.f32 	%f2062, %f2061, %f2056;
	mul.rn.f32 	%f2063, %f2062, %f2055;
	sub.f32 	%f2064, %f2050, %f2055;
	add.f32 	%f2065, %f2064, %f2064;
	neg.f32 	%f2066, %f2055;
	fma.rn.f32 	%f2067, %f2066, %f2050, %f2065;
	mul.rn.f32 	%f2068, %f2052, %f2067;
	add.f32 	%f2069, %f2063, %f2055;
	sub.f32 	%f2070, %f2055, %f2069;
	add.f32 	%f2071, %f2063, %f2070;
	add.f32 	%f2072, %f2068, %f2071;
	add.f32 	%f2073, %f2069, %f2072;
	sub.f32 	%f2074, %f2069, %f2073;
	add.f32 	%f2075, %f2072, %f2074;
	mul.rn.f32 	%f2077, %f2048, %f1595;
	mul.rn.f32 	%f2079, %f2048, %f1597;
	add.f32 	%f2080, %f2077, %f2073;
	sub.f32 	%f2081, %f2077, %f2080;
	add.f32 	%f2082, %f2073, %f2081;
	add.f32 	%f2083, %f2075, %f2082;
	add.f32 	%f2084, %f2079, %f2083;
	add.f32 	%f2085, %f2080, %f2084;
	sub.f32 	%f2086, %f2080, %f2085;
	add.f32 	%f2087, %f2084, %f2086;
	mul.rn.f32 	%f2088, %f1516, %f2085;
	neg.f32 	%f2089, %f2088;
	fma.rn.f32 	%f2090, %f1516, %f2085, %f2089;
	fma.rn.f32 	%f2091, %f1516, %f2087, %f2090;
	fma.rn.f32 	%f2093, %f1994, %f2085, %f2091;
	add.rn.f32 	%f2094, %f2088, %f2093;
	neg.f32 	%f2095, %f2094;
	add.rn.f32 	%f2096, %f2088, %f2095;
	add.rn.f32 	%f2097, %f2096, %f2093;
	mov.b32 	%r691, %f2094;
	setp.eq.s32 	%p593, %r691, 1118925336;
	add.s32 	%r692, %r691, -1;
	mov.b32 	%f2098, %r692;
	add.f32 	%f2099, %f2097, 0f37000000;
	selp.f32 	%f365, %f2099, %f2097, %p593;
	selp.f32 	%f2100, %f2098, %f2094, %p593;
	mul.rn.f32 	%f2101, %f2100, %f1620;
	cvt.rzi.f32.f32 	%f2102, %f2101;
	abs.f32 	%f2103, %f2102;
	setp.gt.f32 	%p594, %f2103, 0f42FC0000;
	mov.b32 	%r693, %f2102;
	and.b32  	%r694, %r693, -2147483648;
	or.b32  	%r695, %r694, 1123811328;
	mov.b32 	%f2104, %r695;
	selp.f32 	%f2105, %f2104, %f2102, %p594;
	fma.rn.f32 	%f2107, %f2105, %f1626, %f2100;
	fma.rn.f32 	%f2109, %f2105, %f1628, %f2107;
	mul.f32 	%f2110, %f2109, 0f3FB8AA3B;
	add.f32 	%f2111, %f2105, 0f4B40007F;
	mov.b32 	%r696, %f2111;
	shl.b32 	%r697, %r696, 23;
	mov.b32 	%f2112, %r697;
	ex2.approx.ftz.f32 	%f2113, %f2110;
	mul.f32 	%f366, %f2113, %f2112;
	setp.eq.f32 	%p595, %f366, 0f7F800000;
	mov.f32 	%f2912, 0f7F800000;
	@%p595 bra 	$L__BB1_372;

	fma.rn.f32 	%f2912, %f366, %f365, %f366;

$L__BB1_372:
	setp.lt.f32 	%p596, %f363, 0f00000000;
	and.pred  	%p36, %p596, %p540;
	setp.eq.f32 	%p598, %f363, 0f00000000;
	@%p598 bra 	$L__BB1_376;
	bra.uni 	$L__BB1_373;

$L__BB1_376:
	add.f32 	%f2118, %f363, %f363;
	selp.f32 	%f2914, %f2118, 0f00000000, %p540;
	bra.uni 	$L__BB1_377;

$L__BB1_373:
	mov.b32 	%r698, %f2912;
	xor.b32  	%r699, %r698, -2147483648;
	mov.b32 	%f2114, %r699;
	selp.f32 	%f2914, %f2114, %f2912, %p36;
	setp.geu.f32 	%p599, %f363, 0f00000000;
	@%p599 bra 	$L__BB1_377;

	cvt.rzi.f32.f32 	%f2116, %f1516;
	setp.eq.f32 	%p600, %f2116, 0f40000000;
	@%p600 bra 	$L__BB1_377;

	mov.f32 	%f2914, 0f7FFFFFFF;

$L__BB1_377:
	add.f32 	%f2119, %f364, 0f40000000;
	mov.b32 	%r700, %f2119;
	setp.lt.s32 	%p602, %r700, 2139095040;
	@%p602 bra 	$L__BB1_382;

	setp.gtu.f32 	%p603, %f364, 0f7F800000;
	@%p603 bra 	$L__BB1_381;
	bra.uni 	$L__BB1_379;

$L__BB1_381:
	add.f32 	%f2914, %f363, 0f40000000;
	bra.uni 	$L__BB1_382;

$L__BB1_379:
	setp.neu.f32 	%p604, %f364, 0f7F800000;
	@%p604 bra 	$L__BB1_382;

	selp.f32 	%f2914, 0fFF800000, 0f7F800000, %p36;

$L__BB1_382:
	mul.f32 	%f2121, %f2914, 0fBF000000;
	setp.eq.f32 	%p605, %f363, 0f3F800000;
	selp.f32 	%f2122, 0fBF000000, %f2121, %p605;
	fma.rn.f32 	%f2125, %f2122, %f1908, %f1509;
	cvt.sat.f32.f32 	%f2128, %f2125;
	fma.rm.f32 	%f2130, %f2128, %f1911, %f1913;
	add.f32 	%f2131, %f2130, 0fCB40007F;
	neg.f32 	%f2132, %f2131;
	fma.rn.f32 	%f2133, %f2122, %f1620, %f2132;
	fma.rn.f32 	%f2135, %f2122, %f1926, %f2133;
	mov.b32 	%r701, %f2130;
	shl.b32 	%r702, %r701, 23;
	mov.b32 	%f2136, %r702;
	ex2.approx.ftz.f32 	%f2137, %f2135;
	mul.f32 	%f2138, %f2137, %f2136;
	sub.f32 	%f375, %f362, %f2138;
	setp.eq.f32 	%p606, %f292, 0f7F800000;
	mov.f32 	%f2915, 0f7F800000;
	@%p606 bra 	$L__BB1_384;

	fma.rn.f32 	%f2915, %f292, %f291, %f292;

$L__BB1_384:
	mov.b32 	%r703, %f2915;
	xor.b32  	%r704, %r703, -2147483648;
	mov.b32 	%f2139, %r704;
	selp.f32 	%f378, %f2139, %f2915, %p29;
	setp.eq.f32 	%p607, %f289, 0f00000000;
	selp.f32 	%f2916, %f293, %f378, %p607;
	@%p33 bra 	$L__BB1_387;

	cvt.rzi.f32.f32 	%f2141, %f1516;
	setp.eq.f32 	%p608, %f2141, 0f40000000;
	mov.f32 	%f2916, %f378;
	@%p608 bra 	$L__BB1_387;

	mov.f32 	%f2916, 0f7FFFFFFF;

$L__BB1_387:
	setp.eq.f32 	%p609, %f297, 0f7F800000;
	mov.f32 	%f2917, 0f7F800000;
	@%p609 bra 	$L__BB1_389;

	fma.rn.f32 	%f2917, %f297, %f296, %f297;

$L__BB1_389:
	mov.b32 	%r705, %f2917;
	xor.b32  	%r706, %r705, -2147483648;
	mov.b32 	%f2144, %r706;
	selp.f32 	%f383, %f2144, %f2917, %p30;
	setp.eq.f32 	%p610, %f294, 0f00000000;
	selp.f32 	%f2918, %f300, %f383, %p610;
	@%p34 bra 	$L__BB1_392;

	cvt.rzi.f32.f32 	%f2146, %f1516;
	setp.eq.f32 	%p611, %f2146, 0f40000000;
	mov.f32 	%f2918, %f383;
	@%p611 bra 	$L__BB1_392;

	mov.f32 	%f2918, 0f7FFFFFFF;

$L__BB1_392:
	mul.f32 	%f2149, %f250, %f375;
	mul.f32 	%f386, %f324, %f2149;
	setp.gtu.f32 	%p612, %f290, 0f7F800000;
	mov.f32 	%f2919, 0f7F800000;
	selp.f32 	%f2150, %f298, %f2916, %p612;
	setp.neu.f32 	%p613, %f290, 0f7F800000;
	selp.f32 	%f2151, %f2150, %f299, %p613;
	setp.gt.s32 	%p614, %r97, 2139095039;
	selp.f32 	%f2152, %f2151, %f2916, %p614;
	mul.f32 	%f2153, %f2152, 0fBF000000;
	setp.eq.f32 	%p615, %f289, 0f3F800000;
	selp.f32 	%f2154, 0fBF000000, %f2153, %p615;
	fma.rn.f32 	%f2157, %f2154, %f1908, %f1509;
	cvt.sat.f32.f32 	%f2160, %f2157;
	fma.rm.f32 	%f2162, %f2160, %f1911, %f1913;
	setp.gtu.f32 	%p616, %f295, 0f7F800000;
	selp.f32 	%f2163, %f302, %f2918, %p616;
	setp.neu.f32 	%p617, %f295, 0f7F800000;
	selp.f32 	%f2164, %f2163, %f303, %p617;
	setp.gt.s32 	%p618, %r98, 2139095039;
	selp.f32 	%f2165, %f2164, %f2918, %p618;
	mul.f32 	%f2166, %f2165, 0fBF000000;
	setp.eq.f32 	%p619, %f294, 0f3F800000;
	selp.f32 	%f2167, 0fBF000000, %f2166, %p619;
	fma.rn.f32 	%f2168, %f2167, %f1908, %f1509;
	cvt.sat.f32.f32 	%f2169, %f2168;
	fma.rm.f32 	%f2170, %f2169, %f1911, %f1913;
	add.f32 	%f2171, %f2170, 0fCB40007F;
	neg.f32 	%f2172, %f2171;
	fma.rn.f32 	%f2173, %f2167, %f1620, %f2172;
	fma.rn.f32 	%f2175, %f2167, %f1926, %f2173;
	mov.b32 	%r707, %f2170;
	shl.b32 	%r708, %r707, 23;
	mov.b32 	%f2176, %r708;
	ex2.approx.ftz.f32 	%f2177, %f2175;
	mul.f32 	%f2178, %f2177, %f2176;
	mul.f32 	%f2179, %f270, %f2178;
	mov.b32 	%r709, %f2162;
	shl.b32 	%r710, %r709, 23;
	mov.b32 	%f2180, %r710;
	add.f32 	%f2181, %f2162, 0fCB40007F;
	neg.f32 	%f2182, %f2181;
	fma.rn.f32 	%f2183, %f2154, %f1620, %f2182;
	fma.rn.f32 	%f2184, %f2154, %f1926, %f2183;
	ex2.approx.ftz.f32 	%f2185, %f2184;
	mul.f32 	%f2186, %f2185, %f2180;
	mul.f32 	%f2187, %f301, %f2186;
	sub.f32 	%f2188, %f2187, %f2179;
	mul.f32 	%f2189, %f251, %f2188;
	mul.f32 	%f387, %f336, %f2189;
	add.f32 	%f2190, %f325, 0f3F800000;
	sub.f32 	%f2191, %f2190, %f2867;
	div.rn.f32 	%f388, %f2191, %f2864;
	abs.f32 	%f389, %f388;
	setp.lt.f32 	%p620, %f389, 0f00800000;
	mul.f32 	%f2192, %f389, 0f4B800000;
	selp.f32 	%f2193, %f2192, %f389, %p620;
	selp.f32 	%f2194, 0fC3170000, 0fC2FE0000, %p620;
	mov.b32 	%r711, %f2193;
	and.b32  	%r712, %r711, 8388607;
	or.b32  	%r713, %r712, 1065353216;
	mov.b32 	%f2195, %r713;
	shr.u32 	%r714, %r711, 23;
	cvt.rn.f32.u32 	%f2196, %r714;
	add.f32 	%f2197, %f2194, %f2196;
	setp.gt.f32 	%p621, %f2195, 0f3FB504F3;
	mul.f32 	%f2198, %f2195, 0f3F000000;
	add.f32 	%f2199, %f2197, 0f3F800000;
	selp.f32 	%f2200, %f2199, %f2197, %p621;
	selp.f32 	%f2201, %f2198, %f2195, %p621;
	add.f32 	%f2202, %f2201, 0fBF800000;
	add.f32 	%f2203, %f2201, 0f3F800000;
	rcp.approx.ftz.f32 	%f2204, %f2203;
	add.f32 	%f2205, %f2202, %f2202;
	mul.f32 	%f2207, %f2205, %f2204;
	mul.f32 	%f2208, %f2207, %f2207;
	fma.rn.f32 	%f2211, %f1577, %f2208, %f1576;
	fma.rn.f32 	%f2213, %f2211, %f2208, %f1579;
	mul.rn.f32 	%f2214, %f2213, %f2208;
	mul.rn.f32 	%f2215, %f2214, %f2207;
	sub.f32 	%f2216, %f2202, %f2207;
	add.f32 	%f2217, %f2216, %f2216;
	neg.f32 	%f2218, %f2207;
	fma.rn.f32 	%f2219, %f2218, %f2202, %f2217;
	mul.rn.f32 	%f2220, %f2204, %f2219;
	add.f32 	%f2221, %f2215, %f2207;
	sub.f32 	%f2222, %f2207, %f2221;
	add.f32 	%f2223, %f2215, %f2222;
	add.f32 	%f2224, %f2220, %f2223;
	add.f32 	%f2225, %f2221, %f2224;
	sub.f32 	%f2226, %f2221, %f2225;
	add.f32 	%f2227, %f2224, %f2226;
	mul.rn.f32 	%f2229, %f2200, %f1595;
	mul.rn.f32 	%f2231, %f2200, %f1597;
	add.f32 	%f2232, %f2229, %f2225;
	sub.f32 	%f2233, %f2229, %f2232;
	add.f32 	%f2234, %f2225, %f2233;
	add.f32 	%f2235, %f2227, %f2234;
	add.f32 	%f2236, %f2231, %f2235;
	add.f32 	%f2237, %f2232, %f2236;
	sub.f32 	%f2238, %f2232, %f2237;
	add.f32 	%f2239, %f2236, %f2238;
	mul.rn.f32 	%f2240, %f1516, %f2237;
	neg.f32 	%f2241, %f2240;
	fma.rn.f32 	%f2242, %f1516, %f2237, %f2241;
	fma.rn.f32 	%f2243, %f1516, %f2239, %f2242;
	fma.rn.f32 	%f2245, %f1994, %f2237, %f2243;
	add.rn.f32 	%f2246, %f2240, %f2245;
	neg.f32 	%f2247, %f2246;
	add.rn.f32 	%f2248, %f2240, %f2247;
	add.rn.f32 	%f2249, %f2248, %f2245;
	mov.b32 	%r715, %f2246;
	setp.eq.s32 	%p622, %r715, 1118925336;
	add.s32 	%r716, %r715, -1;
	mov.b32 	%f2250, %r716;
	add.f32 	%f2251, %f2249, 0f37000000;
	selp.f32 	%f390, %f2251, %f2249, %p622;
	selp.f32 	%f2252, %f2250, %f2246, %p622;
	mul.rn.f32 	%f2253, %f2252, %f1620;
	cvt.rzi.f32.f32 	%f2254, %f2253;
	abs.f32 	%f2255, %f2254;
	setp.gt.f32 	%p623, %f2255, 0f42FC0000;
	mov.b32 	%r717, %f2254;
	and.b32  	%r718, %r717, -2147483648;
	or.b32  	%r719, %r718, 1123811328;
	mov.b32 	%f2256, %r719;
	selp.f32 	%f2257, %f2256, %f2254, %p623;
	fma.rn.f32 	%f2259, %f2257, %f1626, %f2252;
	fma.rn.f32 	%f2261, %f2257, %f1628, %f2259;
	mul.f32 	%f2262, %f2261, 0f3FB8AA3B;
	add.f32 	%f2263, %f2257, 0f4B40007F;
	mov.b32 	%r720, %f2263;
	shl.b32 	%r721, %r720, 23;
	mov.b32 	%f2264, %r721;
	ex2.approx.ftz.f32 	%f2265, %f2262;
	mul.f32 	%f391, %f2265, %f2264;
	setp.eq.f32 	%p624, %f391, 0f7F800000;
	@%p624 bra 	$L__BB1_394;

	fma.rn.f32 	%f2919, %f391, %f390, %f391;

$L__BB1_394:
	setp.lt.f32 	%p625, %f388, 0f00000000;
	and.pred  	%p37, %p625, %p540;
	setp.eq.f32 	%p627, %f388, 0f00000000;
	@%p627 bra 	$L__BB1_398;
	bra.uni 	$L__BB1_395;

$L__BB1_398:
	add.f32 	%f2270, %f388, %f388;
	selp.f32 	%f2921, %f2270, 0f00000000, %p540;
	bra.uni 	$L__BB1_399;

$L__BB1_395:
	mov.b32 	%r722, %f2919;
	xor.b32  	%r723, %r722, -2147483648;
	mov.b32 	%f2266, %r723;
	selp.f32 	%f2921, %f2266, %f2919, %p37;
	setp.geu.f32 	%p628, %f388, 0f00000000;
	@%p628 bra 	$L__BB1_399;

	cvt.rzi.f32.f32 	%f2268, %f1516;
	setp.eq.f32 	%p629, %f2268, 0f40000000;
	@%p629 bra 	$L__BB1_399;

	mov.f32 	%f2921, 0f7FFFFFFF;

$L__BB1_399:
	add.f32 	%f2271, %f389, 0f40000000;
	mov.b32 	%r724, %f2271;
	setp.lt.s32 	%p631, %r724, 2139095040;
	@%p631 bra 	$L__BB1_404;

	setp.gtu.f32 	%p632, %f389, 0f7F800000;
	@%p632 bra 	$L__BB1_403;
	bra.uni 	$L__BB1_401;

$L__BB1_403:
	add.f32 	%f2921, %f388, 0f40000000;
	bra.uni 	$L__BB1_404;

$L__BB1_401:
	setp.neu.f32 	%p633, %f389, 0f7F800000;
	@%p633 bra 	$L__BB1_404;

	selp.f32 	%f2921, 0fFF800000, 0f7F800000, %p37;

$L__BB1_404:
	mul.f32 	%f2273, %f2921, 0fBF000000;
	setp.eq.f32 	%p634, %f388, 0f3F800000;
	selp.f32 	%f2274, 0fBF000000, %f2273, %p634;
	fma.rn.f32 	%f2277, %f2274, %f1908, %f1509;
	cvt.sat.f32.f32 	%f2280, %f2277;
	fma.rm.f32 	%f2282, %f2280, %f1911, %f1913;
	add.f32 	%f2283, %f2282, 0fCB40007F;
	neg.f32 	%f2284, %f2283;
	fma.rn.f32 	%f2285, %f2274, %f1620, %f2284;
	fma.rn.f32 	%f2287, %f2274, %f1926, %f2285;
	mov.b32 	%r725, %f2282;
	shl.b32 	%r726, %r725, 23;
	mov.b32 	%f2288, %r726;
	ex2.approx.ftz.f32 	%f2289, %f2287;
	mul.f32 	%f400, %f2289, %f2288;
	div.rn.f32 	%f401, %f326, %f2864;
	abs.f32 	%f402, %f401;
	setp.lt.f32 	%p635, %f402, 0f00800000;
	mul.f32 	%f2290, %f402, 0f4B800000;
	selp.f32 	%f2291, %f2290, %f402, %p635;
	selp.f32 	%f2292, 0fC3170000, 0fC2FE0000, %p635;
	mov.b32 	%r727, %f2291;
	and.b32  	%r728, %r727, 8388607;
	or.b32  	%r729, %r728, 1065353216;
	mov.b32 	%f2293, %r729;
	shr.u32 	%r730, %r727, 23;
	cvt.rn.f32.u32 	%f2294, %r730;
	add.f32 	%f2295, %f2292, %f2294;
	setp.gt.f32 	%p636, %f2293, 0f3FB504F3;
	mul.f32 	%f2296, %f2293, 0f3F000000;
	add.f32 	%f2297, %f2295, 0f3F800000;
	selp.f32 	%f2298, %f2297, %f2295, %p636;
	selp.f32 	%f2299, %f2296, %f2293, %p636;
	add.f32 	%f2300, %f2299, 0fBF800000;
	add.f32 	%f2301, %f2299, 0f3F800000;
	rcp.approx.ftz.f32 	%f2302, %f2301;
	add.f32 	%f2303, %f2300, %f2300;
	mul.f32 	%f2305, %f2303, %f2302;
	mul.f32 	%f2306, %f2305, %f2305;
	fma.rn.f32 	%f2309, %f1577, %f2306, %f1576;
	fma.rn.f32 	%f2311, %f2309, %f2306, %f1579;
	mul.rn.f32 	%f2312, %f2311, %f2306;
	mul.rn.f32 	%f2313, %f2312, %f2305;
	sub.f32 	%f2314, %f2300, %f2305;
	add.f32 	%f2315, %f2314, %f2314;
	neg.f32 	%f2316, %f2305;
	fma.rn.f32 	%f2317, %f2316, %f2300, %f2315;
	mul.rn.f32 	%f2318, %f2302, %f2317;
	add.f32 	%f2319, %f2313, %f2305;
	sub.f32 	%f2320, %f2305, %f2319;
	add.f32 	%f2321, %f2313, %f2320;
	add.f32 	%f2322, %f2318, %f2321;
	add.f32 	%f2323, %f2319, %f2322;
	sub.f32 	%f2324, %f2319, %f2323;
	add.f32 	%f2325, %f2322, %f2324;
	mul.rn.f32 	%f2327, %f2298, %f1595;
	mul.rn.f32 	%f2329, %f2298, %f1597;
	add.f32 	%f2330, %f2327, %f2323;
	sub.f32 	%f2331, %f2327, %f2330;
	add.f32 	%f2332, %f2323, %f2331;
	add.f32 	%f2333, %f2325, %f2332;
	add.f32 	%f2334, %f2329, %f2333;
	add.f32 	%f2335, %f2330, %f2334;
	sub.f32 	%f2336, %f2330, %f2335;
	add.f32 	%f2337, %f2334, %f2336;
	mul.rn.f32 	%f2338, %f1516, %f2335;
	neg.f32 	%f2339, %f2338;
	fma.rn.f32 	%f2340, %f1516, %f2335, %f2339;
	fma.rn.f32 	%f2341, %f1516, %f2337, %f2340;
	fma.rn.f32 	%f2343, %f1994, %f2335, %f2341;
	add.rn.f32 	%f2344, %f2338, %f2343;
	neg.f32 	%f2345, %f2344;
	add.rn.f32 	%f2346, %f2338, %f2345;
	add.rn.f32 	%f2347, %f2346, %f2343;
	mov.b32 	%r731, %f2344;
	setp.eq.s32 	%p637, %r731, 1118925336;
	add.s32 	%r732, %r731, -1;
	mov.b32 	%f2348, %r732;
	add.f32 	%f2349, %f2347, 0f37000000;
	selp.f32 	%f403, %f2349, %f2347, %p637;
	selp.f32 	%f2350, %f2348, %f2344, %p637;
	mul.rn.f32 	%f2351, %f2350, %f1620;
	cvt.rzi.f32.f32 	%f2352, %f2351;
	abs.f32 	%f2353, %f2352;
	setp.gt.f32 	%p638, %f2353, 0f42FC0000;
	mov.b32 	%r733, %f2352;
	and.b32  	%r734, %r733, -2147483648;
	or.b32  	%r735, %r734, 1123811328;
	mov.b32 	%f2354, %r735;
	selp.f32 	%f2355, %f2354, %f2352, %p638;
	fma.rn.f32 	%f2357, %f2355, %f1626, %f2350;
	fma.rn.f32 	%f2359, %f2355, %f1628, %f2357;
	mul.f32 	%f2360, %f2359, 0f3FB8AA3B;
	add.f32 	%f2361, %f2355, 0f4B40007F;
	mov.b32 	%r736, %f2361;
	shl.b32 	%r737, %r736, 23;
	mov.b32 	%f2362, %r737;
	ex2.approx.ftz.f32 	%f2363, %f2360;
	mul.f32 	%f404, %f2363, %f2362;
	setp.eq.f32 	%p639, %f404, 0f7F800000;
	mov.f32 	%f2922, 0f7F800000;
	@%p639 bra 	$L__BB1_406;

	fma.rn.f32 	%f2922, %f404, %f403, %f404;

$L__BB1_406:
	setp.lt.f32 	%p640, %f401, 0f00000000;
	and.pred  	%p38, %p640, %p540;
	setp.eq.f32 	%p642, %f401, 0f00000000;
	@%p642 bra 	$L__BB1_410;
	bra.uni 	$L__BB1_407;

$L__BB1_410:
	add.f32 	%f2368, %f401, %f401;
	selp.f32 	%f2924, %f2368, 0f00000000, %p540;
	bra.uni 	$L__BB1_411;

$L__BB1_407:
	mov.b32 	%r738, %f2922;
	xor.b32  	%r739, %r738, -2147483648;
	mov.b32 	%f2364, %r739;
	selp.f32 	%f2924, %f2364, %f2922, %p38;
	setp.geu.f32 	%p643, %f401, 0f00000000;
	@%p643 bra 	$L__BB1_411;

	cvt.rzi.f32.f32 	%f2366, %f1516;
	setp.eq.f32 	%p644, %f2366, 0f40000000;
	@%p644 bra 	$L__BB1_411;

	mov.f32 	%f2924, 0f7FFFFFFF;

$L__BB1_411:
	add.f32 	%f2369, %f402, 0f40000000;
	mov.b32 	%r740, %f2369;
	setp.lt.s32 	%p646, %r740, 2139095040;
	@%p646 bra 	$L__BB1_416;

	setp.gtu.f32 	%p647, %f402, 0f7F800000;
	@%p647 bra 	$L__BB1_415;
	bra.uni 	$L__BB1_413;

$L__BB1_415:
	add.f32 	%f2924, %f401, 0f40000000;
	bra.uni 	$L__BB1_416;

$L__BB1_413:
	setp.neu.f32 	%p648, %f402, 0f7F800000;
	@%p648 bra 	$L__BB1_416;

	selp.f32 	%f2924, 0fFF800000, 0f7F800000, %p38;

$L__BB1_416:
	mul.f32 	%f2370, %f2924, 0fBF000000;
	setp.eq.f32 	%p649, %f401, 0f3F800000;
	selp.f32 	%f2371, 0fBF000000, %f2370, %p649;
	fma.rn.f32 	%f2374, %f2371, %f1908, %f1509;
	cvt.sat.f32.f32 	%f2377, %f2374;
	fma.rm.f32 	%f2379, %f2377, %f1911, %f1913;
	add.f32 	%f2380, %f2379, 0fCB40007F;
	neg.f32 	%f2381, %f2380;
	fma.rn.f32 	%f2382, %f2371, %f1620, %f2381;
	fma.rn.f32 	%f2384, %f2371, %f1926, %f2382;
	mov.b32 	%r741, %f2379;
	shl.b32 	%r742, %r741, 23;
	mov.b32 	%f2385, %r742;
	ex2.approx.ftz.f32 	%f2386, %f2384;
	mul.f32 	%f2387, %f2386, %f2385;
	add.f32 	%f2388, %f326, 0f3F800000;
	mul.f32 	%f2389, %f2388, %f400;
	mul.f32 	%f2390, %f326, %f2387;
	sub.f32 	%f2391, %f2389, %f2390;
	mul.f32 	%f2392, %f251, %f2391;
	fma.rn.f32 	%f2393, %f324, %f2392, %f387;
	mul.f32 	%f2394, %f349, %f349;
	div.rn.f32 	%f2395, %f2394, %f337;
	add.f32 	%f2896, %f2896, %f2395;
	mul.f32 	%f2396, %f386, %f349;
	div.rn.f32 	%f2397, %f2396, %f337;
	add.f32 	%f2895, %f2895, %f2397;
	mul.f32 	%f2398, %f324, %f336;
	mul.f32 	%f2399, %f2398, %f349;
	div.rn.f32 	%f2400, %f2399, %f337;
	add.f32 	%f2894, %f2894, %f2400;
	div.rn.f32 	%f2401, %f349, %f337;
	add.f32 	%f2893, %f2893, %f2401;
	mul.f32 	%f2402, %f2393, %f349;
	div.rn.f32 	%f2403, %f2402, %f337;
	add.f32 	%f2892, %f2892, %f2403;
	mul.f32 	%f2404, %f386, %f386;
	div.rn.f32 	%f2405, %f2404, %f337;
	add.f32 	%f2891, %f2891, %f2405;
	mul.f32 	%f2406, %f2398, %f386;
	div.rn.f32 	%f2407, %f2406, %f337;
	add.f32 	%f2890, %f2890, %f2407;
	div.rn.f32 	%f2408, %f386, %f337;
	add.f32 	%f2889, %f2889, %f2408;
	mul.f32 	%f2409, %f2393, %f386;
	div.rn.f32 	%f2410, %f2409, %f337;
	add.f32 	%f2888, %f2888, %f2410;
	mul.f32 	%f2411, %f2398, %f2398;
	div.rn.f32 	%f2412, %f2411, %f337;
	add.f32 	%f2887, %f2887, %f2412;
	div.rn.f32 	%f2413, %f2398, %f337;
	add.f32 	%f2886, %f2886, %f2413;
	mul.f32 	%f2414, %f2393, %f2398;
	div.rn.f32 	%f2415, %f2414, %f337;
	add.f32 	%f2885, %f2885, %f2415;
	rcp.rn.f32 	%f2416, %f337;
	add.f32 	%f2897, %f2897, %f2416;
	div.rn.f32 	%f2417, %f2393, %f337;
	add.f32 	%f2898, %f2898, %f2417;
	mul.f32 	%f2418, %f2393, %f2393;
	div.rn.f32 	%f2419, %f2418, %f337;
	add.f32 	%f2899, %f2899, %f2419;
	setp.leu.f32 	%p650, %f337, 0f00000000;
	@%p650 bra 	$L__BB1_424;

	setp.gt.f32 	%p651, %f338, 0f00000000;
	@%p651 bra 	$L__BB1_419;
	bra.uni 	$L__BB1_418;

$L__BB1_419:
	setp.lt.f32 	%p652, %f337, 0f00800000;
	mul.f32 	%f2420, %f337, 0f4B000000;
	selp.f32 	%f429, %f2420, %f337, %p652;
	selp.f32 	%f2421, 0fC1B80000, 0f00000000, %p652;
	mov.b32 	%r743, %f429;
	add.s32 	%r744, %r743, -1059760811;
	and.b32  	%r745, %r744, -8388608;
	sub.s32 	%r746, %r743, %r745;
	mov.b32 	%f2422, %r746;
	cvt.rn.f32.s32 	%f2423, %r745;
	mov.f32 	%f2424, 0f34000000;
	fma.rn.f32 	%f2425, %f2423, %f2424, %f2421;
	add.f32 	%f2426, %f2422, 0fBF800000;
	mov.f32 	%f2427, 0f3E1039F6;
	mov.f32 	%f2428, 0fBE055027;
	fma.rn.f32 	%f2429, %f2428, %f2426, %f2427;
	mov.f32 	%f2430, 0fBDF8CDCC;
	fma.rn.f32 	%f2431, %f2429, %f2426, %f2430;
	mov.f32 	%f2432, 0f3E0F2955;
	fma.rn.f32 	%f2433, %f2431, %f2426, %f2432;
	mov.f32 	%f2434, 0fBE2AD8B9;
	fma.rn.f32 	%f2435, %f2433, %f2426, %f2434;
	mov.f32 	%f2436, 0f3E4CED0B;
	fma.rn.f32 	%f2437, %f2435, %f2426, %f2436;
	mov.f32 	%f2438, 0fBE7FFF22;
	fma.rn.f32 	%f2439, %f2437, %f2426, %f2438;
	mov.f32 	%f2440, 0f3EAAAA78;
	fma.rn.f32 	%f2441, %f2439, %f2426, %f2440;
	mov.f32 	%f2442, 0fBF000000;
	fma.rn.f32 	%f2443, %f2441, %f2426, %f2442;
	mul.f32 	%f2444, %f2426, %f2443;
	fma.rn.f32 	%f2445, %f2444, %f2426, %f2426;
	mov.f32 	%f2446, 0f3F317218;
	fma.rn.f32 	%f2925, %f2425, %f2446, %f2445;
	setp.lt.u32 	%p653, %r743, 2139095040;
	@%p653 bra 	$L__BB1_421;

	mov.f32 	%f2447, 0f7F800000;
	fma.rn.f32 	%f2925, %f429, %f2447, %f2447;

$L__BB1_421:
	setp.eq.f32 	%p654, %f429, 0f00000000;
	selp.f32 	%f2448, 0fFF800000, %f2925, %p654;
	mul.f32 	%f2449, %f338, %f2448;
	sub.f32 	%f433, %f2449, %f337;
	mul.f32 	%f2450, %f338, 0f4B000000;
	setp.lt.f32 	%p655, %f338, 0f00800000;
	selp.f32 	%f434, %f2450, %f338, %p655;
	selp.f32 	%f2451, 0fC1B80000, 0f00000000, %p655;
	mov.b32 	%r747, %f434;
	add.s32 	%r748, %r747, -1059760811;
	and.b32  	%r749, %r748, -8388608;
	sub.s32 	%r750, %r747, %r749;
	mov.b32 	%f2452, %r750;
	cvt.rn.f32.s32 	%f2453, %r749;
	fma.rn.f32 	%f2455, %f2453, %f2424, %f2451;
	add.f32 	%f2456, %f2452, 0fBF800000;
	fma.rn.f32 	%f2459, %f2428, %f2456, %f2427;
	fma.rn.f32 	%f2461, %f2459, %f2456, %f2430;
	fma.rn.f32 	%f2463, %f2461, %f2456, %f2432;
	fma.rn.f32 	%f2465, %f2463, %f2456, %f2434;
	fma.rn.f32 	%f2467, %f2465, %f2456, %f2436;
	fma.rn.f32 	%f2469, %f2467, %f2456, %f2438;
	fma.rn.f32 	%f2471, %f2469, %f2456, %f2440;
	fma.rn.f32 	%f2473, %f2471, %f2456, %f2442;
	mul.f32 	%f2474, %f2456, %f2473;
	fma.rn.f32 	%f2475, %f2474, %f2456, %f2456;
	fma.rn.f32 	%f2926, %f2455, %f2446, %f2475;
	setp.lt.u32 	%p656, %r747, 2139095040;
	@%p656 bra 	$L__BB1_423;

	mov.f32 	%f2477, 0f7F800000;
	fma.rn.f32 	%f2926, %f434, %f2477, %f2477;

$L__BB1_423:
	setp.eq.f32 	%p657, %f434, 0f00000000;
	selp.f32 	%f2478, 0fFF800000, %f2926, %p657;
	mul.f32 	%f2479, %f338, %f2478;
	sub.f32 	%f2480, %f433, %f2479;
	add.f32 	%f2481, %f338, %f2480;
	add.f32 	%f2927, %f2927, %f2481;
	bra.uni 	$L__BB1_424;

$L__BB1_418:
	sub.f32 	%f2927, %f2927, %f337;

$L__BB1_424:
	add.s32 	%r784, %r784, 1;
	setp.lt.s32 	%p658, %r784, %r102;
	@%p658 bra 	$L__BB1_340;

	add.s32 	%r783, %r783, 1;
	setp.lt.s32 	%p659, %r783, %r102;
	@%p659 bra 	$L__BB1_339;

$L__BB1_426:
	ld.param.u64 	%rd50, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_6];
	ld.param.u64 	%rd49, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_5];
	ld.param.u32 	%r764, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_7];
	ld.param.u64 	%rd48, [_Z20kernel_MLEFit_XYNBS_PKffiiPfS1_S1_i_param_4];
	mov.u32 	%r763, %tid.x;
	mov.u32 	%r762, %ntid.x;
	mov.u32 	%r761, %ctaid.x;
	mad.lo.s32 	%r760, %r761, %r762, %r763;
	rcp.rn.f32 	%f2482, %f2896;
	mov.f32 	%f2483, 0f3F800000;
	mul.f32 	%f2484, %f2482, %f2895;
	mul.f32 	%f2485, %f2482, %f2894;
	mul.f32 	%f2486, %f2482, %f2893;
	mul.f32 	%f2487, %f2482, %f2892;
	fma.rn.f32 	%f2488, %f2484, %f2895, 0f00000000;
	sub.f32 	%f2490, %f2891, %f2488;
	fma.rn.f32 	%f2491, %f2485, %f2895, 0f00000000;
	rcp.rn.f32 	%f2492, %f2490;
	sub.f32 	%f2493, %f2890, %f2491;
	mul.f32 	%f2494, %f2492, %f2493;
	fma.rn.f32 	%f2495, %f2486, %f2895, 0f00000000;
	sub.f32 	%f2496, %f2889, %f2495;
	mul.f32 	%f2497, %f2492, %f2496;
	fma.rn.f32 	%f2498, %f2487, %f2895, 0f00000000;
	sub.f32 	%f2499, %f2888, %f2498;
	mul.f32 	%f2500, %f2492, %f2499;
	fma.rn.f32 	%f2501, %f2484, %f2894, 0f00000000;
	sub.f32 	%f2502, %f2890, %f2501;
	fma.rn.f32 	%f2503, %f2485, %f2894, 0f00000000;
	fma.rn.f32 	%f2504, %f2494, %f2502, %f2503;
	sub.f32 	%f2505, %f2887, %f2504;
	fma.rn.f32 	%f2506, %f2486, %f2894, 0f00000000;
	fma.rn.f32 	%f2507, %f2497, %f2502, %f2506;
	rcp.rn.f32 	%f2508, %f2505;
	sub.f32 	%f2509, %f2886, %f2507;
	mul.f32 	%f2510, %f2508, %f2509;
	fma.rn.f32 	%f2511, %f2487, %f2894, 0f00000000;
	fma.rn.f32 	%f2512, %f2500, %f2502, %f2511;
	sub.f32 	%f2513, %f2885, %f2512;
	mul.f32 	%f2514, %f2508, %f2513;
	fma.rn.f32 	%f2515, %f2484, %f2893, 0f00000000;
	sub.f32 	%f2516, %f2889, %f2515;
	fma.rn.f32 	%f2517, %f2485, %f2893, 0f00000000;
	fma.rn.f32 	%f2518, %f2494, %f2516, %f2517;
	sub.f32 	%f2519, %f2886, %f2518;
	fma.rn.f32 	%f2520, %f2486, %f2893, 0f00000000;
	fma.rn.f32 	%f2521, %f2497, %f2516, %f2520;
	fma.rn.f32 	%f2522, %f2510, %f2519, %f2521;
	sub.f32 	%f2523, %f2897, %f2522;
	fma.rn.f32 	%f2524, %f2487, %f2893, 0f00000000;
	fma.rn.f32 	%f2525, %f2500, %f2516, %f2524;
	fma.rn.f32 	%f2526, %f2514, %f2519, %f2525;
	rcp.rn.f32 	%f2527, %f2523;
	sub.f32 	%f2528, %f2898, %f2526;
	mul.f32 	%f2529, %f2527, %f2528;
	fma.rn.f32 	%f2530, %f2484, %f2892, 0f00000000;
	sub.f32 	%f2531, %f2888, %f2530;
	fma.rn.f32 	%f2532, %f2485, %f2892, 0f00000000;
	fma.rn.f32 	%f2533, %f2494, %f2531, %f2532;
	sub.f32 	%f2534, %f2885, %f2533;
	fma.rn.f32 	%f2535, %f2486, %f2892, 0f00000000;
	fma.rn.f32 	%f2536, %f2497, %f2531, %f2535;
	fma.rn.f32 	%f2537, %f2510, %f2534, %f2536;
	sub.f32 	%f2538, %f2898, %f2537;
	fma.rn.f32 	%f2539, %f2487, %f2892, 0f00000000;
	fma.rn.f32 	%f2540, %f2500, %f2531, %f2539;
	fma.rn.f32 	%f2541, %f2514, %f2534, %f2540;
	fma.rn.f32 	%f2542, %f2529, %f2538, %f2541;
	sub.f32 	%f2543, %f2899, %f2542;
	add.f32 	%f2544, %f2484, 0f00000000;
	sub.f32 	%f2545, %f1492, %f2544;
	add.f32 	%f2546, %f2485, 0f00000000;
	fma.rn.f32 	%f2547, %f2494, %f2545, %f2546;
	sub.f32 	%f2548, %f1492, %f2547;
	add.f32 	%f2549, %f2486, 0f00000000;
	fma.rn.f32 	%f2550, %f2497, %f2545, %f2549;
	fma.rn.f32 	%f2551, %f2510, %f2548, %f2550;
	sub.f32 	%f2552, %f1492, %f2551;
	add.f32 	%f2553, %f2487, 0f00000000;
	fma.rn.f32 	%f2554, %f2500, %f2545, %f2553;
	fma.rn.f32 	%f2555, %f2514, %f2548, %f2554;
	fma.rn.f32 	%f2556, %f2529, %f2552, %f2555;
	sub.f32 	%f2557, %f1492, %f2556;
	div.rn.f32 	%f2558, %f2557, %f2543;
	fma.rn.f32 	%f2559, %f2538, %f2558, 0f00000000;
	sub.f32 	%f2560, %f2552, %f2559;
	mul.f32 	%f2561, %f2527, %f2560;
	fma.rn.f32 	%f2562, %f2519, %f2561, 0f00000000;
	fma.rn.f32 	%f2563, %f2534, %f2558, %f2562;
	sub.f32 	%f2564, %f2548, %f2563;
	mul.f32 	%f2565, %f2508, %f2564;
	fma.rn.f32 	%f2566, %f2502, %f2565, 0f00000000;
	fma.rn.f32 	%f2567, %f2516, %f2561, %f2566;
	fma.rn.f32 	%f2568, %f2531, %f2558, %f2567;
	sub.f32 	%f2569, %f2545, %f2568;
	mul.f32 	%f2570, %f2492, %f2569;
	fma.rn.f32 	%f2571, %f2895, %f2570, 0f00000000;
	fma.rn.f32 	%f2572, %f2894, %f2565, %f2571;
	fma.rn.f32 	%f2573, %f2893, %f2561, %f2572;
	fma.rn.f32 	%f2574, %f2892, %f2558, %f2573;
	sub.f32 	%f2575, %f2483, %f2574;
	mul.f32 	%f2576, %f2482, %f2575;
	fma.rn.f32 	%f2577, %f2484, 0f00000000, 0f00000000;
	sub.f32 	%f2578, %f2483, %f2577;
	fma.rn.f32 	%f2579, %f2485, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2580, %f2494, %f2578, %f2579;
	sub.f32 	%f2581, %f1492, %f2580;
	fma.rn.f32 	%f2582, %f2486, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2583, %f2497, %f2578, %f2582;
	fma.rn.f32 	%f2584, %f2510, %f2581, %f2583;
	sub.f32 	%f2585, %f1492, %f2584;
	fma.rn.f32 	%f2586, %f2487, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2587, %f2500, %f2578, %f2586;
	fma.rn.f32 	%f2588, %f2514, %f2581, %f2587;
	fma.rn.f32 	%f2589, %f2529, %f2585, %f2588;
	sub.f32 	%f2590, %f1492, %f2589;
	div.rn.f32 	%f2591, %f2590, %f2543;
	fma.rn.f32 	%f2592, %f2538, %f2591, 0f00000000;
	sub.f32 	%f2593, %f2585, %f2592;
	mul.f32 	%f2594, %f2527, %f2593;
	fma.rn.f32 	%f2595, %f2519, %f2594, 0f00000000;
	fma.rn.f32 	%f2596, %f2534, %f2591, %f2595;
	sub.f32 	%f2597, %f2581, %f2596;
	mul.f32 	%f2598, %f2508, %f2597;
	fma.rn.f32 	%f2599, %f2502, %f2598, 0f00000000;
	fma.rn.f32 	%f2600, %f2516, %f2594, %f2599;
	fma.rn.f32 	%f2601, %f2531, %f2591, %f2600;
	sub.f32 	%f2602, %f2578, %f2601;
	mul.f32 	%f2603, %f2492, %f2602;
	sub.f32 	%f2604, %f1492, %f2577;
	fma.rn.f32 	%f2605, %f2494, %f2604, %f2579;
	sub.f32 	%f2606, %f2483, %f2605;
	fma.rn.f32 	%f2607, %f2497, %f2604, %f2582;
	fma.rn.f32 	%f2608, %f2510, %f2606, %f2607;
	sub.f32 	%f2609, %f1492, %f2608;
	fma.rn.f32 	%f2610, %f2500, %f2604, %f2586;
	fma.rn.f32 	%f2611, %f2514, %f2606, %f2610;
	fma.rn.f32 	%f2612, %f2529, %f2609, %f2611;
	sub.f32 	%f2613, %f1492, %f2612;
	div.rn.f32 	%f2614, %f2613, %f2543;
	fma.rn.f32 	%f2615, %f2538, %f2614, 0f00000000;
	sub.f32 	%f2616, %f2609, %f2615;
	mul.f32 	%f2617, %f2527, %f2616;
	fma.rn.f32 	%f2618, %f2519, %f2617, 0f00000000;
	fma.rn.f32 	%f2619, %f2534, %f2614, %f2618;
	sub.f32 	%f2620, %f2606, %f2619;
	mul.f32 	%f2621, %f2508, %f2620;
	sub.f32 	%f2622, %f1492, %f2605;
	fma.rn.f32 	%f2623, %f2510, %f2622, %f2607;
	sub.f32 	%f2624, %f2483, %f2623;
	fma.rn.f32 	%f2625, %f2514, %f2622, %f2610;
	fma.rn.f32 	%f2626, %f2529, %f2624, %f2625;
	sub.f32 	%f2627, %f1492, %f2626;
	div.rn.f32 	%f2628, %f2627, %f2543;
	fma.rn.f32 	%f2629, %f2538, %f2628, 0f00000000;
	sub.f32 	%f2630, %f2624, %f2629;
	mul.f32 	%f2631, %f2527, %f2630;
	sub.f32 	%f2632, %f1492, %f2623;
	fma.rn.f32 	%f2633, %f2529, %f2632, %f2625;
	sub.f32 	%f2634, %f2483, %f2633;
	div.rn.f32 	%f2635, %f2634, %f2543;
	cvta.to.global.u64 	%rd30, %rd48;
	mul.wide.s32 	%rd31, %r760, 4;
	add.s64 	%rd32, %rd30, %rd31;
	st.global.f32 	[%rd32], %f2868;
	add.s32 	%r755, %r760, %r764;
	mul.wide.s32 	%rd33, %r764, 4;
	add.s64 	%rd34, %rd32, %rd33;
	st.global.f32 	[%rd34], %f2867;
	add.s32 	%r756, %r755, %r764;
	shl.b32 	%r757, %r764, 3;
	cvt.s64.s32 	%rd35, %r757;
	add.s64 	%rd36, %rd32, %rd35;
	st.global.f32 	[%rd36], %f2866;
	add.s32 	%r758, %r756, %r764;
	mul.wide.s32 	%rd37, %r758, 4;
	add.s64 	%rd38, %rd30, %rd37;
	st.global.f32 	[%rd38], %f2865;
	add.s64 	%rd39, %rd36, %rd35;
	st.global.f32 	[%rd39], %f2864;
	cvta.to.global.u64 	%rd40, %rd49;
	add.s64 	%rd41, %rd40, %rd31;
	st.global.f32 	[%rd41], %f2576;
	add.s64 	%rd42, %rd41, %rd33;
	st.global.f32 	[%rd42], %f2603;
	add.s64 	%rd43, %rd41, %rd35;
	st.global.f32 	[%rd43], %f2621;
	add.s64 	%rd44, %rd40, %rd37;
	st.global.f32 	[%rd44], %f2631;
	add.s64 	%rd45, %rd43, %rd35;
	st.global.f32 	[%rd45], %f2635;
	cvta.to.global.u64 	%rd46, %rd50;
	add.s64 	%rd47, %rd46, %rd31;
	st.global.f32 	[%rd47], %f2927;

$L__BB1_427:
	ret;

}
	// .globl	_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i
.visible .entry _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i(
	.param .u64 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_0,
	.param .f32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_1,
	.param .f32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_2,
	.param .f32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_3,
	.param .f32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_4,
	.param .f32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_5,
	.param .f32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_6,
	.param .f32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_7,
	.param .f32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_8,
	.param .u32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_9,
	.param .u32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_10,
	.param .u64 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_11,
	.param .u64 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_12,
	.param .u64 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_13,
	.param .u32 _Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_14
)
{
	.reg .pred 	%p<1292>;
	.reg .f32 	%f<3358>;
	.reg .b32 	%r<1374>;
	.reg .f64 	%fd<1222>;
	.reg .b64 	%rd<47>;


	ld.param.u64 	%rd3, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_0];
	ld.param.f32 	%f535, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_1];
	ld.param.f32 	%f536, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_2];
	ld.param.f32 	%f537, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_3];
	ld.param.f32 	%f538, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_4];
	ld.param.f32 	%f539, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_5];
	ld.param.f32 	%f540, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_6];
	ld.param.f32 	%f541, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_7];
	ld.param.f32 	%f542, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_8];
	ld.param.u32 	%r182, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_9];
	ld.param.u32 	%r183, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_10];
	ld.param.u32 	%r184, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_14];
	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r185, %ntid.x;
	mov.u32 	%r186, %ctaid.x;
	mov.u32 	%r187, %tid.x;
	mad.lo.s32 	%r1, %r186, %r185, %r187;
	setp.ge.s32 	%p79, %r1, %r184;
	@%p79 bra 	$L__BB2_885;

	mul.lo.s32 	%r188, %r182, %r182;
	mul.lo.s32 	%r2, %r188, %r1;
	setp.lt.s32 	%p80, %r182, 1;
	mov.f32 	%f545, 0f00000000;
	mov.f32 	%f3187, %f545;
	mov.f32 	%f3188, %f545;
	mov.f32 	%f3189, %f545;
	@%p80 bra 	$L__BB2_11;

	add.s32 	%r3, %r182, -1;
	and.b32  	%r4, %r182, 3;
	sub.s32 	%r5, %r182, %r4;
	shl.b32 	%r6, %r182, 2;
	mov.u32 	%r189, 0;
	setp.lt.u32 	%p81, %r3, 3;
	setp.eq.s32 	%p83, %r4, 0;
	setp.eq.s32 	%p84, %r4, 1;
	setp.eq.s32 	%p85, %r4, 2;
	cvt.s64.s32 	%rd9, %r6;
	mov.u32 	%r1361, %r189;

$L__BB2_3:
	cvt.rn.f32.s32 	%f4, %r1361;
	mov.u32 	%r1364, %r189;
	@%p81 bra 	$L__BB2_6;

	mov.u32 	%r1364, %r189;
	mov.u32 	%r1363, %r5;

$L__BB2_5:
	mad.lo.s32 	%r192, %r1364, %r182, %r1361;
	add.s32 	%r193, %r192, %r2;
	mul.wide.s32 	%rd7, %r193, 4;
	add.s64 	%rd8, %rd1, %rd7;
	ld.global.f32 	%f550, [%rd8];
	fma.rn.f32 	%f551, %f550, %f4, %f3187;
	cvt.rn.f32.s32 	%f552, %r1364;
	fma.rn.f32 	%f553, %f550, %f552, %f3188;
	add.f32 	%f554, %f3189, %f550;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.f32 	%f555, [%rd10];
	fma.rn.f32 	%f556, %f555, %f4, %f551;
	add.s32 	%r194, %r1364, 1;
	cvt.rn.f32.s32 	%f557, %r194;
	fma.rn.f32 	%f558, %f555, %f557, %f553;
	add.f32 	%f559, %f554, %f555;
	add.s64 	%rd11, %rd10, %rd9;
	ld.global.f32 	%f560, [%rd11];
	fma.rn.f32 	%f561, %f560, %f4, %f556;
	add.s32 	%r195, %r1364, 2;
	cvt.rn.f32.s32 	%f562, %r195;
	fma.rn.f32 	%f563, %f560, %f562, %f558;
	add.f32 	%f564, %f559, %f560;
	add.s64 	%rd12, %rd11, %rd9;
	ld.global.f32 	%f565, [%rd12];
	fma.rn.f32 	%f3187, %f565, %f4, %f561;
	add.s32 	%r196, %r1364, 3;
	cvt.rn.f32.s32 	%f566, %r196;
	fma.rn.f32 	%f3188, %f565, %f566, %f563;
	add.f32 	%f3189, %f564, %f565;
	add.s32 	%r1364, %r1364, 4;
	add.s32 	%r1363, %r1363, -4;
	setp.ne.s32 	%p82, %r1363, 0;
	@%p82 bra 	$L__BB2_5;

$L__BB2_6:
	@%p83 bra 	$L__BB2_10;

	mad.lo.s32 	%r13, %r1364, %r182, %r1361;
	add.s32 	%r197, %r13, %r2;
	mul.wide.s32 	%rd13, %r197, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.f32 	%f567, [%rd14];
	fma.rn.f32 	%f3187, %f567, %f4, %f3187;
	cvt.rn.f32.s32 	%f568, %r1364;
	fma.rn.f32 	%f3188, %f567, %f568, %f3188;
	add.f32 	%f3189, %f3189, %f567;
	@%p84 bra 	$L__BB2_10;

	add.s32 	%r14, %r13, %r182;
	add.s32 	%r198, %r14, %r2;
	mul.wide.s32 	%rd15, %r198, 4;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.f32 	%f569, [%rd16];
	fma.rn.f32 	%f3187, %f569, %f4, %f3187;
	add.s32 	%r199, %r1364, 1;
	cvt.rn.f32.s32 	%f570, %r199;
	fma.rn.f32 	%f3188, %f569, %f570, %f3188;
	add.f32 	%f3189, %f3189, %f569;
	@%p85 bra 	$L__BB2_10;

	add.s32 	%r200, %r1364, 2;
	add.s32 	%r201, %r14, %r182;
	add.s32 	%r202, %r201, %r2;
	mul.wide.s32 	%rd17, %r202, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.f32 	%f571, [%rd18];
	fma.rn.f32 	%f3187, %f571, %f4, %f3187;
	cvt.rn.f32.s32 	%f572, %r200;
	fma.rn.f32 	%f3188, %f571, %f572, %f3188;
	add.f32 	%f3189, %f3189, %f571;

$L__BB2_10:
	add.s32 	%r1361, %r1361, 1;
	setp.lt.s32 	%p86, %r1361, %r182;
	@%p86 bra 	$L__BB2_3;

$L__BB2_11:
	div.rn.f32 	%f3278, %f3187, %f3189;
	div.rn.f32 	%f3277, %f3188, %f3189;
	mov.f32 	%f3275, 0f51BA43B7;
	mov.f32 	%f3196, %f545;
	@%p80 bra 	$L__BB2_51;

	mov.f32 	%f577, 0f3F000000;
	div.rn.f32 	%f578, %f577, %f535;
	div.rn.f32 	%f579, %f578, %f535;
	cvt.f64.f32 	%fd1, %f579;
	mov.f64 	%fd551, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd551;
	}
	and.b32  	%r17, %r16, 2146435072;
	and.b32  	%r18, %r16, 2147483647;
	setp.gt.s32 	%p88, %r16, -1;
	selp.b32 	%r19, 2146435072, 0, %p88;
	mov.u32 	%r203, 0;
	or.b32  	%r20, %r19, -2147483648;
	setp.eq.s32 	%p90, %r17, 1062207488;
	setp.lt.s32 	%p91, %r16, 0;
	setp.ne.s32 	%p96, %r18, 1071644672;
	setp.eq.s32 	%p123, %r18, 2146435072;
	mov.u32 	%r1365, %r203;
	mov.f32 	%f3196, %f545;

$L__BB2_13:
	mov.u32 	%r1366, %r203;

$L__BB2_14:
	mov.f32 	%f3199, 0f00000000;
	mov.f32 	%f3200, %f3199;
	mov.u32 	%r1367, %r203;

$L__BB2_15:
	sub.s32 	%r24, %r1367, %r1365;
	cvt.rn.f32.s32 	%f582, %r24;
	cvt.f64.f32 	%fd2, %f582;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd2;
	}
	abs.f64 	%fd552, %fd2;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd552;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd551;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 25
	setp.lt.s32 	%p89, %r25, 0;
	and.pred  	%p1, %p89, %p90;
	selp.b32 	%r207, %r25, 0, %p90;
	or.b32  	%r208, %r207, 2146435072;
	selp.b32 	%r26, %r208, %r207, %p91;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd4;
	}
	and.b32  	%r27, %r209, 2146435072;
	setp.ne.s32 	%p92, %r27, 2146435072;
	setp.gtu.f64 	%p93, %fd552, 0d7FF0000000000000;
	setp.gt.f64 	%p94, %fd552, 0d3FF0000000000000;
	selp.b32 	%r210, 2146435072, 0, %p94;
	xor.b32  	%r211, %r210, 2146435072;
	selp.b32 	%r212, %r211, %r210, %p91;
	setp.eq.s32 	%p95, %r24, -1;
	selp.b32 	%r28, 1072693248, %r212, %p95;
	and.b32  	%r29, %r25, 2147483647;
	and.pred  	%p97, %p96, %p1;
	selp.b32 	%r30, %r20, %r19, %p97;
	mul.lo.s32 	%r31, %r1367, %r182;
	or.pred  	%p2, %p92, %p93;
	mov.u32 	%r1368, %r203;

$L__BB2_16:
	not.pred 	%p98, %p1;
	mov.f64 	%fd1073, %fd3;
	@%p98 bra 	$L__BB2_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r213}, %fd3;
	}
	xor.b32  	%r214, %r213, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r215, %temp}, %fd3;
	}
	mov.b64 	%fd1073, {%r215, %r214};

$L__BB2_18:
	setp.eq.s32 	%p99, %r24, 0;
	@%p99 bra 	$L__BB2_22;

	setp.gt.s32 	%p100, %r25, -1;
	@%p100 bra 	$L__BB2_23;

	cvt.rzi.f64.f64 	%fd555, %fd551;
	setp.eq.f64 	%p101, %fd555, 0d4000000000000000;
	@%p101 bra 	$L__BB2_23;

	mov.f64 	%fd1073, 0dFFF8000000000000;
	bra.uni 	$L__BB2_23;

$L__BB2_22:
	mov.u32 	%r216, 0;
	mov.b64 	%fd1073, {%r216, %r26};

$L__BB2_23:
	selp.f64 	%fd1074, %fd1073, %fd4, %p92;
	@%p2 bra 	$L__BB2_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r217, %temp}, %fd551;
	}
	setp.eq.s32 	%p104, %r217, 0;
	and.pred  	%p105, %p123, %p104;
	@%p105 bra 	$L__BB2_27;
	bra.uni 	$L__BB2_25;

$L__BB2_27:
	mov.u32 	%r220, 0;
	mov.b64 	%fd1074, {%r220, %r28};
	bra.uni 	$L__BB2_28;

$L__BB2_25:
	setp.ne.s32 	%p106, %r29, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r218, %temp}, %fd2;
	}
	setp.ne.s32 	%p107, %r218, 0;
	or.pred  	%p108, %p106, %p107;
	mov.f64 	%fd1074, %fd1073;
	@%p108 bra 	$L__BB2_28;

	mov.u32 	%r219, 0;
	mov.b64 	%fd1074, {%r219, %r30};

$L__BB2_28:
	setp.eq.s32 	%p109, %r24, 1;
	selp.f64 	%fd558, 0d3FF0000000000000, %fd1074, %p109;
	mov.f64 	%fd559, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd558, %fd1;
	neg.f64 	%fd560, %fd13;
	mov.f64 	%fd561, 0d4338000000000000;
	mov.f64 	%fd562, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd563, %fd560, %fd562, %fd561;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd563;
	}
	mov.f64 	%fd564, 0dC338000000000000;
	add.rn.f64 	%fd565, %fd563, %fd564;
	mov.f64 	%fd566, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd567, %fd565, %fd566, %fd560;
	mov.f64 	%fd568, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd569, %fd565, %fd568, %fd567;
	mov.f64 	%fd570, 0d3E928AF3FCA213EA;
	mov.f64 	%fd571, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd572, %fd571, %fd569, %fd570;
	mov.f64 	%fd573, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd574, %fd572, %fd569, %fd573;
	mov.f64 	%fd575, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd576, %fd574, %fd569, %fd575;
	mov.f64 	%fd577, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd578, %fd576, %fd569, %fd577;
	mov.f64 	%fd579, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd580, %fd578, %fd569, %fd579;
	mov.f64 	%fd581, 0d3F81111111122322;
	fma.rn.f64 	%fd582, %fd580, %fd569, %fd581;
	mov.f64 	%fd583, 0d3FA55555555502A1;
	fma.rn.f64 	%fd584, %fd582, %fd569, %fd583;
	mov.f64 	%fd585, 0d3FC5555555555511;
	fma.rn.f64 	%fd586, %fd584, %fd569, %fd585;
	mov.f64 	%fd587, 0d3FE000000000000B;
	fma.rn.f64 	%fd588, %fd586, %fd569, %fd587;
	fma.rn.f64 	%fd589, %fd588, %fd569, %fd559;
	fma.rn.f64 	%fd590, %fd589, %fd569, %fd559;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd590;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd590;
	}
	shl.b32 	%r221, %r33, 20;
	add.s32 	%r222, %r35, %r221;
	mov.b64 	%fd1075, {%r34, %r222};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r223}, %fd560;
	}
	mov.b32 	%f583, %r223;
	abs.f32 	%f42, %f583;
	setp.lt.f32 	%p110, %f42, 0f4086232B;
	@%p110 bra 	$L__BB2_31;

	setp.gt.f64 	%p111, %fd13, 0d8000000000000000;
	mov.f64 	%fd591, 0d7FF0000000000000;
	sub.f64 	%fd592, %fd591, %fd13;
	selp.f64 	%fd1075, 0d0000000000000000, %fd592, %p111;
	setp.geu.f32 	%p112, %f42, 0f40874800;
	@%p112 bra 	$L__BB2_31;

	shr.u32 	%r224, %r33, 31;
	add.s32 	%r225, %r33, %r224;
	shr.s32 	%r226, %r225, 1;
	shl.b32 	%r227, %r226, 20;
	add.s32 	%r228, %r35, %r227;
	mov.b64 	%fd593, {%r34, %r228};
	sub.s32 	%r229, %r33, %r226;
	shl.b32 	%r230, %r229, 20;
	add.s32 	%r231, %r230, 1072693248;
	mov.u32 	%r232, 0;
	mov.b64 	%fd594, {%r232, %r231};
	mul.f64 	%fd1075, %fd593, %fd594;

$L__BB2_31:
	sub.s32 	%r36, %r1366, %r1368;
	cvt.rn.f32.s32 	%f584, %r36;
	cvt.f64.f32 	%fd18, %f584;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd551;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1077, [retval0+0];
	} // callseq 26
	setp.lt.s32 	%p113, %r37, 0;
	and.pred  	%p3, %p113, %p90;
	not.pred 	%p115, %p3;
	@%p115 bra 	$L__BB2_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r233}, %fd1077;
	}
	xor.b32  	%r234, %r233, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd1077;
	}
	mov.b64 	%fd1077, {%r235, %r234};

$L__BB2_33:
	setp.eq.s32 	%p116, %r36, 0;
	@%p116 bra 	$L__BB2_37;

	setp.gt.s32 	%p117, %r37, -1;
	@%p117 bra 	$L__BB2_38;

	cvt.rzi.f64.f64 	%fd597, %fd551;
	setp.eq.f64 	%p118, %fd597, 0d4000000000000000;
	@%p118 bra 	$L__BB2_38;

	mov.f64 	%fd1077, 0dFFF8000000000000;
	bra.uni 	$L__BB2_38;

$L__BB2_37:
	mov.u32 	%r236, 0;
	selp.b32 	%r237, %r37, 0, %p90;
	or.b32  	%r238, %r237, 2146435072;
	selp.b32 	%r239, %r238, %r237, %p91;
	mov.b64 	%fd1077, {%r236, %r239};

$L__BB2_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r240}, %fd25;
	}
	and.b32  	%r241, %r240, 2146435072;
	setp.ne.s32 	%p121, %r241, 2146435072;
	mov.f64 	%fd1078, %fd1077;
	@%p121 bra 	$L__BB2_44;

	setp.gtu.f64 	%p122, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd1078, %fd25;
	@%p122 bra 	$L__BB2_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd551;
	}
	setp.eq.s32 	%p124, %r242, 0;
	and.pred  	%p125, %p123, %p124;
	@%p125 bra 	$L__BB2_43;
	bra.uni 	$L__BB2_41;

$L__BB2_43:
	mov.u32 	%r247, 0;
	setp.gt.f64 	%p132, %fd19, 0d3FF0000000000000;
	selp.b32 	%r248, 2146435072, 0, %p132;
	xor.b32  	%r249, %r248, 2146435072;
	selp.b32 	%r250, %r249, %r248, %p91;
	setp.eq.s32 	%p133, %r36, -1;
	selp.b32 	%r251, 1072693248, %r250, %p133;
	mov.b64 	%fd1078, {%r247, %r251};
	bra.uni 	$L__BB2_44;

$L__BB2_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r243, %temp}, %fd18;
	}
	and.b32  	%r244, %r37, 2147483647;
	setp.ne.s32 	%p126, %r244, 2146435072;
	setp.ne.s32 	%p127, %r243, 0;
	or.pred  	%p128, %p126, %p127;
	mov.f64 	%fd1078, %fd1077;
	@%p128 bra 	$L__BB2_44;

	and.pred  	%p130, %p96, %p3;
	selp.b32 	%r245, %r20, %r19, %p130;
	mov.u32 	%r246, 0;
	mov.b64 	%fd1078, {%r246, %r245};

$L__BB2_44:
	setp.eq.s32 	%p134, %r36, 1;
	selp.f64 	%fd600, 0d3FF0000000000000, %fd1078, %p134;
	mul.f64 	%fd29, %fd600, %fd1;
	neg.f64 	%fd602, %fd29;
	fma.rn.f64 	%fd605, %fd602, %fd562, %fd561;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd605;
	}
	add.rn.f64 	%fd607, %fd605, %fd564;
	fma.rn.f64 	%fd609, %fd607, %fd566, %fd602;
	fma.rn.f64 	%fd611, %fd607, %fd568, %fd609;
	fma.rn.f64 	%fd614, %fd571, %fd611, %fd570;
	fma.rn.f64 	%fd616, %fd614, %fd611, %fd573;
	fma.rn.f64 	%fd618, %fd616, %fd611, %fd575;
	fma.rn.f64 	%fd620, %fd618, %fd611, %fd577;
	fma.rn.f64 	%fd622, %fd620, %fd611, %fd579;
	fma.rn.f64 	%fd624, %fd622, %fd611, %fd581;
	fma.rn.f64 	%fd626, %fd624, %fd611, %fd583;
	fma.rn.f64 	%fd628, %fd626, %fd611, %fd585;
	fma.rn.f64 	%fd630, %fd628, %fd611, %fd587;
	fma.rn.f64 	%fd631, %fd630, %fd611, %fd559;
	fma.rn.f64 	%fd632, %fd631, %fd611, %fd559;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd632;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd632;
	}
	shl.b32 	%r252, %r38, 20;
	add.s32 	%r253, %r40, %r252;
	mov.b64 	%fd1079, {%r39, %r253};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r254}, %fd602;
	}
	mov.b32 	%f585, %r254;
	abs.f32 	%f43, %f585;
	setp.lt.f32 	%p135, %f43, 0f4086232B;
	@%p135 bra 	$L__BB2_47;

	setp.gt.f64 	%p136, %fd29, 0d8000000000000000;
	mov.f64 	%fd633, 0d7FF0000000000000;
	sub.f64 	%fd634, %fd633, %fd29;
	selp.f64 	%fd1079, 0d0000000000000000, %fd634, %p136;
	setp.geu.f32 	%p137, %f43, 0f40874800;
	@%p137 bra 	$L__BB2_47;

	shr.u32 	%r255, %r38, 31;
	add.s32 	%r256, %r38, %r255;
	shr.s32 	%r257, %r256, 1;
	shl.b32 	%r258, %r257, 20;
	add.s32 	%r259, %r40, %r258;
	mov.b64 	%fd635, {%r39, %r259};
	sub.s32 	%r260, %r38, %r257;
	shl.b32 	%r261, %r260, 20;
	add.s32 	%r262, %r261, 1072693248;
	mov.u32 	%r263, 0;
	mov.b64 	%fd636, {%r263, %r262};
	mul.f64 	%fd1079, %fd635, %fd636;

$L__BB2_47:
	add.s32 	%r264, %r1368, %r31;
	add.s32 	%r265, %r264, %r2;
	mul.wide.s32 	%rd19, %r265, 4;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.f32 	%f586, [%rd20];
	cvt.f64.f32 	%fd637, %f586;
	mul.f64 	%fd638, %fd1075, %fd1079;
	cvt.f64.f32 	%fd639, %f3200;
	fma.rn.f64 	%fd640, %fd638, %fd637, %fd639;
	cvt.rn.f32.f64 	%f3200, %fd640;
	cvt.f64.f32 	%fd641, %f3199;
	add.f64 	%fd642, %fd638, %fd641;
	cvt.rn.f32.f64 	%f3199, %fd642;
	add.s32 	%r1368, %r1368, 1;
	setp.lt.s32 	%p138, %r1368, %r182;
	@%p138 bra 	$L__BB2_16;

	add.s32 	%r1367, %r1367, 1;
	setp.lt.s32 	%p139, %r1367, %r182;
	@%p139 bra 	$L__BB2_15;

	div.rn.f32 	%f587, %f3200, %f3199;
	max.f32 	%f3196, %f3196, %f587;
	min.f32 	%f3275, %f3275, %f587;
	add.s32 	%r1366, %r1366, 1;
	setp.lt.s32 	%p140, %r1366, %r182;
	@%p140 bra 	$L__BB2_14;

	add.s32 	%r1365, %r1365, 1;
	setp.lt.s32 	%p141, %r1365, %r182;
	@%p141 bra 	$L__BB2_13;

$L__BB2_51:
	sub.f32 	%f589, %f3196, %f3275;
	add.f32 	%f590, %f589, %f589;
	mul.f32 	%f591, %f590, 0f40490FD8;
	mul.f32 	%f592, %f591, %f535;
	mul.f32 	%f593, %f592, %f542;
	mul.f32 	%f594, %f593, 0f3FB504F3;
	max.f32 	%f3276, %f545, %f594;
	setp.lt.s32 	%p142, %r183, 1;
	mov.f32 	%f3274, %f545;
	@%p142 bra 	$L__BB2_623;

	mul.f32 	%f51, %f535, 0f3F000000;
	mul.f32 	%f52, %f542, 0f3F000000;
	mul.f32 	%f596, %f536, 0f40400000;
	cvt.f64.f32 	%fd34, %f596;
	mul.f32 	%f53, %f541, %f541;
	mul.f32 	%f54, %f53, %f541;
	mul.f32 	%f597, %f538, 0f40800000;
	cvt.f64.f32 	%fd35, %f597;
	cvt.f64.f32 	%fd643, %f541;
	add.f64 	%fd36, %fd643, 0d4010000000000000;
	mul.f32 	%f598, %f537, 0f40400000;
	cvt.f64.f32 	%fd37, %f598;
	mul.f32 	%f599, %f539, 0f40800000;
	cvt.f64.f32 	%fd38, %f599;
	mul.f32 	%f55, %f535, 0fBE800000;
	mul.f32 	%f56, %f542, 0fBE800000;
	mov.f32 	%f600, 0f40000000;
	div.rn.f32 	%f57, %f600, %f53;
	mul.f32 	%f58, %f536, 0f40C00000;
	mul.f32 	%f601, %f538, 0f41400000;
	cvt.f64.f32 	%fd39, %f601;
	mul.f32 	%f59, %f537, 0f40C00000;
	mul.f32 	%f602, %f539, 0f41400000;
	cvt.f64.f32 	%fd40, %f602;
	mov.u32 	%r266, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r311}, %fd36;
	}
	and.b32  	%r92, %r311, 2146435072;
	setp.ne.s32 	%p189, %r92, 2146435072;
	setp.eq.f32 	%p193, %f541, 0fBF800000;
	mov.f32 	%f3274, %f545;
	mov.u32 	%r1369, %r266;

$L__BB2_53:
	mov.f32 	%f3218, %f545;
	mov.f32 	%f3219, %f545;
	mov.f32 	%f3220, %f545;
	mov.f32 	%f3221, %f545;
	mov.f32 	%f3222, %f545;
	mov.f32 	%f3223, %f545;
	mov.f32 	%f3224, %f545;
	mov.f32 	%f3225, %f545;
	mov.f32 	%f3226, %f545;
	mov.f32 	%f3227, %f545;
	@%p80 bra 	$L__BB2_622;

	sub.f32 	%f65, %f3274, %f540;
	div.rn.f32 	%f66, %f65, %f541;
	cvt.f64.f32 	%fd41, %f66;
	add.f32 	%f67, %f3274, %f540;
	div.rn.f32 	%f68, %f67, %f541;
	cvt.f64.f32 	%fd42, %f68;
	div.rn.f32 	%f69, %f3276, 0fC0206C98;
	div.rn.f32 	%f623, %f3276, 0f40206C98;
	cvt.f64.f32 	%fd43, %f623;
	add.f32 	%f624, %f65, %f65;
	div.rn.f32 	%f625, %f624, %f53;
	cvt.f64.f32 	%fd44, %f625;
	cvt.f64.f32 	%fd45, %f65;
	add.f64 	%fd46, %fd45, 0d4000000000000000;
	add.f64 	%fd47, %fd45, 0d4008000000000000;
	add.f32 	%f626, %f67, %f67;
	div.rn.f32 	%f627, %f626, %f53;
	cvt.f64.f32 	%fd48, %f627;
	cvt.f64.f32 	%fd49, %f67;
	add.f64 	%fd50, %fd49, 0d4000000000000000;
	add.f64 	%fd51, %fd49, 0d4008000000000000;
	mul.f32 	%f628, %f58, %f65;
	div.rn.f32 	%f629, %f628, %f54;
	add.f32 	%f630, %f57, %f629;
	cvt.f64.f32 	%fd52, %f630;
	mul.f32 	%f631, %f59, %f67;
	div.rn.f32 	%f632, %f631, %f54;
	add.f32 	%f633, %f57, %f632;
	cvt.f64.f32 	%fd53, %f633;
	mov.f32 	%f3218, %f545;
	mov.f32 	%f3219, %f545;
	mov.f32 	%f3220, %f545;
	mov.f32 	%f3221, %f545;
	mov.f32 	%f3222, %f545;
	mov.f32 	%f3223, %f545;
	mov.f32 	%f3224, %f545;
	mov.f32 	%f3225, %f545;
	mov.f32 	%f3226, %f545;
	mov.f32 	%f3227, %f545;
	mov.u32 	%r1370, %r266;

$L__BB2_55:
	cvt.f64.f32 	%fd1054, %f66;
	cvt.f64.f32 	%fd1053, %f68;
	add.f32 	%f3054, %f3274, %f540;
	sub.f32 	%f3053, %f3274, %f540;
	mov.f64 	%fd644, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd644;
	}
	and.b32  	%r48, %r47, 2146435072;
	setp.eq.s32 	%p144, %r48, 1062207488;
	abs.f64 	%fd645, %fd1054;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd645;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd54, [retval0+0];
	} // callseq 27
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd1054;
	}
	setp.lt.s32 	%p145, %r49, 0;
	and.pred  	%p4, %p145, %p144;
	setp.lt.s32 	%p146, %r47, 0;
	add.f64 	%fd646, %fd1054, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r269}, %fd646;
	}
	and.b32  	%r50, %r269, 2146435072;
	setp.ne.s32 	%p147, %r50, 2146435072;
	setp.gtu.f64 	%p148, %fd645, 0d7FF0000000000000;
	mov.f64 	%fd647, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd647;
	}
	and.b32  	%r52, %r51, 2146435072;
	setp.eq.s32 	%p149, %r52, 1073741824;
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd645;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd55, [retval0+0];
	} // callseq 28
	and.pred  	%p5, %p145, %p149;
	and.b32  	%r53, %r47, 2147483647;
	setp.gt.f64 	%p150, %fd645, 0d3FF0000000000000;
	selp.b32 	%r270, 2146435072, 0, %p150;
	xor.b32  	%r271, %r270, 2146435072;
	selp.b32 	%r272, %r271, %r270, %p146;
	setp.eq.f32 	%p151, %f66, 0fBF800000;
	selp.b32 	%r54, 1072693248, %r272, %p151;
	setp.lt.s32 	%p152, %r51, 0;
	add.f64 	%fd648, %fd1054, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r273}, %fd648;
	}
	and.b32  	%r55, %r273, 2146435072;
	setp.ne.s32 	%p153, %r55, 2146435072;
	setp.gt.s32 	%p154, %r47, -1;
	selp.b32 	%r56, 2146435072, 0, %p154;
	setp.ne.s32 	%p155, %r53, 1071644672;
	or.b32  	%r57, %r56, -2147483648;
	mov.f64 	%fd649, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r274}, %fd649;
	}
	and.b32  	%r275, %r274, 2146435072;
	setp.eq.s32 	%p156, %r275, 1072693248;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd645;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd56, [retval0+0];
	} // callseq 29
	and.pred  	%p6, %p145, %p156;
	and.b32  	%r58, %r51, 2147483647;
	selp.b32 	%r276, %r271, %r270, %p152;
	selp.b32 	%r59, 1072693248, %r276, %p151;
	selp.b32 	%r277, %r49, 0, %p156;
	setp.lt.s32 	%p157, %r274, 0;
	or.b32  	%r278, %r277, 2146435072;
	selp.b32 	%r60, %r278, %r277, %p157;
	add.f64 	%fd650, %fd1054, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r279}, %fd650;
	}
	and.b32  	%r61, %r279, 2146435072;
	setp.ne.s32 	%p158, %r61, 2146435072;
	setp.gt.s32 	%p159, %r51, -1;
	selp.b32 	%r62, 2146435072, 0, %p159;
	or.b32  	%r63, %r62, -2147483648;
	abs.f64 	%fd651, %fd1053;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd651;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd57, [retval0+0];
	} // callseq 30
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd1053;
	}
	setp.lt.s32 	%p160, %r64, 0;
	and.pred  	%p7, %p160, %p144;
	and.b32  	%r65, %r274, 2147483647;
	selp.b32 	%r280, %r271, %r270, %p157;
	selp.b32 	%r66, 1072693248, %r280, %p151;
	add.f64 	%fd652, %fd1053, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r281}, %fd652;
	}
	and.b32  	%r67, %r281, 2146435072;
	setp.ne.s32 	%p161, %r67, 2146435072;
	setp.gt.s32 	%p162, %r274, -1;
	selp.b32 	%r282, 2146435072, 0, %p162;
	setp.ne.s32 	%p163, %r65, 1071644672;
	and.pred  	%p164, %p163, %p6;
	or.b32  	%r283, %r282, -2147483648;
	selp.b32 	%r68, %r283, %r282, %p164;
	setp.gtu.f64 	%p165, %fd651, 0d7FF0000000000000;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd651;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd58, [retval0+0];
	} // callseq 31
	and.pred  	%p8, %p160, %p149;
	setp.gt.f64 	%p166, %fd651, 0d3FF0000000000000;
	selp.b32 	%r284, 2146435072, 0, %p166;
	xor.b32  	%r285, %r284, 2146435072;
	selp.b32 	%r286, %r285, %r284, %p146;
	setp.eq.f32 	%p167, %f68, 0fBF800000;
	selp.b32 	%r69, 1072693248, %r286, %p167;
	add.f64 	%fd653, %fd1053, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r287}, %fd653;
	}
	and.b32  	%r70, %r287, 2146435072;
	setp.ne.s32 	%p168, %r70, 2146435072;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd651;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd59, [retval0+0];
	} // callseq 32
	and.pred  	%p9, %p160, %p156;
	selp.b32 	%r288, %r285, %r284, %p152;
	selp.b32 	%r71, 1072693248, %r288, %p167;
	selp.b32 	%r289, %r64, 0, %p156;
	or.b32  	%r290, %r289, 2146435072;
	selp.b32 	%r72, %r290, %r289, %p157;
	add.f64 	%fd654, %fd1053, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r291}, %fd654;
	}
	and.b32  	%r73, %r291, 2146435072;
	setp.ne.s32 	%p169, %r73, 2146435072;
	cvt.rn.f32.s32 	%f80, %r1370;
	sub.f32 	%f634, %f80, %f3278;
	add.f32 	%f81, %f634, 0f3F000000;
	add.f32 	%f82, %f634, 0fBF000000;
	selp.b32 	%r292, %r285, %r284, %p157;
	selp.b32 	%r74, 1072693248, %r292, %p167;
	and.pred  	%p170, %p163, %p9;
	selp.b32 	%r75, %r283, %r282, %p170;
	cvt.f64.f32 	%fd655, %f81;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd655;
	}
	abs.f64 	%fd656, %fd655;
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd656;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd60, [retval0+0];
	} // callseq 33
	setp.lt.s32 	%p171, %r76, 0;
	and.pred  	%p10, %p171, %p149;
	add.f64 	%fd61, %fd655, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r293}, %fd61;
	}
	and.b32  	%r77, %r293, 2146435072;
	setp.ne.s32 	%p172, %r77, 2146435072;
	mov.f64 	%fd657, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd657;
	}
	setp.gtu.f64 	%p173, %fd656, 0d7FF0000000000000;
	cvt.f64.f32 	%fd658, %f82;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd658;
	}
	abs.f64 	%fd659, %fd658;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd659;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd62, [retval0+0];
	} // callseq 34
	setp.lt.s32 	%p174, %r79, 0;
	and.pred  	%p11, %p174, %p149;
	setp.gt.f64 	%p175, %fd656, 0d3FF0000000000000;
	selp.b32 	%r294, 2146435072, 0, %p175;
	xor.b32  	%r295, %r294, 2146435072;
	selp.b32 	%r296, %r295, %r294, %p152;
	setp.eq.f32 	%p176, %f81, 0fBF800000;
	selp.b32 	%r80, 1072693248, %r296, %p176;
	add.f64 	%fd63, %fd658, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r297}, %fd63;
	}
	and.b32  	%r81, %r297, 2146435072;
	setp.ne.s32 	%p177, %r81, 2146435072;
	setp.gtu.f64 	%p178, %fd659, 0d7FF0000000000000;
	setp.gt.f64 	%p179, %fd659, 0d3FF0000000000000;
	selp.b32 	%r298, 2146435072, 0, %p179;
	xor.b32  	%r299, %r298, 2146435072;
	selp.b32 	%r300, %r299, %r298, %p152;
	setp.eq.f32 	%p180, %f82, 0fBF800000;
	selp.b32 	%r82, 1072693248, %r300, %p180;
	abs.f64 	%fd660, %fd45;
	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd660;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd64, [retval0+0];
	} // callseq 35
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd45;
	}
	setp.lt.s32 	%p181, %r83, 0;
	and.pred  	%p12, %p181, %p144;
	selp.b32 	%r301, %r83, 0, %p144;
	or.b32  	%r302, %r301, 2146435072;
	selp.b32 	%r84, %r302, %r301, %p146;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r303}, %fd46;
	}
	and.b32  	%r85, %r303, 2146435072;
	setp.ne.s32 	%p182, %r85, 2146435072;
	setp.gtu.f64 	%p183, %fd660, 0d7FF0000000000000;
	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd660;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd65, [retval0+0];
	} // callseq 36
	and.pred  	%p13, %p181, %p149;
	setp.gt.f64 	%p184, %fd660, 0d3FF0000000000000;
	selp.b32 	%r304, 2146435072, 0, %p184;
	xor.b32  	%r305, %r304, 2146435072;
	selp.b32 	%r306, %r305, %r304, %p146;
	setp.eq.f32 	%p185, %f3053, 0fBF800000;
	selp.b32 	%r86, 1072693248, %r306, %p185;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r307}, %fd47;
	}
	and.b32  	%r87, %r307, 2146435072;
	setp.ne.s32 	%p186, %r87, 2146435072;
	and.pred  	%p187, %p155, %p12;
	selp.b32 	%r88, %r57, %r56, %p187;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r89}, %fd643;
	}
	abs.f64 	%fd662, %fd643;
	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd662;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd66, [retval0+0];
	} // callseq 37
	setp.lt.s32 	%p188, %r89, 0;
	and.pred  	%p14, %p188, %p156;
	selp.b32 	%r308, %r305, %r304, %p152;
	selp.b32 	%r90, 1072693248, %r308, %p185;
	selp.b32 	%r309, %r89, 0, %p156;
	or.b32  	%r310, %r309, 2146435072;
	selp.b32 	%r91, %r310, %r309, %p157;
	setp.gtu.f64 	%p190, %fd662, 0d7FF0000000000000;
	abs.f64 	%fd663, %fd49;
	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd663;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd67, [retval0+0];
	} // callseq 38
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r93}, %fd49;
	}
	setp.lt.s32 	%p191, %r93, 0;
	and.pred  	%p15, %p191, %p144;
	setp.gt.f64 	%p192, %fd662, 0d3FF0000000000000;
	selp.b32 	%r312, 2146435072, 0, %p192;
	xor.b32  	%r313, %r312, 2146435072;
	selp.b32 	%r314, %r313, %r312, %p157;
	selp.b32 	%r94, 1072693248, %r314, %p193;
	selp.b32 	%r315, %r93, 0, %p144;
	or.b32  	%r316, %r315, 2146435072;
	selp.b32 	%r95, %r316, %r315, %p146;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r317}, %fd50;
	}
	and.b32  	%r96, %r317, 2146435072;
	setp.ne.s32 	%p194, %r96, 2146435072;
	and.pred  	%p195, %p163, %p14;
	selp.b32 	%r97, %r283, %r282, %p195;
	setp.gtu.f64 	%p196, %fd663, 0d7FF0000000000000;
	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd663;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd68, [retval0+0];
	} // callseq 39
	and.pred  	%p16, %p191, %p149;
	setp.gt.f64 	%p197, %fd663, 0d3FF0000000000000;
	selp.b32 	%r318, 2146435072, 0, %p197;
	xor.b32  	%r319, %r318, 2146435072;
	selp.b32 	%r320, %r319, %r318, %p146;
	setp.eq.f32 	%p198, %f3054, 0fBF800000;
	selp.b32 	%r98, 1072693248, %r320, %p198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r321}, %fd51;
	}
	and.b32  	%r99, %r321, 2146435072;
	setp.ne.s32 	%p199, %r99, 2146435072;
	and.pred  	%p200, %p155, %p15;
	selp.b32 	%r100, %r57, %r56, %p200;
	selp.b32 	%r322, %r319, %r318, %p152;
	selp.b32 	%r101, 1072693248, %r322, %p198;
	or.pred  	%p17, %p147, %p148;
	or.pred  	%p18, %p153, %p148;
	or.pred  	%p19, %p158, %p148;
	or.pred  	%p20, %p161, %p165;
	or.pred  	%p21, %p168, %p165;
	or.pred  	%p22, %p169, %p165;
	or.pred  	%p23, %p172, %p173;
	or.pred  	%p24, %p177, %p178;
	or.pred  	%p25, %p182, %p183;
	or.pred  	%p26, %p186, %p183;
	or.pred  	%p27, %p189, %p190;
	or.pred  	%p28, %p194, %p196;
	or.pred  	%p29, %p199, %p196;
	shr.s32 	%r323, %r47, 31;
	and.b32  	%r102, %r323, 2146435072;
	mov.u32 	%r1371, %r266;

$L__BB2_56:
	not.pred 	%p201, %p4;
	mov.f64 	%fd1081, %fd54;
	@%p201 bra 	$L__BB2_58;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r324}, %fd54;
	}
	xor.b32  	%r325, %r324, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r326, %temp}, %fd54;
	}
	mov.b64 	%fd1081, {%r326, %r325};

$L__BB2_58:
	setp.eq.f32 	%p202, %f66, 0f00000000;
	@%p202 bra 	$L__BB2_62;
	bra.uni 	$L__BB2_59;

$L__BB2_62:
	mov.u32 	%r327, 0;
	selp.b32 	%r329, %r49, 0, %p144;
	or.b32  	%r330, %r329, 2146435072;
	selp.b32 	%r331, %r330, %r329, %p146;
	mov.b64 	%fd1081, {%r327, %r331};
	bra.uni 	$L__BB2_63;

$L__BB2_59:
	setp.gt.s32 	%p203, %r49, -1;
	@%p203 bra 	$L__BB2_63;

	cvt.rzi.f64.f64 	%fd665, %fd644;
	setp.eq.f64 	%p204, %fd665, 0d4000000000000000;
	@%p204 bra 	$L__BB2_63;

	mov.f64 	%fd1081, 0dFFF8000000000000;

$L__BB2_63:
	cvt.f64.f32 	%fd1056, %f66;
	add.f64 	%fd1055, %fd1054, 0d4000000000000000;
	selp.f64 	%fd1082, %fd1081, %fd1055, %p147;
	@%p17 bra 	$L__BB2_68;

	setp.eq.s32 	%p208, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r332, %temp}, %fd644;
	}
	setp.eq.s32 	%p209, %r332, 0;
	and.pred  	%p210, %p208, %p209;
	@%p210 bra 	$L__BB2_67;
	bra.uni 	$L__BB2_65;

$L__BB2_67:
	mov.u32 	%r339, 0;
	mov.b64 	%fd1082, {%r339, %r54};
	bra.uni 	$L__BB2_68;

$L__BB2_65:
	and.b32  	%r333, %r49, 2147483647;
	setp.ne.s32 	%p211, %r333, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r334, %temp}, %fd41;
	}
	setp.ne.s32 	%p212, %r334, 0;
	or.pred  	%p213, %p211, %p212;
	mov.f64 	%fd1082, %fd1081;
	@%p213 bra 	$L__BB2_68;

	and.pred  	%p215, %p155, %p4;
	selp.b32 	%r337, %r57, %r56, %p215;
	mov.u32 	%r338, 0;
	mov.b64 	%fd1082, {%r338, %r337};

$L__BB2_68:
	not.pred 	%p216, %p5;
	mov.f64 	%fd1084, %fd55;
	@%p216 bra 	$L__BB2_70;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r340}, %fd55;
	}
	xor.b32  	%r341, %r340, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r342, %temp}, %fd55;
	}
	mov.b64 	%fd1084, {%r342, %r341};

$L__BB2_70:
	@%p202 bra 	$L__BB2_74;
	bra.uni 	$L__BB2_71;

$L__BB2_74:
	mov.u32 	%r343, 0;
	selp.b32 	%r345, %r49, 0, %p149;
	or.b32  	%r346, %r345, 2146435072;
	selp.b32 	%r347, %r346, %r345, %p152;
	mov.b64 	%fd1084, {%r343, %r347};
	bra.uni 	$L__BB2_75;

$L__BB2_71:
	setp.gt.s32 	%p218, %r49, -1;
	@%p218 bra 	$L__BB2_75;

	cvt.rzi.f64.f64 	%fd670, %fd647;
	setp.eq.f64 	%p219, %fd670, 0d4008000000000000;
	@%p219 bra 	$L__BB2_75;

	mov.f64 	%fd1084, 0dFFF8000000000000;

$L__BB2_75:
	cvt.f64.f32 	%fd1058, %f66;
	add.f64 	%fd1057, %fd1054, 0d4008000000000000;
	selp.f64 	%fd1085, %fd1084, %fd1057, %p153;
	@%p18 bra 	$L__BB2_80;

	setp.eq.s32 	%p223, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r348, %temp}, %fd647;
	}
	setp.eq.s32 	%p224, %r348, 0;
	and.pred  	%p225, %p223, %p224;
	@%p225 bra 	$L__BB2_79;
	bra.uni 	$L__BB2_77;

$L__BB2_79:
	mov.u32 	%r355, 0;
	mov.b64 	%fd1085, {%r355, %r59};
	bra.uni 	$L__BB2_80;

$L__BB2_77:
	and.b32  	%r349, %r49, 2147483647;
	setp.ne.s32 	%p226, %r349, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r350, %temp}, %fd41;
	}
	setp.ne.s32 	%p227, %r350, 0;
	or.pred  	%p228, %p226, %p227;
	mov.f64 	%fd1085, %fd1084;
	@%p228 bra 	$L__BB2_80;

	setp.ne.s32 	%p229, %r58, 1071644672;
	and.pred  	%p230, %p229, %p5;
	selp.b32 	%r353, %r63, %r62, %p230;
	mov.u32 	%r354, 0;
	mov.b64 	%fd1085, {%r354, %r353};

$L__BB2_80:
	setp.eq.f32 	%p231, %f66, 0f3F800000;
	selp.f64 	%fd674, 0d3FF0000000000000, %fd1085, %p231;
	cvt.f64.f32 	%fd675, %f536;
	add.f64 	%fd676, %fd1082, 0d3FF0000000000000;
	selp.f64 	%fd677, 0d4000000000000000, %fd676, %p231;
	fma.rn.f64 	%fd85, %fd674, %fd675, %fd677;
	not.pred 	%p232, %p6;
	mov.f64 	%fd1087, %fd56;
	@%p232 bra 	$L__BB2_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r356}, %fd56;
	}
	xor.b32  	%r357, %r356, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r358, %temp}, %fd56;
	}
	mov.b64 	%fd1087, {%r358, %r357};

$L__BB2_82:
	@%p202 bra 	$L__BB2_86;
	bra.uni 	$L__BB2_83;

$L__BB2_86:
	mov.u32 	%r359, 0;
	mov.b64 	%fd1087, {%r359, %r60};
	bra.uni 	$L__BB2_87;

$L__BB2_83:
	setp.gt.s32 	%p234, %r49, -1;
	@%p234 bra 	$L__BB2_87;

	cvt.rzi.f64.f64 	%fd679, %fd649;
	setp.eq.f64 	%p235, %fd679, 0d4010000000000000;
	@%p235 bra 	$L__BB2_87;

	mov.f64 	%fd1087, 0dFFF8000000000000;

$L__BB2_87:
	cvt.f64.f32 	%fd1060, %f66;
	add.f64 	%fd1059, %fd1054, 0d4010000000000000;
	selp.f64 	%fd1088, %fd1087, %fd1059, %p158;
	@%p19 bra 	$L__BB2_92;

	setp.eq.s32 	%p237, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r360, %temp}, %fd649;
	}
	setp.eq.s32 	%p238, %r360, 0;
	and.pred  	%p239, %p237, %p238;
	@%p239 bra 	$L__BB2_91;
	bra.uni 	$L__BB2_89;

$L__BB2_91:
	mov.u32 	%r364, 0;
	mov.b64 	%fd1088, {%r364, %r66};
	bra.uni 	$L__BB2_92;

$L__BB2_89:
	and.b32  	%r361, %r49, 2147483647;
	setp.ne.s32 	%p240, %r361, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r362, %temp}, %fd41;
	}
	setp.ne.s32 	%p241, %r362, 0;
	or.pred  	%p242, %p240, %p241;
	mov.f64 	%fd1088, %fd1087;
	@%p242 bra 	$L__BB2_92;

	mov.u32 	%r363, 0;
	mov.b64 	%fd1088, {%r363, %r68};

$L__BB2_92:
	selp.f64 	%fd683, 0d3FF0000000000000, %fd1088, %p231;
	cvt.f64.f32 	%fd684, %f538;
	fma.rn.f64 	%fd685, %fd683, %fd684, %fd85;
	cvt.rn.f32.f64 	%f96, %fd685;
	not.pred 	%p244, %p7;
	mov.f64 	%fd1090, %fd57;
	@%p244 bra 	$L__BB2_94;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r365}, %fd57;
	}
	xor.b32  	%r366, %r365, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r367, %temp}, %fd57;
	}
	mov.b64 	%fd1090, {%r367, %r366};

$L__BB2_94:
	setp.eq.f32 	%p245, %f68, 0f00000000;
	@%p245 bra 	$L__BB2_98;
	bra.uni 	$L__BB2_95;

$L__BB2_98:
	mov.u32 	%r368, 0;
	selp.b32 	%r370, %r64, 0, %p144;
	or.b32  	%r371, %r370, 2146435072;
	selp.b32 	%r372, %r371, %r370, %p146;
	mov.b64 	%fd1090, {%r368, %r372};
	bra.uni 	$L__BB2_99;

$L__BB2_95:
	setp.gt.s32 	%p246, %r64, -1;
	@%p246 bra 	$L__BB2_99;

	cvt.rzi.f64.f64 	%fd687, %fd644;
	setp.eq.f64 	%p247, %fd687, 0d4000000000000000;
	@%p247 bra 	$L__BB2_99;

	mov.f64 	%fd1090, 0dFFF8000000000000;

$L__BB2_99:
	cvt.f64.f32 	%fd1062, %f68;
	add.f64 	%fd1061, %fd1053, 0d4000000000000000;
	selp.f64 	%fd1091, %fd1090, %fd1061, %p161;
	@%p20 bra 	$L__BB2_104;

	setp.eq.s32 	%p251, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r373, %temp}, %fd644;
	}
	setp.eq.s32 	%p252, %r373, 0;
	and.pred  	%p253, %p251, %p252;
	@%p253 bra 	$L__BB2_103;
	bra.uni 	$L__BB2_101;

$L__BB2_103:
	mov.u32 	%r380, 0;
	mov.b64 	%fd1091, {%r380, %r69};
	bra.uni 	$L__BB2_104;

$L__BB2_101:
	and.b32  	%r374, %r64, 2147483647;
	setp.ne.s32 	%p254, %r374, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r375, %temp}, %fd42;
	}
	setp.ne.s32 	%p255, %r375, 0;
	or.pred  	%p256, %p254, %p255;
	mov.f64 	%fd1091, %fd1090;
	@%p256 bra 	$L__BB2_104;

	and.pred  	%p258, %p155, %p7;
	selp.b32 	%r378, %r57, %r56, %p258;
	mov.u32 	%r379, 0;
	mov.b64 	%fd1091, {%r379, %r378};

$L__BB2_104:
	not.pred 	%p259, %p8;
	mov.f64 	%fd1093, %fd58;
	@%p259 bra 	$L__BB2_106;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r381}, %fd58;
	}
	xor.b32  	%r382, %r381, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r383, %temp}, %fd58;
	}
	mov.b64 	%fd1093, {%r383, %r382};

$L__BB2_106:
	@%p245 bra 	$L__BB2_110;
	bra.uni 	$L__BB2_107;

$L__BB2_110:
	mov.u32 	%r384, 0;
	selp.b32 	%r386, %r64, 0, %p149;
	or.b32  	%r387, %r386, 2146435072;
	selp.b32 	%r388, %r387, %r386, %p152;
	mov.b64 	%fd1093, {%r384, %r388};
	bra.uni 	$L__BB2_111;

$L__BB2_107:
	setp.gt.s32 	%p261, %r64, -1;
	@%p261 bra 	$L__BB2_111;

	cvt.rzi.f64.f64 	%fd692, %fd647;
	setp.eq.f64 	%p262, %fd692, 0d4008000000000000;
	@%p262 bra 	$L__BB2_111;

	mov.f64 	%fd1093, 0dFFF8000000000000;

$L__BB2_111:
	cvt.f64.f32 	%fd1064, %f68;
	add.f64 	%fd1063, %fd1053, 0d4008000000000000;
	selp.f64 	%fd1094, %fd1093, %fd1063, %p168;
	@%p21 bra 	$L__BB2_116;

	setp.eq.s32 	%p266, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r389, %temp}, %fd647;
	}
	setp.eq.s32 	%p267, %r389, 0;
	and.pred  	%p268, %p266, %p267;
	@%p268 bra 	$L__BB2_115;
	bra.uni 	$L__BB2_113;

$L__BB2_115:
	mov.u32 	%r396, 0;
	mov.b64 	%fd1094, {%r396, %r71};
	bra.uni 	$L__BB2_116;

$L__BB2_113:
	and.b32  	%r390, %r64, 2147483647;
	setp.ne.s32 	%p269, %r390, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r391, %temp}, %fd42;
	}
	setp.ne.s32 	%p270, %r391, 0;
	or.pred  	%p271, %p269, %p270;
	mov.f64 	%fd1094, %fd1093;
	@%p271 bra 	$L__BB2_116;

	setp.ne.s32 	%p272, %r58, 1071644672;
	and.pred  	%p273, %p272, %p8;
	selp.b32 	%r394, %r63, %r62, %p273;
	mov.u32 	%r395, 0;
	mov.b64 	%fd1094, {%r395, %r394};

$L__BB2_116:
	setp.eq.f32 	%p274, %f68, 0f3F800000;
	selp.f64 	%fd696, 0d3FF0000000000000, %fd1094, %p274;
	cvt.f64.f32 	%fd697, %f537;
	add.f64 	%fd698, %fd1091, 0d3FF0000000000000;
	selp.f64 	%fd699, 0d4000000000000000, %fd698, %p274;
	fma.rn.f64 	%fd110, %fd696, %fd697, %fd699;
	not.pred 	%p275, %p9;
	mov.f64 	%fd1096, %fd59;
	@%p275 bra 	$L__BB2_118;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r397}, %fd59;
	}
	xor.b32  	%r398, %r397, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r399, %temp}, %fd59;
	}
	mov.b64 	%fd1096, {%r399, %r398};

$L__BB2_118:
	@%p245 bra 	$L__BB2_122;
	bra.uni 	$L__BB2_119;

$L__BB2_122:
	mov.u32 	%r400, 0;
	mov.b64 	%fd1096, {%r400, %r72};
	bra.uni 	$L__BB2_123;

$L__BB2_119:
	setp.gt.s32 	%p277, %r64, -1;
	@%p277 bra 	$L__BB2_123;

	cvt.rzi.f64.f64 	%fd701, %fd649;
	setp.eq.f64 	%p278, %fd701, 0d4010000000000000;
	@%p278 bra 	$L__BB2_123;

	mov.f64 	%fd1096, 0dFFF8000000000000;

$L__BB2_123:
	cvt.f64.f32 	%fd1066, %f68;
	add.f64 	%fd1065, %fd1053, 0d4010000000000000;
	selp.f64 	%fd1097, %fd1096, %fd1065, %p169;
	@%p22 bra 	$L__BB2_128;

	setp.eq.s32 	%p280, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r401, %temp}, %fd649;
	}
	setp.eq.s32 	%p281, %r401, 0;
	and.pred  	%p282, %p280, %p281;
	@%p282 bra 	$L__BB2_127;
	bra.uni 	$L__BB2_125;

$L__BB2_127:
	mov.u32 	%r405, 0;
	mov.b64 	%fd1097, {%r405, %r74};
	bra.uni 	$L__BB2_128;

$L__BB2_125:
	and.b32  	%r402, %r64, 2147483647;
	setp.ne.s32 	%p283, %r402, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r403, %temp}, %fd42;
	}
	setp.ne.s32 	%p284, %r403, 0;
	or.pred  	%p285, %p283, %p284;
	mov.f64 	%fd1097, %fd1096;
	@%p285 bra 	$L__BB2_128;

	mov.u32 	%r404, 0;
	mov.b64 	%fd1097, {%r404, %r75};

$L__BB2_128:
	selp.f64 	%fd705, 0d3FF0000000000000, %fd1097, %p274;
	cvt.f64.f32 	%fd706, %f539;
	fma.rn.f64 	%fd707, %fd705, %fd706, %fd110;
	cvt.rn.f32.f64 	%f97, %fd707;
	sqrt.rn.f32 	%f98, %f96;
	mul.f32 	%f99, %f98, %f535;
	sqrt.rn.f32 	%f100, %f97;
	mul.f32 	%f101, %f100, %f542;
	mov.f32 	%f646, 0f3F000000;
	div.rn.f32 	%f647, %f646, %f99;
	div.rn.f32 	%f648, %f647, %f99;
	sqrt.rn.f32 	%f102, %f648;
	mul.f32 	%f103, %f102, %f81;
	abs.f32 	%f649, %f103;
	setp.ltu.f32 	%p287, %f649, 0f3F8060FE;
	setp.ge.f32 	%p288, %f649, 0f3F8060FE;
	mul.f32 	%f650, %f103, %f103;
	selp.f32 	%f651, %f649, %f650, %p288;
	selp.f32 	%f652, 0f3789CA3C, 0f38B1E96A, %p288;
	selp.f32 	%f653, 0fB9F560B9, 0fBA574D20, %p288;
	fma.rn.f32 	%f654, %f652, %f651, %f653;
	selp.f32 	%f655, 0f3BAC840B, 0f3BAAD5EA, %p288;
	fma.rn.f32 	%f656, %f654, %f651, %f655;
	selp.f32 	%f657, 0fBD0C8162, 0fBCDC1BE7, %p288;
	fma.rn.f32 	%f658, %f656, %f651, %f657;
	selp.f32 	%f659, 0f3E1CF906, 0f3DE718AF, %p288;
	fma.rn.f32 	%f660, %f658, %f651, %f659;
	selp.f32 	%f661, 0f3F6A937E, 0fBEC093AC, %p288;
	fma.rn.f32 	%f662, %f660, %f651, %f661;
	selp.f32 	%f663, 0f3F20D842, 0f3E0375D3, %p288;
	fma.rn.f32 	%f664, %f662, %f651, %f663;
	neg.f32 	%f665, %f649;
	selp.f32 	%f666, %f665, %f103, %p288;
	fma.rn.f32 	%f3228, %f664, %f666, %f666;
	@%p287 bra 	$L__BB2_130;

	mov.f32 	%f3132, 0f3F800000;
	ex2.approx.ftz.f32 	%f667, %f3228;
	sub.f32 	%f669, %f3132, %f667;
	mov.b32 	%r406, %f669;
	mov.b32 	%r407, %f103;
	and.b32  	%r408, %r407, -2147483648;
	or.b32  	%r409, %r408, %r406;
	mov.b32 	%f3228, %r409;

$L__BB2_130:
	mul.f32 	%f107, %f102, %f82;
	abs.f32 	%f670, %f107;
	setp.ltu.f32 	%p289, %f670, 0f3F8060FE;
	setp.ge.f32 	%p290, %f670, 0f3F8060FE;
	mul.f32 	%f671, %f107, %f107;
	selp.f32 	%f672, %f670, %f671, %p290;
	selp.f32 	%f673, 0f3789CA3C, 0f38B1E96A, %p290;
	selp.f32 	%f674, 0fB9F560B9, 0fBA574D20, %p290;
	fma.rn.f32 	%f675, %f673, %f672, %f674;
	selp.f32 	%f676, 0f3BAC840B, 0f3BAAD5EA, %p290;
	fma.rn.f32 	%f677, %f675, %f672, %f676;
	selp.f32 	%f678, 0fBD0C8162, 0fBCDC1BE7, %p290;
	fma.rn.f32 	%f679, %f677, %f672, %f678;
	selp.f32 	%f680, 0f3E1CF906, 0f3DE718AF, %p290;
	fma.rn.f32 	%f681, %f679, %f672, %f680;
	selp.f32 	%f682, 0f3F6A937E, 0fBEC093AC, %p290;
	fma.rn.f32 	%f683, %f681, %f672, %f682;
	selp.f32 	%f684, 0f3F20D842, 0f3E0375D3, %p290;
	fma.rn.f32 	%f685, %f683, %f672, %f684;
	neg.f32 	%f686, %f670;
	selp.f32 	%f687, %f686, %f107, %p290;
	fma.rn.f32 	%f3229, %f685, %f687, %f687;
	@%p289 bra 	$L__BB2_132;

	mov.f32 	%f3131, 0f3F800000;
	ex2.approx.ftz.f32 	%f688, %f3229;
	sub.f32 	%f690, %f3131, %f688;
	mov.b32 	%r410, %f690;
	mov.b32 	%r411, %f107;
	and.b32  	%r412, %r411, -2147483648;
	or.b32  	%r413, %r412, %r410;
	mov.b32 	%f3229, %r413;

$L__BB2_132:
	mov.f32 	%f3055, 0f3F000000;
	sub.f32 	%f691, %f3228, %f3229;
	mul.f32 	%f111, %f691, 0f3F000000;
	div.rn.f32 	%f693, %f3055, %f101;
	div.rn.f32 	%f694, %f693, %f101;
	cvt.rn.f32.s32 	%f112, %r1371;
	sub.f32 	%f113, %f112, %f3277;
	add.f32 	%f114, %f113, 0f3F000000;
	sqrt.rn.f32 	%f115, %f694;
	mul.f32 	%f116, %f115, %f114;
	abs.f32 	%f695, %f116;
	setp.ltu.f32 	%p291, %f695, 0f3F8060FE;
	setp.ge.f32 	%p292, %f695, 0f3F8060FE;
	mul.f32 	%f696, %f116, %f116;
	selp.f32 	%f697, %f695, %f696, %p292;
	selp.f32 	%f698, 0f3789CA3C, 0f38B1E96A, %p292;
	selp.f32 	%f699, 0fB9F560B9, 0fBA574D20, %p292;
	fma.rn.f32 	%f700, %f698, %f697, %f699;
	selp.f32 	%f701, 0f3BAC840B, 0f3BAAD5EA, %p292;
	fma.rn.f32 	%f702, %f700, %f697, %f701;
	selp.f32 	%f703, 0fBD0C8162, 0fBCDC1BE7, %p292;
	fma.rn.f32 	%f704, %f702, %f697, %f703;
	selp.f32 	%f705, 0f3E1CF906, 0f3DE718AF, %p292;
	fma.rn.f32 	%f706, %f704, %f697, %f705;
	selp.f32 	%f707, 0f3F6A937E, 0fBEC093AC, %p292;
	fma.rn.f32 	%f708, %f706, %f697, %f707;
	selp.f32 	%f709, 0f3F20D842, 0f3E0375D3, %p292;
	fma.rn.f32 	%f710, %f708, %f697, %f709;
	neg.f32 	%f711, %f695;
	selp.f32 	%f712, %f711, %f116, %p292;
	fma.rn.f32 	%f3230, %f710, %f712, %f712;
	@%p291 bra 	$L__BB2_134;

	mov.f32 	%f3130, 0f3F800000;
	ex2.approx.ftz.f32 	%f713, %f3230;
	sub.f32 	%f715, %f3130, %f713;
	mov.b32 	%r414, %f715;
	mov.b32 	%r415, %f116;
	and.b32  	%r416, %r415, -2147483648;
	or.b32  	%r417, %r416, %r414;
	mov.b32 	%f3230, %r417;

$L__BB2_134:
	cvt.rn.f32.s32 	%f3057, %r1371;
	sub.f32 	%f3056, %f3057, %f3277;
	add.f32 	%f120, %f3056, 0fBF000000;
	mul.f32 	%f121, %f115, %f120;
	abs.f32 	%f716, %f121;
	setp.ltu.f32 	%p293, %f716, 0f3F8060FE;
	setp.ge.f32 	%p294, %f716, 0f3F8060FE;
	mul.f32 	%f717, %f121, %f121;
	selp.f32 	%f718, %f716, %f717, %p294;
	selp.f32 	%f719, 0f3789CA3C, 0f38B1E96A, %p294;
	selp.f32 	%f720, 0fB9F560B9, 0fBA574D20, %p294;
	fma.rn.f32 	%f721, %f719, %f718, %f720;
	selp.f32 	%f722, 0f3BAC840B, 0f3BAAD5EA, %p294;
	fma.rn.f32 	%f723, %f721, %f718, %f722;
	selp.f32 	%f724, 0fBD0C8162, 0fBCDC1BE7, %p294;
	fma.rn.f32 	%f725, %f723, %f718, %f724;
	selp.f32 	%f726, 0f3E1CF906, 0f3DE718AF, %p294;
	fma.rn.f32 	%f727, %f725, %f718, %f726;
	selp.f32 	%f728, 0f3F6A937E, 0fBEC093AC, %p294;
	fma.rn.f32 	%f729, %f727, %f718, %f728;
	selp.f32 	%f730, 0f3F20D842, 0f3E0375D3, %p294;
	fma.rn.f32 	%f731, %f729, %f718, %f730;
	neg.f32 	%f732, %f716;
	selp.f32 	%f733, %f732, %f121, %p294;
	fma.rn.f32 	%f3231, %f731, %f733, %f733;
	@%p293 bra 	$L__BB2_136;

	mov.f32 	%f3129, 0f3F800000;
	ex2.approx.ftz.f32 	%f734, %f3231;
	sub.f32 	%f736, %f3129, %f734;
	mov.b32 	%r418, %f736;
	mov.b32 	%r419, %f121;
	and.b32  	%r420, %r419, -2147483648;
	or.b32  	%r421, %r420, %r418;
	mov.b32 	%f3231, %r421;

$L__BB2_136:
	cvt.rn.f32.s32 	%f3060, %r1370;
	add.f32 	%f3059, %f3060, 0f3F000000;
	sub.f32 	%f3058, %f3059, %f3278;
	sub.f32 	%f738, %f3230, %f3231;
	mul.f32 	%f125, %f738, 0f3F000000;
	div.rn.f32 	%f126, %f3058, %f99;
	abs.f32 	%f127, %f126;
	setp.lt.f32 	%p295, %f127, 0f00800000;
	mul.f32 	%f739, %f127, 0f4B800000;
	selp.f32 	%f740, %f739, %f127, %p295;
	selp.f32 	%f741, 0fC3170000, 0fC2FE0000, %p295;
	mov.b32 	%r422, %f740;
	and.b32  	%r423, %r422, 8388607;
	or.b32  	%r424, %r423, 1065353216;
	mov.b32 	%f742, %r424;
	shr.u32 	%r425, %r422, 23;
	cvt.rn.f32.u32 	%f743, %r425;
	add.f32 	%f744, %f741, %f743;
	setp.gt.f32 	%p296, %f742, 0f3FB504F3;
	mul.f32 	%f745, %f742, 0f3F000000;
	add.f32 	%f746, %f744, 0f3F800000;
	selp.f32 	%f747, %f746, %f744, %p296;
	selp.f32 	%f748, %f745, %f742, %p296;
	add.f32 	%f749, %f748, 0fBF800000;
	add.f32 	%f750, %f748, 0f3F800000;
	rcp.approx.ftz.f32 	%f751, %f750;
	add.f32 	%f752, %f749, %f749;
	mul.f32 	%f754, %f752, %f751;
	mul.f32 	%f755, %f754, %f754;
	mov.f32 	%f756, 0f3C4CAF63;
	mov.f32 	%f757, 0f3B18F0FE;
	fma.rn.f32 	%f758, %f757, %f755, %f756;
	mov.f32 	%f759, 0f3DAAAABD;
	fma.rn.f32 	%f760, %f758, %f755, %f759;
	mul.rn.f32 	%f761, %f760, %f755;
	mul.rn.f32 	%f762, %f761, %f754;
	sub.f32 	%f763, %f749, %f754;
	add.f32 	%f764, %f763, %f763;
	neg.f32 	%f765, %f754;
	fma.rn.f32 	%f766, %f765, %f749, %f764;
	mul.rn.f32 	%f767, %f751, %f766;
	add.f32 	%f768, %f762, %f754;
	sub.f32 	%f769, %f754, %f768;
	add.f32 	%f770, %f762, %f769;
	add.f32 	%f771, %f767, %f770;
	add.f32 	%f772, %f768, %f771;
	sub.f32 	%f773, %f768, %f772;
	add.f32 	%f774, %f771, %f773;
	mov.f32 	%f775, 0f3F317200;
	mul.rn.f32 	%f776, %f747, %f775;
	mov.f32 	%f777, 0f35BFBE8E;
	mul.rn.f32 	%f778, %f747, %f777;
	add.f32 	%f779, %f776, %f772;
	sub.f32 	%f780, %f776, %f779;
	add.f32 	%f781, %f772, %f780;
	add.f32 	%f782, %f774, %f781;
	add.f32 	%f783, %f778, %f782;
	add.f32 	%f784, %f779, %f783;
	sub.f32 	%f785, %f779, %f784;
	add.f32 	%f786, %f783, %f785;
	mul.rn.f32 	%f787, %f600, %f784;
	neg.f32 	%f788, %f787;
	fma.rn.f32 	%f789, %f600, %f784, %f788;
	fma.rn.f32 	%f790, %f600, %f786, %f789;
	mov.f32 	%f3263, 0f00000000;
	fma.rn.f32 	%f792, %f3263, %f784, %f790;
	add.rn.f32 	%f793, %f787, %f792;
	neg.f32 	%f794, %f793;
	add.rn.f32 	%f795, %f787, %f794;
	add.rn.f32 	%f796, %f795, %f792;
	mov.b32 	%r426, %f793;
	setp.eq.s32 	%p297, %r426, 1118925336;
	add.s32 	%r427, %r426, -1;
	mov.b32 	%f797, %r427;
	add.f32 	%f798, %f796, 0f37000000;
	selp.f32 	%f128, %f798, %f796, %p297;
	selp.f32 	%f799, %f797, %f793, %p297;
	mov.f32 	%f800, 0f3FB8AA3B;
	mul.rn.f32 	%f801, %f799, %f800;
	cvt.rzi.f32.f32 	%f802, %f801;
	abs.f32 	%f803, %f802;
	setp.gt.f32 	%p298, %f803, 0f42FC0000;
	mov.b32 	%r428, %f802;
	and.b32  	%r429, %r428, -2147483648;
	or.b32  	%r430, %r429, 1123811328;
	mov.b32 	%f804, %r430;
	selp.f32 	%f805, %f804, %f802, %p298;
	mov.f32 	%f806, 0fBF317218;
	fma.rn.f32 	%f807, %f805, %f806, %f799;
	mov.f32 	%f808, 0f3102E308;
	fma.rn.f32 	%f809, %f805, %f808, %f807;
	mul.f32 	%f810, %f809, 0f3FB8AA3B;
	add.f32 	%f811, %f805, 0f4B40007F;
	mov.b32 	%r431, %f811;
	shl.b32 	%r432, %r431, 23;
	mov.b32 	%f812, %r432;
	ex2.approx.ftz.f32 	%f813, %f810;
	mul.f32 	%f129, %f813, %f812;
	setp.eq.f32 	%p299, %f129, 0f7F800000;
	mov.f32 	%f3232, 0f7F800000;
	@%p299 bra 	$L__BB2_138;

	fma.rn.f32 	%f3232, %f129, %f128, %f129;

$L__BB2_138:
	mov.f32 	%f3065, 0f3F800000;
	cvt.rzi.f32.f32 	%f3064, %f3065;
	add.f32 	%f3063, %f3064, %f3064;
	sub.f32 	%f3062, %f600, %f3063;
	abs.f32 	%f3061, %f3062;
	setp.lt.f32 	%p300, %f126, 0f00000000;
	setp.eq.f32 	%p301, %f3061, 0f3F800000;
	and.pred  	%p30, %p300, %p301;
	setp.eq.f32 	%p302, %f126, 0f00000000;
	@%p302 bra 	$L__BB2_142;
	bra.uni 	$L__BB2_139;

$L__BB2_142:
	add.f32 	%f818, %f126, %f126;
	selp.f32 	%f3234, %f818, 0f00000000, %p301;
	bra.uni 	$L__BB2_143;

$L__BB2_139:
	mov.b32 	%r433, %f3232;
	xor.b32  	%r434, %r433, -2147483648;
	mov.b32 	%f814, %r434;
	selp.f32 	%f3234, %f814, %f3232, %p30;
	setp.geu.f32 	%p303, %f126, 0f00000000;
	@%p303 bra 	$L__BB2_143;

	cvt.rzi.f32.f32 	%f816, %f600;
	setp.eq.f32 	%p304, %f816, 0f40000000;
	@%p304 bra 	$L__BB2_143;

	mov.f32 	%f3234, 0f7FFFFFFF;

$L__BB2_143:
	add.f32 	%f819, %f127, 0f40000000;
	mov.b32 	%r435, %f819;
	setp.lt.s32 	%p306, %r435, 2139095040;
	@%p306 bra 	$L__BB2_148;

	setp.gtu.f32 	%p307, %f127, 0f7F800000;
	@%p307 bra 	$L__BB2_147;
	bra.uni 	$L__BB2_145;

$L__BB2_147:
	add.f32 	%f3234, %f126, 0f40000000;
	bra.uni 	$L__BB2_148;

$L__BB2_145:
	setp.neu.f32 	%p308, %f127, 0f7F800000;
	@%p308 bra 	$L__BB2_148;

	selp.f32 	%f3234, 0fFF800000, 0f7F800000, %p30;

$L__BB2_148:
	mov.f32 	%f3073, 0f3102E308;
	mov.f32 	%f3072, 0fBF317218;
	mov.f32 	%f3071, 0f35BFBE8E;
	mov.f32 	%f3070, 0f3F317200;
	mov.f32 	%f3069, 0f3DAAAABD;
	mov.f32 	%f3068, 0f3C4CAF63;
	mov.f32 	%f3067, 0f3B18F0FE;
	mov.f32 	%f3066, 0f3F000000;
	mul.f32 	%f821, %f3234, 0fBF000000;
	setp.eq.f32 	%p309, %f126, 0f3F800000;
	selp.f32 	%f822, 0fBF000000, %f821, %p309;
	mov.f32 	%f824, 0f3BBB989D;
	fma.rn.f32 	%f825, %f822, %f824, %f3066;
	mov.f32 	%f827, 0f437C0000;
	cvt.sat.f32.f32 	%f828, %f825;
	mov.f32 	%f829, 0f4B400001;
	fma.rm.f32 	%f830, %f828, %f827, %f829;
	add.f32 	%f831, %f830, 0fCB40007F;
	neg.f32 	%f832, %f831;
	fma.rn.f32 	%f833, %f822, %f800, %f832;
	mov.f32 	%f834, 0f32A57060;
	fma.rn.f32 	%f835, %f822, %f834, %f833;
	mov.b32 	%r436, %f830;
	shl.b32 	%r437, %r436, 23;
	mov.b32 	%f836, %r437;
	ex2.approx.ftz.f32 	%f837, %f835;
	mul.f32 	%f138, %f837, %f836;
	div.rn.f32 	%f139, %f82, %f99;
	abs.f32 	%f140, %f139;
	setp.lt.f32 	%p310, %f140, 0f00800000;
	mul.f32 	%f838, %f140, 0f4B800000;
	selp.f32 	%f839, %f838, %f140, %p310;
	selp.f32 	%f840, 0fC3170000, 0fC2FE0000, %p310;
	mov.b32 	%r438, %f839;
	and.b32  	%r439, %r438, 8388607;
	or.b32  	%r440, %r439, 1065353216;
	mov.b32 	%f841, %r440;
	shr.u32 	%r441, %r438, 23;
	cvt.rn.f32.u32 	%f842, %r441;
	add.f32 	%f843, %f840, %f842;
	setp.gt.f32 	%p311, %f841, 0f3FB504F3;
	mul.f32 	%f844, %f841, 0f3F000000;
	add.f32 	%f845, %f843, 0f3F800000;
	selp.f32 	%f846, %f845, %f843, %p311;
	selp.f32 	%f847, %f844, %f841, %p311;
	add.f32 	%f848, %f847, 0fBF800000;
	add.f32 	%f849, %f847, 0f3F800000;
	rcp.approx.ftz.f32 	%f850, %f849;
	add.f32 	%f851, %f848, %f848;
	mul.f32 	%f853, %f851, %f850;
	mul.f32 	%f854, %f853, %f853;
	fma.rn.f32 	%f857, %f3067, %f854, %f3068;
	fma.rn.f32 	%f859, %f857, %f854, %f3069;
	mul.rn.f32 	%f860, %f859, %f854;
	mul.rn.f32 	%f861, %f860, %f853;
	sub.f32 	%f862, %f848, %f853;
	add.f32 	%f863, %f862, %f862;
	neg.f32 	%f864, %f853;
	fma.rn.f32 	%f865, %f864, %f848, %f863;
	mul.rn.f32 	%f866, %f850, %f865;
	add.f32 	%f867, %f861, %f853;
	sub.f32 	%f868, %f853, %f867;
	add.f32 	%f869, %f861, %f868;
	add.f32 	%f870, %f866, %f869;
	add.f32 	%f871, %f867, %f870;
	sub.f32 	%f872, %f867, %f871;
	add.f32 	%f873, %f870, %f872;
	mul.rn.f32 	%f875, %f846, %f3070;
	mul.rn.f32 	%f877, %f846, %f3071;
	add.f32 	%f878, %f875, %f871;
	sub.f32 	%f879, %f875, %f878;
	add.f32 	%f880, %f871, %f879;
	add.f32 	%f881, %f873, %f880;
	add.f32 	%f882, %f877, %f881;
	add.f32 	%f883, %f878, %f882;
	sub.f32 	%f884, %f878, %f883;
	add.f32 	%f885, %f882, %f884;
	mul.rn.f32 	%f886, %f600, %f883;
	neg.f32 	%f887, %f886;
	fma.rn.f32 	%f888, %f600, %f883, %f887;
	fma.rn.f32 	%f889, %f600, %f885, %f888;
	fma.rn.f32 	%f891, %f3263, %f883, %f889;
	add.rn.f32 	%f892, %f886, %f891;
	neg.f32 	%f893, %f892;
	add.rn.f32 	%f894, %f886, %f893;
	add.rn.f32 	%f895, %f894, %f891;
	mov.b32 	%r442, %f892;
	setp.eq.s32 	%p312, %r442, 1118925336;
	add.s32 	%r443, %r442, -1;
	mov.b32 	%f896, %r443;
	add.f32 	%f897, %f895, 0f37000000;
	selp.f32 	%f141, %f897, %f895, %p312;
	selp.f32 	%f898, %f896, %f892, %p312;
	mul.rn.f32 	%f899, %f898, %f800;
	cvt.rzi.f32.f32 	%f900, %f899;
	abs.f32 	%f901, %f900;
	setp.gt.f32 	%p313, %f901, 0f42FC0000;
	mov.b32 	%r444, %f900;
	and.b32  	%r445, %r444, -2147483648;
	or.b32  	%r446, %r445, 1123811328;
	mov.b32 	%f902, %r446;
	selp.f32 	%f903, %f902, %f900, %p313;
	fma.rn.f32 	%f905, %f903, %f3072, %f898;
	fma.rn.f32 	%f907, %f903, %f3073, %f905;
	mul.f32 	%f908, %f907, 0f3FB8AA3B;
	add.f32 	%f909, %f903, 0f4B40007F;
	mov.b32 	%r447, %f909;
	shl.b32 	%r448, %r447, 23;
	mov.b32 	%f910, %r448;
	ex2.approx.ftz.f32 	%f911, %f908;
	mul.f32 	%f142, %f911, %f910;
	setp.eq.f32 	%p314, %f142, 0f7F800000;
	mov.f32 	%f3235, 0f7F800000;
	@%p314 bra 	$L__BB2_150;

	fma.rn.f32 	%f3235, %f142, %f141, %f142;

$L__BB2_150:
	setp.lt.f32 	%p315, %f139, 0f00000000;
	and.pred  	%p31, %p315, %p301;
	setp.eq.f32 	%p317, %f139, 0f00000000;
	@%p317 bra 	$L__BB2_154;
	bra.uni 	$L__BB2_151;

$L__BB2_154:
	add.f32 	%f916, %f139, %f139;
	selp.f32 	%f3237, %f916, 0f00000000, %p301;
	bra.uni 	$L__BB2_155;

$L__BB2_151:
	mov.b32 	%r449, %f3235;
	xor.b32  	%r450, %r449, -2147483648;
	mov.b32 	%f912, %r450;
	selp.f32 	%f3237, %f912, %f3235, %p31;
	setp.geu.f32 	%p318, %f139, 0f00000000;
	@%p318 bra 	$L__BB2_155;

	cvt.rzi.f32.f32 	%f914, %f600;
	setp.eq.f32 	%p319, %f914, 0f40000000;
	@%p319 bra 	$L__BB2_155;

	mov.f32 	%f3237, 0f7FFFFFFF;

$L__BB2_155:
	add.f32 	%f917, %f140, 0f40000000;
	mov.b32 	%r451, %f917;
	setp.lt.s32 	%p321, %r451, 2139095040;
	@%p321 bra 	$L__BB2_160;

	setp.gtu.f32 	%p322, %f140, 0f7F800000;
	@%p322 bra 	$L__BB2_159;
	bra.uni 	$L__BB2_157;

$L__BB2_159:
	add.f32 	%f3237, %f139, 0f40000000;
	bra.uni 	$L__BB2_160;

$L__BB2_157:
	setp.neu.f32 	%p323, %f140, 0f7F800000;
	@%p323 bra 	$L__BB2_160;

	selp.f32 	%f3237, 0fFF800000, 0f7F800000, %p31;

$L__BB2_160:
	mov.f32 	%f3078, 0f32A57060;
	mov.f32 	%f3077, 0f4B400001;
	mov.f32 	%f3076, 0f437C0000;
	mov.f32 	%f3075, 0f3BBB989D;
	mov.f32 	%f3074, 0f3F000000;
	mul.f32 	%f918, %f3237, 0fBF000000;
	setp.eq.f32 	%p324, %f139, 0f3F800000;
	selp.f32 	%f919, 0fBF000000, %f918, %p324;
	fma.rn.f32 	%f922, %f919, %f3075, %f3074;
	cvt.sat.f32.f32 	%f925, %f922;
	fma.rm.f32 	%f927, %f925, %f3076, %f3077;
	add.f32 	%f928, %f927, 0fCB40007F;
	neg.f32 	%f929, %f928;
	fma.rn.f32 	%f930, %f919, %f800, %f929;
	fma.rn.f32 	%f932, %f919, %f3078, %f930;
	mov.b32 	%r452, %f927;
	shl.b32 	%r453, %r452, 23;
	mov.b32 	%f933, %r453;
	ex2.approx.ftz.f32 	%f934, %f932;
	mul.f32 	%f151, %f934, %f933;
	sub.f32 	%f935, %f138, %f151;
	div.rn.f32 	%f152, %f69, %f99;
	mul.f32 	%f936, %f152, %f935;
	mul.f32 	%f153, %f125, %f936;
	cvt.f64.f32 	%fd119, %f99;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r104}, %fd119;
	}
	abs.f64 	%fd120, %fd119;
	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd120;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1099, [retval0+0];
	} // callseq 40
	setp.lt.s32 	%p325, %r104, 0;
	and.pred  	%p32, %p325, %p149;
	not.pred 	%p327, %p32;
	@%p327 bra 	$L__BB2_162;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r454}, %fd1099;
	}
	xor.b32  	%r455, %r454, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r456, %temp}, %fd1099;
	}
	mov.b64 	%fd1099, {%r456, %r455};

$L__BB2_162:
	setp.eq.f32 	%p328, %f99, 0f00000000;
	@%p328 bra 	$L__BB2_166;
	bra.uni 	$L__BB2_163;

$L__BB2_166:
	mov.u32 	%r457, 0;
	selp.b32 	%r458, %r104, 0, %p149;
	or.b32  	%r459, %r458, 2146435072;
	selp.b32 	%r460, %r459, %r458, %p152;
	mov.b64 	%fd1099, {%r457, %r460};
	bra.uni 	$L__BB2_167;

$L__BB2_163:
	setp.gt.s32 	%p329, %r104, -1;
	@%p329 bra 	$L__BB2_167;

	cvt.rzi.f64.f64 	%fd710, %fd647;
	setp.eq.f64 	%p330, %fd710, 0d4008000000000000;
	@%p330 bra 	$L__BB2_167;

	mov.f64 	%fd1099, 0dFFF8000000000000;

$L__BB2_167:
	add.f64 	%fd126, %fd119, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r461}, %fd126;
	}
	and.b32  	%r462, %r461, 2146435072;
	setp.ne.s32 	%p333, %r462, 2146435072;
	mov.f64 	%fd1100, %fd1099;
	@%p333 bra 	$L__BB2_173;

	setp.gtu.f64 	%p334, %fd120, 0d7FF0000000000000;
	mov.f64 	%fd1100, %fd126;
	@%p334 bra 	$L__BB2_173;

	setp.eq.s32 	%p335, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r463, %temp}, %fd647;
	}
	setp.eq.s32 	%p336, %r463, 0;
	and.pred  	%p337, %p335, %p336;
	@%p337 bra 	$L__BB2_172;
	bra.uni 	$L__BB2_170;

$L__BB2_172:
	mov.u32 	%r468, 0;
	setp.gt.f64 	%p344, %fd120, 0d3FF0000000000000;
	selp.b32 	%r469, 2146435072, 0, %p344;
	xor.b32  	%r470, %r469, 2146435072;
	selp.b32 	%r471, %r470, %r469, %p152;
	setp.eq.f32 	%p345, %f99, 0fBF800000;
	selp.b32 	%r472, 1072693248, %r471, %p345;
	mov.b64 	%fd1100, {%r468, %r472};
	bra.uni 	$L__BB2_173;

$L__BB2_170:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r464, %temp}, %fd119;
	}
	and.b32  	%r465, %r104, 2147483647;
	setp.ne.s32 	%p338, %r465, 2146435072;
	setp.ne.s32 	%p339, %r464, 0;
	or.pred  	%p340, %p338, %p339;
	mov.f64 	%fd1100, %fd1099;
	@%p340 bra 	$L__BB2_173;

	setp.ne.s32 	%p341, %r58, 1071644672;
	and.pred  	%p342, %p341, %p32;
	selp.b32 	%r466, %r63, %r62, %p342;
	mov.u32 	%r467, 0;
	mov.b64 	%fd1100, {%r467, %r466};

$L__BB2_173:
	cvt.rn.f32.s32 	%f3089, %r1371;
	mov.f32 	%f3088, 0f3102E308;
	mov.f32 	%f3087, 0fBF317218;
	mov.f32 	%f3086, 0f35BFBE8E;
	mov.f32 	%f3085, 0f3F317200;
	mov.f32 	%f3084, 0f3DAAAABD;
	mov.f32 	%f3083, 0f3C4CAF63;
	mov.f32 	%f3082, 0f3B18F0FE;
	cvt.rn.f32.s32 	%f3081, %r1370;
	add.f32 	%f3080, %f3081, 0f3F000000;
	sub.f32 	%f3079, %f3080, %f3278;
	setp.eq.f32 	%p346, %f99, 0f3F800000;
	selp.f64 	%fd713, 0d3FF0000000000000, %fd1100, %p346;
	cvt.f64.f32 	%fd714, %f69;
	div.rn.f64 	%fd715, %fd714, %fd713;
	mul.f32 	%f938, %f82, %f151;
	mul.f32 	%f939, %f3079, %f138;
	sub.f32 	%f940, %f939, %f938;
	cvt.f64.f32 	%fd716, %f940;
	mul.f64 	%fd717, %fd715, %fd716;
	cvt.f64.f32 	%fd718, %f125;
	mul.f64 	%fd719, %fd717, %fd718;
	cvt.rn.f32.f64 	%f154, %fd719;
	add.f32 	%f941, %f3089, 0f3F000000;
	sub.f32 	%f155, %f941, %f3277;
	div.rn.f32 	%f156, %f155, %f101;
	abs.f32 	%f157, %f156;
	setp.lt.f32 	%p347, %f157, 0f00800000;
	mul.f32 	%f942, %f157, 0f4B800000;
	selp.f32 	%f943, %f942, %f157, %p347;
	selp.f32 	%f944, 0fC3170000, 0fC2FE0000, %p347;
	mov.b32 	%r473, %f943;
	and.b32  	%r474, %r473, 8388607;
	or.b32  	%r475, %r474, 1065353216;
	mov.b32 	%f945, %r475;
	shr.u32 	%r476, %r473, 23;
	cvt.rn.f32.u32 	%f946, %r476;
	add.f32 	%f947, %f944, %f946;
	setp.gt.f32 	%p348, %f945, 0f3FB504F3;
	mul.f32 	%f948, %f945, 0f3F000000;
	add.f32 	%f949, %f947, 0f3F800000;
	selp.f32 	%f950, %f949, %f947, %p348;
	selp.f32 	%f951, %f948, %f945, %p348;
	add.f32 	%f952, %f951, 0fBF800000;
	add.f32 	%f953, %f951, 0f3F800000;
	rcp.approx.ftz.f32 	%f954, %f953;
	add.f32 	%f955, %f952, %f952;
	mul.f32 	%f957, %f955, %f954;
	mul.f32 	%f958, %f957, %f957;
	fma.rn.f32 	%f961, %f3082, %f958, %f3083;
	fma.rn.f32 	%f963, %f961, %f958, %f3084;
	mul.rn.f32 	%f964, %f963, %f958;
	mul.rn.f32 	%f965, %f964, %f957;
	sub.f32 	%f966, %f952, %f957;
	add.f32 	%f967, %f966, %f966;
	neg.f32 	%f968, %f957;
	fma.rn.f32 	%f969, %f968, %f952, %f967;
	mul.rn.f32 	%f970, %f954, %f969;
	add.f32 	%f971, %f965, %f957;
	sub.f32 	%f972, %f957, %f971;
	add.f32 	%f973, %f965, %f972;
	add.f32 	%f974, %f970, %f973;
	add.f32 	%f975, %f971, %f974;
	sub.f32 	%f976, %f971, %f975;
	add.f32 	%f977, %f974, %f976;
	mul.rn.f32 	%f979, %f950, %f3085;
	mul.rn.f32 	%f981, %f950, %f3086;
	add.f32 	%f982, %f979, %f975;
	sub.f32 	%f983, %f979, %f982;
	add.f32 	%f984, %f975, %f983;
	add.f32 	%f985, %f977, %f984;
	add.f32 	%f986, %f981, %f985;
	add.f32 	%f987, %f982, %f986;
	sub.f32 	%f988, %f982, %f987;
	add.f32 	%f989, %f986, %f988;
	mul.rn.f32 	%f990, %f600, %f987;
	neg.f32 	%f991, %f990;
	fma.rn.f32 	%f992, %f600, %f987, %f991;
	fma.rn.f32 	%f993, %f600, %f989, %f992;
	fma.rn.f32 	%f995, %f3263, %f987, %f993;
	add.rn.f32 	%f996, %f990, %f995;
	neg.f32 	%f997, %f996;
	add.rn.f32 	%f998, %f990, %f997;
	add.rn.f32 	%f999, %f998, %f995;
	mov.b32 	%r477, %f996;
	setp.eq.s32 	%p349, %r477, 1118925336;
	add.s32 	%r478, %r477, -1;
	mov.b32 	%f1000, %r478;
	add.f32 	%f1001, %f999, 0f37000000;
	selp.f32 	%f158, %f1001, %f999, %p349;
	selp.f32 	%f1002, %f1000, %f996, %p349;
	mul.rn.f32 	%f1004, %f1002, %f800;
	cvt.rzi.f32.f32 	%f1005, %f1004;
	abs.f32 	%f1006, %f1005;
	setp.gt.f32 	%p350, %f1006, 0f42FC0000;
	mov.b32 	%r479, %f1005;
	and.b32  	%r480, %r479, -2147483648;
	or.b32  	%r481, %r480, 1123811328;
	mov.b32 	%f1007, %r481;
	selp.f32 	%f1008, %f1007, %f1005, %p350;
	fma.rn.f32 	%f1010, %f1008, %f3087, %f1002;
	fma.rn.f32 	%f1012, %f1008, %f3088, %f1010;
	mul.f32 	%f1013, %f1012, 0f3FB8AA3B;
	add.f32 	%f1014, %f1008, 0f4B40007F;
	mov.b32 	%r482, %f1014;
	shl.b32 	%r483, %r482, 23;
	mov.b32 	%f1015, %r483;
	ex2.approx.ftz.f32 	%f1016, %f1013;
	mul.f32 	%f159, %f1016, %f1015;
	setp.eq.f32 	%p351, %f159, 0f7F800000;
	mov.f32 	%f3238, 0f7F800000;
	@%p351 bra 	$L__BB2_175;

	fma.rn.f32 	%f3238, %f159, %f158, %f159;

$L__BB2_175:
	setp.lt.f32 	%p352, %f156, 0f00000000;
	and.pred  	%p33, %p352, %p301;
	setp.eq.f32 	%p354, %f156, 0f00000000;
	@%p354 bra 	$L__BB2_179;
	bra.uni 	$L__BB2_176;

$L__BB2_179:
	add.f32 	%f1021, %f156, %f156;
	selp.f32 	%f3240, %f1021, 0f00000000, %p301;
	bra.uni 	$L__BB2_180;

$L__BB2_176:
	mov.b32 	%r484, %f3238;
	xor.b32  	%r485, %r484, -2147483648;
	mov.b32 	%f1017, %r485;
	selp.f32 	%f3240, %f1017, %f3238, %p33;
	setp.geu.f32 	%p355, %f156, 0f00000000;
	@%p355 bra 	$L__BB2_180;

	cvt.rzi.f32.f32 	%f1019, %f600;
	setp.eq.f32 	%p356, %f1019, 0f40000000;
	@%p356 bra 	$L__BB2_180;

	mov.f32 	%f3240, 0f7FFFFFFF;

$L__BB2_180:
	abs.f32 	%f3137, %f156;
	add.f32 	%f1022, %f3137, 0f40000000;
	mov.b32 	%r486, %f1022;
	setp.lt.s32 	%p358, %r486, 2139095040;
	@%p358 bra 	$L__BB2_185;

	abs.f32 	%f3141, %f156;
	setp.gtu.f32 	%p359, %f3141, 0f7F800000;
	@%p359 bra 	$L__BB2_184;
	bra.uni 	$L__BB2_182;

$L__BB2_184:
	add.f32 	%f3240, %f156, 0f40000000;
	bra.uni 	$L__BB2_185;

$L__BB2_182:
	abs.f32 	%f3142, %f156;
	setp.neu.f32 	%p360, %f3142, 0f7F800000;
	@%p360 bra 	$L__BB2_185;

	selp.f32 	%f3240, 0fFF800000, 0f7F800000, %p33;

$L__BB2_185:
	mov.f32 	%f3101, 0f32A57060;
	mov.f32 	%f3100, 0f4B400001;
	mov.f32 	%f3099, 0f437C0000;
	mov.f32 	%f3098, 0f3BBB989D;
	mov.f32 	%f3097, 0f3102E308;
	mov.f32 	%f3096, 0fBF317218;
	mov.f32 	%f3095, 0f35BFBE8E;
	mov.f32 	%f3094, 0f3F317200;
	mov.f32 	%f3093, 0f3DAAAABD;
	mov.f32 	%f3092, 0f3C4CAF63;
	mov.f32 	%f3091, 0f3B18F0FE;
	mov.f32 	%f3090, 0f3F000000;
	mul.f32 	%f1024, %f3240, 0fBF000000;
	setp.eq.f32 	%p361, %f156, 0f3F800000;
	selp.f32 	%f1025, 0fBF000000, %f1024, %p361;
	fma.rn.f32 	%f1028, %f1025, %f3098, %f3090;
	cvt.sat.f32.f32 	%f1031, %f1028;
	fma.rm.f32 	%f1033, %f1031, %f3099, %f3100;
	add.f32 	%f1034, %f1033, 0fCB40007F;
	neg.f32 	%f1035, %f1034;
	fma.rn.f32 	%f1036, %f1025, %f800, %f1035;
	fma.rn.f32 	%f1038, %f1025, %f3101, %f1036;
	mov.b32 	%r487, %f1033;
	shl.b32 	%r488, %r487, 23;
	mov.b32 	%f1039, %r488;
	ex2.approx.ftz.f32 	%f1040, %f1038;
	mul.f32 	%f168, %f1040, %f1039;
	div.rn.f32 	%f169, %f120, %f101;
	abs.f32 	%f170, %f169;
	setp.lt.f32 	%p362, %f170, 0f00800000;
	mul.f32 	%f1041, %f170, 0f4B800000;
	selp.f32 	%f1042, %f1041, %f170, %p362;
	selp.f32 	%f1043, 0fC3170000, 0fC2FE0000, %p362;
	mov.b32 	%r489, %f1042;
	and.b32  	%r490, %r489, 8388607;
	or.b32  	%r491, %r490, 1065353216;
	mov.b32 	%f1044, %r491;
	shr.u32 	%r492, %r489, 23;
	cvt.rn.f32.u32 	%f1045, %r492;
	add.f32 	%f1046, %f1043, %f1045;
	setp.gt.f32 	%p363, %f1044, 0f3FB504F3;
	mul.f32 	%f1047, %f1044, 0f3F000000;
	add.f32 	%f1048, %f1046, 0f3F800000;
	selp.f32 	%f1049, %f1048, %f1046, %p363;
	selp.f32 	%f1050, %f1047, %f1044, %p363;
	add.f32 	%f1051, %f1050, 0fBF800000;
	add.f32 	%f1052, %f1050, 0f3F800000;
	rcp.approx.ftz.f32 	%f1053, %f1052;
	add.f32 	%f1054, %f1051, %f1051;
	mul.f32 	%f1056, %f1054, %f1053;
	mul.f32 	%f1057, %f1056, %f1056;
	fma.rn.f32 	%f1060, %f3091, %f1057, %f3092;
	fma.rn.f32 	%f1062, %f1060, %f1057, %f3093;
	mul.rn.f32 	%f1063, %f1062, %f1057;
	mul.rn.f32 	%f1064, %f1063, %f1056;
	sub.f32 	%f1065, %f1051, %f1056;
	add.f32 	%f1066, %f1065, %f1065;
	neg.f32 	%f1067, %f1056;
	fma.rn.f32 	%f1068, %f1067, %f1051, %f1066;
	mul.rn.f32 	%f1069, %f1053, %f1068;
	add.f32 	%f1070, %f1064, %f1056;
	sub.f32 	%f1071, %f1056, %f1070;
	add.f32 	%f1072, %f1064, %f1071;
	add.f32 	%f1073, %f1069, %f1072;
	add.f32 	%f1074, %f1070, %f1073;
	sub.f32 	%f1075, %f1070, %f1074;
	add.f32 	%f1076, %f1073, %f1075;
	mul.rn.f32 	%f1078, %f1049, %f3094;
	mul.rn.f32 	%f1080, %f1049, %f3095;
	add.f32 	%f1081, %f1078, %f1074;
	sub.f32 	%f1082, %f1078, %f1081;
	add.f32 	%f1083, %f1074, %f1082;
	add.f32 	%f1084, %f1076, %f1083;
	add.f32 	%f1085, %f1080, %f1084;
	add.f32 	%f1086, %f1081, %f1085;
	sub.f32 	%f1087, %f1081, %f1086;
	add.f32 	%f1088, %f1085, %f1087;
	mul.rn.f32 	%f1089, %f600, %f1086;
	neg.f32 	%f1090, %f1089;
	fma.rn.f32 	%f1091, %f600, %f1086, %f1090;
	fma.rn.f32 	%f1092, %f600, %f1088, %f1091;
	fma.rn.f32 	%f1094, %f3263, %f1086, %f1092;
	add.rn.f32 	%f1095, %f1089, %f1094;
	neg.f32 	%f1096, %f1095;
	add.rn.f32 	%f1097, %f1089, %f1096;
	add.rn.f32 	%f1098, %f1097, %f1094;
	mov.b32 	%r493, %f1095;
	setp.eq.s32 	%p364, %r493, 1118925336;
	add.s32 	%r494, %r493, -1;
	mov.b32 	%f1099, %r494;
	add.f32 	%f1100, %f1098, 0f37000000;
	selp.f32 	%f171, %f1100, %f1098, %p364;
	selp.f32 	%f1101, %f1099, %f1095, %p364;
	mul.rn.f32 	%f1102, %f1101, %f800;
	cvt.rzi.f32.f32 	%f1103, %f1102;
	abs.f32 	%f1104, %f1103;
	setp.gt.f32 	%p365, %f1104, 0f42FC0000;
	mov.b32 	%r495, %f1103;
	and.b32  	%r496, %r495, -2147483648;
	or.b32  	%r497, %r496, 1123811328;
	mov.b32 	%f1105, %r497;
	selp.f32 	%f1106, %f1105, %f1103, %p365;
	fma.rn.f32 	%f1108, %f1106, %f3096, %f1101;
	fma.rn.f32 	%f1110, %f1106, %f3097, %f1108;
	mul.f32 	%f1111, %f1110, 0f3FB8AA3B;
	add.f32 	%f1112, %f1106, 0f4B40007F;
	mov.b32 	%r498, %f1112;
	shl.b32 	%r499, %r498, 23;
	mov.b32 	%f1113, %r499;
	ex2.approx.ftz.f32 	%f1114, %f1111;
	mul.f32 	%f172, %f1114, %f1113;
	setp.eq.f32 	%p366, %f172, 0f7F800000;
	mov.f32 	%f3241, 0f7F800000;
	@%p366 bra 	$L__BB2_187;

	fma.rn.f32 	%f3241, %f172, %f171, %f172;

$L__BB2_187:
	setp.lt.f32 	%p367, %f169, 0f00000000;
	and.pred  	%p34, %p367, %p301;
	setp.eq.f32 	%p369, %f169, 0f00000000;
	@%p369 bra 	$L__BB2_191;
	bra.uni 	$L__BB2_188;

$L__BB2_191:
	add.f32 	%f1119, %f169, %f169;
	selp.f32 	%f3243, %f1119, 0f00000000, %p301;
	bra.uni 	$L__BB2_192;

$L__BB2_188:
	mov.b32 	%r500, %f3241;
	xor.b32  	%r501, %r500, -2147483648;
	mov.b32 	%f1115, %r501;
	selp.f32 	%f3243, %f1115, %f3241, %p34;
	setp.geu.f32 	%p370, %f169, 0f00000000;
	@%p370 bra 	$L__BB2_192;

	cvt.rzi.f32.f32 	%f1117, %f600;
	setp.eq.f32 	%p371, %f1117, 0f40000000;
	@%p371 bra 	$L__BB2_192;

	mov.f32 	%f3243, 0f7FFFFFFF;

$L__BB2_192:
	abs.f32 	%f3143, %f169;
	add.f32 	%f1120, %f3143, 0f40000000;
	mov.b32 	%r502, %f1120;
	setp.lt.s32 	%p373, %r502, 2139095040;
	@%p373 bra 	$L__BB2_197;

	abs.f32 	%f3144, %f169;
	setp.gtu.f32 	%p374, %f3144, 0f7F800000;
	@%p374 bra 	$L__BB2_196;
	bra.uni 	$L__BB2_194;

$L__BB2_196:
	add.f32 	%f3243, %f169, 0f40000000;
	bra.uni 	$L__BB2_197;

$L__BB2_194:
	abs.f32 	%f3145, %f169;
	setp.neu.f32 	%p375, %f3145, 0f7F800000;
	@%p375 bra 	$L__BB2_197;

	selp.f32 	%f3243, 0fFF800000, 0f7F800000, %p34;

$L__BB2_197:
	mov.f32 	%f3106, 0f32A57060;
	mov.f32 	%f3105, 0f4B400001;
	mov.f32 	%f3104, 0f437C0000;
	mov.f32 	%f3103, 0f3BBB989D;
	mov.f32 	%f3102, 0f3F000000;
	mul.f32 	%f1121, %f3243, 0fBF000000;
	setp.eq.f32 	%p376, %f169, 0f3F800000;
	selp.f32 	%f1122, 0fBF000000, %f1121, %p376;
	fma.rn.f32 	%f1125, %f1122, %f3103, %f3102;
	cvt.sat.f32.f32 	%f1128, %f1125;
	fma.rm.f32 	%f1130, %f1128, %f3104, %f3105;
	add.f32 	%f1131, %f1130, 0fCB40007F;
	neg.f32 	%f1132, %f1131;
	fma.rn.f32 	%f1133, %f1122, %f800, %f1132;
	fma.rn.f32 	%f1135, %f1122, %f3106, %f1133;
	mov.b32 	%r503, %f1130;
	shl.b32 	%r504, %r503, 23;
	mov.b32 	%f1136, %r504;
	ex2.approx.ftz.f32 	%f1137, %f1135;
	mul.f32 	%f181, %f1137, %f1136;
	sub.f32 	%f1138, %f168, %f181;
	div.rn.f32 	%f182, %f69, %f101;
	mul.f32 	%f1139, %f182, %f1138;
	mul.f32 	%f183, %f111, %f1139;
	cvt.f64.f32 	%fd130, %f101;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r105}, %fd130;
	}
	abs.f64 	%fd131, %fd130;
	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd131;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1102, [retval0+0];
	} // callseq 41
	setp.lt.s32 	%p377, %r105, 0;
	and.pred  	%p35, %p377, %p149;
	not.pred 	%p379, %p35;
	@%p379 bra 	$L__BB2_199;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r505}, %fd1102;
	}
	xor.b32  	%r506, %r505, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r507, %temp}, %fd1102;
	}
	mov.b64 	%fd1102, {%r507, %r506};

$L__BB2_199:
	setp.eq.f32 	%p380, %f101, 0f00000000;
	@%p380 bra 	$L__BB2_203;
	bra.uni 	$L__BB2_200;

$L__BB2_203:
	mov.u32 	%r508, 0;
	selp.b32 	%r509, %r105, 0, %p149;
	or.b32  	%r510, %r509, 2146435072;
	selp.b32 	%r511, %r510, %r509, %p152;
	mov.b64 	%fd1102, {%r508, %r511};
	bra.uni 	$L__BB2_204;

$L__BB2_200:
	setp.gt.s32 	%p381, %r105, -1;
	@%p381 bra 	$L__BB2_204;

	cvt.rzi.f64.f64 	%fd722, %fd647;
	setp.eq.f64 	%p382, %fd722, 0d4008000000000000;
	@%p382 bra 	$L__BB2_204;

	mov.f64 	%fd1102, 0dFFF8000000000000;

$L__BB2_204:
	add.f64 	%fd137, %fd130, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r512}, %fd137;
	}
	and.b32  	%r513, %r512, 2146435072;
	setp.ne.s32 	%p385, %r513, 2146435072;
	mov.f64 	%fd1103, %fd1102;
	@%p385 bra 	$L__BB2_210;

	setp.gtu.f64 	%p386, %fd131, 0d7FF0000000000000;
	mov.f64 	%fd1103, %fd137;
	@%p386 bra 	$L__BB2_210;

	setp.eq.s32 	%p387, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r514, %temp}, %fd647;
	}
	setp.eq.s32 	%p388, %r514, 0;
	and.pred  	%p389, %p387, %p388;
	@%p389 bra 	$L__BB2_209;
	bra.uni 	$L__BB2_207;

$L__BB2_209:
	mov.u32 	%r519, 0;
	setp.gt.f64 	%p396, %fd131, 0d3FF0000000000000;
	selp.b32 	%r520, 2146435072, 0, %p396;
	xor.b32  	%r521, %r520, 2146435072;
	selp.b32 	%r522, %r521, %r520, %p152;
	setp.eq.f32 	%p397, %f101, 0fBF800000;
	selp.b32 	%r523, 1072693248, %r522, %p397;
	mov.b64 	%fd1103, {%r519, %r523};
	bra.uni 	$L__BB2_210;

$L__BB2_207:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r515, %temp}, %fd130;
	}
	and.b32  	%r516, %r105, 2147483647;
	setp.ne.s32 	%p390, %r516, 2146435072;
	setp.ne.s32 	%p391, %r515, 0;
	or.pred  	%p392, %p390, %p391;
	mov.f64 	%fd1103, %fd1102;
	@%p392 bra 	$L__BB2_210;

	setp.ne.s32 	%p393, %r58, 1071644672;
	and.pred  	%p394, %p393, %p35;
	selp.b32 	%r517, %r63, %r62, %p394;
	mov.u32 	%r518, 0;
	mov.b64 	%fd1103, {%r518, %r517};

$L__BB2_210:
	cvt.rn.f32.s32 	%f3140, %r1371;
	add.f32 	%f3139, %f3140, 0f3F000000;
	sub.f32 	%f3138, %f3139, %f3277;
	cvt.f64.f32 	%fd1071, %f69;
	cvt.rn.f32.s32 	%f3114, %r1370;
	mov.f32 	%f3113, 0f3102E308;
	mov.f32 	%f3112, 0fBF317218;
	mov.f32 	%f3111, 0f35BFBE8E;
	mov.f32 	%f3110, 0f3F317200;
	mov.f32 	%f3109, 0f3DAAAABD;
	mov.f32 	%f3108, 0f3C4CAF63;
	mov.f32 	%f3107, 0f3B18F0FE;
	setp.eq.f32 	%p398, %f101, 0f3F800000;
	selp.f64 	%fd725, 0d3FF0000000000000, %fd1103, %p398;
	div.rn.f64 	%fd727, %fd1071, %fd725;
	mul.f32 	%f1141, %f120, %f181;
	mul.f32 	%f1142, %f3138, %f168;
	sub.f32 	%f1143, %f1142, %f1141;
	cvt.f64.f32 	%fd728, %f1143;
	mul.f64 	%fd729, %fd727, %fd728;
	cvt.f64.f32 	%fd730, %f111;
	mul.f64 	%fd731, %fd729, %fd730;
	cvt.rn.f32.f64 	%f184, %fd731;
	add.f32 	%f1144, %f3114, 0f3F800000;
	sub.f32 	%f1145, %f1144, %f3278;
	div.rn.f32 	%f185, %f1145, %f99;
	abs.f32 	%f186, %f185;
	setp.lt.f32 	%p399, %f186, 0f00800000;
	mul.f32 	%f1146, %f186, 0f4B800000;
	selp.f32 	%f1147, %f1146, %f186, %p399;
	selp.f32 	%f1148, 0fC3170000, 0fC2FE0000, %p399;
	mov.b32 	%r524, %f1147;
	and.b32  	%r525, %r524, 8388607;
	or.b32  	%r526, %r525, 1065353216;
	mov.b32 	%f1149, %r526;
	shr.u32 	%r527, %r524, 23;
	cvt.rn.f32.u32 	%f1150, %r527;
	add.f32 	%f1151, %f1148, %f1150;
	setp.gt.f32 	%p400, %f1149, 0f3FB504F3;
	mul.f32 	%f1152, %f1149, 0f3F000000;
	add.f32 	%f1153, %f1151, 0f3F800000;
	selp.f32 	%f1154, %f1153, %f1151, %p400;
	selp.f32 	%f1155, %f1152, %f1149, %p400;
	add.f32 	%f1156, %f1155, 0fBF800000;
	add.f32 	%f1157, %f1155, 0f3F800000;
	rcp.approx.ftz.f32 	%f1158, %f1157;
	add.f32 	%f1159, %f1156, %f1156;
	mul.f32 	%f1161, %f1159, %f1158;
	mul.f32 	%f1162, %f1161, %f1161;
	fma.rn.f32 	%f1165, %f3107, %f1162, %f3108;
	fma.rn.f32 	%f1167, %f1165, %f1162, %f3109;
	mul.rn.f32 	%f1168, %f1167, %f1162;
	mul.rn.f32 	%f1169, %f1168, %f1161;
	sub.f32 	%f1170, %f1156, %f1161;
	add.f32 	%f1171, %f1170, %f1170;
	neg.f32 	%f1172, %f1161;
	fma.rn.f32 	%f1173, %f1172, %f1156, %f1171;
	mul.rn.f32 	%f1174, %f1158, %f1173;
	add.f32 	%f1175, %f1169, %f1161;
	sub.f32 	%f1176, %f1161, %f1175;
	add.f32 	%f1177, %f1169, %f1176;
	add.f32 	%f1178, %f1174, %f1177;
	add.f32 	%f1179, %f1175, %f1178;
	sub.f32 	%f1180, %f1175, %f1179;
	add.f32 	%f1181, %f1178, %f1180;
	mul.rn.f32 	%f1183, %f1154, %f3110;
	mul.rn.f32 	%f1185, %f1154, %f3111;
	add.f32 	%f1186, %f1183, %f1179;
	sub.f32 	%f1187, %f1183, %f1186;
	add.f32 	%f1188, %f1179, %f1187;
	add.f32 	%f1189, %f1181, %f1188;
	add.f32 	%f1190, %f1185, %f1189;
	add.f32 	%f1191, %f1186, %f1190;
	sub.f32 	%f1192, %f1186, %f1191;
	add.f32 	%f1193, %f1190, %f1192;
	mul.rn.f32 	%f1194, %f600, %f1191;
	neg.f32 	%f1195, %f1194;
	fma.rn.f32 	%f1196, %f600, %f1191, %f1195;
	fma.rn.f32 	%f1197, %f600, %f1193, %f1196;
	fma.rn.f32 	%f1199, %f3263, %f1191, %f1197;
	add.rn.f32 	%f1200, %f1194, %f1199;
	neg.f32 	%f1201, %f1200;
	add.rn.f32 	%f1202, %f1194, %f1201;
	add.rn.f32 	%f1203, %f1202, %f1199;
	mov.b32 	%r528, %f1200;
	setp.eq.s32 	%p401, %r528, 1118925336;
	add.s32 	%r529, %r528, -1;
	mov.b32 	%f1204, %r529;
	add.f32 	%f1205, %f1203, 0f37000000;
	selp.f32 	%f187, %f1205, %f1203, %p401;
	selp.f32 	%f1206, %f1204, %f1200, %p401;
	mul.rn.f32 	%f1208, %f1206, %f800;
	cvt.rzi.f32.f32 	%f1209, %f1208;
	abs.f32 	%f1210, %f1209;
	setp.gt.f32 	%p402, %f1210, 0f42FC0000;
	mov.b32 	%r530, %f1209;
	and.b32  	%r531, %r530, -2147483648;
	or.b32  	%r532, %r531, 1123811328;
	mov.b32 	%f1211, %r532;
	selp.f32 	%f1212, %f1211, %f1209, %p402;
	fma.rn.f32 	%f1214, %f1212, %f3112, %f1206;
	fma.rn.f32 	%f1216, %f1212, %f3113, %f1214;
	mul.f32 	%f1217, %f1216, 0f3FB8AA3B;
	add.f32 	%f1218, %f1212, 0f4B40007F;
	mov.b32 	%r533, %f1218;
	shl.b32 	%r534, %r533, 23;
	mov.b32 	%f1219, %r534;
	ex2.approx.ftz.f32 	%f1220, %f1217;
	mul.f32 	%f188, %f1220, %f1219;
	setp.eq.f32 	%p403, %f188, 0f7F800000;
	mov.f32 	%f3244, 0f7F800000;
	@%p403 bra 	$L__BB2_212;

	fma.rn.f32 	%f3244, %f188, %f187, %f188;

$L__BB2_212:
	setp.lt.f32 	%p404, %f185, 0f00000000;
	and.pred  	%p36, %p404, %p301;
	setp.eq.f32 	%p406, %f185, 0f00000000;
	@%p406 bra 	$L__BB2_216;
	bra.uni 	$L__BB2_213;

$L__BB2_216:
	add.f32 	%f1225, %f185, %f185;
	selp.f32 	%f3246, %f1225, 0f00000000, %p301;
	bra.uni 	$L__BB2_217;

$L__BB2_213:
	mov.b32 	%r535, %f3244;
	xor.b32  	%r536, %r535, -2147483648;
	mov.b32 	%f1221, %r536;
	selp.f32 	%f3246, %f1221, %f3244, %p36;
	setp.geu.f32 	%p407, %f185, 0f00000000;
	@%p407 bra 	$L__BB2_217;

	cvt.rzi.f32.f32 	%f1223, %f600;
	setp.eq.f32 	%p408, %f1223, 0f40000000;
	@%p408 bra 	$L__BB2_217;

	mov.f32 	%f3246, 0f7FFFFFFF;

$L__BB2_217:
	abs.f32 	%f3146, %f185;
	add.f32 	%f1226, %f3146, 0f40000000;
	mov.b32 	%r537, %f1226;
	setp.lt.s32 	%p410, %r537, 2139095040;
	@%p410 bra 	$L__BB2_222;

	abs.f32 	%f3147, %f185;
	setp.gtu.f32 	%p411, %f3147, 0f7F800000;
	@%p411 bra 	$L__BB2_221;
	bra.uni 	$L__BB2_219;

$L__BB2_221:
	add.f32 	%f3246, %f185, 0f40000000;
	bra.uni 	$L__BB2_222;

$L__BB2_219:
	abs.f32 	%f3148, %f185;
	setp.neu.f32 	%p412, %f3148, 0f7F800000;
	@%p412 bra 	$L__BB2_222;

	selp.f32 	%f3246, 0fFF800000, 0f7F800000, %p36;

$L__BB2_222:
	cvt.rn.f32.s32 	%f3128, %r1370;
	sub.f32 	%f3127, %f3128, %f3278;
	mov.f32 	%f3126, 0f32A57060;
	mov.f32 	%f3125, 0f4B400001;
	mov.f32 	%f3124, 0f437C0000;
	mov.f32 	%f3123, 0f3BBB989D;
	mov.f32 	%f3122, 0f3102E308;
	mov.f32 	%f3121, 0fBF317218;
	mov.f32 	%f3120, 0f35BFBE8E;
	mov.f32 	%f3119, 0f3F317200;
	mov.f32 	%f3118, 0f3DAAAABD;
	mov.f32 	%f3117, 0f3C4CAF63;
	mov.f32 	%f3116, 0f3B18F0FE;
	mov.f32 	%f3115, 0f3F000000;
	mul.f32 	%f1228, %f3246, 0fBF000000;
	setp.eq.f32 	%p413, %f185, 0f3F800000;
	selp.f32 	%f1229, 0fBF000000, %f1228, %p413;
	fma.rn.f32 	%f1232, %f1229, %f3123, %f3115;
	cvt.sat.f32.f32 	%f1235, %f1232;
	fma.rm.f32 	%f1237, %f1235, %f3124, %f3125;
	add.f32 	%f1238, %f1237, 0fCB40007F;
	neg.f32 	%f1239, %f1238;
	fma.rn.f32 	%f1240, %f1229, %f800, %f1239;
	fma.rn.f32 	%f1242, %f1229, %f3126, %f1240;
	mov.b32 	%r538, %f1237;
	shl.b32 	%r539, %r538, 23;
	mov.b32 	%f1243, %r539;
	ex2.approx.ftz.f32 	%f1244, %f1242;
	mul.f32 	%f197, %f1244, %f1243;
	div.rn.f32 	%f198, %f3127, %f99;
	abs.f32 	%f199, %f198;
	setp.lt.f32 	%p414, %f199, 0f00800000;
	mul.f32 	%f1246, %f199, 0f4B800000;
	selp.f32 	%f1247, %f1246, %f199, %p414;
	selp.f32 	%f1248, 0fC3170000, 0fC2FE0000, %p414;
	mov.b32 	%r540, %f1247;
	and.b32  	%r541, %r540, 8388607;
	or.b32  	%r542, %r541, 1065353216;
	mov.b32 	%f1249, %r542;
	shr.u32 	%r543, %r540, 23;
	cvt.rn.f32.u32 	%f1250, %r543;
	add.f32 	%f1251, %f1248, %f1250;
	setp.gt.f32 	%p415, %f1249, 0f3FB504F3;
	mul.f32 	%f1252, %f1249, 0f3F000000;
	add.f32 	%f1253, %f1251, 0f3F800000;
	selp.f32 	%f1254, %f1253, %f1251, %p415;
	selp.f32 	%f1255, %f1252, %f1249, %p415;
	add.f32 	%f1256, %f1255, 0fBF800000;
	add.f32 	%f1257, %f1255, 0f3F800000;
	rcp.approx.ftz.f32 	%f1258, %f1257;
	add.f32 	%f1259, %f1256, %f1256;
	mul.f32 	%f1261, %f1259, %f1258;
	mul.f32 	%f1262, %f1261, %f1261;
	fma.rn.f32 	%f1265, %f3116, %f1262, %f3117;
	fma.rn.f32 	%f1267, %f1265, %f1262, %f3118;
	mul.rn.f32 	%f1268, %f1267, %f1262;
	mul.rn.f32 	%f1269, %f1268, %f1261;
	sub.f32 	%f1270, %f1256, %f1261;
	add.f32 	%f1271, %f1270, %f1270;
	neg.f32 	%f1272, %f1261;
	fma.rn.f32 	%f1273, %f1272, %f1256, %f1271;
	mul.rn.f32 	%f1274, %f1258, %f1273;
	add.f32 	%f1275, %f1269, %f1261;
	sub.f32 	%f1276, %f1261, %f1275;
	add.f32 	%f1277, %f1269, %f1276;
	add.f32 	%f1278, %f1274, %f1277;
	add.f32 	%f1279, %f1275, %f1278;
	sub.f32 	%f1280, %f1275, %f1279;
	add.f32 	%f1281, %f1278, %f1280;
	mul.rn.f32 	%f1283, %f1254, %f3119;
	mul.rn.f32 	%f1285, %f1254, %f3120;
	add.f32 	%f1286, %f1283, %f1279;
	sub.f32 	%f1287, %f1283, %f1286;
	add.f32 	%f1288, %f1279, %f1287;
	add.f32 	%f1289, %f1281, %f1288;
	add.f32 	%f1290, %f1285, %f1289;
	add.f32 	%f1291, %f1286, %f1290;
	sub.f32 	%f1292, %f1286, %f1291;
	add.f32 	%f1293, %f1290, %f1292;
	mul.rn.f32 	%f1294, %f600, %f1291;
	neg.f32 	%f1295, %f1294;
	fma.rn.f32 	%f1296, %f600, %f1291, %f1295;
	fma.rn.f32 	%f1297, %f600, %f1293, %f1296;
	fma.rn.f32 	%f1299, %f3263, %f1291, %f1297;
	add.rn.f32 	%f1300, %f1294, %f1299;
	neg.f32 	%f1301, %f1300;
	add.rn.f32 	%f1302, %f1294, %f1301;
	add.rn.f32 	%f1303, %f1302, %f1299;
	mov.b32 	%r544, %f1300;
	setp.eq.s32 	%p416, %r544, 1118925336;
	add.s32 	%r545, %r544, -1;
	mov.b32 	%f1304, %r545;
	add.f32 	%f1305, %f1303, 0f37000000;
	selp.f32 	%f200, %f1305, %f1303, %p416;
	selp.f32 	%f1306, %f1304, %f1300, %p416;
	mul.rn.f32 	%f1307, %f1306, %f800;
	cvt.rzi.f32.f32 	%f1308, %f1307;
	abs.f32 	%f1309, %f1308;
	setp.gt.f32 	%p417, %f1309, 0f42FC0000;
	mov.b32 	%r546, %f1308;
	and.b32  	%r547, %r546, -2147483648;
	or.b32  	%r548, %r547, 1123811328;
	mov.b32 	%f1310, %r548;
	selp.f32 	%f1311, %f1310, %f1308, %p417;
	fma.rn.f32 	%f1313, %f1311, %f3121, %f1306;
	fma.rn.f32 	%f1315, %f1311, %f3122, %f1313;
	mul.f32 	%f1316, %f1315, 0f3FB8AA3B;
	add.f32 	%f1317, %f1311, 0f4B40007F;
	mov.b32 	%r549, %f1317;
	shl.b32 	%r550, %r549, 23;
	mov.b32 	%f1318, %r550;
	ex2.approx.ftz.f32 	%f1319, %f1316;
	mul.f32 	%f201, %f1319, %f1318;
	setp.eq.f32 	%p418, %f201, 0f7F800000;
	mov.f32 	%f3247, 0f7F800000;
	@%p418 bra 	$L__BB2_224;

	fma.rn.f32 	%f3247, %f201, %f200, %f201;

$L__BB2_224:
	setp.lt.f32 	%p419, %f198, 0f00000000;
	and.pred  	%p37, %p419, %p301;
	setp.eq.f32 	%p421, %f198, 0f00000000;
	@%p421 bra 	$L__BB2_228;
	bra.uni 	$L__BB2_225;

$L__BB2_228:
	add.f32 	%f1324, %f198, %f198;
	selp.f32 	%f3249, %f1324, 0f00000000, %p301;
	bra.uni 	$L__BB2_229;

$L__BB2_225:
	mov.b32 	%r551, %f3247;
	xor.b32  	%r552, %r551, -2147483648;
	mov.b32 	%f1320, %r552;
	selp.f32 	%f3249, %f1320, %f3247, %p37;
	setp.geu.f32 	%p422, %f198, 0f00000000;
	@%p422 bra 	$L__BB2_229;

	cvt.rzi.f32.f32 	%f1322, %f600;
	setp.eq.f32 	%p423, %f1322, 0f40000000;
	@%p423 bra 	$L__BB2_229;

	mov.f32 	%f3249, 0f7FFFFFFF;

$L__BB2_229:
	abs.f32 	%f2984, %f198;
	add.f32 	%f1325, %f2984, 0f40000000;
	mov.b32 	%r553, %f1325;
	setp.lt.s32 	%p425, %r553, 2139095040;
	@%p425 bra 	$L__BB2_234;

	abs.f32 	%f3135, %f198;
	setp.gtu.f32 	%p426, %f3135, 0f7F800000;
	@%p426 bra 	$L__BB2_233;
	bra.uni 	$L__BB2_231;

$L__BB2_233:
	add.f32 	%f3249, %f198, 0f40000000;
	bra.uni 	$L__BB2_234;

$L__BB2_231:
	abs.f32 	%f3136, %f198;
	setp.neu.f32 	%p427, %f3136, 0f7F800000;
	@%p427 bra 	$L__BB2_234;

	selp.f32 	%f3249, 0fFF800000, 0f7F800000, %p37;

$L__BB2_234:
	cvt.f64.f32 	%fd1046, %f99;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1345}, %fd1046;
	}
	setp.lt.s32 	%p1283, %r1345, 0;
	mov.f64 	%fd1045, 0d4014000000000000;
	cvt.rn.f32.s32 	%f2991, %r1370;
	sub.f32 	%f2990, %f2991, %f3278;
	mov.f32 	%f2989, 0f32A57060;
	mov.f32 	%f2988, 0f4B400001;
	mov.f32 	%f2987, 0f437C0000;
	mov.f32 	%f2986, 0f3BBB989D;
	mov.f32 	%f2985, 0f3F000000;
	and.b32  	%r554, %r78, 2146435072;
	setp.eq.s32 	%p428, %r554, 1074790400;
	mul.f32 	%f1326, %f3249, 0fBF000000;
	setp.eq.f32 	%p429, %f198, 0f3F800000;
	selp.f32 	%f1327, 0fBF000000, %f1326, %p429;
	fma.rn.f32 	%f1330, %f1327, %f2986, %f2985;
	cvt.sat.f32.f32 	%f1333, %f1330;
	fma.rm.f32 	%f1335, %f1333, %f2987, %f2988;
	add.f32 	%f1336, %f1335, 0fCB40007F;
	neg.f32 	%f1337, %f1336;
	fma.rn.f32 	%f1338, %f1327, %f800, %f1337;
	fma.rn.f32 	%f1340, %f1327, %f2989, %f1338;
	mov.b32 	%r555, %f1335;
	shl.b32 	%r556, %r555, 23;
	mov.b32 	%f1341, %r556;
	ex2.approx.ftz.f32 	%f1342, %f1340;
	mul.f32 	%f210, %f1342, %f1341;
	add.f32 	%f1344, %f2990, 0f3F800000;
	mul.f32 	%f1345, %f1344, %f197;
	mul.f32 	%f1346, %f2990, %f210;
	sub.f32 	%f1347, %f1345, %f1346;
	div.rn.f32 	%f1348, %f152, %f99;
	mul.f32 	%f1349, %f1348, %f1347;
	mul.f32 	%f211, %f125, %f1349;
	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd120;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd1045;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1105, [retval0+0];
	} // callseq 42
	and.pred  	%p38, %p1283, %p428;
	not.pred 	%p431, %p38;
	@%p431 bra 	$L__BB2_236;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r557}, %fd1105;
	}
	xor.b32  	%r558, %r557, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r559, %temp}, %fd1105;
	}
	mov.b64 	%fd1105, {%r559, %r558};

$L__BB2_236:
	setp.eq.f32 	%p1284, %f99, 0f00000000;
	@%p1284 bra 	$L__BB2_240;
	bra.uni 	$L__BB2_237;

$L__BB2_240:
	setp.lt.s32 	%p435, %r78, 0;
	mov.u32 	%r560, 0;
	selp.b32 	%r562, %r104, 0, %p428;
	or.b32  	%r563, %r562, 2146435072;
	selp.b32 	%r564, %r563, %r562, %p435;
	mov.b64 	%fd1105, {%r560, %r564};
	bra.uni 	$L__BB2_241;

$L__BB2_237:
	setp.gt.s32 	%p433, %r104, -1;
	@%p433 bra 	$L__BB2_241;

	mov.f64 	%fd1070, 0d4014000000000000;
	cvt.rzi.f64.f64 	%fd734, %fd1070;
	setp.eq.f64 	%p434, %fd734, 0d4014000000000000;
	@%p434 bra 	$L__BB2_241;

	mov.f64 	%fd1105, 0dFFF8000000000000;

$L__BB2_241:
	add.f64 	%fd146, %fd119, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r565}, %fd146;
	}
	and.b32  	%r566, %r565, 2146435072;
	setp.ne.s32 	%p437, %r566, 2146435072;
	mov.f64 	%fd1106, %fd1105;
	@%p437 bra 	$L__BB2_247;

	setp.gtu.f64 	%p438, %fd120, 0d7FF0000000000000;
	mov.f64 	%fd1106, %fd146;
	@%p438 bra 	$L__BB2_247;

	mov.f64 	%fd1069, 0d4014000000000000;
	and.b32  	%r567, %r78, 2147483647;
	setp.eq.s32 	%p439, %r567, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r568, %temp}, %fd1069;
	}
	setp.eq.s32 	%p440, %r568, 0;
	and.pred  	%p441, %p439, %p440;
	@%p441 bra 	$L__BB2_246;
	bra.uni 	$L__BB2_244;

$L__BB2_246:
	setp.lt.s32 	%p448, %r78, 0;
	mov.u32 	%r576, 0;
	setp.gt.f64 	%p449, %fd120, 0d3FF0000000000000;
	selp.b32 	%r577, 2146435072, 0, %p449;
	xor.b32  	%r578, %r577, 2146435072;
	selp.b32 	%r579, %r578, %r577, %p448;
	setp.eq.f32 	%p450, %f99, 0fBF800000;
	selp.b32 	%r580, 1072693248, %r579, %p450;
	mov.b64 	%fd1106, {%r576, %r580};
	bra.uni 	$L__BB2_247;

$L__BB2_244:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r569, %temp}, %fd119;
	}
	and.b32  	%r570, %r104, 2147483647;
	setp.ne.s32 	%p442, %r570, 2146435072;
	setp.ne.s32 	%p443, %r569, 0;
	or.pred  	%p444, %p442, %p443;
	mov.f64 	%fd1106, %fd1105;
	@%p444 bra 	$L__BB2_247;

	setp.ne.s32 	%p445, %r567, 1071644672;
	and.pred  	%p446, %p445, %p38;
	setp.gt.s32 	%p447, %r78, -1;
	selp.b32 	%r572, 2146435072, 0, %p447;
	mov.u32 	%r573, 0;
	or.b32  	%r574, %r572, -2147483648;
	selp.b32 	%r575, %r574, %r572, %p446;
	mov.b64 	%fd1106, {%r573, %r575};

$L__BB2_247:
	not.pred 	%p451, %p10;
	mov.f64 	%fd1108, %fd60;
	@%p451 bra 	$L__BB2_249;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r581}, %fd60;
	}
	xor.b32  	%r582, %r581, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r583, %temp}, %fd60;
	}
	mov.b64 	%fd1108, {%r583, %r582};

$L__BB2_249:
	setp.eq.f32 	%p1285, %f99, 0f3F800000;
	setp.eq.f32 	%p452, %f81, 0f00000000;
	selp.f64 	%fd152, 0d3FF0000000000000, %fd1106, %p1285;
	@%p452 bra 	$L__BB2_253;
	bra.uni 	$L__BB2_250;

$L__BB2_253:
	mov.u32 	%r584, 0;
	selp.b32 	%r586, %r76, 0, %p149;
	or.b32  	%r587, %r586, 2146435072;
	selp.b32 	%r588, %r587, %r586, %p152;
	mov.b64 	%fd1108, {%r584, %r588};
	bra.uni 	$L__BB2_254;

$L__BB2_250:
	setp.gt.s32 	%p454, %r76, -1;
	@%p454 bra 	$L__BB2_254;

	cvt.rzi.f64.f64 	%fd738, %fd647;
	setp.eq.f64 	%p455, %fd738, 0d4008000000000000;
	@%p455 bra 	$L__BB2_254;

	mov.f64 	%fd1108, 0dFFF8000000000000;

$L__BB2_254:
	selp.f64 	%fd1109, %fd1108, %fd61, %p172;
	@%p23 bra 	$L__BB2_259;

	setp.eq.s32 	%p459, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r589, %temp}, %fd647;
	}
	setp.eq.s32 	%p460, %r589, 0;
	and.pred  	%p461, %p459, %p460;
	@%p461 bra 	$L__BB2_258;
	bra.uni 	$L__BB2_256;

$L__BB2_258:
	mov.u32 	%r596, 0;
	mov.b64 	%fd1109, {%r596, %r80};
	bra.uni 	$L__BB2_259;

$L__BB2_256:
	cvt.rn.f32.s32 	%f2994, %r1370;
	sub.f32 	%f2993, %f2994, %f3278;
	add.f32 	%f2992, %f2993, 0f3F000000;
	cvt.f64.f32 	%fd1047, %f2992;
	and.b32  	%r590, %r76, 2147483647;
	setp.ne.s32 	%p462, %r590, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r591, %temp}, %fd1047;
	}
	setp.ne.s32 	%p463, %r591, 0;
	or.pred  	%p464, %p462, %p463;
	mov.f64 	%fd1109, %fd1108;
	@%p464 bra 	$L__BB2_259;

	setp.ne.s32 	%p465, %r58, 1071644672;
	and.pred  	%p466, %p465, %p10;
	selp.b32 	%r594, %r63, %r62, %p466;
	mov.u32 	%r595, 0;
	mov.b64 	%fd1109, {%r595, %r594};

$L__BB2_259:
	setp.eq.f32 	%p467, %f81, 0f3F800000;
	selp.f64 	%fd742, 0d3FF0000000000000, %fd1109, %p467;
	cvt.f64.f32 	%fd743, %f197;
	mul.f64 	%fd159, %fd742, %fd743;
	not.pred 	%p468, %p11;
	mov.f64 	%fd1111, %fd62;
	@%p468 bra 	$L__BB2_261;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r597}, %fd62;
	}
	xor.b32  	%r598, %r597, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r599, %temp}, %fd62;
	}
	mov.b64 	%fd1111, {%r599, %r598};

$L__BB2_261:
	setp.eq.f32 	%p469, %f82, 0f00000000;
	@%p469 bra 	$L__BB2_265;
	bra.uni 	$L__BB2_262;

$L__BB2_265:
	mov.u32 	%r600, 0;
	selp.b32 	%r602, %r79, 0, %p149;
	or.b32  	%r603, %r602, 2146435072;
	selp.b32 	%r604, %r603, %r602, %p152;
	mov.b64 	%fd1111, {%r600, %r604};
	bra.uni 	$L__BB2_266;

$L__BB2_262:
	setp.gt.s32 	%p470, %r79, -1;
	@%p470 bra 	$L__BB2_266;

	cvt.rzi.f64.f64 	%fd745, %fd647;
	setp.eq.f64 	%p471, %fd745, 0d4008000000000000;
	@%p471 bra 	$L__BB2_266;

	mov.f64 	%fd1111, 0dFFF8000000000000;

$L__BB2_266:
	selp.f64 	%fd1112, %fd1111, %fd63, %p177;
	@%p24 bra 	$L__BB2_271;

	setp.eq.s32 	%p475, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r605, %temp}, %fd647;
	}
	setp.eq.s32 	%p476, %r605, 0;
	and.pred  	%p477, %p475, %p476;
	@%p477 bra 	$L__BB2_270;
	bra.uni 	$L__BB2_268;

$L__BB2_270:
	mov.u32 	%r612, 0;
	mov.b64 	%fd1112, {%r612, %r82};
	bra.uni 	$L__BB2_271;

$L__BB2_268:
	cvt.rn.f32.s32 	%f2997, %r1370;
	sub.f32 	%f2996, %f2997, %f3278;
	add.f32 	%f2995, %f2996, 0fBF000000;
	cvt.f64.f32 	%fd1048, %f2995;
	and.b32  	%r606, %r79, 2147483647;
	setp.ne.s32 	%p478, %r606, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r607, %temp}, %fd1048;
	}
	setp.ne.s32 	%p479, %r607, 0;
	or.pred  	%p480, %p478, %p479;
	mov.f64 	%fd1112, %fd1111;
	@%p480 bra 	$L__BB2_271;

	setp.ne.s32 	%p481, %r58, 1071644672;
	and.pred  	%p482, %p481, %p11;
	selp.b32 	%r610, %r63, %r62, %p482;
	mov.u32 	%r611, 0;
	mov.b64 	%fd1112, {%r611, %r610};

$L__BB2_271:
	cvt.f64.f32 	%fd1049, %f125;
	cvt.rn.f32.s32 	%f3005, %r1371;
	mov.f32 	%f3004, 0f3102E308;
	mov.f32 	%f3003, 0fBF317218;
	mov.f32 	%f3002, 0f35BFBE8E;
	mov.f32 	%f3001, 0f3F317200;
	mov.f32 	%f3000, 0f3DAAAABD;
	mov.f32 	%f2999, 0f3C4CAF63;
	mov.f32 	%f2998, 0f3B18F0FE;
	setp.eq.f32 	%p483, %f82, 0f3F800000;
	selp.f64 	%fd749, 0d3FF0000000000000, %fd1112, %p483;
	cvt.f64.f32 	%fd750, %f210;
	mul.f64 	%fd751, %fd749, %fd750;
	sub.f64 	%fd752, %fd159, %fd751;
	div.rn.f64 	%fd753, %fd43, %fd152;
	mul.f64 	%fd754, %fd753, %fd752;
	mul.f64 	%fd756, %fd754, %fd1049;
	mov.f32 	%f1355, 0fC0000000;
	div.rn.f32 	%f1356, %f1355, %f99;
	mul.f32 	%f1357, %f1356, %f211;
	cvt.f64.f32 	%fd757, %f1357;
	sub.f64 	%fd758, %fd757, %fd756;
	cvt.rn.f32.f64 	%f212, %fd758;
	add.f32 	%f1358, %f3005, 0f3F800000;
	sub.f32 	%f1359, %f1358, %f3277;
	div.rn.f32 	%f213, %f1359, %f101;
	abs.f32 	%f214, %f213;
	setp.lt.f32 	%p484, %f214, 0f00800000;
	mul.f32 	%f1360, %f214, 0f4B800000;
	selp.f32 	%f1361, %f1360, %f214, %p484;
	selp.f32 	%f1362, 0fC3170000, 0fC2FE0000, %p484;
	mov.b32 	%r613, %f1361;
	and.b32  	%r614, %r613, 8388607;
	or.b32  	%r615, %r614, 1065353216;
	mov.b32 	%f1363, %r615;
	shr.u32 	%r616, %r613, 23;
	cvt.rn.f32.u32 	%f1364, %r616;
	add.f32 	%f1365, %f1362, %f1364;
	setp.gt.f32 	%p485, %f1363, 0f3FB504F3;
	mul.f32 	%f1366, %f1363, 0f3F000000;
	add.f32 	%f1367, %f1365, 0f3F800000;
	selp.f32 	%f1368, %f1367, %f1365, %p485;
	selp.f32 	%f1369, %f1366, %f1363, %p485;
	add.f32 	%f1370, %f1369, 0fBF800000;
	add.f32 	%f1371, %f1369, 0f3F800000;
	rcp.approx.ftz.f32 	%f1372, %f1371;
	add.f32 	%f1373, %f1370, %f1370;
	mul.f32 	%f1375, %f1373, %f1372;
	mul.f32 	%f1376, %f1375, %f1375;
	fma.rn.f32 	%f1379, %f2998, %f1376, %f2999;
	fma.rn.f32 	%f1381, %f1379, %f1376, %f3000;
	mul.rn.f32 	%f1382, %f1381, %f1376;
	mul.rn.f32 	%f1383, %f1382, %f1375;
	sub.f32 	%f1384, %f1370, %f1375;
	add.f32 	%f1385, %f1384, %f1384;
	neg.f32 	%f1386, %f1375;
	fma.rn.f32 	%f1387, %f1386, %f1370, %f1385;
	mul.rn.f32 	%f1388, %f1372, %f1387;
	add.f32 	%f1389, %f1383, %f1375;
	sub.f32 	%f1390, %f1375, %f1389;
	add.f32 	%f1391, %f1383, %f1390;
	add.f32 	%f1392, %f1388, %f1391;
	add.f32 	%f1393, %f1389, %f1392;
	sub.f32 	%f1394, %f1389, %f1393;
	add.f32 	%f1395, %f1392, %f1394;
	mul.rn.f32 	%f1397, %f1368, %f3001;
	mul.rn.f32 	%f1399, %f1368, %f3002;
	add.f32 	%f1400, %f1397, %f1393;
	sub.f32 	%f1401, %f1397, %f1400;
	add.f32 	%f1402, %f1393, %f1401;
	add.f32 	%f1403, %f1395, %f1402;
	add.f32 	%f1404, %f1399, %f1403;
	add.f32 	%f1405, %f1400, %f1404;
	sub.f32 	%f1406, %f1400, %f1405;
	add.f32 	%f1407, %f1404, %f1406;
	mul.rn.f32 	%f1408, %f600, %f1405;
	neg.f32 	%f1409, %f1408;
	fma.rn.f32 	%f1410, %f600, %f1405, %f1409;
	fma.rn.f32 	%f1411, %f600, %f1407, %f1410;
	fma.rn.f32 	%f1413, %f3263, %f1405, %f1411;
	add.rn.f32 	%f1414, %f1408, %f1413;
	neg.f32 	%f1415, %f1414;
	add.rn.f32 	%f1416, %f1408, %f1415;
	add.rn.f32 	%f1417, %f1416, %f1413;
	mov.b32 	%r617, %f1414;
	setp.eq.s32 	%p486, %r617, 1118925336;
	add.s32 	%r618, %r617, -1;
	mov.b32 	%f1418, %r618;
	add.f32 	%f1419, %f1417, 0f37000000;
	selp.f32 	%f215, %f1419, %f1417, %p486;
	selp.f32 	%f1420, %f1418, %f1414, %p486;
	mul.rn.f32 	%f1422, %f1420, %f800;
	cvt.rzi.f32.f32 	%f1423, %f1422;
	abs.f32 	%f1424, %f1423;
	setp.gt.f32 	%p487, %f1424, 0f42FC0000;
	mov.b32 	%r619, %f1423;
	and.b32  	%r620, %r619, -2147483648;
	or.b32  	%r621, %r620, 1123811328;
	mov.b32 	%f1425, %r621;
	selp.f32 	%f1426, %f1425, %f1423, %p487;
	fma.rn.f32 	%f1428, %f1426, %f3003, %f1420;
	fma.rn.f32 	%f1430, %f1426, %f3004, %f1428;
	mul.f32 	%f1431, %f1430, 0f3FB8AA3B;
	add.f32 	%f1432, %f1426, 0f4B40007F;
	mov.b32 	%r622, %f1432;
	shl.b32 	%r623, %r622, 23;
	mov.b32 	%f1433, %r623;
	ex2.approx.ftz.f32 	%f1434, %f1431;
	mul.f32 	%f216, %f1434, %f1433;
	setp.eq.f32 	%p488, %f216, 0f7F800000;
	mov.f32 	%f3250, 0f7F800000;
	@%p488 bra 	$L__BB2_273;

	fma.rn.f32 	%f3250, %f216, %f215, %f216;

$L__BB2_273:
	setp.lt.f32 	%p489, %f213, 0f00000000;
	and.pred  	%p39, %p489, %p301;
	setp.eq.f32 	%p491, %f213, 0f00000000;
	@%p491 bra 	$L__BB2_277;
	bra.uni 	$L__BB2_274;

$L__BB2_277:
	add.f32 	%f1439, %f213, %f213;
	selp.f32 	%f3252, %f1439, 0f00000000, %p301;
	bra.uni 	$L__BB2_278;

$L__BB2_274:
	mov.b32 	%r624, %f3250;
	xor.b32  	%r625, %r624, -2147483648;
	mov.b32 	%f1435, %r625;
	selp.f32 	%f3252, %f1435, %f3250, %p39;
	setp.geu.f32 	%p492, %f213, 0f00000000;
	@%p492 bra 	$L__BB2_278;

	cvt.rzi.f32.f32 	%f1437, %f600;
	setp.eq.f32 	%p493, %f1437, 0f40000000;
	@%p493 bra 	$L__BB2_278;

	mov.f32 	%f3252, 0f7FFFFFFF;

$L__BB2_278:
	abs.f32 	%f3149, %f213;
	add.f32 	%f1440, %f3149, 0f40000000;
	mov.b32 	%r626, %f1440;
	setp.lt.s32 	%p495, %r626, 2139095040;
	@%p495 bra 	$L__BB2_283;

	abs.f32 	%f3151, %f213;
	setp.gtu.f32 	%p496, %f3151, 0f7F800000;
	@%p496 bra 	$L__BB2_282;
	bra.uni 	$L__BB2_280;

$L__BB2_282:
	add.f32 	%f3252, %f213, 0f40000000;
	bra.uni 	$L__BB2_283;

$L__BB2_280:
	abs.f32 	%f3152, %f213;
	setp.neu.f32 	%p497, %f3152, 0f7F800000;
	@%p497 bra 	$L__BB2_283;

	selp.f32 	%f3252, 0fFF800000, 0f7F800000, %p39;

$L__BB2_283:
	mov.f32 	%f3019, 0f32A57060;
	mov.f32 	%f3018, 0f4B400001;
	mov.f32 	%f3017, 0f437C0000;
	mov.f32 	%f3016, 0f3BBB989D;
	mov.f32 	%f3015, 0f3102E308;
	mov.f32 	%f3014, 0fBF317218;
	mov.f32 	%f3013, 0f35BFBE8E;
	mov.f32 	%f3012, 0f3F317200;
	mov.f32 	%f3011, 0f3DAAAABD;
	mov.f32 	%f3010, 0f3C4CAF63;
	mov.f32 	%f3009, 0f3B18F0FE;
	cvt.rn.f32.s32 	%f3008, %r1371;
	sub.f32 	%f3007, %f3008, %f3277;
	mov.f32 	%f3006, 0f3F000000;
	mul.f32 	%f1442, %f3252, 0fBF000000;
	setp.eq.f32 	%p498, %f213, 0f3F800000;
	selp.f32 	%f1443, 0fBF000000, %f1442, %p498;
	fma.rn.f32 	%f1446, %f1443, %f3016, %f3006;
	cvt.sat.f32.f32 	%f1449, %f1446;
	fma.rm.f32 	%f1451, %f1449, %f3017, %f3018;
	add.f32 	%f1452, %f1451, 0fCB40007F;
	neg.f32 	%f1453, %f1452;
	fma.rn.f32 	%f1454, %f1443, %f800, %f1453;
	fma.rn.f32 	%f1456, %f1443, %f3019, %f1454;
	mov.b32 	%r627, %f1451;
	shl.b32 	%r628, %r627, 23;
	mov.b32 	%f1457, %r628;
	ex2.approx.ftz.f32 	%f1458, %f1456;
	mul.f32 	%f225, %f1458, %f1457;
	div.rn.f32 	%f226, %f3007, %f101;
	abs.f32 	%f227, %f226;
	setp.lt.f32 	%p499, %f227, 0f00800000;
	mul.f32 	%f1459, %f227, 0f4B800000;
	selp.f32 	%f1460, %f1459, %f227, %p499;
	selp.f32 	%f1461, 0fC3170000, 0fC2FE0000, %p499;
	mov.b32 	%r629, %f1460;
	and.b32  	%r630, %r629, 8388607;
	or.b32  	%r631, %r630, 1065353216;
	mov.b32 	%f1462, %r631;
	shr.u32 	%r632, %r629, 23;
	cvt.rn.f32.u32 	%f1463, %r632;
	add.f32 	%f1464, %f1461, %f1463;
	setp.gt.f32 	%p500, %f1462, 0f3FB504F3;
	mul.f32 	%f1465, %f1462, 0f3F000000;
	add.f32 	%f1466, %f1464, 0f3F800000;
	selp.f32 	%f1467, %f1466, %f1464, %p500;
	selp.f32 	%f1468, %f1465, %f1462, %p500;
	add.f32 	%f1469, %f1468, 0fBF800000;
	add.f32 	%f1470, %f1468, 0f3F800000;
	rcp.approx.ftz.f32 	%f1471, %f1470;
	add.f32 	%f1472, %f1469, %f1469;
	mul.f32 	%f1474, %f1472, %f1471;
	mul.f32 	%f1475, %f1474, %f1474;
	fma.rn.f32 	%f1478, %f3009, %f1475, %f3010;
	fma.rn.f32 	%f1480, %f1478, %f1475, %f3011;
	mul.rn.f32 	%f1481, %f1480, %f1475;
	mul.rn.f32 	%f1482, %f1481, %f1474;
	sub.f32 	%f1483, %f1469, %f1474;
	add.f32 	%f1484, %f1483, %f1483;
	neg.f32 	%f1485, %f1474;
	fma.rn.f32 	%f1486, %f1485, %f1469, %f1484;
	mul.rn.f32 	%f1487, %f1471, %f1486;
	add.f32 	%f1488, %f1482, %f1474;
	sub.f32 	%f1489, %f1474, %f1488;
	add.f32 	%f1490, %f1482, %f1489;
	add.f32 	%f1491, %f1487, %f1490;
	add.f32 	%f1492, %f1488, %f1491;
	sub.f32 	%f1493, %f1488, %f1492;
	add.f32 	%f1494, %f1491, %f1493;
	mul.rn.f32 	%f1496, %f1467, %f3012;
	mul.rn.f32 	%f1498, %f1467, %f3013;
	add.f32 	%f1499, %f1496, %f1492;
	sub.f32 	%f1500, %f1496, %f1499;
	add.f32 	%f1501, %f1492, %f1500;
	add.f32 	%f1502, %f1494, %f1501;
	add.f32 	%f1503, %f1498, %f1502;
	add.f32 	%f1504, %f1499, %f1503;
	sub.f32 	%f1505, %f1499, %f1504;
	add.f32 	%f1506, %f1503, %f1505;
	mul.rn.f32 	%f1507, %f600, %f1504;
	neg.f32 	%f1508, %f1507;
	fma.rn.f32 	%f1509, %f600, %f1504, %f1508;
	fma.rn.f32 	%f1510, %f600, %f1506, %f1509;
	fma.rn.f32 	%f1512, %f3263, %f1504, %f1510;
	add.rn.f32 	%f1513, %f1507, %f1512;
	neg.f32 	%f1514, %f1513;
	add.rn.f32 	%f1515, %f1507, %f1514;
	add.rn.f32 	%f1516, %f1515, %f1512;
	mov.b32 	%r633, %f1513;
	setp.eq.s32 	%p501, %r633, 1118925336;
	add.s32 	%r634, %r633, -1;
	mov.b32 	%f1517, %r634;
	add.f32 	%f1518, %f1516, 0f37000000;
	selp.f32 	%f228, %f1518, %f1516, %p501;
	selp.f32 	%f1519, %f1517, %f1513, %p501;
	mul.rn.f32 	%f1520, %f1519, %f800;
	cvt.rzi.f32.f32 	%f1521, %f1520;
	abs.f32 	%f1522, %f1521;
	setp.gt.f32 	%p502, %f1522, 0f42FC0000;
	mov.b32 	%r635, %f1521;
	and.b32  	%r636, %r635, -2147483648;
	or.b32  	%r637, %r636, 1123811328;
	mov.b32 	%f1523, %r637;
	selp.f32 	%f1524, %f1523, %f1521, %p502;
	fma.rn.f32 	%f1526, %f1524, %f3014, %f1519;
	fma.rn.f32 	%f1528, %f1524, %f3015, %f1526;
	mul.f32 	%f1529, %f1528, 0f3FB8AA3B;
	add.f32 	%f1530, %f1524, 0f4B40007F;
	mov.b32 	%r638, %f1530;
	shl.b32 	%r639, %r638, 23;
	mov.b32 	%f1531, %r639;
	ex2.approx.ftz.f32 	%f1532, %f1529;
	mul.f32 	%f229, %f1532, %f1531;
	setp.eq.f32 	%p503, %f229, 0f7F800000;
	mov.f32 	%f3253, 0f7F800000;
	@%p503 bra 	$L__BB2_285;

	fma.rn.f32 	%f3253, %f229, %f228, %f229;

$L__BB2_285:
	setp.lt.f32 	%p504, %f226, 0f00000000;
	and.pred  	%p40, %p504, %p301;
	setp.eq.f32 	%p506, %f226, 0f00000000;
	@%p506 bra 	$L__BB2_289;
	bra.uni 	$L__BB2_286;

$L__BB2_289:
	add.f32 	%f1537, %f226, %f226;
	selp.f32 	%f3255, %f1537, 0f00000000, %p301;
	bra.uni 	$L__BB2_290;

$L__BB2_286:
	mov.b32 	%r640, %f3253;
	xor.b32  	%r641, %r640, -2147483648;
	mov.b32 	%f1533, %r641;
	selp.f32 	%f3255, %f1533, %f3253, %p40;
	setp.geu.f32 	%p507, %f226, 0f00000000;
	@%p507 bra 	$L__BB2_290;

	cvt.rzi.f32.f32 	%f1535, %f600;
	setp.eq.f32 	%p508, %f1535, 0f40000000;
	@%p508 bra 	$L__BB2_290;

	mov.f32 	%f3255, 0f7FFFFFFF;

$L__BB2_290:
	abs.f32 	%f3153, %f226;
	add.f32 	%f1538, %f3153, 0f40000000;
	mov.b32 	%r642, %f1538;
	setp.lt.s32 	%p510, %r642, 2139095040;
	@%p510 bra 	$L__BB2_295;

	abs.f32 	%f3154, %f226;
	setp.gtu.f32 	%p511, %f3154, 0f7F800000;
	@%p511 bra 	$L__BB2_294;
	bra.uni 	$L__BB2_292;

$L__BB2_294:
	add.f32 	%f3255, %f226, 0f40000000;
	bra.uni 	$L__BB2_295;

$L__BB2_292:
	abs.f32 	%f3155, %f226;
	setp.neu.f32 	%p512, %f3155, 0f7F800000;
	@%p512 bra 	$L__BB2_295;

	selp.f32 	%f3255, 0fFF800000, 0f7F800000, %p40;

$L__BB2_295:
	cvt.f64.f32 	%fd1051, %f101;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1346}, %fd1051;
	}
	setp.lt.s32 	%p1286, %r1346, 0;
	mov.f64 	%fd1050, 0d4014000000000000;
	mov.f32 	%f3026, 0f32A57060;
	mov.f32 	%f3025, 0f4B400001;
	mov.f32 	%f3024, 0f437C0000;
	mov.f32 	%f3023, 0f3BBB989D;
	cvt.rn.f32.s32 	%f3022, %r1371;
	sub.f32 	%f3021, %f3022, %f3277;
	mov.f32 	%f3020, 0f3F000000;
	mul.f32 	%f1539, %f3255, 0fBF000000;
	setp.eq.f32 	%p514, %f226, 0f3F800000;
	selp.f32 	%f1540, 0fBF000000, %f1539, %p514;
	fma.rn.f32 	%f1543, %f1540, %f3023, %f3020;
	cvt.sat.f32.f32 	%f1546, %f1543;
	fma.rm.f32 	%f1548, %f1546, %f3024, %f3025;
	add.f32 	%f1549, %f1548, 0fCB40007F;
	neg.f32 	%f1550, %f1549;
	fma.rn.f32 	%f1551, %f1540, %f800, %f1550;
	fma.rn.f32 	%f1553, %f1540, %f3026, %f1551;
	mov.b32 	%r644, %f1548;
	shl.b32 	%r645, %r644, 23;
	mov.b32 	%f1554, %r645;
	ex2.approx.ftz.f32 	%f1555, %f1553;
	mul.f32 	%f238, %f1555, %f1554;
	add.f32 	%f1556, %f3021, 0f3F800000;
	mul.f32 	%f1557, %f1556, %f225;
	mul.f32 	%f1558, %f3021, %f238;
	sub.f32 	%f1559, %f1557, %f1558;
	div.rn.f32 	%f1560, %f182, %f101;
	mul.f32 	%f1561, %f1560, %f1559;
	mul.f32 	%f239, %f111, %f1561;
	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd131;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd1050;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1114, [retval0+0];
	} // callseq 43
	and.pred  	%p41, %p1286, %p428;
	not.pred 	%p516, %p41;
	@%p516 bra 	$L__BB2_297;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r646}, %fd1114;
	}
	xor.b32  	%r647, %r646, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r648, %temp}, %fd1114;
	}
	mov.b64 	%fd1114, {%r648, %r647};

$L__BB2_297:
	setp.eq.f32 	%p1287, %f101, 0f00000000;
	@%p1287 bra 	$L__BB2_301;
	bra.uni 	$L__BB2_298;

$L__BB2_301:
	setp.lt.s32 	%p520, %r78, 0;
	mov.u32 	%r649, 0;
	selp.b32 	%r651, %r105, 0, %p428;
	or.b32  	%r652, %r651, 2146435072;
	selp.b32 	%r653, %r652, %r651, %p520;
	mov.b64 	%fd1114, {%r649, %r653};
	bra.uni 	$L__BB2_302;

$L__BB2_298:
	setp.gt.s32 	%p518, %r105, -1;
	@%p518 bra 	$L__BB2_302;

	mov.f64 	%fd1068, 0d4014000000000000;
	cvt.rzi.f64.f64 	%fd761, %fd1068;
	setp.eq.f64 	%p519, %fd761, 0d4014000000000000;
	@%p519 bra 	$L__BB2_302;

	mov.f64 	%fd1114, 0dFFF8000000000000;

$L__BB2_302:
	add.f64 	%fd173, %fd130, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r654}, %fd173;
	}
	and.b32  	%r655, %r654, 2146435072;
	setp.ne.s32 	%p522, %r655, 2146435072;
	mov.f64 	%fd1115, %fd1114;
	@%p522 bra 	$L__BB2_308;

	setp.gtu.f64 	%p523, %fd131, 0d7FF0000000000000;
	mov.f64 	%fd1115, %fd173;
	@%p523 bra 	$L__BB2_308;

	mov.f64 	%fd1067, 0d4014000000000000;
	and.b32  	%r656, %r78, 2147483647;
	setp.eq.s32 	%p524, %r656, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r657, %temp}, %fd1067;
	}
	setp.eq.s32 	%p525, %r657, 0;
	and.pred  	%p526, %p524, %p525;
	@%p526 bra 	$L__BB2_307;
	bra.uni 	$L__BB2_305;

$L__BB2_307:
	setp.lt.s32 	%p533, %r78, 0;
	mov.u32 	%r665, 0;
	setp.gt.f64 	%p534, %fd131, 0d3FF0000000000000;
	selp.b32 	%r666, 2146435072, 0, %p534;
	xor.b32  	%r667, %r666, 2146435072;
	selp.b32 	%r668, %r667, %r666, %p533;
	setp.eq.f32 	%p535, %f101, 0fBF800000;
	selp.b32 	%r669, 1072693248, %r668, %p535;
	mov.b64 	%fd1115, {%r665, %r669};
	bra.uni 	$L__BB2_308;

$L__BB2_305:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r658, %temp}, %fd130;
	}
	and.b32  	%r659, %r105, 2147483647;
	setp.ne.s32 	%p527, %r659, 2146435072;
	setp.ne.s32 	%p528, %r658, 0;
	or.pred  	%p529, %p527, %p528;
	mov.f64 	%fd1115, %fd1114;
	@%p529 bra 	$L__BB2_308;

	setp.ne.s32 	%p530, %r656, 1071644672;
	and.pred  	%p531, %p530, %p41;
	setp.gt.s32 	%p532, %r78, -1;
	selp.b32 	%r661, 2146435072, 0, %p532;
	mov.u32 	%r662, 0;
	or.b32  	%r663, %r661, -2147483648;
	selp.b32 	%r664, %r663, %r661, %p531;
	mov.b64 	%fd1115, {%r662, %r664};

$L__BB2_308:
	cvt.f64.f32 	%fd177, %f114;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd177;
	}
	abs.f64 	%fd178, %fd177;
	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd178;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1117, [retval0+0];
	} // callseq 44
	setp.lt.s32 	%p536, %r106, 0;
	and.pred  	%p42, %p536, %p149;
	not.pred 	%p538, %p42;
	@%p538 bra 	$L__BB2_310;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r670}, %fd1117;
	}
	xor.b32  	%r671, %r670, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r672, %temp}, %fd1117;
	}
	mov.b64 	%fd1117, {%r672, %r671};

$L__BB2_310:
	setp.eq.f32 	%p1288, %f101, 0f3F800000;
	setp.eq.f32 	%p539, %f114, 0f00000000;
	selp.f64 	%fd182, 0d3FF0000000000000, %fd1115, %p1288;
	@%p539 bra 	$L__BB2_314;
	bra.uni 	$L__BB2_311;

$L__BB2_314:
	mov.u32 	%r673, 0;
	selp.b32 	%r674, %r106, 0, %p149;
	or.b32  	%r675, %r674, 2146435072;
	selp.b32 	%r676, %r675, %r674, %p152;
	mov.b64 	%fd1117, {%r673, %r676};
	bra.uni 	$L__BB2_315;

$L__BB2_311:
	setp.gt.s32 	%p541, %r106, -1;
	@%p541 bra 	$L__BB2_315;

	cvt.rzi.f64.f64 	%fd766, %fd647;
	setp.eq.f64 	%p542, %fd766, 0d4008000000000000;
	@%p542 bra 	$L__BB2_315;

	mov.f64 	%fd1117, 0dFFF8000000000000;

$L__BB2_315:
	add.f64 	%fd185, %fd177, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r677}, %fd185;
	}
	and.b32  	%r678, %r677, 2146435072;
	setp.ne.s32 	%p545, %r678, 2146435072;
	mov.f64 	%fd1118, %fd1117;
	@%p545 bra 	$L__BB2_321;

	setp.gtu.f64 	%p546, %fd178, 0d7FF0000000000000;
	mov.f64 	%fd1118, %fd185;
	@%p546 bra 	$L__BB2_321;

	setp.eq.s32 	%p547, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r679, %temp}, %fd647;
	}
	setp.eq.s32 	%p548, %r679, 0;
	and.pred  	%p549, %p547, %p548;
	@%p549 bra 	$L__BB2_320;
	bra.uni 	$L__BB2_318;

$L__BB2_320:
	mov.u32 	%r684, 0;
	setp.gt.f64 	%p556, %fd178, 0d3FF0000000000000;
	selp.b32 	%r685, 2146435072, 0, %p556;
	xor.b32  	%r686, %r685, 2146435072;
	selp.b32 	%r687, %r686, %r685, %p152;
	setp.eq.f32 	%p557, %f114, 0fBF800000;
	selp.b32 	%r688, 1072693248, %r687, %p557;
	mov.b64 	%fd1118, {%r684, %r688};
	bra.uni 	$L__BB2_321;

$L__BB2_318:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r680, %temp}, %fd177;
	}
	and.b32  	%r681, %r106, 2147483647;
	setp.ne.s32 	%p550, %r681, 2146435072;
	setp.ne.s32 	%p551, %r680, 0;
	or.pred  	%p552, %p550, %p551;
	mov.f64 	%fd1118, %fd1117;
	@%p552 bra 	$L__BB2_321;

	setp.ne.s32 	%p553, %r58, 1071644672;
	and.pred  	%p554, %p553, %p42;
	selp.b32 	%r682, %r63, %r62, %p554;
	mov.u32 	%r683, 0;
	mov.b64 	%fd1118, {%r683, %r682};

$L__BB2_321:
	setp.eq.f32 	%p558, %f114, 0f3F800000;
	selp.f64 	%fd769, 0d3FF0000000000000, %fd1118, %p558;
	cvt.f64.f32 	%fd770, %f225;
	mul.f64 	%fd189, %fd769, %fd770;
	cvt.f64.f32 	%fd190, %f120;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r107}, %fd190;
	}
	abs.f64 	%fd191, %fd190;
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd191;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd647;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1120, [retval0+0];
	} // callseq 45
	setp.lt.s32 	%p559, %r107, 0;
	and.pred  	%p43, %p559, %p149;
	not.pred 	%p561, %p43;
	@%p561 bra 	$L__BB2_323;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r689}, %fd1120;
	}
	xor.b32  	%r690, %r689, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r691, %temp}, %fd1120;
	}
	mov.b64 	%fd1120, {%r691, %r690};

$L__BB2_323:
	setp.eq.f32 	%p562, %f120, 0f00000000;
	@%p562 bra 	$L__BB2_327;
	bra.uni 	$L__BB2_324;

$L__BB2_327:
	mov.u32 	%r692, 0;
	selp.b32 	%r693, %r107, 0, %p149;
	or.b32  	%r694, %r693, 2146435072;
	selp.b32 	%r695, %r694, %r693, %p152;
	mov.b64 	%fd1120, {%r692, %r695};
	bra.uni 	$L__BB2_328;

$L__BB2_324:
	setp.gt.s32 	%p563, %r107, -1;
	@%p563 bra 	$L__BB2_328;

	cvt.rzi.f64.f64 	%fd773, %fd647;
	setp.eq.f64 	%p564, %fd773, 0d4008000000000000;
	@%p564 bra 	$L__BB2_328;

	mov.f64 	%fd1120, 0dFFF8000000000000;

$L__BB2_328:
	add.f64 	%fd197, %fd190, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r696}, %fd197;
	}
	and.b32  	%r697, %r696, 2146435072;
	setp.ne.s32 	%p567, %r697, 2146435072;
	mov.f64 	%fd1121, %fd1120;
	@%p567 bra 	$L__BB2_334;

	setp.gtu.f64 	%p568, %fd191, 0d7FF0000000000000;
	mov.f64 	%fd1121, %fd197;
	@%p568 bra 	$L__BB2_334;

	setp.eq.s32 	%p569, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r698, %temp}, %fd647;
	}
	setp.eq.s32 	%p570, %r698, 0;
	and.pred  	%p571, %p569, %p570;
	@%p571 bra 	$L__BB2_333;
	bra.uni 	$L__BB2_331;

$L__BB2_333:
	mov.u32 	%r703, 0;
	setp.gt.f64 	%p578, %fd191, 0d3FF0000000000000;
	selp.b32 	%r704, 2146435072, 0, %p578;
	xor.b32  	%r705, %r704, 2146435072;
	selp.b32 	%r706, %r705, %r704, %p152;
	setp.eq.f32 	%p579, %f120, 0fBF800000;
	selp.b32 	%r707, 1072693248, %r706, %p579;
	mov.b64 	%fd1121, {%r703, %r707};
	bra.uni 	$L__BB2_334;

$L__BB2_331:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r699, %temp}, %fd190;
	}
	and.b32  	%r700, %r107, 2147483647;
	setp.ne.s32 	%p572, %r700, 2146435072;
	setp.ne.s32 	%p573, %r699, 0;
	or.pred  	%p574, %p572, %p573;
	mov.f64 	%fd1121, %fd1120;
	@%p574 bra 	$L__BB2_334;

	setp.ne.s32 	%p575, %r58, 1071644672;
	and.pred  	%p576, %p575, %p43;
	selp.b32 	%r701, %r63, %r62, %p576;
	mov.u32 	%r702, 0;
	mov.b64 	%fd1121, {%r702, %r701};

$L__BB2_334:
	mov.f32 	%f3150, 0fC0000000;
	cvt.f64.f32 	%fd1052, %f111;
	setp.eq.f32 	%p580, %f120, 0f3F800000;
	selp.f64 	%fd776, 0d3FF0000000000000, %fd1121, %p580;
	cvt.f64.f32 	%fd777, %f238;
	mul.f64 	%fd778, %fd776, %fd777;
	sub.f64 	%fd779, %fd189, %fd778;
	div.rn.f64 	%fd780, %fd43, %fd182;
	mul.f64 	%fd781, %fd780, %fd779;
	mul.f64 	%fd783, %fd781, %fd1052;
	div.rn.f32 	%f1563, %f3150, %f101;
	mul.f32 	%f1564, %f1563, %f239;
	cvt.f64.f32 	%fd784, %f1564;
	sub.f64 	%fd201, %fd784, %fd783;
	div.rn.f32 	%f240, %f51, %f98;
	div.rn.f32 	%f241, %f52, %f100;
	not.pred 	%p581, %p12;
	mov.f64 	%fd1123, %fd64;
	@%p581 bra 	$L__BB2_336;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r708}, %fd64;
	}
	xor.b32  	%r709, %r708, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r710, %temp}, %fd64;
	}
	mov.b64 	%fd1123, {%r710, %r709};

$L__BB2_336:
	sub.f32 	%f3027, %f3274, %f540;
	setp.eq.f32 	%p582, %f3027, 0f00000000;
	@%p582 bra 	$L__BB2_340;
	bra.uni 	$L__BB2_337;

$L__BB2_340:
	mov.u32 	%r711, 0;
	mov.b64 	%fd1123, {%r711, %r84};
	bra.uni 	$L__BB2_341;

$L__BB2_337:
	setp.gt.s32 	%p583, %r83, -1;
	@%p583 bra 	$L__BB2_341;

	cvt.rzi.f64.f64 	%fd786, %fd644;
	setp.eq.f64 	%p584, %fd786, 0d4000000000000000;
	@%p584 bra 	$L__BB2_341;

	mov.f64 	%fd1123, 0dFFF8000000000000;

$L__BB2_341:
	selp.f64 	%fd1124, %fd1123, %fd46, %p182;
	@%p25 bra 	$L__BB2_346;

	setp.eq.s32 	%p586, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r712, %temp}, %fd644;
	}
	setp.eq.s32 	%p587, %r712, 0;
	and.pred  	%p588, %p586, %p587;
	@%p588 bra 	$L__BB2_345;
	bra.uni 	$L__BB2_343;

$L__BB2_345:
	mov.u32 	%r716, 0;
	mov.b64 	%fd1124, {%r716, %r86};
	bra.uni 	$L__BB2_346;

$L__BB2_343:
	and.b32  	%r713, %r83, 2147483647;
	setp.ne.s32 	%p589, %r713, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r714, %temp}, %fd45;
	}
	setp.ne.s32 	%p590, %r714, 0;
	or.pred  	%p591, %p589, %p590;
	mov.f64 	%fd1124, %fd1123;
	@%p591 bra 	$L__BB2_346;

	mov.u32 	%r715, 0;
	mov.b64 	%fd1124, {%r715, %r88};

$L__BB2_346:
	cvt.f64.f32 	%fd210, %f54;
	not.pred 	%p592, %p13;
	mov.f64 	%fd1126, %fd65;
	@%p592 bra 	$L__BB2_348;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r717}, %fd65;
	}
	xor.b32  	%r718, %r717, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r719, %temp}, %fd65;
	}
	mov.b64 	%fd1126, {%r719, %r718};

$L__BB2_348:
	@%p582 bra 	$L__BB2_352;
	bra.uni 	$L__BB2_349;

$L__BB2_352:
	mov.u32 	%r720, 0;
	selp.b32 	%r722, %r83, 0, %p149;
	or.b32  	%r723, %r722, 2146435072;
	selp.b32 	%r724, %r723, %r722, %p152;
	mov.b64 	%fd1126, {%r720, %r724};
	bra.uni 	$L__BB2_353;

$L__BB2_349:
	setp.gt.s32 	%p594, %r83, -1;
	@%p594 bra 	$L__BB2_353;

	cvt.rzi.f64.f64 	%fd790, %fd647;
	setp.eq.f64 	%p595, %fd790, 0d4008000000000000;
	@%p595 bra 	$L__BB2_353;

	mov.f64 	%fd1126, 0dFFF8000000000000;

$L__BB2_353:
	selp.f64 	%fd1127, %fd1126, %fd47, %p186;
	@%p26 bra 	$L__BB2_358;

	setp.eq.s32 	%p599, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r725, %temp}, %fd647;
	}
	setp.eq.s32 	%p600, %r725, 0;
	and.pred  	%p601, %p599, %p600;
	@%p601 bra 	$L__BB2_357;
	bra.uni 	$L__BB2_355;

$L__BB2_357:
	mov.u32 	%r732, 0;
	mov.b64 	%fd1127, {%r732, %r90};
	bra.uni 	$L__BB2_358;

$L__BB2_355:
	and.b32  	%r726, %r83, 2147483647;
	setp.ne.s32 	%p602, %r726, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r727, %temp}, %fd45;
	}
	setp.ne.s32 	%p603, %r727, 0;
	or.pred  	%p604, %p602, %p603;
	mov.f64 	%fd1127, %fd1126;
	@%p604 bra 	$L__BB2_358;

	setp.ne.s32 	%p605, %r58, 1071644672;
	and.pred  	%p606, %p605, %p13;
	selp.b32 	%r730, %r63, %r62, %p606;
	mov.u32 	%r731, 0;
	mov.b64 	%fd1127, {%r731, %r730};

$L__BB2_358:
	not.pred 	%p607, %p14;
	mov.f64 	%fd1129, %fd66;
	@%p607 bra 	$L__BB2_360;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r733}, %fd66;
	}
	xor.b32  	%r734, %r733, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r735, %temp}, %fd66;
	}
	mov.b64 	%fd1129, {%r735, %r734};

$L__BB2_360:
	setp.eq.f32 	%p608, %f541, 0f00000000;
	@%p608 bra 	$L__BB2_364;
	bra.uni 	$L__BB2_361;

$L__BB2_364:
	mov.u32 	%r736, 0;
	mov.b64 	%fd1129, {%r736, %r91};
	bra.uni 	$L__BB2_365;

$L__BB2_361:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1347}, %fd643;
	}
	setp.gt.s32 	%p609, %r1347, -1;
	@%p609 bra 	$L__BB2_365;

	cvt.rzi.f64.f64 	%fd794, %fd649;
	setp.eq.f64 	%p610, %fd794, 0d4010000000000000;
	@%p610 bra 	$L__BB2_365;

	mov.f64 	%fd1129, 0dFFF8000000000000;

$L__BB2_365:
	selp.f64 	%fd1130, %fd1129, %fd36, %p189;
	@%p27 bra 	$L__BB2_370;

	setp.eq.s32 	%p612, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r737, %temp}, %fd649;
	}
	setp.eq.s32 	%p613, %r737, 0;
	and.pred  	%p614, %p612, %p613;
	@%p614 bra 	$L__BB2_369;
	bra.uni 	$L__BB2_367;

$L__BB2_369:
	mov.u32 	%r741, 0;
	mov.b64 	%fd1130, {%r741, %r94};
	bra.uni 	$L__BB2_370;

$L__BB2_367:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1348}, %fd643;
	}
	and.b32  	%r738, %r1348, 2147483647;
	setp.ne.s32 	%p615, %r738, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r739, %temp}, %fd643;
	}
	setp.ne.s32 	%p616, %r739, 0;
	or.pred  	%p617, %p615, %p616;
	mov.f64 	%fd1130, %fd1129;
	@%p617 bra 	$L__BB2_370;

	mov.u32 	%r740, 0;
	mov.b64 	%fd1130, {%r740, %r97};

$L__BB2_370:
	sub.f32 	%f3028, %f3274, %f540;
	setp.eq.f32 	%p618, %f541, 0f3F800000;
	selp.f64 	%fd798, 0d3FF0000000000000, %fd1130, %p618;
	setp.eq.f32 	%p619, %f3028, 0f3F800000;
	selp.f64 	%fd799, 0d3FF0000000000000, %fd1127, %p619;
	mul.f64 	%fd800, %fd799, %fd35;
	div.rn.f64 	%fd801, %fd800, %fd798;
	selp.f64 	%fd802, 0d3FF0000000000000, %fd1124, %p619;
	mul.f64 	%fd803, %fd802, %fd34;
	div.rn.f64 	%fd804, %fd803, %fd210;
	add.f64 	%fd805, %fd804, %fd44;
	add.f64 	%fd806, %fd805, %fd801;
	cvt.rn.f32.f64 	%f242, %fd806;
	mul.f32 	%f243, %f240, %f242;
	not.pred 	%p620, %p15;
	mov.f64 	%fd1132, %fd67;
	@%p620 bra 	$L__BB2_372;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r742}, %fd67;
	}
	xor.b32  	%r743, %r742, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r744, %temp}, %fd67;
	}
	mov.b64 	%fd1132, {%r744, %r743};

$L__BB2_372:
	add.f32 	%f3029, %f3274, %f540;
	setp.eq.f32 	%p621, %f3029, 0f00000000;
	@%p621 bra 	$L__BB2_376;
	bra.uni 	$L__BB2_373;

$L__BB2_376:
	mov.u32 	%r745, 0;
	mov.b64 	%fd1132, {%r745, %r95};
	bra.uni 	$L__BB2_377;

$L__BB2_373:
	setp.gt.s32 	%p622, %r93, -1;
	@%p622 bra 	$L__BB2_377;

	cvt.rzi.f64.f64 	%fd808, %fd644;
	setp.eq.f64 	%p623, %fd808, 0d4000000000000000;
	@%p623 bra 	$L__BB2_377;

	mov.f64 	%fd1132, 0dFFF8000000000000;

$L__BB2_377:
	selp.f64 	%fd1133, %fd1132, %fd50, %p194;
	@%p28 bra 	$L__BB2_382;

	setp.eq.s32 	%p625, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r746, %temp}, %fd644;
	}
	setp.eq.s32 	%p626, %r746, 0;
	and.pred  	%p627, %p625, %p626;
	@%p627 bra 	$L__BB2_381;
	bra.uni 	$L__BB2_379;

$L__BB2_381:
	mov.u32 	%r750, 0;
	mov.b64 	%fd1133, {%r750, %r98};
	bra.uni 	$L__BB2_382;

$L__BB2_379:
	and.b32  	%r747, %r93, 2147483647;
	setp.ne.s32 	%p628, %r747, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r748, %temp}, %fd49;
	}
	setp.ne.s32 	%p629, %r748, 0;
	or.pred  	%p630, %p628, %p629;
	mov.f64 	%fd1133, %fd1132;
	@%p630 bra 	$L__BB2_382;

	mov.u32 	%r749, 0;
	mov.b64 	%fd1133, {%r749, %r100};

$L__BB2_382:
	add.f32 	%f3030, %f3274, %f540;
	setp.eq.f32 	%p631, %f3030, 0f3F800000;
	selp.f64 	%fd811, 0d3FF0000000000000, %fd1133, %p631;
	mul.f64 	%fd812, %fd811, %fd37;
	div.rn.f64 	%fd235, %fd812, %fd210;
	not.pred 	%p632, %p16;
	mov.f64 	%fd1135, %fd68;
	@%p632 bra 	$L__BB2_384;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r751}, %fd68;
	}
	xor.b32  	%r752, %r751, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r753, %temp}, %fd68;
	}
	mov.b64 	%fd1135, {%r753, %r752};

$L__BB2_384:
	@%p621 bra 	$L__BB2_388;
	bra.uni 	$L__BB2_385;

$L__BB2_388:
	mov.u32 	%r754, 0;
	selp.b32 	%r756, %r93, 0, %p149;
	or.b32  	%r757, %r756, 2146435072;
	selp.b32 	%r758, %r757, %r756, %p152;
	mov.b64 	%fd1135, {%r754, %r758};
	bra.uni 	$L__BB2_389;

$L__BB2_385:
	setp.gt.s32 	%p634, %r93, -1;
	@%p634 bra 	$L__BB2_389;

	cvt.rzi.f64.f64 	%fd814, %fd647;
	setp.eq.f64 	%p635, %fd814, 0d4008000000000000;
	@%p635 bra 	$L__BB2_389;

	mov.f64 	%fd1135, 0dFFF8000000000000;

$L__BB2_389:
	selp.f64 	%fd1136, %fd1135, %fd51, %p199;
	@%p29 bra 	$L__BB2_394;

	setp.eq.s32 	%p639, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r759, %temp}, %fd647;
	}
	setp.eq.s32 	%p640, %r759, 0;
	and.pred  	%p641, %p639, %p640;
	@%p641 bra 	$L__BB2_393;
	bra.uni 	$L__BB2_391;

$L__BB2_393:
	mov.u32 	%r766, 0;
	mov.b64 	%fd1136, {%r766, %r101};
	bra.uni 	$L__BB2_394;

$L__BB2_391:
	and.b32  	%r760, %r93, 2147483647;
	setp.ne.s32 	%p642, %r760, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r761, %temp}, %fd49;
	}
	setp.ne.s32 	%p643, %r761, 0;
	or.pred  	%p644, %p642, %p643;
	mov.f64 	%fd1136, %fd1135;
	@%p644 bra 	$L__BB2_394;

	setp.ne.s32 	%p645, %r58, 1071644672;
	and.pred  	%p646, %p645, %p16;
	selp.b32 	%r764, %r63, %r62, %p646;
	mov.u32 	%r765, 0;
	mov.b64 	%fd1136, {%r765, %r764};

$L__BB2_394:
	mov.f64 	%fd1138, %fd66;
	@%p607 bra 	$L__BB2_396;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r767}, %fd66;
	}
	xor.b32  	%r768, %r767, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r769, %temp}, %fd66;
	}
	mov.b64 	%fd1138, {%r769, %r768};

$L__BB2_396:
	@%p608 bra 	$L__BB2_400;
	bra.uni 	$L__BB2_397;

$L__BB2_400:
	mov.u32 	%r770, 0;
	mov.b64 	%fd1138, {%r770, %r91};
	bra.uni 	$L__BB2_401;

$L__BB2_397:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1349}, %fd643;
	}
	setp.gt.s32 	%p649, %r1349, -1;
	@%p649 bra 	$L__BB2_401;

	cvt.rzi.f64.f64 	%fd818, %fd649;
	setp.eq.f64 	%p650, %fd818, 0d4010000000000000;
	@%p650 bra 	$L__BB2_401;

	mov.f64 	%fd1138, 0dFFF8000000000000;

$L__BB2_401:
	selp.f64 	%fd1139, %fd1138, %fd36, %p189;
	@%p27 bra 	$L__BB2_406;

	setp.eq.s32 	%p652, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r771, %temp}, %fd649;
	}
	setp.eq.s32 	%p653, %r771, 0;
	and.pred  	%p654, %p652, %p653;
	@%p654 bra 	$L__BB2_405;
	bra.uni 	$L__BB2_403;

$L__BB2_405:
	mov.u32 	%r775, 0;
	mov.b64 	%fd1139, {%r775, %r94};
	bra.uni 	$L__BB2_406;

$L__BB2_403:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1350}, %fd643;
	}
	and.b32  	%r772, %r1350, 2147483647;
	setp.ne.s32 	%p655, %r772, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r773, %temp}, %fd643;
	}
	setp.ne.s32 	%p656, %r773, 0;
	or.pred  	%p657, %p655, %p656;
	mov.f64 	%fd1139, %fd1138;
	@%p657 bra 	$L__BB2_406;

	mov.u32 	%r774, 0;
	mov.b64 	%fd1139, {%r774, %r97};

$L__BB2_406:
	mov.f32 	%f3038, 0f3FC00000;
	mov.f32 	%f3037, 0f3102E308;
	mov.f32 	%f3036, 0fBF317218;
	mov.f32 	%f3035, 0f35BFBE8E;
	mov.f32 	%f3034, 0f3F317200;
	mov.f32 	%f3033, 0f3DAAAABD;
	mov.f32 	%f3032, 0f3C4CAF63;
	mov.f32 	%f3031, 0f3B18F0FE;
	selp.f64 	%fd822, 0d3FF0000000000000, %fd1139, %p618;
	selp.f64 	%fd823, 0d3FF0000000000000, %fd1136, %p631;
	mul.f64 	%fd824, %fd823, %fd38;
	div.rn.f64 	%fd825, %fd824, %fd822;
	add.f64 	%fd826, %fd235, %fd48;
	add.f64 	%fd827, %fd826, %fd825;
	cvt.rn.f32.f64 	%f244, %fd827;
	mul.f32 	%f245, %f241, %f244;
	mul.f32 	%f1566, %f239, %f245;
	fma.rn.f32 	%f246, %f211, %f243, %f1566;
	abs.f32 	%f247, %f96;
	setp.lt.f32 	%p660, %f247, 0f00800000;
	mul.f32 	%f1567, %f247, 0f4B800000;
	selp.f32 	%f1568, %f1567, %f247, %p660;
	selp.f32 	%f1569, 0fC3170000, 0fC2FE0000, %p660;
	mov.b32 	%r776, %f1568;
	and.b32  	%r777, %r776, 8388607;
	or.b32  	%r778, %r777, 1065353216;
	mov.b32 	%f1570, %r778;
	shr.u32 	%r779, %r776, 23;
	cvt.rn.f32.u32 	%f1571, %r779;
	add.f32 	%f1572, %f1569, %f1571;
	setp.gt.f32 	%p661, %f1570, 0f3FB504F3;
	mul.f32 	%f1573, %f1570, 0f3F000000;
	add.f32 	%f1574, %f1572, 0f3F800000;
	selp.f32 	%f1575, %f1574, %f1572, %p661;
	selp.f32 	%f1576, %f1573, %f1570, %p661;
	add.f32 	%f1577, %f1576, 0fBF800000;
	add.f32 	%f1578, %f1576, 0f3F800000;
	rcp.approx.ftz.f32 	%f1579, %f1578;
	add.f32 	%f1580, %f1577, %f1577;
	mul.f32 	%f1581, %f1580, %f1579;
	mul.f32 	%f1582, %f1581, %f1581;
	fma.rn.f32 	%f1585, %f3031, %f1582, %f3032;
	fma.rn.f32 	%f1587, %f1585, %f1582, %f3033;
	mul.rn.f32 	%f1588, %f1587, %f1582;
	mul.rn.f32 	%f1589, %f1588, %f1581;
	sub.f32 	%f1590, %f1577, %f1581;
	add.f32 	%f1591, %f1590, %f1590;
	neg.f32 	%f1592, %f1581;
	fma.rn.f32 	%f1593, %f1592, %f1577, %f1591;
	mul.rn.f32 	%f1594, %f1579, %f1593;
	add.f32 	%f1595, %f1589, %f1581;
	sub.f32 	%f1596, %f1581, %f1595;
	add.f32 	%f1597, %f1589, %f1596;
	add.f32 	%f1598, %f1594, %f1597;
	add.f32 	%f1599, %f1595, %f1598;
	sub.f32 	%f1600, %f1595, %f1599;
	add.f32 	%f1601, %f1598, %f1600;
	mul.rn.f32 	%f1603, %f1575, %f3034;
	mul.rn.f32 	%f1605, %f1575, %f3035;
	add.f32 	%f1606, %f1603, %f1599;
	sub.f32 	%f1607, %f1603, %f1606;
	add.f32 	%f1608, %f1599, %f1607;
	add.f32 	%f1609, %f1601, %f1608;
	add.f32 	%f1610, %f1605, %f1609;
	add.f32 	%f1611, %f1606, %f1610;
	sub.f32 	%f1612, %f1606, %f1611;
	add.f32 	%f1613, %f1610, %f1612;
	mul.rn.f32 	%f1615, %f3038, %f1611;
	neg.f32 	%f1616, %f1615;
	fma.rn.f32 	%f1617, %f3038, %f1611, %f1616;
	fma.rn.f32 	%f1618, %f3038, %f1613, %f1617;
	fma.rn.f32 	%f1620, %f3263, %f1611, %f1618;
	add.rn.f32 	%f1621, %f1615, %f1620;
	neg.f32 	%f1622, %f1621;
	add.rn.f32 	%f1623, %f1615, %f1622;
	add.rn.f32 	%f1624, %f1623, %f1620;
	mov.b32 	%r780, %f1621;
	setp.eq.s32 	%p662, %r780, 1118925336;
	add.s32 	%r781, %r780, -1;
	mov.b32 	%f1625, %r781;
	add.f32 	%f1626, %f1624, 0f37000000;
	selp.f32 	%f248, %f1626, %f1624, %p662;
	selp.f32 	%f1627, %f1625, %f1621, %p662;
	mul.rn.f32 	%f1629, %f1627, %f800;
	cvt.rzi.f32.f32 	%f1630, %f1629;
	abs.f32 	%f1631, %f1630;
	setp.gt.f32 	%p663, %f1631, 0f42FC0000;
	mov.b32 	%r782, %f1630;
	and.b32  	%r783, %r782, -2147483648;
	or.b32  	%r784, %r783, 1123811328;
	mov.b32 	%f1632, %r784;
	selp.f32 	%f1633, %f1632, %f1630, %p663;
	fma.rn.f32 	%f1635, %f1633, %f3036, %f1627;
	fma.rn.f32 	%f1637, %f1633, %f3037, %f1635;
	mul.f32 	%f1638, %f1637, 0f3FB8AA3B;
	add.f32 	%f1639, %f1633, 0f4B40007F;
	mov.b32 	%r785, %f1639;
	shl.b32 	%r786, %r785, 23;
	mov.b32 	%f1640, %r786;
	ex2.approx.ftz.f32 	%f1641, %f1638;
	mul.f32 	%f249, %f1641, %f1640;
	setp.eq.f32 	%p664, %f249, 0f7F800000;
	mov.f32 	%f3256, 0f7F800000;
	@%p664 bra 	$L__BB2_408;

	fma.rn.f32 	%f3256, %f249, %f248, %f249;

$L__BB2_408:
	mov.f32 	%f3044, 0f3F400000;
	cvt.rzi.f32.f32 	%f3043, %f3044;
	add.f32 	%f3042, %f3043, %f3043;
	mov.f32 	%f3041, 0f3FC00000;
	sub.f32 	%f3040, %f3041, %f3042;
	abs.f32 	%f3039, %f3040;
	setp.lt.f32 	%p665, %f96, 0f00000000;
	setp.eq.f32 	%p666, %f3039, 0f3F800000;
	and.pred  	%p44, %p665, %p666;
	setp.eq.f32 	%p667, %f96, 0f00000000;
	@%p667 bra 	$L__BB2_412;
	bra.uni 	$L__BB2_409;

$L__BB2_412:
	add.f32 	%f1646, %f96, %f96;
	selp.f32 	%f3258, %f1646, 0f00000000, %p666;
	bra.uni 	$L__BB2_413;

$L__BB2_409:
	mov.b32 	%r787, %f3256;
	xor.b32  	%r788, %r787, -2147483648;
	mov.b32 	%f1642, %r788;
	selp.f32 	%f3258, %f1642, %f3256, %p44;
	setp.geu.f32 	%p668, %f96, 0f00000000;
	@%p668 bra 	$L__BB2_413;

	mov.f32 	%f3134, 0f3FC00000;
	cvt.rzi.f32.f32 	%f1644, %f3134;
	setp.eq.f32 	%p669, %f1644, 0f3FC00000;
	@%p669 bra 	$L__BB2_413;

	mov.f32 	%f3258, 0f7FFFFFFF;

$L__BB2_413:
	abs.f32 	%f3156, %f96;
	add.f32 	%f1647, %f3156, 0f3FC00000;
	mov.b32 	%r789, %f1647;
	setp.lt.s32 	%p671, %r789, 2139095040;
	@%p671 bra 	$L__BB2_418;

	abs.f32 	%f3170, %f96;
	setp.gtu.f32 	%p672, %f3170, 0f7F800000;
	@%p672 bra 	$L__BB2_417;
	bra.uni 	$L__BB2_415;

$L__BB2_417:
	add.f32 	%f3258, %f96, 0f3FC00000;
	bra.uni 	$L__BB2_418;

$L__BB2_415:
	abs.f32 	%f3171, %f96;
	setp.neu.f32 	%p673, %f3171, 0f7F800000;
	@%p673 bra 	$L__BB2_418;

	selp.f32 	%f3258, 0fFF800000, 0f7F800000, %p44;

$L__BB2_418:
	mov.f32 	%f3052, 0f3FC00000;
	mov.f32 	%f3051, 0f3102E308;
	mov.f32 	%f3050, 0fBF317218;
	mov.f32 	%f3049, 0f35BFBE8E;
	mov.f32 	%f3048, 0f3F317200;
	mov.f32 	%f3047, 0f3DAAAABD;
	mov.f32 	%f3046, 0f3C4CAF63;
	mov.f32 	%f3045, 0f3B18F0FE;
	setp.eq.f32 	%p674, %f96, 0f3F800000;
	selp.f32 	%f1649, 0f3F800000, %f3258, %p674;
	div.rn.f32 	%f258, %f55, %f1649;
	abs.f32 	%f259, %f97;
	setp.lt.f32 	%p675, %f259, 0f00800000;
	mul.f32 	%f1650, %f259, 0f4B800000;
	selp.f32 	%f1651, %f1650, %f259, %p675;
	selp.f32 	%f1652, 0fC3170000, 0fC2FE0000, %p675;
	mov.b32 	%r790, %f1651;
	and.b32  	%r791, %r790, 8388607;
	or.b32  	%r792, %r791, 1065353216;
	mov.b32 	%f1653, %r792;
	shr.u32 	%r793, %r790, 23;
	cvt.rn.f32.u32 	%f1654, %r793;
	add.f32 	%f1655, %f1652, %f1654;
	setp.gt.f32 	%p676, %f1653, 0f3FB504F3;
	mul.f32 	%f1656, %f1653, 0f3F000000;
	add.f32 	%f1657, %f1655, 0f3F800000;
	selp.f32 	%f1658, %f1657, %f1655, %p676;
	selp.f32 	%f1659, %f1656, %f1653, %p676;
	add.f32 	%f1660, %f1659, 0fBF800000;
	add.f32 	%f1661, %f1659, 0f3F800000;
	rcp.approx.ftz.f32 	%f1662, %f1661;
	add.f32 	%f1663, %f1660, %f1660;
	mul.f32 	%f1664, %f1663, %f1662;
	mul.f32 	%f1665, %f1664, %f1664;
	fma.rn.f32 	%f1668, %f3045, %f1665, %f3046;
	fma.rn.f32 	%f1670, %f1668, %f1665, %f3047;
	mul.rn.f32 	%f1671, %f1670, %f1665;
	mul.rn.f32 	%f1672, %f1671, %f1664;
	sub.f32 	%f1673, %f1660, %f1664;
	add.f32 	%f1674, %f1673, %f1673;
	neg.f32 	%f1675, %f1664;
	fma.rn.f32 	%f1676, %f1675, %f1660, %f1674;
	mul.rn.f32 	%f1677, %f1662, %f1676;
	add.f32 	%f1678, %f1672, %f1664;
	sub.f32 	%f1679, %f1664, %f1678;
	add.f32 	%f1680, %f1672, %f1679;
	add.f32 	%f1681, %f1677, %f1680;
	add.f32 	%f1682, %f1678, %f1681;
	sub.f32 	%f1683, %f1678, %f1682;
	add.f32 	%f1684, %f1681, %f1683;
	mul.rn.f32 	%f1686, %f1658, %f3048;
	mul.rn.f32 	%f1688, %f1658, %f3049;
	add.f32 	%f1689, %f1686, %f1682;
	sub.f32 	%f1690, %f1686, %f1689;
	add.f32 	%f1691, %f1682, %f1690;
	add.f32 	%f1692, %f1684, %f1691;
	add.f32 	%f1693, %f1688, %f1692;
	add.f32 	%f1694, %f1689, %f1693;
	sub.f32 	%f1695, %f1689, %f1694;
	add.f32 	%f1696, %f1693, %f1695;
	mul.rn.f32 	%f1698, %f3052, %f1694;
	neg.f32 	%f1699, %f1698;
	fma.rn.f32 	%f1700, %f3052, %f1694, %f1699;
	fma.rn.f32 	%f1701, %f3052, %f1696, %f1700;
	fma.rn.f32 	%f1703, %f3263, %f1694, %f1701;
	add.rn.f32 	%f1704, %f1698, %f1703;
	neg.f32 	%f1705, %f1704;
	add.rn.f32 	%f1706, %f1698, %f1705;
	add.rn.f32 	%f1707, %f1706, %f1703;
	mov.b32 	%r794, %f1704;
	setp.eq.s32 	%p677, %r794, 1118925336;
	add.s32 	%r795, %r794, -1;
	mov.b32 	%f1708, %r795;
	add.f32 	%f1709, %f1707, 0f37000000;
	selp.f32 	%f260, %f1709, %f1707, %p677;
	selp.f32 	%f1710, %f1708, %f1704, %p677;
	mul.rn.f32 	%f1712, %f1710, %f800;
	cvt.rzi.f32.f32 	%f1713, %f1712;
	abs.f32 	%f1714, %f1713;
	setp.gt.f32 	%p678, %f1714, 0f42FC0000;
	mov.b32 	%r796, %f1713;
	and.b32  	%r797, %r796, -2147483648;
	or.b32  	%r798, %r797, 1123811328;
	mov.b32 	%f1715, %r798;
	selp.f32 	%f1716, %f1715, %f1713, %p678;
	fma.rn.f32 	%f1718, %f1716, %f3050, %f1710;
	fma.rn.f32 	%f1720, %f1716, %f3051, %f1718;
	mul.f32 	%f1721, %f1720, 0f3FB8AA3B;
	add.f32 	%f1722, %f1716, 0f4B40007F;
	mov.b32 	%r799, %f1722;
	shl.b32 	%r800, %r799, 23;
	mov.b32 	%f1723, %r800;
	ex2.approx.ftz.f32 	%f1724, %f1721;
	mul.f32 	%f261, %f1724, %f1723;
	setp.eq.f32 	%p679, %f261, 0f7F800000;
	mov.f32 	%f3259, 0f7F800000;
	@%p679 bra 	$L__BB2_420;

	fma.rn.f32 	%f3259, %f261, %f260, %f261;

$L__BB2_420:
	setp.lt.f32 	%p680, %f97, 0f00000000;
	and.pred  	%p45, %p680, %p666;
	setp.eq.f32 	%p682, %f97, 0f00000000;
	@%p682 bra 	$L__BB2_424;
	bra.uni 	$L__BB2_421;

$L__BB2_424:
	add.f32 	%f1729, %f97, %f97;
	selp.f32 	%f3261, %f1729, 0f00000000, %p666;
	bra.uni 	$L__BB2_425;

$L__BB2_421:
	mov.b32 	%r801, %f3259;
	xor.b32  	%r802, %r801, -2147483648;
	mov.b32 	%f1725, %r802;
	selp.f32 	%f3261, %f1725, %f3259, %p45;
	setp.geu.f32 	%p683, %f97, 0f00000000;
	@%p683 bra 	$L__BB2_425;

	mov.f32 	%f3133, 0f3FC00000;
	cvt.rzi.f32.f32 	%f1727, %f3133;
	setp.eq.f32 	%p684, %f1727, 0f3FC00000;
	@%p684 bra 	$L__BB2_425;

	mov.f32 	%f3261, 0f7FFFFFFF;

$L__BB2_425:
	abs.f32 	%f3172, %f97;
	add.f32 	%f1730, %f3172, 0f3FC00000;
	mov.b32 	%r803, %f1730;
	setp.lt.s32 	%p686, %r803, 2139095040;
	@%p686 bra 	$L__BB2_430;

	abs.f32 	%f3173, %f97;
	setp.gtu.f32 	%p687, %f3173, 0f7F800000;
	@%p687 bra 	$L__BB2_429;
	bra.uni 	$L__BB2_427;

$L__BB2_429:
	add.f32 	%f3261, %f97, 0f3FC00000;
	bra.uni 	$L__BB2_430;

$L__BB2_427:
	abs.f32 	%f3174, %f97;
	setp.neu.f32 	%p688, %f3174, 0f7F800000;
	@%p688 bra 	$L__BB2_430;

	selp.f32 	%f3261, 0fFF800000, 0f7F800000, %p45;

$L__BB2_430:
	cvt.rn.f32.f64 	%f3157, %fd806;
	setp.eq.f32 	%p689, %f97, 0f3F800000;
	selp.f32 	%f270, 0f3F800000, %f3261, %p689;
	cvt.f64.f32 	%fd252, %f3157;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r108}, %fd252;
	}
	abs.f64 	%fd253, %fd252;
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd253;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1141, [retval0+0];
	} // callseq 46
	setp.lt.s32 	%p690, %r108, 0;
	and.pred  	%p46, %p690, %p144;
	not.pred 	%p692, %p46;
	@%p692 bra 	$L__BB2_432;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r804}, %fd1141;
	}
	xor.b32  	%r805, %r804, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r806, %temp}, %fd1141;
	}
	mov.b64 	%fd1141, {%r806, %r805};

$L__BB2_432:
	cvt.rn.f32.f64 	%f3158, %fd806;
	setp.eq.f32 	%p693, %f3158, 0f00000000;
	@%p693 bra 	$L__BB2_436;
	bra.uni 	$L__BB2_433;

$L__BB2_436:
	mov.u32 	%r807, 0;
	selp.b32 	%r808, %r108, 0, %p144;
	or.b32  	%r809, %r808, 2146435072;
	selp.b32 	%r810, %r809, %r808, %p146;
	mov.b64 	%fd1141, {%r807, %r810};
	bra.uni 	$L__BB2_437;

$L__BB2_433:
	setp.gt.s32 	%p694, %r108, -1;
	@%p694 bra 	$L__BB2_437;

	cvt.rzi.f64.f64 	%fd830, %fd644;
	setp.eq.f64 	%p695, %fd830, 0d4000000000000000;
	@%p695 bra 	$L__BB2_437;

	mov.f64 	%fd1141, 0dFFF8000000000000;

$L__BB2_437:
	add.f64 	%fd259, %fd252, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r811}, %fd259;
	}
	and.b32  	%r812, %r811, 2146435072;
	setp.ne.s32 	%p698, %r812, 2146435072;
	mov.f64 	%fd1142, %fd1141;
	@%p698 bra 	$L__BB2_443;

	setp.gtu.f64 	%p699, %fd253, 0d7FF0000000000000;
	mov.f64 	%fd1142, %fd259;
	@%p699 bra 	$L__BB2_443;

	setp.eq.s32 	%p700, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r813, %temp}, %fd644;
	}
	setp.eq.s32 	%p701, %r813, 0;
	and.pred  	%p702, %p700, %p701;
	@%p702 bra 	$L__BB2_442;
	bra.uni 	$L__BB2_440;

$L__BB2_442:
	cvt.rn.f32.f64 	%f3169, %fd806;
	mov.u32 	%r818, 0;
	setp.gt.f64 	%p709, %fd253, 0d3FF0000000000000;
	selp.b32 	%r819, 2146435072, 0, %p709;
	xor.b32  	%r820, %r819, 2146435072;
	selp.b32 	%r821, %r820, %r819, %p146;
	setp.eq.f32 	%p710, %f3169, 0fBF800000;
	selp.b32 	%r822, 1072693248, %r821, %p710;
	mov.b64 	%fd1142, {%r818, %r822};
	bra.uni 	$L__BB2_443;

$L__BB2_440:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r814, %temp}, %fd252;
	}
	and.b32  	%r815, %r108, 2147483647;
	setp.ne.s32 	%p703, %r815, 2146435072;
	setp.ne.s32 	%p704, %r814, 0;
	or.pred  	%p705, %p703, %p704;
	mov.f64 	%fd1142, %fd1141;
	@%p705 bra 	$L__BB2_443;

	and.pred  	%p707, %p155, %p46;
	selp.b32 	%r816, %r57, %r56, %p707;
	mov.u32 	%r817, 0;
	mov.b64 	%fd1142, {%r817, %r816};

$L__BB2_443:
	cvt.rn.f32.f64 	%f3159, %fd806;
	not.pred 	%p1289, %p12;
	setp.eq.f32 	%p711, %f3159, 0f3F800000;
	selp.f64 	%fd833, 0d3FF0000000000000, %fd1142, %p711;
	cvt.f64.f32 	%fd834, %f258;
	mul.f64 	%fd263, %fd833, %fd834;
	mov.f64 	%fd1144, %fd64;
	@%p1289 bra 	$L__BB2_445;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r823}, %fd64;
	}
	xor.b32  	%r824, %r823, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r825, %temp}, %fd64;
	}
	mov.b64 	%fd1144, {%r825, %r824};

$L__BB2_445:
	@%p582 bra 	$L__BB2_449;
	bra.uni 	$L__BB2_446;

$L__BB2_449:
	mov.u32 	%r826, 0;
	mov.b64 	%fd1144, {%r826, %r84};
	bra.uni 	$L__BB2_450;

$L__BB2_446:
	setp.gt.s32 	%p714, %r83, -1;
	@%p714 bra 	$L__BB2_450;

	cvt.rzi.f64.f64 	%fd836, %fd644;
	setp.eq.f64 	%p715, %fd836, 0d4000000000000000;
	@%p715 bra 	$L__BB2_450;

	mov.f64 	%fd1144, 0dFFF8000000000000;

$L__BB2_450:
	selp.f64 	%fd1145, %fd1144, %fd46, %p182;
	@%p25 bra 	$L__BB2_455;

	setp.eq.s32 	%p717, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r827, %temp}, %fd644;
	}
	setp.eq.s32 	%p718, %r827, 0;
	and.pred  	%p719, %p717, %p718;
	@%p719 bra 	$L__BB2_454;
	bra.uni 	$L__BB2_452;

$L__BB2_454:
	mov.u32 	%r831, 0;
	mov.b64 	%fd1145, {%r831, %r86};
	bra.uni 	$L__BB2_455;

$L__BB2_452:
	and.b32  	%r828, %r83, 2147483647;
	setp.ne.s32 	%p720, %r828, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r829, %temp}, %fd45;
	}
	setp.ne.s32 	%p721, %r829, 0;
	or.pred  	%p722, %p720, %p721;
	mov.f64 	%fd1145, %fd1144;
	@%p722 bra 	$L__BB2_455;

	mov.u32 	%r830, 0;
	mov.b64 	%fd1145, {%r830, %r88};

$L__BB2_455:
	mov.f64 	%fd1147, %fd66;
	@%p607 bra 	$L__BB2_457;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r832}, %fd66;
	}
	xor.b32  	%r833, %r832, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r834, %temp}, %fd66;
	}
	mov.b64 	%fd1147, {%r834, %r833};

$L__BB2_457:
	@%p608 bra 	$L__BB2_461;
	bra.uni 	$L__BB2_458;

$L__BB2_461:
	mov.u32 	%r835, 0;
	mov.b64 	%fd1147, {%r835, %r91};
	bra.uni 	$L__BB2_462;

$L__BB2_458:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1351}, %fd643;
	}
	setp.gt.s32 	%p725, %r1351, -1;
	@%p725 bra 	$L__BB2_462;

	cvt.rzi.f64.f64 	%fd840, %fd649;
	setp.eq.f64 	%p726, %fd840, 0d4010000000000000;
	@%p726 bra 	$L__BB2_462;

	mov.f64 	%fd1147, 0dFFF8000000000000;

$L__BB2_462:
	selp.f64 	%fd1148, %fd1147, %fd36, %p189;
	@%p27 bra 	$L__BB2_467;

	setp.eq.s32 	%p728, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r836, %temp}, %fd649;
	}
	setp.eq.s32 	%p729, %r836, 0;
	and.pred  	%p730, %p728, %p729;
	@%p730 bra 	$L__BB2_466;
	bra.uni 	$L__BB2_464;

$L__BB2_466:
	mov.u32 	%r840, 0;
	mov.b64 	%fd1148, {%r840, %r94};
	bra.uni 	$L__BB2_467;

$L__BB2_464:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1352}, %fd643;
	}
	and.b32  	%r837, %r1352, 2147483647;
	setp.ne.s32 	%p731, %r837, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r838, %temp}, %fd643;
	}
	setp.ne.s32 	%p732, %r838, 0;
	or.pred  	%p733, %p731, %p732;
	mov.f64 	%fd1148, %fd1147;
	@%p733 bra 	$L__BB2_467;

	mov.u32 	%r839, 0;
	mov.b64 	%fd1148, {%r839, %r97};

$L__BB2_467:
	cvt.rn.f32.f64 	%f3161, %fd827;
	sub.f32 	%f3160, %f3274, %f540;
	setp.eq.f32 	%p1290, %f3160, 0f3F800000;
	selp.f64 	%fd844, 0d3FF0000000000000, %fd1148, %p618;
	selp.f64 	%fd845, 0d3FF0000000000000, %fd1145, %p1290;
	mul.f64 	%fd846, %fd845, %fd39;
	div.rn.f64 	%fd847, %fd846, %fd844;
	add.f64 	%fd848, %fd847, %fd52;
	cvt.rn.f32.f64 	%f1731, %fd848;
	mul.f32 	%f1732, %f240, %f1731;
	cvt.f64.f32 	%fd849, %f1732;
	add.f64 	%fd280, %fd263, %fd849;
	cvt.f64.f32 	%fd281, %f3161;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r109}, %fd281;
	}
	abs.f64 	%fd282, %fd281;
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd282;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1150, [retval0+0];
	} // callseq 47
	setp.lt.s32 	%p736, %r109, 0;
	and.pred  	%p47, %p736, %p144;
	not.pred 	%p738, %p47;
	@%p738 bra 	$L__BB2_469;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r841}, %fd1150;
	}
	xor.b32  	%r842, %r841, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r843, %temp}, %fd1150;
	}
	mov.b64 	%fd1150, {%r843, %r842};

$L__BB2_469:
	cvt.rn.f32.f64 	%f3162, %fd827;
	setp.eq.f32 	%p739, %f3162, 0f00000000;
	@%p739 bra 	$L__BB2_473;
	bra.uni 	$L__BB2_470;

$L__BB2_473:
	mov.u32 	%r844, 0;
	selp.b32 	%r845, %r109, 0, %p144;
	or.b32  	%r846, %r845, 2146435072;
	selp.b32 	%r847, %r846, %r845, %p146;
	mov.b64 	%fd1150, {%r844, %r847};
	bra.uni 	$L__BB2_474;

$L__BB2_470:
	setp.gt.s32 	%p740, %r109, -1;
	@%p740 bra 	$L__BB2_474;

	cvt.rzi.f64.f64 	%fd852, %fd644;
	setp.eq.f64 	%p741, %fd852, 0d4000000000000000;
	@%p741 bra 	$L__BB2_474;

	mov.f64 	%fd1150, 0dFFF8000000000000;

$L__BB2_474:
	add.f64 	%fd288, %fd281, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r848}, %fd288;
	}
	and.b32  	%r849, %r848, 2146435072;
	setp.ne.s32 	%p744, %r849, 2146435072;
	mov.f64 	%fd1151, %fd1150;
	@%p744 bra 	$L__BB2_480;

	setp.gtu.f64 	%p745, %fd282, 0d7FF0000000000000;
	mov.f64 	%fd1151, %fd288;
	@%p745 bra 	$L__BB2_480;

	setp.eq.s32 	%p746, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r850, %temp}, %fd644;
	}
	setp.eq.s32 	%p747, %r850, 0;
	and.pred  	%p748, %p746, %p747;
	@%p748 bra 	$L__BB2_479;
	bra.uni 	$L__BB2_477;

$L__BB2_479:
	cvt.rn.f32.f64 	%f3168, %fd827;
	mov.u32 	%r855, 0;
	setp.gt.f64 	%p755, %fd282, 0d3FF0000000000000;
	selp.b32 	%r856, 2146435072, 0, %p755;
	xor.b32  	%r857, %r856, 2146435072;
	selp.b32 	%r858, %r857, %r856, %p146;
	setp.eq.f32 	%p756, %f3168, 0fBF800000;
	selp.b32 	%r859, 1072693248, %r858, %p756;
	mov.b64 	%fd1151, {%r855, %r859};
	bra.uni 	$L__BB2_480;

$L__BB2_477:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r851, %temp}, %fd281;
	}
	and.b32  	%r852, %r109, 2147483647;
	setp.ne.s32 	%p749, %r852, 2146435072;
	setp.ne.s32 	%p750, %r851, 0;
	or.pred  	%p751, %p749, %p750;
	mov.f64 	%fd1151, %fd1150;
	@%p751 bra 	$L__BB2_480;

	and.pred  	%p753, %p155, %p47;
	selp.b32 	%r853, %r57, %r56, %p753;
	mov.u32 	%r854, 0;
	mov.b64 	%fd1151, {%r854, %r853};

$L__BB2_480:
	cvt.rn.f32.f64 	%f3163, %fd827;
	not.pred 	%p1291, %p15;
	setp.eq.f32 	%p757, %f3163, 0f3F800000;
	selp.f64 	%fd855, 0d3FF0000000000000, %fd1151, %p757;
	div.rn.f32 	%f1733, %f56, %f270;
	cvt.f64.f32 	%fd856, %f1733;
	mul.f64 	%fd292, %fd855, %fd856;
	mov.f64 	%fd1153, %fd67;
	@%p1291 bra 	$L__BB2_482;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r860}, %fd67;
	}
	xor.b32  	%r861, %r860, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r862, %temp}, %fd67;
	}
	mov.b64 	%fd1153, {%r862, %r861};

$L__BB2_482:
	@%p621 bra 	$L__BB2_486;
	bra.uni 	$L__BB2_483;

$L__BB2_486:
	mov.u32 	%r863, 0;
	mov.b64 	%fd1153, {%r863, %r95};
	bra.uni 	$L__BB2_487;

$L__BB2_483:
	setp.gt.s32 	%p760, %r93, -1;
	@%p760 bra 	$L__BB2_487;

	cvt.rzi.f64.f64 	%fd858, %fd644;
	setp.eq.f64 	%p761, %fd858, 0d4000000000000000;
	@%p761 bra 	$L__BB2_487;

	mov.f64 	%fd1153, 0dFFF8000000000000;

$L__BB2_487:
	selp.f64 	%fd1154, %fd1153, %fd50, %p194;
	@%p28 bra 	$L__BB2_492;

	setp.eq.s32 	%p763, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r864, %temp}, %fd644;
	}
	setp.eq.s32 	%p764, %r864, 0;
	and.pred  	%p765, %p763, %p764;
	@%p765 bra 	$L__BB2_491;
	bra.uni 	$L__BB2_489;

$L__BB2_491:
	mov.u32 	%r868, 0;
	mov.b64 	%fd1154, {%r868, %r98};
	bra.uni 	$L__BB2_492;

$L__BB2_489:
	and.b32  	%r865, %r93, 2147483647;
	setp.ne.s32 	%p766, %r865, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r866, %temp}, %fd49;
	}
	setp.ne.s32 	%p767, %r866, 0;
	or.pred  	%p768, %p766, %p767;
	mov.f64 	%fd1154, %fd1153;
	@%p768 bra 	$L__BB2_492;

	mov.u32 	%r867, 0;
	mov.b64 	%fd1154, {%r867, %r100};

$L__BB2_492:
	mov.f64 	%fd1156, %fd66;
	@%p607 bra 	$L__BB2_494;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r869}, %fd66;
	}
	xor.b32  	%r870, %r869, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r871, %temp}, %fd66;
	}
	mov.b64 	%fd1156, {%r871, %r870};

$L__BB2_494:
	@%p608 bra 	$L__BB2_498;
	bra.uni 	$L__BB2_495;

$L__BB2_498:
	mov.u32 	%r872, 0;
	mov.b64 	%fd1156, {%r872, %r91};
	bra.uni 	$L__BB2_499;

$L__BB2_495:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1353}, %fd643;
	}
	setp.gt.s32 	%p771, %r1353, -1;
	@%p771 bra 	$L__BB2_499;

	cvt.rzi.f64.f64 	%fd862, %fd649;
	setp.eq.f64 	%p772, %fd862, 0d4010000000000000;
	@%p772 bra 	$L__BB2_499;

	mov.f64 	%fd1156, 0dFFF8000000000000;

$L__BB2_499:
	selp.f64 	%fd1157, %fd1156, %fd36, %p189;
	@%p27 bra 	$L__BB2_504;

	setp.eq.s32 	%p774, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r873, %temp}, %fd649;
	}
	setp.eq.s32 	%p775, %r873, 0;
	and.pred  	%p776, %p774, %p775;
	@%p776 bra 	$L__BB2_503;
	bra.uni 	$L__BB2_501;

$L__BB2_503:
	mov.u32 	%r877, 0;
	mov.b64 	%fd1157, {%r877, %r94};
	bra.uni 	$L__BB2_504;

$L__BB2_501:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1354}, %fd643;
	}
	and.b32  	%r874, %r1354, 2147483647;
	setp.ne.s32 	%p777, %r874, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r875, %temp}, %fd643;
	}
	setp.ne.s32 	%p778, %r875, 0;
	or.pred  	%p779, %p777, %p778;
	mov.f64 	%fd1157, %fd1156;
	@%p779 bra 	$L__BB2_504;

	mov.u32 	%r876, 0;
	mov.b64 	%fd1157, {%r876, %r97};

$L__BB2_504:
	cvt.rn.f32.f64 	%f3167, %fd827;
	mul.f32 	%f3166, %f241, %f3167;
	cvt.rn.f32.f64 	%f3165, %fd806;
	mul.f32 	%f3164, %f240, %f3165;
	selp.f64 	%fd866, 0d3FF0000000000000, %fd1157, %p618;
	selp.f64 	%fd867, 0d3FF0000000000000, %fd1154, %p631;
	mul.f64 	%fd868, %fd867, %fd40;
	div.rn.f64 	%fd869, %fd868, %fd866;
	add.f64 	%fd870, %fd869, %fd53;
	cvt.rn.f32.f64 	%f1735, %fd870;
	mul.f32 	%f1736, %f241, %f1735;
	cvt.f64.f32 	%fd871, %f1736;
	add.f64 	%fd872, %fd292, %fd871;
	cvt.rn.f32.f64 	%f1737, %fd872;
	mul.f32 	%f1738, %f3164, %f3164;
	cvt.rn.f32.f64 	%f1739, %fd280;
	mul.f32 	%f1740, %f211, %f1739;
	fma.rn.f32 	%f1741, %f1738, %f212, %f1740;
	mul.f32 	%f1742, %f3166, %f3166;
	cvt.rn.f32.f64 	%f1743, %fd201;
	fma.rn.f32 	%f1744, %f1742, %f1743, %f1741;
	fma.rn.f32 	%f271, %f239, %f1737, %f1744;
	mul.f32 	%f1745, %f111, %f3276;
	fma.rn.f32 	%f272, %f125, %f1745, %f3275;
	mad.lo.s32 	%r878, %r1371, %r182, %r1370;
	add.s32 	%r879, %r878, %r2;
	mul.wide.s32 	%rd22, %r879, 4;
	add.s64 	%rd23, %rd1, %rd22;
	ld.global.f32 	%f273, [%rd23];
	mul.f32 	%f274, %f111, %f125;
	setp.leu.f32 	%p782, %f272, 0f3C23D70A;
	mov.f32 	%f3262, %f3263;
	@%p782 bra 	$L__BB2_506;

	div.rn.f32 	%f1746, %f273, %f272;
	add.f32 	%f3262, %f1746, 0fBF800000;

$L__BB2_506:
	@%p782 bra 	$L__BB2_521;

	cvt.f64.f32 	%fd309, %f272;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r110}, %fd309;
	}
	abs.f64 	%fd310, %fd309;
	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd310;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1159, [retval0+0];
	} // callseq 48
	setp.lt.s32 	%p785, %r110, 0;
	and.pred  	%p48, %p785, %p144;
	not.pred 	%p786, %p48;
	@%p786 bra 	$L__BB2_509;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r880}, %fd1159;
	}
	xor.b32  	%r881, %r880, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r882, %temp}, %fd1159;
	}
	mov.b64 	%fd1159, {%r882, %r881};

$L__BB2_509:
	setp.eq.f32 	%p787, %f272, 0f00000000;
	@%p787 bra 	$L__BB2_513;
	bra.uni 	$L__BB2_510;

$L__BB2_513:
	mov.u32 	%r883, 0;
	selp.b32 	%r884, %r110, 0, %p144;
	or.b32  	%r885, %r884, 2146435072;
	selp.b32 	%r886, %r885, %r884, %p146;
	mov.b64 	%fd1159, {%r883, %r886};
	bra.uni 	$L__BB2_514;

$L__BB2_510:
	setp.gt.s32 	%p788, %r110, -1;
	@%p788 bra 	$L__BB2_514;

	cvt.rzi.f64.f64 	%fd875, %fd644;
	setp.eq.f64 	%p789, %fd875, 0d4000000000000000;
	@%p789 bra 	$L__BB2_514;

	mov.f64 	%fd1159, 0dFFF8000000000000;

$L__BB2_514:
	add.f64 	%fd316, %fd309, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r887}, %fd316;
	}
	and.b32  	%r888, %r887, 2146435072;
	setp.ne.s32 	%p792, %r888, 2146435072;
	mov.f64 	%fd1160, %fd1159;
	@%p792 bra 	$L__BB2_520;

	setp.gtu.f64 	%p793, %fd310, 0d7FF0000000000000;
	mov.f64 	%fd1160, %fd316;
	@%p793 bra 	$L__BB2_520;

	setp.eq.s32 	%p794, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r889, %temp}, %fd644;
	}
	setp.eq.s32 	%p795, %r889, 0;
	and.pred  	%p796, %p794, %p795;
	@%p796 bra 	$L__BB2_519;
	bra.uni 	$L__BB2_517;

$L__BB2_519:
	mov.u32 	%r894, 0;
	setp.gt.f64 	%p803, %fd310, 0d3FF0000000000000;
	selp.b32 	%r895, 2146435072, 0, %p803;
	xor.b32  	%r896, %r895, 2146435072;
	selp.b32 	%r897, %r896, %r895, %p146;
	setp.eq.f32 	%p804, %f272, 0fBF800000;
	selp.b32 	%r898, 1072693248, %r897, %p804;
	mov.b64 	%fd1160, {%r894, %r898};
	bra.uni 	$L__BB2_520;

$L__BB2_517:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r890, %temp}, %fd309;
	}
	and.b32  	%r891, %r110, 2147483647;
	setp.ne.s32 	%p797, %r891, 2146435072;
	setp.ne.s32 	%p798, %r890, 0;
	or.pred  	%p799, %p797, %p798;
	mov.f64 	%fd1160, %fd1159;
	@%p799 bra 	$L__BB2_520;

	and.pred  	%p801, %p155, %p48;
	selp.b32 	%r892, %r57, %r56, %p801;
	mov.u32 	%r893, 0;
	mov.b64 	%fd1160, {%r893, %r892};

$L__BB2_520:
	setp.eq.f32 	%p805, %f272, 0f3F800000;
	selp.f64 	%fd878, 0d3FF0000000000000, %fd1160, %p805;
	cvt.f64.f32 	%fd879, %f273;
	div.rn.f64 	%fd880, %fd879, %fd878;
	cvt.rn.f32.f64 	%f3263, %fd880;

$L__BB2_521:
	mov.f32 	%f1748, 0f47C35000;
	min.f32 	%f1749, %f3263, %f1748;
	cvt.f64.f32 	%fd320, %f1749;
	min.f32 	%f279, %f3262, %f1748;
	fma.rn.f32 	%f3222, %f279, %f153, %f3222;
	mul.f32 	%f1750, %f279, %f154;
	cvt.f64.f32 	%fd321, %f1750;
	cvt.f64.f32 	%fd322, %f153;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r111}, %fd322;
	}
	abs.f64 	%fd323, %fd322;
	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd323;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1161, [retval0+0];
	} // callseq 49
	@%p144 bra 	$L__BB2_567;
	bra.uni 	$L__BB2_522;

$L__BB2_567:
	setp.gt.s32 	%p867, %r111, -1;
	@%p867 bra 	$L__BB2_569;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r947}, %fd1161;
	}
	xor.b32  	%r948, %r947, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r949, %temp}, %fd1161;
	}
	mov.b64 	%fd1161, {%r949, %r948};

$L__BB2_569:
	setp.eq.f32 	%p868, %f153, 0f00000000;
	@%p868 bra 	$L__BB2_573;
	bra.uni 	$L__BB2_570;

$L__BB2_573:
	mov.u32 	%r950, 0;
	or.b32  	%r951, %r111, 2146435072;
	selp.b32 	%r952, %r951, %r111, %p146;
	mov.b64 	%fd1161, {%r950, %r952};
	bra.uni 	$L__BB2_574;

$L__BB2_522:
	setp.eq.f32 	%p807, %f153, 0f00000000;
	@%p807 bra 	$L__BB2_526;
	bra.uni 	$L__BB2_523;

$L__BB2_526:
	mov.u32 	%r899, 0;
	mov.b64 	%fd1161, {%r899, %r102};
	bra.uni 	$L__BB2_527;

$L__BB2_570:
	@%p867 bra 	$L__BB2_574;

	cvt.rzi.f64.f64 	%fd923, %fd644;
	setp.eq.f64 	%p870, %fd923, 0d4000000000000000;
	@%p870 bra 	$L__BB2_574;

	mov.f64 	%fd1161, 0dFFF8000000000000;

$L__BB2_574:
	add.f64 	%fd367, %fd322, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r953}, %fd367;
	}
	and.b32  	%r954, %r953, 2146435072;
	setp.ne.s32 	%p872, %r954, 2146435072;
	mov.f64 	%fd1171, %fd1161;
	@%p872 bra 	$L__BB2_580;

	setp.gtu.f64 	%p873, %fd323, 0d7FF0000000000000;
	mov.f64 	%fd1171, %fd367;
	@%p873 bra 	$L__BB2_580;

	setp.eq.s32 	%p874, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r955, %temp}, %fd644;
	}
	setp.eq.s32 	%p875, %r955, 0;
	and.pred  	%p876, %p874, %p875;
	@%p876 bra 	$L__BB2_579;
	bra.uni 	$L__BB2_577;

$L__BB2_579:
	mov.u32 	%r960, 0;
	setp.gt.f64 	%p884, %fd323, 0d3FF0000000000000;
	selp.b32 	%r961, 2146435072, 0, %p884;
	xor.b32  	%r962, %r961, 2146435072;
	selp.b32 	%r963, %r962, %r961, %p146;
	setp.eq.f32 	%p885, %f153, 0fBF800000;
	selp.b32 	%r964, 1072693248, %r963, %p885;
	mov.b64 	%fd1171, {%r960, %r964};
	bra.uni 	$L__BB2_580;

$L__BB2_523:
	setp.gt.s32 	%p808, %r111, -1;
	@%p808 bra 	$L__BB2_527;

	cvt.rzi.f64.f64 	%fd883, %fd644;
	setp.eq.f64 	%p809, %fd883, 0d4000000000000000;
	@%p809 bra 	$L__BB2_527;

	mov.f64 	%fd1161, 0dFFF8000000000000;

$L__BB2_527:
	add.f64 	%fd327, %fd322, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r900}, %fd327;
	}
	and.b32  	%r901, %r900, 2146435072;
	setp.ne.s32 	%p810, %r901, 2146435072;
	mov.f64 	%fd1162, %fd1161;
	@%p810 bra 	$L__BB2_533;

	setp.gtu.f64 	%p811, %fd323, 0d7FF0000000000000;
	mov.f64 	%fd1162, %fd327;
	@%p811 bra 	$L__BB2_533;

	setp.eq.s32 	%p812, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r902, %temp}, %fd644;
	}
	setp.eq.s32 	%p813, %r902, 0;
	and.pred  	%p814, %p812, %p813;
	@%p814 bra 	$L__BB2_532;
	bra.uni 	$L__BB2_530;

$L__BB2_532:
	mov.u32 	%r906, 0;
	setp.gt.f64 	%p819, %fd323, 0d3FF0000000000000;
	selp.b32 	%r907, 2146435072, 0, %p819;
	xor.b32  	%r908, %r907, 2146435072;
	selp.b32 	%r909, %r908, %r907, %p146;
	setp.eq.f32 	%p820, %f153, 0fBF800000;
	selp.b32 	%r910, 1072693248, %r909, %p820;
	mov.b64 	%fd1162, {%r906, %r910};
	bra.uni 	$L__BB2_533;

$L__BB2_577:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r956, %temp}, %fd322;
	}
	and.b32  	%r957, %r111, 2147483647;
	setp.ne.s32 	%p877, %r957, 2146435072;
	setp.ne.s32 	%p878, %r956, 0;
	or.pred  	%p879, %p877, %p878;
	mov.f64 	%fd1171, %fd1161;
	@%p879 bra 	$L__BB2_580;

	setp.lt.s32 	%p880, %r111, 0;
	mov.u32 	%r958, 0;
	and.pred  	%p882, %p155, %p880;
	selp.b32 	%r959, %r57, %r56, %p882;
	mov.b64 	%fd1171, {%r958, %r959};

$L__BB2_580:
	setp.eq.f32 	%p886, %f153, 0f3F800000;
	selp.f64 	%fd926, 0d3FF0000000000000, %fd1171, %p886;
	mul.f64 	%fd927, %fd926, %fd320;
	sub.f64 	%fd928, %fd321, %fd927;
	cvt.f64.f32 	%fd929, %f3227;
	add.f64 	%fd1185, %fd928, %fd929;
	cvt.f64.f32 	%fd372, %f183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r115}, %fd372;
	}
	abs.f64 	%fd373, %fd372;
	{ // callseq 53, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd373;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1173, [retval0+0];
	} // callseq 53
	setp.gt.s32 	%p887, %r115, -1;
	@%p887 bra 	$L__BB2_582;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r965}, %fd1173;
	}
	xor.b32  	%r966, %r965, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r967, %temp}, %fd1173;
	}
	mov.b64 	%fd1173, {%r967, %r966};

$L__BB2_582:
	setp.eq.f32 	%p888, %f183, 0f00000000;
	@%p888 bra 	$L__BB2_586;
	bra.uni 	$L__BB2_583;

$L__BB2_586:
	mov.u32 	%r968, 0;
	or.b32  	%r969, %r115, 2146435072;
	selp.b32 	%r970, %r969, %r115, %p146;
	mov.b64 	%fd1173, {%r968, %r970};
	bra.uni 	$L__BB2_587;

$L__BB2_583:
	@%p887 bra 	$L__BB2_587;

	cvt.rzi.f64.f64 	%fd932, %fd644;
	setp.eq.f64 	%p890, %fd932, 0d4000000000000000;
	@%p890 bra 	$L__BB2_587;

	mov.f64 	%fd1173, 0dFFF8000000000000;

$L__BB2_587:
	add.f64 	%fd379, %fd372, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r971}, %fd379;
	}
	and.b32  	%r972, %r971, 2146435072;
	setp.ne.s32 	%p892, %r972, 2146435072;
	mov.f64 	%fd1174, %fd1173;
	@%p892 bra 	$L__BB2_593;

	setp.gtu.f64 	%p893, %fd373, 0d7FF0000000000000;
	mov.f64 	%fd1174, %fd379;
	@%p893 bra 	$L__BB2_593;

	setp.eq.s32 	%p894, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r973, %temp}, %fd644;
	}
	setp.eq.s32 	%p895, %r973, 0;
	and.pred  	%p896, %p894, %p895;
	@%p896 bra 	$L__BB2_592;
	bra.uni 	$L__BB2_590;

$L__BB2_592:
	mov.u32 	%r978, 0;
	setp.gt.f64 	%p904, %fd373, 0d3FF0000000000000;
	selp.b32 	%r979, 2146435072, 0, %p904;
	xor.b32  	%r980, %r979, 2146435072;
	selp.b32 	%r981, %r980, %r979, %p146;
	setp.eq.f32 	%p905, %f183, 0fBF800000;
	selp.b32 	%r982, 1072693248, %r981, %p905;
	mov.b64 	%fd1174, {%r978, %r982};
	bra.uni 	$L__BB2_593;

$L__BB2_530:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r903, %temp}, %fd322;
	}
	and.b32  	%r904, %r111, 2147483647;
	setp.ne.s32 	%p815, %r904, 2146435072;
	setp.ne.s32 	%p816, %r903, 0;
	or.pred  	%p817, %p815, %p816;
	mov.f64 	%fd1162, %fd1161;
	@%p817 bra 	$L__BB2_533;

	mov.u32 	%r905, 0;
	mov.b64 	%fd1162, {%r905, %r56};

$L__BB2_533:
	setp.eq.f32 	%p821, %f153, 0f3F800000;
	selp.f64 	%fd886, 0d3FF0000000000000, %fd1162, %p821;
	mul.f64 	%fd887, %fd886, %fd320;
	sub.f64 	%fd888, %fd321, %fd887;
	cvt.f64.f32 	%fd889, %f3227;
	add.f64 	%fd1185, %fd888, %fd889;
	cvt.f64.f32 	%fd332, %f183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd332;
	}
	abs.f64 	%fd333, %fd332;
	setp.eq.f32 	%p822, %f183, 0f00000000;
	@%p822 bra 	$L__BB2_537;
	bra.uni 	$L__BB2_534;

$L__BB2_537:
	mov.u32 	%r911, 0;
	mov.b64 	%fd1163, {%r911, %r102};
	bra.uni 	$L__BB2_538;

$L__BB2_534:
	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd333;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1163, [retval0+0];
	} // callseq 50
	setp.gt.s32 	%p823, %r112, -1;
	@%p823 bra 	$L__BB2_538;

	cvt.rzi.f64.f64 	%fd892, %fd644;
	setp.eq.f64 	%p824, %fd892, 0d4000000000000000;
	@%p824 bra 	$L__BB2_538;

	mov.f64 	%fd1163, 0dFFF8000000000000;

$L__BB2_538:
	add.f64 	%fd337, %fd332, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r912}, %fd337;
	}
	and.b32  	%r913, %r912, 2146435072;
	setp.ne.s32 	%p825, %r913, 2146435072;
	mov.f64 	%fd1164, %fd1163;
	@%p825 bra 	$L__BB2_544;

	setp.gtu.f64 	%p826, %fd333, 0d7FF0000000000000;
	mov.f64 	%fd1164, %fd337;
	@%p826 bra 	$L__BB2_544;

	setp.eq.s32 	%p827, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r914, %temp}, %fd644;
	}
	setp.eq.s32 	%p828, %r914, 0;
	and.pred  	%p829, %p827, %p828;
	@%p829 bra 	$L__BB2_543;
	bra.uni 	$L__BB2_541;

$L__BB2_543:
	mov.u32 	%r918, 0;
	setp.gt.f64 	%p834, %fd333, 0d3FF0000000000000;
	selp.b32 	%r919, 2146435072, 0, %p834;
	xor.b32  	%r920, %r919, 2146435072;
	selp.b32 	%r921, %r920, %r919, %p146;
	setp.eq.f32 	%p835, %f183, 0fBF800000;
	selp.b32 	%r922, 1072693248, %r921, %p835;
	mov.b64 	%fd1164, {%r918, %r922};
	bra.uni 	$L__BB2_544;

$L__BB2_590:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r974, %temp}, %fd372;
	}
	and.b32  	%r975, %r115, 2147483647;
	setp.ne.s32 	%p897, %r975, 2146435072;
	setp.ne.s32 	%p898, %r974, 0;
	or.pred  	%p899, %p897, %p898;
	mov.f64 	%fd1174, %fd1173;
	@%p899 bra 	$L__BB2_593;

	setp.lt.s32 	%p900, %r115, 0;
	mov.u32 	%r976, 0;
	and.pred  	%p902, %p155, %p900;
	selp.b32 	%r977, %r57, %r56, %p902;
	mov.b64 	%fd1174, {%r976, %r977};

$L__BB2_593:
	setp.eq.f32 	%p906, %f183, 0f3F800000;
	selp.f64 	%fd935, 0d3FF0000000000000, %fd1174, %p906;
	mul.f64 	%fd936, %fd935, %fd320;
	mul.f32 	%f1754, %f279, %f184;
	cvt.f64.f32 	%fd937, %f1754;
	sub.f64 	%fd938, %fd937, %fd936;
	cvt.f64.f32 	%fd939, %f3226;
	add.f64 	%fd1184, %fd938, %fd939;
	cvt.f64.f32 	%fd384, %f274;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r116}, %fd384;
	}
	abs.f64 	%fd385, %fd384;
	{ // callseq 54, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd385;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1176, [retval0+0];
	} // callseq 54
	setp.gt.s32 	%p907, %r116, -1;
	@%p907 bra 	$L__BB2_595;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r983}, %fd1176;
	}
	xor.b32  	%r984, %r983, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r985, %temp}, %fd1176;
	}
	mov.b64 	%fd1176, {%r985, %r984};

$L__BB2_595:
	setp.eq.f32 	%p908, %f274, 0f00000000;
	@%p908 bra 	$L__BB2_599;
	bra.uni 	$L__BB2_596;

$L__BB2_599:
	mov.u32 	%r986, 0;
	or.b32  	%r987, %r116, 2146435072;
	selp.b32 	%r988, %r987, %r116, %p146;
	mov.b64 	%fd1176, {%r986, %r988};
	bra.uni 	$L__BB2_600;

$L__BB2_596:
	@%p907 bra 	$L__BB2_600;

	cvt.rzi.f64.f64 	%fd942, %fd644;
	setp.eq.f64 	%p910, %fd942, 0d4000000000000000;
	@%p910 bra 	$L__BB2_600;

	mov.f64 	%fd1176, 0dFFF8000000000000;

$L__BB2_600:
	add.f64 	%fd391, %fd384, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r989}, %fd391;
	}
	and.b32  	%r990, %r989, 2146435072;
	setp.ne.s32 	%p912, %r990, 2146435072;
	mov.f64 	%fd1177, %fd1176;
	@%p912 bra 	$L__BB2_606;

	setp.gtu.f64 	%p913, %fd385, 0d7FF0000000000000;
	mov.f64 	%fd1177, %fd391;
	@%p913 bra 	$L__BB2_606;

	setp.eq.s32 	%p914, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r991, %temp}, %fd644;
	}
	setp.eq.s32 	%p915, %r991, 0;
	and.pred  	%p916, %p914, %p915;
	@%p916 bra 	$L__BB2_605;
	bra.uni 	$L__BB2_603;

$L__BB2_605:
	mov.u32 	%r996, 0;
	setp.gt.f64 	%p924, %fd385, 0d3FF0000000000000;
	selp.b32 	%r997, 2146435072, 0, %p924;
	xor.b32  	%r998, %r997, 2146435072;
	selp.b32 	%r999, %r998, %r997, %p146;
	setp.eq.f32 	%p925, %f274, 0fBF800000;
	selp.b32 	%r1000, 1072693248, %r999, %p925;
	mov.b64 	%fd1177, {%r996, %r1000};
	bra.uni 	$L__BB2_606;

$L__BB2_541:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r915, %temp}, %fd332;
	}
	and.b32  	%r916, %r112, 2147483647;
	setp.ne.s32 	%p830, %r916, 2146435072;
	setp.ne.s32 	%p831, %r915, 0;
	or.pred  	%p832, %p830, %p831;
	mov.f64 	%fd1164, %fd1163;
	@%p832 bra 	$L__BB2_544;

	mov.u32 	%r917, 0;
	mov.b64 	%fd1164, {%r917, %r56};

$L__BB2_544:
	setp.eq.f32 	%p836, %f183, 0f3F800000;
	selp.f64 	%fd895, 0d3FF0000000000000, %fd1164, %p836;
	mul.f64 	%fd896, %fd895, %fd320;
	mul.f32 	%f1751, %f279, %f184;
	cvt.f64.f32 	%fd897, %f1751;
	sub.f64 	%fd898, %fd897, %fd896;
	cvt.f64.f32 	%fd899, %f3226;
	add.f64 	%fd1184, %fd898, %fd899;
	cvt.f64.f32 	%fd342, %f274;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd342;
	}
	abs.f64 	%fd343, %fd342;
	setp.eq.f32 	%p837, %f274, 0f00000000;
	@%p837 bra 	$L__BB2_548;
	bra.uni 	$L__BB2_545;

$L__BB2_548:
	mov.u32 	%r923, 0;
	mov.b64 	%fd1165, {%r923, %r102};
	bra.uni 	$L__BB2_549;

$L__BB2_545:
	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1165, [retval0+0];
	} // callseq 51
	setp.gt.s32 	%p838, %r113, -1;
	@%p838 bra 	$L__BB2_549;

	cvt.rzi.f64.f64 	%fd902, %fd644;
	setp.eq.f64 	%p839, %fd902, 0d4000000000000000;
	@%p839 bra 	$L__BB2_549;

	mov.f64 	%fd1165, 0dFFF8000000000000;

$L__BB2_549:
	add.f64 	%fd347, %fd342, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r924}, %fd347;
	}
	and.b32  	%r925, %r924, 2146435072;
	setp.ne.s32 	%p840, %r925, 2146435072;
	mov.f64 	%fd1166, %fd1165;
	@%p840 bra 	$L__BB2_555;

	setp.gtu.f64 	%p841, %fd343, 0d7FF0000000000000;
	mov.f64 	%fd1166, %fd347;
	@%p841 bra 	$L__BB2_555;

	setp.eq.s32 	%p842, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r926, %temp}, %fd644;
	}
	setp.eq.s32 	%p843, %r926, 0;
	and.pred  	%p844, %p842, %p843;
	@%p844 bra 	$L__BB2_554;
	bra.uni 	$L__BB2_552;

$L__BB2_554:
	mov.u32 	%r930, 0;
	setp.gt.f64 	%p849, %fd343, 0d3FF0000000000000;
	selp.b32 	%r931, 2146435072, 0, %p849;
	xor.b32  	%r932, %r931, 2146435072;
	selp.b32 	%r933, %r932, %r931, %p146;
	setp.eq.f32 	%p850, %f274, 0fBF800000;
	selp.b32 	%r934, 1072693248, %r933, %p850;
	mov.b64 	%fd1166, {%r930, %r934};
	bra.uni 	$L__BB2_555;

$L__BB2_603:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r992, %temp}, %fd384;
	}
	and.b32  	%r993, %r116, 2147483647;
	setp.ne.s32 	%p917, %r993, 2146435072;
	setp.ne.s32 	%p918, %r992, 0;
	or.pred  	%p919, %p917, %p918;
	mov.f64 	%fd1177, %fd1176;
	@%p919 bra 	$L__BB2_606;

	setp.lt.s32 	%p920, %r116, 0;
	mov.u32 	%r994, 0;
	and.pred  	%p922, %p155, %p920;
	selp.b32 	%r995, %r57, %r56, %p922;
	mov.b64 	%fd1177, {%r994, %r995};

$L__BB2_606:
	mul.f32 	%f1755, %f279, 0f00000000;
	cvt.f64.f32 	%fd945, %f1755;
	setp.eq.f32 	%p926, %f274, 0f3F800000;
	selp.f64 	%fd946, 0d3FF0000000000000, %fd1177, %p926;
	mul.f64 	%fd947, %fd946, %fd320;
	sub.f64 	%fd948, %fd945, %fd947;
	cvt.f64.f32 	%fd949, %f3225;
	add.f64 	%fd1183, %fd948, %fd949;
	cvt.f64.f32 	%fd950, %f3224;
	sub.f64 	%fd951, %fd945, %fd320;
	add.f64 	%fd1182, %fd951, %fd950;
	cvt.f64.f32 	%fd397, %f246;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r117}, %fd397;
	}
	abs.f64 	%fd398, %fd397;
	{ // callseq 55, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd398;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1179, [retval0+0];
	} // callseq 55
	setp.gt.s32 	%p927, %r117, -1;
	@%p927 bra 	$L__BB2_608;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1001}, %fd1179;
	}
	xor.b32  	%r1002, %r1001, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1003, %temp}, %fd1179;
	}
	mov.b64 	%fd1179, {%r1003, %r1002};

$L__BB2_608:
	setp.eq.f32 	%p928, %f246, 0f00000000;
	@%p928 bra 	$L__BB2_612;
	bra.uni 	$L__BB2_609;

$L__BB2_612:
	mov.u32 	%r1004, 0;
	or.b32  	%r1005, %r117, 2146435072;
	selp.b32 	%r1006, %r1005, %r117, %p146;
	mov.b64 	%fd1179, {%r1004, %r1006};
	bra.uni 	$L__BB2_613;

$L__BB2_609:
	@%p927 bra 	$L__BB2_613;

	cvt.rzi.f64.f64 	%fd954, %fd644;
	setp.eq.f64 	%p930, %fd954, 0d4000000000000000;
	@%p930 bra 	$L__BB2_613;

	mov.f64 	%fd1179, 0dFFF8000000000000;

$L__BB2_613:
	add.f64 	%fd404, %fd397, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1007}, %fd404;
	}
	and.b32  	%r1008, %r1007, 2146435072;
	setp.ne.s32 	%p932, %r1008, 2146435072;
	mov.f64 	%fd1180, %fd1179;
	@%p932 bra 	$L__BB2_619;

	setp.gtu.f64 	%p933, %fd398, 0d7FF0000000000000;
	mov.f64 	%fd1180, %fd404;
	@%p933 bra 	$L__BB2_619;

	setp.eq.s32 	%p934, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1009, %temp}, %fd644;
	}
	setp.eq.s32 	%p935, %r1009, 0;
	and.pred  	%p936, %p934, %p935;
	@%p936 bra 	$L__BB2_618;
	bra.uni 	$L__BB2_616;

$L__BB2_618:
	mov.u32 	%r1014, 0;
	setp.gt.f64 	%p944, %fd398, 0d3FF0000000000000;
	selp.b32 	%r1015, 2146435072, 0, %p944;
	xor.b32  	%r1016, %r1015, 2146435072;
	selp.b32 	%r1017, %r1016, %r1015, %p146;
	setp.eq.f32 	%p945, %f246, 0fBF800000;
	selp.b32 	%r1018, 1072693248, %r1017, %p945;
	mov.b64 	%fd1180, {%r1014, %r1018};
	bra.uni 	$L__BB2_619;

$L__BB2_552:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r927, %temp}, %fd342;
	}
	and.b32  	%r928, %r113, 2147483647;
	setp.ne.s32 	%p845, %r928, 2146435072;
	setp.ne.s32 	%p846, %r927, 0;
	or.pred  	%p847, %p845, %p846;
	mov.f64 	%fd1166, %fd1165;
	@%p847 bra 	$L__BB2_555;

	mov.u32 	%r929, 0;
	mov.b64 	%fd1166, {%r929, %r56};

$L__BB2_555:
	mul.f32 	%f1752, %f279, 0f00000000;
	cvt.f64.f32 	%fd905, %f1752;
	setp.eq.f32 	%p851, %f274, 0f3F800000;
	selp.f64 	%fd906, 0d3FF0000000000000, %fd1166, %p851;
	mul.f64 	%fd907, %fd906, %fd320;
	sub.f64 	%fd908, %fd905, %fd907;
	cvt.f64.f32 	%fd909, %f3225;
	add.f64 	%fd1183, %fd908, %fd909;
	cvt.f64.f32 	%fd910, %f3224;
	sub.f64 	%fd911, %fd905, %fd320;
	add.f64 	%fd1182, %fd911, %fd910;
	cvt.f64.f32 	%fd353, %f246;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd353;
	}
	abs.f64 	%fd354, %fd353;
	setp.eq.f32 	%p852, %f246, 0f00000000;
	@%p852 bra 	$L__BB2_559;
	bra.uni 	$L__BB2_556;

$L__BB2_559:
	mov.u32 	%r935, 0;
	mov.b64 	%fd1167, {%r935, %r102};
	bra.uni 	$L__BB2_560;

$L__BB2_556:
	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd354;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd644;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1167, [retval0+0];
	} // callseq 52
	setp.gt.s32 	%p853, %r114, -1;
	@%p853 bra 	$L__BB2_560;

	cvt.rzi.f64.f64 	%fd914, %fd644;
	setp.eq.f64 	%p854, %fd914, 0d4000000000000000;
	@%p854 bra 	$L__BB2_560;

	mov.f64 	%fd1167, 0dFFF8000000000000;

$L__BB2_560:
	add.f64 	%fd358, %fd353, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r936}, %fd358;
	}
	and.b32  	%r937, %r936, 2146435072;
	setp.ne.s32 	%p855, %r937, 2146435072;
	mov.f64 	%fd1168, %fd1167;
	@%p855 bra 	$L__BB2_566;

	setp.gtu.f64 	%p856, %fd354, 0d7FF0000000000000;
	mov.f64 	%fd1168, %fd358;
	@%p856 bra 	$L__BB2_566;

	setp.eq.s32 	%p857, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r938, %temp}, %fd644;
	}
	setp.eq.s32 	%p858, %r938, 0;
	and.pred  	%p859, %p857, %p858;
	@%p859 bra 	$L__BB2_565;
	bra.uni 	$L__BB2_563;

$L__BB2_565:
	mov.u32 	%r942, 0;
	setp.gt.f64 	%p864, %fd354, 0d3FF0000000000000;
	selp.b32 	%r943, 2146435072, 0, %p864;
	xor.b32  	%r944, %r943, 2146435072;
	selp.b32 	%r945, %r944, %r943, %p146;
	setp.eq.f32 	%p865, %f246, 0fBF800000;
	selp.b32 	%r946, 1072693248, %r945, %p865;
	mov.b64 	%fd1168, {%r942, %r946};
	bra.uni 	$L__BB2_566;

$L__BB2_616:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1010, %temp}, %fd397;
	}
	and.b32  	%r1011, %r117, 2147483647;
	setp.ne.s32 	%p937, %r1011, 2146435072;
	setp.ne.s32 	%p938, %r1010, 0;
	or.pred  	%p939, %p937, %p938;
	mov.f64 	%fd1180, %fd1179;
	@%p939 bra 	$L__BB2_619;

	setp.lt.s32 	%p940, %r117, 0;
	mov.u32 	%r1012, 0;
	and.pred  	%p942, %p155, %p940;
	selp.b32 	%r1013, %r57, %r56, %p942;
	mov.b64 	%fd1180, {%r1012, %r1013};

$L__BB2_619:
	setp.eq.f32 	%p946, %f246, 0f3F800000;
	selp.f64 	%fd957, 0d3FF0000000000000, %fd1180, %p946;
	mul.f64 	%fd958, %fd957, %fd320;
	mul.f32 	%f1756, %f279, %f271;
	cvt.f64.f32 	%fd959, %f1756;
	sub.f64 	%fd960, %fd959, %fd958;
	cvt.f64.f32 	%fd961, %f3223;
	add.f64 	%fd1181, %fd960, %fd961;
	bra.uni 	$L__BB2_620;

$L__BB2_563:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r939, %temp}, %fd353;
	}
	and.b32  	%r940, %r114, 2147483647;
	setp.ne.s32 	%p860, %r940, 2146435072;
	setp.ne.s32 	%p861, %r939, 0;
	or.pred  	%p862, %p860, %p861;
	mov.f64 	%fd1168, %fd1167;
	@%p862 bra 	$L__BB2_566;

	mov.u32 	%r941, 0;
	mov.b64 	%fd1168, {%r941, %r56};

$L__BB2_566:
	setp.eq.f32 	%p866, %f246, 0f3F800000;
	selp.f64 	%fd917, 0d3FF0000000000000, %fd1168, %p866;
	mul.f64 	%fd918, %fd917, %fd320;
	mul.f32 	%f1753, %f279, %f271;
	cvt.f64.f32 	%fd919, %f1753;
	sub.f64 	%fd920, %fd919, %fd918;
	cvt.f64.f32 	%fd921, %f3223;
	add.f64 	%fd1181, %fd920, %fd921;

$L__BB2_620:
	cvt.rn.f32.f64 	%f3227, %fd1185;
	cvt.rn.f32.f64 	%f3226, %fd1184;
	cvt.rn.f32.f64 	%f3225, %fd1183;
	cvt.rn.f32.f64 	%f3224, %fd1182;
	cvt.rn.f32.f64 	%f3223, %fd1181;
	fma.rn.f32 	%f3221, %f279, %f183, %f3221;
	fma.rn.f32 	%f3220, %f279, %f274, %f3220;
	add.f32 	%f3219, %f3219, %f279;
	fma.rn.f32 	%f3218, %f279, %f246, %f3218;
	add.s32 	%r1371, %r1371, 1;
	setp.lt.s32 	%p947, %r1371, %r182;
	@%p947 bra 	$L__BB2_56;

	add.s32 	%r1370, %r1370, 1;
	setp.lt.s32 	%p948, %r1370, %r182;
	@%p948 bra 	$L__BB2_55;

$L__BB2_622:
	ld.param.u32 	%r1355, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_10];
	div.rn.f32 	%f1757, %f3222, %f3227;
	mov.f32 	%f1758, 0fBF800000;
	max.f32 	%f1759, %f1757, %f1758;
	mov.f32 	%f1760, 0f3F800000;
	min.f32 	%f1761, %f1759, %f1760;
	sub.f32 	%f3278, %f3278, %f1761;
	div.rn.f32 	%f1762, %f3221, %f3226;
	max.f32 	%f1763, %f1762, %f1758;
	min.f32 	%f1764, %f1763, %f1760;
	sub.f32 	%f3277, %f3277, %f1764;
	neg.f32 	%f1765, %f3276;
	div.rn.f32 	%f1766, %f3220, %f3225;
	max.f32 	%f1767, %f1766, %f1765;
	min.f32 	%f1768, %f1767, %f3276;
	sub.f32 	%f1769, %f3276, %f1768;
	neg.f32 	%f1770, %f3275;
	div.rn.f32 	%f1771, %f3219, %f3224;
	max.f32 	%f1772, %f1771, %f1770;
	min.f32 	%f1773, %f1772, %f3275;
	sub.f32 	%f1774, %f3275, %f1773;
	div.rn.f32 	%f1775, %f3218, %f3223;
	mov.f32 	%f1776, 0fBDCCCCCD;
	max.f32 	%f1777, %f1775, %f1776;
	mov.f32 	%f1778, 0f3DCCCCCD;
	min.f32 	%f1779, %f1777, %f1778;
	sub.f32 	%f3274, %f3274, %f1779;
	max.f32 	%f3276, %f1769, %f1760;
	mov.f32 	%f1780, 0f3C23D70A;
	max.f32 	%f3275, %f1774, %f1780;
	add.s32 	%r1369, %r1369, 1;
	setp.lt.s32 	%p949, %r1369, %r1355;
	@%p949 bra 	$L__BB2_53;

$L__BB2_623:
	mov.f32 	%f3295, %f545;
	mov.f32 	%f3296, %f545;
	mov.f32 	%f3297, %f545;
	mov.f32 	%f3300, %f545;
	mov.f32 	%f3304, %f545;
	mov.f32 	%f3298, %f545;
	mov.f32 	%f3299, %f545;
	mov.f32 	%f3301, %f545;
	mov.f32 	%f3305, %f545;
	mov.f32 	%f3302, %f545;
	mov.f32 	%f3303, %f545;
	mov.f32 	%f3306, %f545;
	mov.f32 	%f3307, %f545;
	mov.f32 	%f3308, %f545;
	mov.f32 	%f3309, %f545;
	mov.f32 	%f3341, %f545;
	@%p80 bra 	$L__BB2_884;

	sub.f32 	%f310, %f3274, %f540;
	div.rn.f32 	%f311, %f310, %f541;
	cvt.f64.f32 	%fd414, %f311;
	add.f64 	%fd415, %fd414, 0d4000000000000000;
	mov.f64 	%fd962, 0d4000000000000000;
	cvt.f64.f32 	%fd416, %f536;
	setp.eq.f32 	%p951, %f311, 0fBF800000;
	add.f64 	%fd417, %fd414, 0d4008000000000000;
	mov.f64 	%fd963, 0d4008000000000000;
	cvt.f64.f32 	%fd418, %f538;
	add.f64 	%fd419, %fd414, 0d4010000000000000;
	mov.f64 	%fd964, 0d4010000000000000;
	add.f32 	%f312, %f3274, %f540;
	div.rn.f32 	%f313, %f312, %f541;
	cvt.f64.f32 	%fd420, %f313;
	add.f64 	%fd421, %fd420, 0d4000000000000000;
	cvt.f64.f32 	%fd422, %f537;
	setp.eq.f32 	%p952, %f313, 0fBF800000;
	add.f64 	%fd423, %fd420, 0d4008000000000000;
	cvt.f64.f32 	%fd424, %f539;
	add.f64 	%fd425, %fd420, 0d4010000000000000;
	div.rn.f32 	%f314, %f3276, 0fC0206C98;
	mul.f32 	%f315, %f535, 0f3F000000;
	mul.f32 	%f316, %f542, 0f3F000000;
	add.f32 	%f1813, %f310, %f310;
	mov.f32 	%f1814, 0f40000000;
	mul.f32 	%f1815, %f541, %f541;
	div.rn.f32 	%f1816, %f1813, %f1815;
	cvt.f64.f32 	%fd426, %f1816;
	mul.f32 	%f1817, %f536, 0f40400000;
	cvt.f64.f32 	%fd427, %f1817;
	cvt.f64.f32 	%fd428, %f310;
	add.f64 	%fd429, %fd428, 0d4000000000000000;
	mul.f32 	%f1818, %f1815, %f541;
	cvt.f64.f32 	%fd430, %f1818;
	mul.f32 	%f1819, %f538, 0f40800000;
	cvt.f64.f32 	%fd431, %f1819;
	setp.eq.f32 	%p953, %f310, 0fBF800000;
	add.f64 	%fd432, %fd428, 0d4008000000000000;
	cvt.f64.f32 	%fd433, %f541;
	add.f64 	%fd434, %fd433, 0d4010000000000000;
	add.f32 	%f1820, %f312, %f312;
	div.rn.f32 	%f1821, %f1820, %f1815;
	cvt.f64.f32 	%fd435, %f1821;
	mul.f32 	%f1822, %f537, 0f40400000;
	cvt.f64.f32 	%fd436, %f1822;
	cvt.f64.f32 	%fd437, %f312;
	add.f64 	%fd438, %fd437, 0d4000000000000000;
	mul.f32 	%f1823, %f539, 0f40800000;
	cvt.f64.f32 	%fd439, %f1823;
	setp.eq.f32 	%p954, %f312, 0fBF800000;
	add.f64 	%fd440, %fd437, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd414;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1020}, %fd962;
	}
	and.b32  	%r1021, %r1020, 2146435072;
	setp.eq.s32 	%p955, %r1021, 1062207488;
	abs.f64 	%fd965, %fd414;
	{ // callseq 56, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd965;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd962;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd441, [retval0+0];
	} // callseq 56
	mov.u32 	%r1019, 0;
	setp.lt.s32 	%p956, %r121, 0;
	and.pred  	%p49, %p956, %p955;
	selp.b32 	%r1022, %r121, 0, %p955;
	setp.lt.s32 	%p957, %r1020, 0;
	or.b32  	%r1023, %r1022, 2146435072;
	selp.b32 	%r122, %r1023, %r1022, %p957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1024}, %fd415;
	}
	and.b32  	%r123, %r1024, 2146435072;
	setp.ne.s32 	%p958, %r123, 2146435072;
	setp.gtu.f64 	%p959, %fd965, 0d7FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1025}, %fd963;
	}
	and.b32  	%r1026, %r1025, 2146435072;
	setp.eq.s32 	%p960, %r1026, 1073741824;
	{ // callseq 57, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd965;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd963;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd442, [retval0+0];
	} // callseq 57
	and.pred  	%p50, %p956, %p960;
	and.b32  	%r124, %r1020, 2147483647;
	setp.gt.f64 	%p961, %fd965, 0d3FF0000000000000;
	selp.b32 	%r1027, 2146435072, 0, %p961;
	xor.b32  	%r1028, %r1027, 2146435072;
	selp.b32 	%r1029, %r1028, %r1027, %p957;
	selp.b32 	%r125, 1072693248, %r1029, %p951;
	and.b32  	%r126, %r121, 2147483647;
	selp.b32 	%r1030, %r121, 0, %p960;
	setp.lt.s32 	%p962, %r1025, 0;
	or.b32  	%r1031, %r1030, 2146435072;
	selp.b32 	%r127, %r1031, %r1030, %p962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1032}, %fd417;
	}
	and.b32  	%r128, %r1032, 2146435072;
	setp.ne.s32 	%p963, %r128, 2146435072;
	setp.gt.s32 	%p964, %r1020, -1;
	selp.b32 	%r1033, 2146435072, 0, %p964;
	setp.ne.s32 	%p965, %r124, 1071644672;
	and.pred  	%p966, %p965, %p49;
	or.b32  	%r1034, %r1033, -2147483648;
	selp.b32 	%r129, %r1034, %r1033, %p966;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1035}, %fd964;
	}
	and.b32  	%r1036, %r1035, 2146435072;
	setp.eq.s32 	%p967, %r1036, 1072693248;
	{ // callseq 58, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd965;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd964;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd443, [retval0+0];
	} // callseq 58
	and.pred  	%p51, %p956, %p967;
	and.b32  	%r130, %r1025, 2147483647;
	selp.b32 	%r1037, %r1028, %r1027, %p962;
	selp.b32 	%r131, 1072693248, %r1037, %p951;
	selp.b32 	%r1038, %r121, 0, %p967;
	setp.lt.s32 	%p968, %r1035, 0;
	or.b32  	%r1039, %r1038, 2146435072;
	selp.b32 	%r132, %r1039, %r1038, %p968;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1040}, %fd419;
	}
	and.b32  	%r133, %r1040, 2146435072;
	setp.ne.s32 	%p969, %r133, 2146435072;
	setp.gt.s32 	%p970, %r1025, -1;
	selp.b32 	%r1041, 2146435072, 0, %p970;
	setp.ne.s32 	%p971, %r130, 1071644672;
	and.pred  	%p972, %p971, %p50;
	or.b32  	%r1042, %r1041, -2147483648;
	selp.b32 	%r134, %r1042, %r1041, %p972;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r135}, %fd420;
	}
	abs.f64 	%fd966, %fd420;
	{ // callseq 59, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd966;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd962;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd444, [retval0+0];
	} // callseq 59
	setp.lt.s32 	%p973, %r135, 0;
	and.pred  	%p52, %p973, %p955;
	and.b32  	%r136, %r1035, 2147483647;
	selp.b32 	%r1043, %r1028, %r1027, %p968;
	selp.b32 	%r137, 1072693248, %r1043, %p951;
	selp.b32 	%r1044, %r135, 0, %p955;
	or.b32  	%r1045, %r1044, 2146435072;
	selp.b32 	%r138, %r1045, %r1044, %p957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1046}, %fd421;
	}
	and.b32  	%r139, %r1046, 2146435072;
	setp.ne.s32 	%p974, %r139, 2146435072;
	setp.gt.s32 	%p975, %r1035, -1;
	selp.b32 	%r1047, 2146435072, 0, %p975;
	setp.ne.s32 	%p976, %r136, 1071644672;
	and.pred  	%p977, %p976, %p51;
	or.b32  	%r1048, %r1047, -2147483648;
	selp.b32 	%r140, %r1048, %r1047, %p977;
	setp.gtu.f64 	%p978, %fd966, 0d7FF0000000000000;
	{ // callseq 60, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd966;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd963;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd445, [retval0+0];
	} // callseq 60
	and.pred  	%p53, %p973, %p960;
	setp.gt.f64 	%p979, %fd966, 0d3FF0000000000000;
	selp.b32 	%r1049, 2146435072, 0, %p979;
	xor.b32  	%r1050, %r1049, 2146435072;
	selp.b32 	%r1051, %r1050, %r1049, %p957;
	selp.b32 	%r141, 1072693248, %r1051, %p952;
	and.b32  	%r142, %r135, 2147483647;
	selp.b32 	%r1052, %r135, 0, %p960;
	or.b32  	%r1053, %r1052, 2146435072;
	selp.b32 	%r143, %r1053, %r1052, %p962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1054}, %fd423;
	}
	and.b32  	%r144, %r1054, 2146435072;
	setp.ne.s32 	%p980, %r144, 2146435072;
	and.pred  	%p981, %p965, %p52;
	selp.b32 	%r145, %r1034, %r1033, %p981;
	{ // callseq 61, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd966;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd964;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd446, [retval0+0];
	} // callseq 61
	and.pred  	%p54, %p973, %p967;
	selp.b32 	%r1055, %r1050, %r1049, %p962;
	selp.b32 	%r146, 1072693248, %r1055, %p952;
	selp.b32 	%r1056, %r135, 0, %p967;
	or.b32  	%r1057, %r1056, 2146435072;
	selp.b32 	%r147, %r1057, %r1056, %p968;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1058}, %fd425;
	}
	and.b32  	%r148, %r1058, 2146435072;
	setp.ne.s32 	%p982, %r148, 2146435072;
	and.pred  	%p983, %p971, %p53;
	selp.b32 	%r149, %r1042, %r1041, %p983;
	selp.b32 	%r1059, %r1050, %r1049, %p968;
	selp.b32 	%r150, 1072693248, %r1059, %p952;
	and.pred  	%p984, %p976, %p54;
	selp.b32 	%r151, %r1048, %r1047, %p984;
	mov.f32 	%f1824, 0f3F800000;
	cvt.rzi.f32.f32 	%f1825, %f1824;
	add.f32 	%f1826, %f1825, %f1825;
	sub.f32 	%f1827, %f1814, %f1826;
	abs.f32 	%f317, %f1827;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r152}, %fd428;
	}
	abs.f64 	%fd967, %fd428;
	{ // callseq 62, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd967;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd962;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd447, [retval0+0];
	} // callseq 62
	setp.lt.s32 	%p985, %r152, 0;
	and.pred  	%p55, %p985, %p955;
	selp.b32 	%r1060, %r152, 0, %p955;
	or.b32  	%r1061, %r1060, 2146435072;
	selp.b32 	%r153, %r1061, %r1060, %p957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1062}, %fd429;
	}
	and.b32  	%r154, %r1062, 2146435072;
	setp.ne.s32 	%p986, %r154, 2146435072;
	setp.gtu.f64 	%p987, %fd967, 0d7FF0000000000000;
	{ // callseq 63, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd967;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd963;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd448, [retval0+0];
	} // callseq 63
	and.pred  	%p56, %p985, %p960;
	setp.gt.f64 	%p988, %fd967, 0d3FF0000000000000;
	selp.b32 	%r1063, 2146435072, 0, %p988;
	xor.b32  	%r1064, %r1063, 2146435072;
	selp.b32 	%r1065, %r1064, %r1063, %p957;
	selp.b32 	%r155, 1072693248, %r1065, %p953;
	and.b32  	%r156, %r152, 2147483647;
	selp.b32 	%r1066, %r152, 0, %p960;
	or.b32  	%r1067, %r1066, 2146435072;
	selp.b32 	%r157, %r1067, %r1066, %p962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1068}, %fd432;
	}
	and.b32  	%r158, %r1068, 2146435072;
	setp.ne.s32 	%p989, %r158, 2146435072;
	and.pred  	%p990, %p965, %p55;
	selp.b32 	%r159, %r1034, %r1033, %p990;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r160}, %fd433;
	}
	abs.f64 	%fd968, %fd433;
	{ // callseq 64, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd968;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd964;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd449, [retval0+0];
	} // callseq 64
	setp.lt.s32 	%p991, %r160, 0;
	and.pred  	%p57, %p991, %p967;
	selp.b32 	%r1069, %r1064, %r1063, %p962;
	selp.b32 	%r161, 1072693248, %r1069, %p953;
	selp.b32 	%r1070, %r160, 0, %p967;
	or.b32  	%r1071, %r1070, 2146435072;
	selp.b32 	%r162, %r1071, %r1070, %p968;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1072}, %fd434;
	}
	and.b32  	%r163, %r1072, 2146435072;
	setp.ne.s32 	%p992, %r163, 2146435072;
	and.pred  	%p993, %p971, %p56;
	selp.b32 	%r164, %r1042, %r1041, %p993;
	setp.gtu.f64 	%p994, %fd968, 0d7FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r165}, %fd437;
	}
	abs.f64 	%fd969, %fd437;
	{ // callseq 65, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd969;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd962;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd450, [retval0+0];
	} // callseq 65
	setp.lt.s32 	%p995, %r165, 0;
	and.pred  	%p58, %p995, %p955;
	setp.gt.f64 	%p996, %fd968, 0d3FF0000000000000;
	selp.b32 	%r1073, 2146435072, 0, %p996;
	xor.b32  	%r1074, %r1073, 2146435072;
	selp.b32 	%r1075, %r1074, %r1073, %p968;
	setp.eq.f32 	%p997, %f541, 0fBF800000;
	selp.b32 	%r166, 1072693248, %r1075, %p997;
	and.b32  	%r167, %r160, 2147483647;
	selp.b32 	%r1076, %r165, 0, %p955;
	or.b32  	%r1077, %r1076, 2146435072;
	selp.b32 	%r168, %r1077, %r1076, %p957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1078}, %fd438;
	}
	and.b32  	%r169, %r1078, 2146435072;
	setp.ne.s32 	%p998, %r169, 2146435072;
	and.pred  	%p999, %p976, %p57;
	selp.b32 	%r170, %r1048, %r1047, %p999;
	setp.gtu.f64 	%p1000, %fd969, 0d7FF0000000000000;
	{ // callseq 66, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd969;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd963;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd451, [retval0+0];
	} // callseq 66
	and.pred  	%p59, %p995, %p960;
	setp.gt.f64 	%p1001, %fd969, 0d3FF0000000000000;
	selp.b32 	%r1079, 2146435072, 0, %p1001;
	xor.b32  	%r1080, %r1079, 2146435072;
	selp.b32 	%r1081, %r1080, %r1079, %p957;
	selp.b32 	%r171, 1072693248, %r1081, %p954;
	and.b32  	%r172, %r165, 2147483647;
	selp.b32 	%r1082, %r165, 0, %p960;
	or.b32  	%r1083, %r1082, 2146435072;
	selp.b32 	%r173, %r1083, %r1082, %p962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1084}, %fd440;
	}
	and.b32  	%r174, %r1084, 2146435072;
	setp.ne.s32 	%p1002, %r174, 2146435072;
	and.pred  	%p1003, %p965, %p58;
	selp.b32 	%r175, %r1034, %r1033, %p1003;
	selp.b32 	%r1085, %r1080, %r1079, %p962;
	selp.b32 	%r176, 1072693248, %r1085, %p954;
	and.pred  	%p1004, %p971, %p59;
	selp.b32 	%r177, %r1042, %r1041, %p1004;
	or.pred  	%p60, %p958, %p959;
	or.pred  	%p61, %p963, %p959;
	or.pred  	%p62, %p969, %p959;
	or.pred  	%p63, %p974, %p978;
	or.pred  	%p64, %p980, %p978;
	or.pred  	%p65, %p982, %p978;
	or.pred  	%p66, %p986, %p987;
	or.pred  	%p67, %p989, %p987;
	or.pred  	%p68, %p992, %p994;
	or.pred  	%p69, %p998, %p1000;
	or.pred  	%p70, %p1002, %p1000;
	mov.f32 	%f3295, %f545;
	mov.f32 	%f3296, %f545;
	mov.f32 	%f3297, %f545;
	mov.f32 	%f3298, %f545;
	mov.f32 	%f3299, %f545;
	mov.f32 	%f3300, %f545;
	mov.f32 	%f3301, %f545;
	mov.f32 	%f3302, %f545;
	mov.f32 	%f3303, %f545;
	mov.f32 	%f3304, %f545;
	mov.f32 	%f3305, %f545;
	mov.f32 	%f3306, %f545;
	mov.f32 	%f3307, %f545;
	mov.f32 	%f3308, %f545;
	mov.f32 	%f3309, %f545;
	mov.f32 	%f3341, %f545;
	mov.u32 	%r1372, %r1019;

$L__BB2_625:
	cvt.rn.f32.s32 	%f1828, %r1372;
	sub.f32 	%f334, %f1828, %f3278;
	add.f32 	%f335, %f334, 0f3F000000;
	add.f32 	%f336, %f334, 0fBF000000;
	add.f32 	%f1829, %f1828, 0f3F000000;
	sub.f32 	%f337, %f1829, %f3278;
	add.f32 	%f1830, %f1828, 0f3F800000;
	sub.f32 	%f338, %f1830, %f3278;
	add.f32 	%f339, %f334, 0f3F800000;
	mov.u32 	%r1373, %r1019;

$L__BB2_626:
	not.pred 	%p1005, %p49;
	mov.f64 	%fd1187, %fd441;
	@%p1005 bra 	$L__BB2_628;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1087}, %fd441;
	}
	xor.b32  	%r1088, %r1087, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1089, %temp}, %fd441;
	}
	mov.b64 	%fd1187, {%r1089, %r1088};

$L__BB2_628:
	setp.eq.f32 	%p1006, %f311, 0f00000000;
	@%p1006 bra 	$L__BB2_632;
	bra.uni 	$L__BB2_629;

$L__BB2_632:
	mov.u32 	%r1090, 0;
	mov.b64 	%fd1187, {%r1090, %r122};
	bra.uni 	$L__BB2_633;

$L__BB2_629:
	setp.gt.s32 	%p1007, %r121, -1;
	@%p1007 bra 	$L__BB2_633;

	cvt.rzi.f64.f64 	%fd971, %fd962;
	setp.eq.f64 	%p1008, %fd971, 0d4000000000000000;
	@%p1008 bra 	$L__BB2_633;

	mov.f64 	%fd1187, 0dFFF8000000000000;

$L__BB2_633:
	selp.f64 	%fd1188, %fd1187, %fd415, %p958;
	@%p60 bra 	$L__BB2_638;

	setp.eq.s32 	%p1010, %r124, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1091, %temp}, %fd962;
	}
	setp.eq.s32 	%p1011, %r1091, 0;
	and.pred  	%p1012, %p1010, %p1011;
	@%p1012 bra 	$L__BB2_637;
	bra.uni 	$L__BB2_635;

$L__BB2_637:
	mov.u32 	%r1094, 0;
	mov.b64 	%fd1188, {%r1094, %r125};
	bra.uni 	$L__BB2_638;

$L__BB2_635:
	setp.ne.s32 	%p1013, %r126, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1092, %temp}, %fd414;
	}
	setp.ne.s32 	%p1014, %r1092, 0;
	or.pred  	%p1015, %p1013, %p1014;
	mov.f64 	%fd1188, %fd1187;
	@%p1015 bra 	$L__BB2_638;

	mov.u32 	%r1093, 0;
	mov.b64 	%fd1188, {%r1093, %r129};

$L__BB2_638:
	not.pred 	%p1016, %p50;
	mov.f64 	%fd1190, %fd442;
	@%p1016 bra 	$L__BB2_640;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1095}, %fd442;
	}
	xor.b32  	%r1096, %r1095, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1097, %temp}, %fd442;
	}
	mov.b64 	%fd1190, {%r1097, %r1096};

$L__BB2_640:
	@%p1006 bra 	$L__BB2_644;
	bra.uni 	$L__BB2_641;

$L__BB2_644:
	mov.u32 	%r1098, 0;
	mov.b64 	%fd1190, {%r1098, %r127};
	bra.uni 	$L__BB2_645;

$L__BB2_641:
	setp.gt.s32 	%p1018, %r121, -1;
	@%p1018 bra 	$L__BB2_645;

	cvt.rzi.f64.f64 	%fd975, %fd963;
	setp.eq.f64 	%p1019, %fd975, 0d4008000000000000;
	@%p1019 bra 	$L__BB2_645;

	mov.f64 	%fd1190, 0dFFF8000000000000;

$L__BB2_645:
	selp.f64 	%fd1191, %fd1190, %fd417, %p963;
	@%p61 bra 	$L__BB2_650;

	setp.eq.s32 	%p1021, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1099, %temp}, %fd963;
	}
	setp.eq.s32 	%p1022, %r1099, 0;
	and.pred  	%p1023, %p1021, %p1022;
	@%p1023 bra 	$L__BB2_649;
	bra.uni 	$L__BB2_647;

$L__BB2_649:
	mov.u32 	%r1102, 0;
	mov.b64 	%fd1191, {%r1102, %r131};
	bra.uni 	$L__BB2_650;

$L__BB2_647:
	setp.ne.s32 	%p1024, %r126, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1100, %temp}, %fd414;
	}
	setp.ne.s32 	%p1025, %r1100, 0;
	or.pred  	%p1026, %p1024, %p1025;
	mov.f64 	%fd1191, %fd1190;
	@%p1026 bra 	$L__BB2_650;

	mov.u32 	%r1101, 0;
	mov.b64 	%fd1191, {%r1101, %r134};

$L__BB2_650:
	setp.eq.f32 	%p1027, %f311, 0f3F800000;
	selp.f64 	%fd978, 0d3FF0000000000000, %fd1191, %p1027;
	add.f64 	%fd979, %fd1188, 0d3FF0000000000000;
	selp.f64 	%fd980, 0d4000000000000000, %fd979, %p1027;
	fma.rn.f64 	%fd468, %fd978, %fd416, %fd980;
	not.pred 	%p1028, %p51;
	mov.f64 	%fd1193, %fd443;
	@%p1028 bra 	$L__BB2_652;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1103}, %fd443;
	}
	xor.b32  	%r1104, %r1103, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1105, %temp}, %fd443;
	}
	mov.b64 	%fd1193, {%r1105, %r1104};

$L__BB2_652:
	@%p1006 bra 	$L__BB2_656;
	bra.uni 	$L__BB2_653;

$L__BB2_656:
	mov.u32 	%r1106, 0;
	mov.b64 	%fd1193, {%r1106, %r132};
	bra.uni 	$L__BB2_657;

$L__BB2_653:
	setp.gt.s32 	%p1030, %r121, -1;
	@%p1030 bra 	$L__BB2_657;

	cvt.rzi.f64.f64 	%fd982, %fd964;
	setp.eq.f64 	%p1031, %fd982, 0d4010000000000000;
	@%p1031 bra 	$L__BB2_657;

	mov.f64 	%fd1193, 0dFFF8000000000000;

$L__BB2_657:
	selp.f64 	%fd1194, %fd1193, %fd419, %p969;
	@%p62 bra 	$L__BB2_662;

	setp.eq.s32 	%p1033, %r136, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1107, %temp}, %fd964;
	}
	setp.eq.s32 	%p1034, %r1107, 0;
	and.pred  	%p1035, %p1033, %p1034;
	@%p1035 bra 	$L__BB2_661;
	bra.uni 	$L__BB2_659;

$L__BB2_661:
	mov.u32 	%r1110, 0;
	mov.b64 	%fd1194, {%r1110, %r137};
	bra.uni 	$L__BB2_662;

$L__BB2_659:
	setp.ne.s32 	%p1036, %r126, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1108, %temp}, %fd414;
	}
	setp.ne.s32 	%p1037, %r1108, 0;
	or.pred  	%p1038, %p1036, %p1037;
	mov.f64 	%fd1194, %fd1193;
	@%p1038 bra 	$L__BB2_662;

	mov.u32 	%r1109, 0;
	mov.b64 	%fd1194, {%r1109, %r140};

$L__BB2_662:
	selp.f64 	%fd985, 0d3FF0000000000000, %fd1194, %p1027;
	fma.rn.f64 	%fd477, %fd985, %fd418, %fd468;
	not.pred 	%p1040, %p52;
	mov.f64 	%fd1196, %fd444;
	@%p1040 bra 	$L__BB2_664;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1111}, %fd444;
	}
	xor.b32  	%r1112, %r1111, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1113, %temp}, %fd444;
	}
	mov.b64 	%fd1196, {%r1113, %r1112};

$L__BB2_664:
	setp.eq.f32 	%p1041, %f313, 0f00000000;
	@%p1041 bra 	$L__BB2_668;
	bra.uni 	$L__BB2_665;

$L__BB2_668:
	mov.u32 	%r1114, 0;
	mov.b64 	%fd1196, {%r1114, %r138};
	bra.uni 	$L__BB2_669;

$L__BB2_665:
	setp.gt.s32 	%p1042, %r135, -1;
	@%p1042 bra 	$L__BB2_669;

	cvt.rzi.f64.f64 	%fd987, %fd962;
	setp.eq.f64 	%p1043, %fd987, 0d4000000000000000;
	@%p1043 bra 	$L__BB2_669;

	mov.f64 	%fd1196, 0dFFF8000000000000;

$L__BB2_669:
	selp.f64 	%fd1197, %fd1196, %fd421, %p974;
	@%p63 bra 	$L__BB2_674;

	setp.eq.s32 	%p1045, %r124, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1115, %temp}, %fd962;
	}
	setp.eq.s32 	%p1046, %r1115, 0;
	and.pred  	%p1047, %p1045, %p1046;
	@%p1047 bra 	$L__BB2_673;
	bra.uni 	$L__BB2_671;

$L__BB2_673:
	mov.u32 	%r1118, 0;
	mov.b64 	%fd1197, {%r1118, %r141};
	bra.uni 	$L__BB2_674;

$L__BB2_671:
	setp.ne.s32 	%p1048, %r142, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1116, %temp}, %fd420;
	}
	setp.ne.s32 	%p1049, %r1116, 0;
	or.pred  	%p1050, %p1048, %p1049;
	mov.f64 	%fd1197, %fd1196;
	@%p1050 bra 	$L__BB2_674;

	mov.u32 	%r1117, 0;
	mov.b64 	%fd1197, {%r1117, %r145};

$L__BB2_674:
	not.pred 	%p1051, %p53;
	mov.f64 	%fd1199, %fd445;
	@%p1051 bra 	$L__BB2_676;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1119}, %fd445;
	}
	xor.b32  	%r1120, %r1119, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1121, %temp}, %fd445;
	}
	mov.b64 	%fd1199, {%r1121, %r1120};

$L__BB2_676:
	@%p1041 bra 	$L__BB2_680;
	bra.uni 	$L__BB2_677;

$L__BB2_680:
	mov.u32 	%r1122, 0;
	mov.b64 	%fd1199, {%r1122, %r143};
	bra.uni 	$L__BB2_681;

$L__BB2_677:
	setp.gt.s32 	%p1053, %r135, -1;
	@%p1053 bra 	$L__BB2_681;

	cvt.rzi.f64.f64 	%fd991, %fd963;
	setp.eq.f64 	%p1054, %fd991, 0d4008000000000000;
	@%p1054 bra 	$L__BB2_681;

	mov.f64 	%fd1199, 0dFFF8000000000000;

$L__BB2_681:
	selp.f64 	%fd1200, %fd1199, %fd423, %p980;
	@%p64 bra 	$L__BB2_686;

	setp.eq.s32 	%p1056, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1123, %temp}, %fd963;
	}
	setp.eq.s32 	%p1057, %r1123, 0;
	and.pred  	%p1058, %p1056, %p1057;
	@%p1058 bra 	$L__BB2_685;
	bra.uni 	$L__BB2_683;

$L__BB2_685:
	mov.u32 	%r1126, 0;
	mov.b64 	%fd1200, {%r1126, %r146};
	bra.uni 	$L__BB2_686;

$L__BB2_683:
	setp.ne.s32 	%p1059, %r142, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1124, %temp}, %fd420;
	}
	setp.ne.s32 	%p1060, %r1124, 0;
	or.pred  	%p1061, %p1059, %p1060;
	mov.f64 	%fd1200, %fd1199;
	@%p1061 bra 	$L__BB2_686;

	mov.u32 	%r1125, 0;
	mov.b64 	%fd1200, {%r1125, %r149};

$L__BB2_686:
	setp.eq.f32 	%p1062, %f313, 0f3F800000;
	selp.f64 	%fd994, 0d3FF0000000000000, %fd1200, %p1062;
	add.f64 	%fd995, %fd1197, 0d3FF0000000000000;
	selp.f64 	%fd996, 0d4000000000000000, %fd995, %p1062;
	fma.rn.f64 	%fd494, %fd994, %fd422, %fd996;
	not.pred 	%p1063, %p54;
	mov.f64 	%fd1202, %fd446;
	@%p1063 bra 	$L__BB2_688;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1127}, %fd446;
	}
	xor.b32  	%r1128, %r1127, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1129, %temp}, %fd446;
	}
	mov.b64 	%fd1202, {%r1129, %r1128};

$L__BB2_688:
	@%p1041 bra 	$L__BB2_692;
	bra.uni 	$L__BB2_689;

$L__BB2_692:
	mov.u32 	%r1130, 0;
	mov.b64 	%fd1202, {%r1130, %r147};
	bra.uni 	$L__BB2_693;

$L__BB2_689:
	setp.gt.s32 	%p1065, %r135, -1;
	@%p1065 bra 	$L__BB2_693;

	cvt.rzi.f64.f64 	%fd998, %fd964;
	setp.eq.f64 	%p1066, %fd998, 0d4010000000000000;
	@%p1066 bra 	$L__BB2_693;

	mov.f64 	%fd1202, 0dFFF8000000000000;

$L__BB2_693:
	selp.f64 	%fd1203, %fd1202, %fd425, %p982;
	@%p65 bra 	$L__BB2_698;

	setp.eq.s32 	%p1068, %r136, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1131, %temp}, %fd964;
	}
	setp.eq.s32 	%p1069, %r1131, 0;
	and.pred  	%p1070, %p1068, %p1069;
	@%p1070 bra 	$L__BB2_697;
	bra.uni 	$L__BB2_695;

$L__BB2_697:
	mov.u32 	%r1134, 0;
	mov.b64 	%fd1203, {%r1134, %r150};
	bra.uni 	$L__BB2_698;

$L__BB2_695:
	setp.ne.s32 	%p1071, %r142, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1132, %temp}, %fd420;
	}
	setp.ne.s32 	%p1072, %r1132, 0;
	or.pred  	%p1073, %p1071, %p1072;
	mov.f64 	%fd1203, %fd1202;
	@%p1073 bra 	$L__BB2_698;

	mov.u32 	%r1133, 0;
	mov.b64 	%fd1203, {%r1133, %r151};

$L__BB2_698:
	selp.f64 	%fd1001, 0d3FF0000000000000, %fd1203, %p1062;
	fma.rn.f64 	%fd1002, %fd1001, %fd424, %fd494;
	cvt.rn.f32.f64 	%f1831, %fd1002;
	cvt.rn.f32.f64 	%f1832, %fd477;
	sqrt.rn.f32 	%f356, %f1832;
	mul.f32 	%f357, %f356, %f535;
	sqrt.rn.f32 	%f358, %f1831;
	mul.f32 	%f359, %f358, %f542;
	mov.f32 	%f1833, 0f3F000000;
	div.rn.f32 	%f1834, %f1833, %f357;
	div.rn.f32 	%f1835, %f1834, %f357;
	sqrt.rn.f32 	%f360, %f1835;
	mul.f32 	%f361, %f360, %f335;
	abs.f32 	%f1836, %f361;
	setp.ltu.f32 	%p1075, %f1836, 0f3F8060FE;
	setp.ge.f32 	%p1076, %f1836, 0f3F8060FE;
	mul.f32 	%f1837, %f361, %f361;
	selp.f32 	%f1838, %f1836, %f1837, %p1076;
	selp.f32 	%f1839, 0f3789CA3C, 0f38B1E96A, %p1076;
	selp.f32 	%f1840, 0fB9F560B9, 0fBA574D20, %p1076;
	fma.rn.f32 	%f1841, %f1839, %f1838, %f1840;
	selp.f32 	%f1842, 0f3BAC840B, 0f3BAAD5EA, %p1076;
	fma.rn.f32 	%f1843, %f1841, %f1838, %f1842;
	selp.f32 	%f1844, 0fBD0C8162, 0fBCDC1BE7, %p1076;
	fma.rn.f32 	%f1845, %f1843, %f1838, %f1844;
	selp.f32 	%f1846, 0f3E1CF906, 0f3DE718AF, %p1076;
	fma.rn.f32 	%f1847, %f1845, %f1838, %f1846;
	selp.f32 	%f1848, 0f3F6A937E, 0fBEC093AC, %p1076;
	fma.rn.f32 	%f1849, %f1847, %f1838, %f1848;
	selp.f32 	%f1850, 0f3F20D842, 0f3E0375D3, %p1076;
	fma.rn.f32 	%f1851, %f1849, %f1838, %f1850;
	neg.f32 	%f1852, %f1836;
	selp.f32 	%f1853, %f1852, %f361, %p1076;
	fma.rn.f32 	%f3311, %f1851, %f1853, %f1853;
	@%p1075 bra 	$L__BB2_700;

	ex2.approx.ftz.f32 	%f1854, %f3311;
	sub.f32 	%f1856, %f1824, %f1854;
	mov.b32 	%r1135, %f1856;
	mov.b32 	%r1136, %f361;
	and.b32  	%r1137, %r1136, -2147483648;
	or.b32  	%r1138, %r1137, %r1135;
	mov.b32 	%f3311, %r1138;

$L__BB2_700:
	mul.f32 	%f365, %f360, %f336;
	abs.f32 	%f1857, %f365;
	setp.ltu.f32 	%p1077, %f1857, 0f3F8060FE;
	setp.ge.f32 	%p1078, %f1857, 0f3F8060FE;
	mul.f32 	%f1858, %f365, %f365;
	selp.f32 	%f1859, %f1857, %f1858, %p1078;
	selp.f32 	%f1860, 0f3789CA3C, 0f38B1E96A, %p1078;
	selp.f32 	%f1861, 0fB9F560B9, 0fBA574D20, %p1078;
	fma.rn.f32 	%f1862, %f1860, %f1859, %f1861;
	selp.f32 	%f1863, 0f3BAC840B, 0f3BAAD5EA, %p1078;
	fma.rn.f32 	%f1864, %f1862, %f1859, %f1863;
	selp.f32 	%f1865, 0fBD0C8162, 0fBCDC1BE7, %p1078;
	fma.rn.f32 	%f1866, %f1864, %f1859, %f1865;
	selp.f32 	%f1867, 0f3E1CF906, 0f3DE718AF, %p1078;
	fma.rn.f32 	%f1868, %f1866, %f1859, %f1867;
	selp.f32 	%f1869, 0f3F6A937E, 0fBEC093AC, %p1078;
	fma.rn.f32 	%f1870, %f1868, %f1859, %f1869;
	selp.f32 	%f1871, 0f3F20D842, 0f3E0375D3, %p1078;
	fma.rn.f32 	%f1872, %f1870, %f1859, %f1871;
	neg.f32 	%f1873, %f1857;
	selp.f32 	%f1874, %f1873, %f365, %p1078;
	fma.rn.f32 	%f3312, %f1872, %f1874, %f1874;
	@%p1077 bra 	$L__BB2_702;

	ex2.approx.ftz.f32 	%f1875, %f3312;
	sub.f32 	%f1877, %f1824, %f1875;
	mov.b32 	%r1139, %f1877;
	mov.b32 	%r1140, %f365;
	and.b32  	%r1141, %r1140, -2147483648;
	or.b32  	%r1142, %r1141, %r1139;
	mov.b32 	%f3312, %r1142;

$L__BB2_702:
	sub.f32 	%f1878, %f3311, %f3312;
	mul.f32 	%f369, %f1878, 0f3F000000;
	div.rn.f32 	%f1880, %f1833, %f359;
	div.rn.f32 	%f1881, %f1880, %f359;
	cvt.rn.f32.s32 	%f370, %r1373;
	sub.f32 	%f371, %f370, %f3277;
	add.f32 	%f1882, %f371, 0f3F000000;
	sqrt.rn.f32 	%f372, %f1881;
	mul.f32 	%f373, %f372, %f1882;
	abs.f32 	%f1883, %f373;
	setp.ltu.f32 	%p1079, %f1883, 0f3F8060FE;
	setp.ge.f32 	%p1080, %f1883, 0f3F8060FE;
	mul.f32 	%f1884, %f373, %f373;
	selp.f32 	%f1885, %f1883, %f1884, %p1080;
	selp.f32 	%f1886, 0f3789CA3C, 0f38B1E96A, %p1080;
	selp.f32 	%f1887, 0fB9F560B9, 0fBA574D20, %p1080;
	fma.rn.f32 	%f1888, %f1886, %f1885, %f1887;
	selp.f32 	%f1889, 0f3BAC840B, 0f3BAAD5EA, %p1080;
	fma.rn.f32 	%f1890, %f1888, %f1885, %f1889;
	selp.f32 	%f1891, 0fBD0C8162, 0fBCDC1BE7, %p1080;
	fma.rn.f32 	%f1892, %f1890, %f1885, %f1891;
	selp.f32 	%f1893, 0f3E1CF906, 0f3DE718AF, %p1080;
	fma.rn.f32 	%f1894, %f1892, %f1885, %f1893;
	selp.f32 	%f1895, 0f3F6A937E, 0fBEC093AC, %p1080;
	fma.rn.f32 	%f1896, %f1894, %f1885, %f1895;
	selp.f32 	%f1897, 0f3F20D842, 0f3E0375D3, %p1080;
	fma.rn.f32 	%f1898, %f1896, %f1885, %f1897;
	neg.f32 	%f1899, %f1883;
	selp.f32 	%f1900, %f1899, %f373, %p1080;
	fma.rn.f32 	%f3313, %f1898, %f1900, %f1900;
	@%p1079 bra 	$L__BB2_704;

	ex2.approx.ftz.f32 	%f1901, %f3313;
	sub.f32 	%f1903, %f1824, %f1901;
	mov.b32 	%r1143, %f1903;
	mov.b32 	%r1144, %f373;
	and.b32  	%r1145, %r1144, -2147483648;
	or.b32  	%r1146, %r1145, %r1143;
	mov.b32 	%f3313, %r1146;

$L__BB2_704:
	add.f32 	%f377, %f371, 0fBF000000;
	mul.f32 	%f378, %f372, %f377;
	abs.f32 	%f1904, %f378;
	setp.ltu.f32 	%p1081, %f1904, 0f3F8060FE;
	setp.ge.f32 	%p1082, %f1904, 0f3F8060FE;
	mul.f32 	%f1905, %f378, %f378;
	selp.f32 	%f1906, %f1904, %f1905, %p1082;
	selp.f32 	%f1907, 0f3789CA3C, 0f38B1E96A, %p1082;
	selp.f32 	%f1908, 0fB9F560B9, 0fBA574D20, %p1082;
	fma.rn.f32 	%f1909, %f1907, %f1906, %f1908;
	selp.f32 	%f1910, 0f3BAC840B, 0f3BAAD5EA, %p1082;
	fma.rn.f32 	%f1911, %f1909, %f1906, %f1910;
	selp.f32 	%f1912, 0fBD0C8162, 0fBCDC1BE7, %p1082;
	fma.rn.f32 	%f1913, %f1911, %f1906, %f1912;
	selp.f32 	%f1914, 0f3E1CF906, 0f3DE718AF, %p1082;
	fma.rn.f32 	%f1915, %f1913, %f1906, %f1914;
	selp.f32 	%f1916, 0f3F6A937E, 0fBEC093AC, %p1082;
	fma.rn.f32 	%f1917, %f1915, %f1906, %f1916;
	selp.f32 	%f1918, 0f3F20D842, 0f3E0375D3, %p1082;
	fma.rn.f32 	%f1919, %f1917, %f1906, %f1918;
	neg.f32 	%f1920, %f1904;
	selp.f32 	%f1921, %f1920, %f378, %p1082;
	fma.rn.f32 	%f3314, %f1919, %f1921, %f1921;
	@%p1081 bra 	$L__BB2_706;

	ex2.approx.ftz.f32 	%f1922, %f3314;
	sub.f32 	%f1924, %f1824, %f1922;
	mov.b32 	%r1147, %f1924;
	mov.b32 	%r1148, %f378;
	and.b32  	%r1149, %r1148, -2147483648;
	or.b32  	%r1150, %r1149, %r1147;
	mov.b32 	%f3314, %r1150;

$L__BB2_706:
	sub.f32 	%f1926, %f3313, %f3314;
	mul.f32 	%f382, %f1926, 0f3F000000;
	div.rn.f32 	%f383, %f337, %f357;
	abs.f32 	%f384, %f383;
	setp.lt.f32 	%p1083, %f384, 0f00800000;
	mul.f32 	%f1927, %f384, 0f4B800000;
	selp.f32 	%f1928, %f1927, %f384, %p1083;
	selp.f32 	%f1929, 0fC3170000, 0fC2FE0000, %p1083;
	mov.b32 	%r1151, %f1928;
	and.b32  	%r1152, %r1151, 8388607;
	or.b32  	%r1153, %r1152, 1065353216;
	mov.b32 	%f1930, %r1153;
	shr.u32 	%r1154, %r1151, 23;
	cvt.rn.f32.u32 	%f1931, %r1154;
	add.f32 	%f1932, %f1929, %f1931;
	setp.gt.f32 	%p1084, %f1930, 0f3FB504F3;
	mul.f32 	%f1933, %f1930, 0f3F000000;
	add.f32 	%f1934, %f1932, 0f3F800000;
	selp.f32 	%f1935, %f1934, %f1932, %p1084;
	selp.f32 	%f1936, %f1933, %f1930, %p1084;
	add.f32 	%f1937, %f1936, 0fBF800000;
	add.f32 	%f1938, %f1936, 0f3F800000;
	rcp.approx.ftz.f32 	%f1939, %f1938;
	add.f32 	%f1940, %f1937, %f1937;
	mul.f32 	%f1942, %f1940, %f1939;
	mul.f32 	%f1943, %f1942, %f1942;
	mov.f32 	%f1944, 0f3C4CAF63;
	mov.f32 	%f1945, 0f3B18F0FE;
	fma.rn.f32 	%f1946, %f1945, %f1943, %f1944;
	mov.f32 	%f1947, 0f3DAAAABD;
	fma.rn.f32 	%f1948, %f1946, %f1943, %f1947;
	mul.rn.f32 	%f1949, %f1948, %f1943;
	mul.rn.f32 	%f1950, %f1949, %f1942;
	sub.f32 	%f1951, %f1937, %f1942;
	add.f32 	%f1952, %f1951, %f1951;
	neg.f32 	%f1953, %f1942;
	fma.rn.f32 	%f1954, %f1953, %f1937, %f1952;
	mul.rn.f32 	%f1955, %f1939, %f1954;
	add.f32 	%f1956, %f1950, %f1942;
	sub.f32 	%f1957, %f1942, %f1956;
	add.f32 	%f1958, %f1950, %f1957;
	add.f32 	%f1959, %f1955, %f1958;
	add.f32 	%f1960, %f1956, %f1959;
	sub.f32 	%f1961, %f1956, %f1960;
	add.f32 	%f1962, %f1959, %f1961;
	mov.f32 	%f1963, 0f3F317200;
	mul.rn.f32 	%f1964, %f1935, %f1963;
	mov.f32 	%f1965, 0f35BFBE8E;
	mul.rn.f32 	%f1966, %f1935, %f1965;
	add.f32 	%f1967, %f1964, %f1960;
	sub.f32 	%f1968, %f1964, %f1967;
	add.f32 	%f1969, %f1960, %f1968;
	add.f32 	%f1970, %f1962, %f1969;
	add.f32 	%f1971, %f1966, %f1970;
	add.f32 	%f1972, %f1967, %f1971;
	sub.f32 	%f1973, %f1967, %f1972;
	add.f32 	%f1974, %f1971, %f1973;
	mul.rn.f32 	%f1975, %f1814, %f1972;
	neg.f32 	%f1976, %f1975;
	fma.rn.f32 	%f1977, %f1814, %f1972, %f1976;
	fma.rn.f32 	%f1978, %f1814, %f1974, %f1977;
	mov.f32 	%f1979, 0f00000000;
	fma.rn.f32 	%f1980, %f1979, %f1972, %f1978;
	add.rn.f32 	%f1981, %f1975, %f1980;
	neg.f32 	%f1982, %f1981;
	add.rn.f32 	%f1983, %f1975, %f1982;
	add.rn.f32 	%f1984, %f1983, %f1980;
	mov.b32 	%r1155, %f1981;
	setp.eq.s32 	%p1085, %r1155, 1118925336;
	add.s32 	%r1156, %r1155, -1;
	mov.b32 	%f1985, %r1156;
	add.f32 	%f1986, %f1984, 0f37000000;
	selp.f32 	%f385, %f1986, %f1984, %p1085;
	selp.f32 	%f1987, %f1985, %f1981, %p1085;
	mov.f32 	%f1988, 0f3FB8AA3B;
	mul.rn.f32 	%f1989, %f1987, %f1988;
	cvt.rzi.f32.f32 	%f1990, %f1989;
	abs.f32 	%f1991, %f1990;
	setp.gt.f32 	%p1086, %f1991, 0f42FC0000;
	mov.b32 	%r1157, %f1990;
	and.b32  	%r1158, %r1157, -2147483648;
	or.b32  	%r1159, %r1158, 1123811328;
	mov.b32 	%f1992, %r1159;
	selp.f32 	%f1993, %f1992, %f1990, %p1086;
	mov.f32 	%f1994, 0fBF317218;
	fma.rn.f32 	%f1995, %f1993, %f1994, %f1987;
	mov.f32 	%f1996, 0f3102E308;
	fma.rn.f32 	%f1997, %f1993, %f1996, %f1995;
	mul.f32 	%f1998, %f1997, 0f3FB8AA3B;
	add.f32 	%f1999, %f1993, 0f4B40007F;
	mov.b32 	%r1160, %f1999;
	shl.b32 	%r1161, %r1160, 23;
	mov.b32 	%f2000, %r1161;
	ex2.approx.ftz.f32 	%f2001, %f1998;
	mul.f32 	%f386, %f2001, %f2000;
	setp.eq.f32 	%p1087, %f386, 0f7F800000;
	mov.f32 	%f3315, 0f7F800000;
	@%p1087 bra 	$L__BB2_708;

	fma.rn.f32 	%f3315, %f386, %f385, %f386;

$L__BB2_708:
	setp.lt.f32 	%p1088, %f383, 0f00000000;
	setp.eq.f32 	%p1089, %f317, 0f3F800000;
	and.pred  	%p71, %p1088, %p1089;
	setp.eq.f32 	%p1090, %f383, 0f00000000;
	@%p1090 bra 	$L__BB2_712;
	bra.uni 	$L__BB2_709;

$L__BB2_712:
	add.f32 	%f2006, %f383, %f383;
	selp.f32 	%f3317, %f2006, 0f00000000, %p1089;
	bra.uni 	$L__BB2_713;

$L__BB2_709:
	mov.b32 	%r1162, %f3315;
	xor.b32  	%r1163, %r1162, -2147483648;
	mov.b32 	%f2002, %r1163;
	selp.f32 	%f3317, %f2002, %f3315, %p71;
	setp.geu.f32 	%p1091, %f383, 0f00000000;
	@%p1091 bra 	$L__BB2_713;

	cvt.rzi.f32.f32 	%f2004, %f1814;
	setp.eq.f32 	%p1092, %f2004, 0f40000000;
	@%p1092 bra 	$L__BB2_713;

	mov.f32 	%f3317, 0f7FFFFFFF;

$L__BB2_713:
	add.f32 	%f2007, %f384, 0f40000000;
	mov.b32 	%r1164, %f2007;
	setp.lt.s32 	%p1094, %r1164, 2139095040;
	@%p1094 bra 	$L__BB2_718;

	setp.gtu.f32 	%p1095, %f384, 0f7F800000;
	@%p1095 bra 	$L__BB2_717;
	bra.uni 	$L__BB2_715;

$L__BB2_717:
	add.f32 	%f3317, %f383, 0f40000000;
	bra.uni 	$L__BB2_718;

$L__BB2_715:
	setp.neu.f32 	%p1096, %f384, 0f7F800000;
	@%p1096 bra 	$L__BB2_718;

	selp.f32 	%f3317, 0fFF800000, 0f7F800000, %p71;

$L__BB2_718:
	mul.f32 	%f2009, %f3317, 0fBF000000;
	setp.eq.f32 	%p1097, %f383, 0f3F800000;
	selp.f32 	%f2010, 0fBF000000, %f2009, %p1097;
	mov.f32 	%f2012, 0f3BBB989D;
	fma.rn.f32 	%f2013, %f2010, %f2012, %f1833;
	mov.f32 	%f2015, 0f437C0000;
	cvt.sat.f32.f32 	%f2016, %f2013;
	mov.f32 	%f2017, 0f4B400001;
	fma.rm.f32 	%f2018, %f2016, %f2015, %f2017;
	add.f32 	%f2019, %f2018, 0fCB40007F;
	neg.f32 	%f2020, %f2019;
	fma.rn.f32 	%f2021, %f2010, %f1988, %f2020;
	mov.f32 	%f2022, 0f32A57060;
	fma.rn.f32 	%f2023, %f2010, %f2022, %f2021;
	mov.b32 	%r1165, %f2018;
	shl.b32 	%r1166, %r1165, 23;
	mov.b32 	%f2024, %r1166;
	ex2.approx.ftz.f32 	%f2025, %f2023;
	mul.f32 	%f395, %f2025, %f2024;
	div.rn.f32 	%f396, %f336, %f357;
	abs.f32 	%f397, %f396;
	setp.lt.f32 	%p1098, %f397, 0f00800000;
	mul.f32 	%f2026, %f397, 0f4B800000;
	selp.f32 	%f2027, %f2026, %f397, %p1098;
	selp.f32 	%f2028, 0fC3170000, 0fC2FE0000, %p1098;
	mov.b32 	%r1167, %f2027;
	and.b32  	%r1168, %r1167, 8388607;
	or.b32  	%r1169, %r1168, 1065353216;
	mov.b32 	%f2029, %r1169;
	shr.u32 	%r1170, %r1167, 23;
	cvt.rn.f32.u32 	%f2030, %r1170;
	add.f32 	%f2031, %f2028, %f2030;
	setp.gt.f32 	%p1099, %f2029, 0f3FB504F3;
	mul.f32 	%f2032, %f2029, 0f3F000000;
	add.f32 	%f2033, %f2031, 0f3F800000;
	selp.f32 	%f2034, %f2033, %f2031, %p1099;
	selp.f32 	%f2035, %f2032, %f2029, %p1099;
	add.f32 	%f2036, %f2035, 0fBF800000;
	add.f32 	%f2037, %f2035, 0f3F800000;
	rcp.approx.ftz.f32 	%f2038, %f2037;
	add.f32 	%f2039, %f2036, %f2036;
	mul.f32 	%f2041, %f2039, %f2038;
	mul.f32 	%f2042, %f2041, %f2041;
	fma.rn.f32 	%f2045, %f1945, %f2042, %f1944;
	fma.rn.f32 	%f2047, %f2045, %f2042, %f1947;
	mul.rn.f32 	%f2048, %f2047, %f2042;
	mul.rn.f32 	%f2049, %f2048, %f2041;
	sub.f32 	%f2050, %f2036, %f2041;
	add.f32 	%f2051, %f2050, %f2050;
	neg.f32 	%f2052, %f2041;
	fma.rn.f32 	%f2053, %f2052, %f2036, %f2051;
	mul.rn.f32 	%f2054, %f2038, %f2053;
	add.f32 	%f2055, %f2049, %f2041;
	sub.f32 	%f2056, %f2041, %f2055;
	add.f32 	%f2057, %f2049, %f2056;
	add.f32 	%f2058, %f2054, %f2057;
	add.f32 	%f2059, %f2055, %f2058;
	sub.f32 	%f2060, %f2055, %f2059;
	add.f32 	%f2061, %f2058, %f2060;
	mul.rn.f32 	%f2063, %f2034, %f1963;
	mul.rn.f32 	%f2065, %f2034, %f1965;
	add.f32 	%f2066, %f2063, %f2059;
	sub.f32 	%f2067, %f2063, %f2066;
	add.f32 	%f2068, %f2059, %f2067;
	add.f32 	%f2069, %f2061, %f2068;
	add.f32 	%f2070, %f2065, %f2069;
	add.f32 	%f2071, %f2066, %f2070;
	sub.f32 	%f2072, %f2066, %f2071;
	add.f32 	%f2073, %f2070, %f2072;
	mul.rn.f32 	%f2074, %f1814, %f2071;
	neg.f32 	%f2075, %f2074;
	fma.rn.f32 	%f2076, %f1814, %f2071, %f2075;
	fma.rn.f32 	%f2077, %f1814, %f2073, %f2076;
	fma.rn.f32 	%f2079, %f1979, %f2071, %f2077;
	add.rn.f32 	%f2080, %f2074, %f2079;
	neg.f32 	%f2081, %f2080;
	add.rn.f32 	%f2082, %f2074, %f2081;
	add.rn.f32 	%f2083, %f2082, %f2079;
	mov.b32 	%r1171, %f2080;
	setp.eq.s32 	%p1100, %r1171, 1118925336;
	add.s32 	%r1172, %r1171, -1;
	mov.b32 	%f2084, %r1172;
	add.f32 	%f2085, %f2083, 0f37000000;
	selp.f32 	%f398, %f2085, %f2083, %p1100;
	selp.f32 	%f2086, %f2084, %f2080, %p1100;
	mul.rn.f32 	%f2087, %f2086, %f1988;
	cvt.rzi.f32.f32 	%f2088, %f2087;
	abs.f32 	%f2089, %f2088;
	setp.gt.f32 	%p1101, %f2089, 0f42FC0000;
	mov.b32 	%r1173, %f2088;
	and.b32  	%r1174, %r1173, -2147483648;
	or.b32  	%r1175, %r1174, 1123811328;
	mov.b32 	%f2090, %r1175;
	selp.f32 	%f2091, %f2090, %f2088, %p1101;
	fma.rn.f32 	%f2093, %f2091, %f1994, %f2086;
	fma.rn.f32 	%f2095, %f2091, %f1996, %f2093;
	mul.f32 	%f2096, %f2095, 0f3FB8AA3B;
	add.f32 	%f2097, %f2091, 0f4B40007F;
	mov.b32 	%r1176, %f2097;
	shl.b32 	%r1177, %r1176, 23;
	mov.b32 	%f2098, %r1177;
	ex2.approx.ftz.f32 	%f2099, %f2096;
	mul.f32 	%f399, %f2099, %f2098;
	setp.eq.f32 	%p1102, %f399, 0f7F800000;
	mov.f32 	%f3318, 0f7F800000;
	@%p1102 bra 	$L__BB2_720;

	fma.rn.f32 	%f3318, %f399, %f398, %f399;

$L__BB2_720:
	setp.lt.f32 	%p1103, %f396, 0f00000000;
	and.pred  	%p72, %p1103, %p1089;
	setp.eq.f32 	%p1105, %f396, 0f00000000;
	@%p1105 bra 	$L__BB2_724;
	bra.uni 	$L__BB2_721;

$L__BB2_724:
	add.f32 	%f2104, %f396, %f396;
	selp.f32 	%f3320, %f2104, 0f00000000, %p1089;
	bra.uni 	$L__BB2_725;

$L__BB2_721:
	mov.b32 	%r1178, %f3318;
	xor.b32  	%r1179, %r1178, -2147483648;
	mov.b32 	%f2100, %r1179;
	selp.f32 	%f3320, %f2100, %f3318, %p72;
	setp.geu.f32 	%p1106, %f396, 0f00000000;
	@%p1106 bra 	$L__BB2_725;

	cvt.rzi.f32.f32 	%f2102, %f1814;
	setp.eq.f32 	%p1107, %f2102, 0f40000000;
	@%p1107 bra 	$L__BB2_725;

	mov.f32 	%f3320, 0f7FFFFFFF;

$L__BB2_725:
	add.f32 	%f2105, %f397, 0f40000000;
	mov.b32 	%r1180, %f2105;
	setp.lt.s32 	%p1109, %r1180, 2139095040;
	@%p1109 bra 	$L__BB2_730;

	setp.gtu.f32 	%p1110, %f397, 0f7F800000;
	@%p1110 bra 	$L__BB2_729;
	bra.uni 	$L__BB2_727;

$L__BB2_729:
	add.f32 	%f3320, %f396, 0f40000000;
	bra.uni 	$L__BB2_730;

$L__BB2_727:
	setp.neu.f32 	%p1111, %f397, 0f7F800000;
	@%p1111 bra 	$L__BB2_730;

	selp.f32 	%f3320, 0fFF800000, 0f7F800000, %p72;

$L__BB2_730:
	mul.f32 	%f2107, %f3320, 0fBF000000;
	setp.eq.f32 	%p1112, %f396, 0f3F800000;
	selp.f32 	%f2108, 0fBF000000, %f2107, %p1112;
	fma.rn.f32 	%f2111, %f2108, %f2012, %f1833;
	cvt.sat.f32.f32 	%f2114, %f2111;
	fma.rm.f32 	%f2116, %f2114, %f2015, %f2017;
	add.f32 	%f2117, %f2116, 0fCB40007F;
	neg.f32 	%f2118, %f2117;
	fma.rn.f32 	%f2119, %f2108, %f1988, %f2118;
	fma.rn.f32 	%f2121, %f2108, %f2022, %f2119;
	mov.b32 	%r1181, %f2116;
	shl.b32 	%r1182, %r1181, 23;
	mov.b32 	%f2122, %r1182;
	ex2.approx.ftz.f32 	%f2123, %f2121;
	mul.f32 	%f2124, %f2123, %f2122;
	sub.f32 	%f2125, %f395, %f2124;
	div.rn.f32 	%f408, %f314, %f357;
	mul.f32 	%f2126, %f408, %f2125;
	mul.f32 	%f409, %f382, %f2126;
	add.f32 	%f2127, %f370, 0f3F000000;
	sub.f32 	%f2128, %f2127, %f3277;
	div.rn.f32 	%f410, %f2128, %f359;
	abs.f32 	%f411, %f410;
	setp.lt.f32 	%p1113, %f411, 0f00800000;
	mul.f32 	%f2129, %f411, 0f4B800000;
	selp.f32 	%f2130, %f2129, %f411, %p1113;
	selp.f32 	%f2131, 0fC3170000, 0fC2FE0000, %p1113;
	mov.b32 	%r1183, %f2130;
	and.b32  	%r1184, %r1183, 8388607;
	or.b32  	%r1185, %r1184, 1065353216;
	mov.b32 	%f2132, %r1185;
	shr.u32 	%r1186, %r1183, 23;
	cvt.rn.f32.u32 	%f2133, %r1186;
	add.f32 	%f2134, %f2131, %f2133;
	setp.gt.f32 	%p1114, %f2132, 0f3FB504F3;
	mul.f32 	%f2135, %f2132, 0f3F000000;
	add.f32 	%f2136, %f2134, 0f3F800000;
	selp.f32 	%f2137, %f2136, %f2134, %p1114;
	selp.f32 	%f2138, %f2135, %f2132, %p1114;
	add.f32 	%f2139, %f2138, 0fBF800000;
	add.f32 	%f2140, %f2138, 0f3F800000;
	rcp.approx.ftz.f32 	%f2141, %f2140;
	add.f32 	%f2142, %f2139, %f2139;
	mul.f32 	%f2144, %f2142, %f2141;
	mul.f32 	%f2145, %f2144, %f2144;
	fma.rn.f32 	%f2148, %f1945, %f2145, %f1944;
	fma.rn.f32 	%f2150, %f2148, %f2145, %f1947;
	mul.rn.f32 	%f2151, %f2150, %f2145;
	mul.rn.f32 	%f2152, %f2151, %f2144;
	sub.f32 	%f2153, %f2139, %f2144;
	add.f32 	%f2154, %f2153, %f2153;
	neg.f32 	%f2155, %f2144;
	fma.rn.f32 	%f2156, %f2155, %f2139, %f2154;
	mul.rn.f32 	%f2157, %f2141, %f2156;
	add.f32 	%f2158, %f2152, %f2144;
	sub.f32 	%f2159, %f2144, %f2158;
	add.f32 	%f2160, %f2152, %f2159;
	add.f32 	%f2161, %f2157, %f2160;
	add.f32 	%f2162, %f2158, %f2161;
	sub.f32 	%f2163, %f2158, %f2162;
	add.f32 	%f2164, %f2161, %f2163;
	mul.rn.f32 	%f2166, %f2137, %f1963;
	mul.rn.f32 	%f2168, %f2137, %f1965;
	add.f32 	%f2169, %f2166, %f2162;
	sub.f32 	%f2170, %f2166, %f2169;
	add.f32 	%f2171, %f2162, %f2170;
	add.f32 	%f2172, %f2164, %f2171;
	add.f32 	%f2173, %f2168, %f2172;
	add.f32 	%f2174, %f2169, %f2173;
	sub.f32 	%f2175, %f2169, %f2174;
	add.f32 	%f2176, %f2173, %f2175;
	mul.rn.f32 	%f2177, %f1814, %f2174;
	neg.f32 	%f2178, %f2177;
	fma.rn.f32 	%f2179, %f1814, %f2174, %f2178;
	fma.rn.f32 	%f2180, %f1814, %f2176, %f2179;
	fma.rn.f32 	%f2182, %f1979, %f2174, %f2180;
	add.rn.f32 	%f2183, %f2177, %f2182;
	neg.f32 	%f2184, %f2183;
	add.rn.f32 	%f2185, %f2177, %f2184;
	add.rn.f32 	%f2186, %f2185, %f2182;
	mov.b32 	%r1187, %f2183;
	setp.eq.s32 	%p1115, %r1187, 1118925336;
	add.s32 	%r1188, %r1187, -1;
	mov.b32 	%f2187, %r1188;
	add.f32 	%f2188, %f2186, 0f37000000;
	selp.f32 	%f412, %f2188, %f2186, %p1115;
	selp.f32 	%f2189, %f2187, %f2183, %p1115;
	mul.rn.f32 	%f2190, %f2189, %f1988;
	cvt.rzi.f32.f32 	%f2191, %f2190;
	abs.f32 	%f2192, %f2191;
	setp.gt.f32 	%p1116, %f2192, 0f42FC0000;
	mov.b32 	%r1189, %f2191;
	and.b32  	%r1190, %r1189, -2147483648;
	or.b32  	%r1191, %r1190, 1123811328;
	mov.b32 	%f2193, %r1191;
	selp.f32 	%f2194, %f2193, %f2191, %p1116;
	fma.rn.f32 	%f2196, %f2194, %f1994, %f2189;
	fma.rn.f32 	%f2198, %f2194, %f1996, %f2196;
	mul.f32 	%f2199, %f2198, 0f3FB8AA3B;
	add.f32 	%f2200, %f2194, 0f4B40007F;
	mov.b32 	%r1192, %f2200;
	shl.b32 	%r1193, %r1192, 23;
	mov.b32 	%f2201, %r1193;
	ex2.approx.ftz.f32 	%f2202, %f2199;
	mul.f32 	%f413, %f2202, %f2201;
	setp.eq.f32 	%p1117, %f413, 0f7F800000;
	mov.f32 	%f3321, 0f7F800000;
	@%p1117 bra 	$L__BB2_732;

	fma.rn.f32 	%f3321, %f413, %f412, %f413;

$L__BB2_732:
	setp.lt.f32 	%p1118, %f410, 0f00000000;
	and.pred  	%p73, %p1118, %p1089;
	setp.eq.f32 	%p1120, %f410, 0f00000000;
	@%p1120 bra 	$L__BB2_736;
	bra.uni 	$L__BB2_733;

$L__BB2_736:
	add.f32 	%f2207, %f410, %f410;
	selp.f32 	%f3323, %f2207, 0f00000000, %p1089;
	bra.uni 	$L__BB2_737;

$L__BB2_733:
	mov.b32 	%r1194, %f3321;
	xor.b32  	%r1195, %r1194, -2147483648;
	mov.b32 	%f2203, %r1195;
	selp.f32 	%f3323, %f2203, %f3321, %p73;
	setp.geu.f32 	%p1121, %f410, 0f00000000;
	@%p1121 bra 	$L__BB2_737;

	cvt.rzi.f32.f32 	%f2205, %f1814;
	setp.eq.f32 	%p1122, %f2205, 0f40000000;
	@%p1122 bra 	$L__BB2_737;

	mov.f32 	%f3323, 0f7FFFFFFF;

$L__BB2_737:
	add.f32 	%f2208, %f411, 0f40000000;
	mov.b32 	%r1196, %f2208;
	setp.lt.s32 	%p1124, %r1196, 2139095040;
	@%p1124 bra 	$L__BB2_742;

	setp.gtu.f32 	%p1125, %f411, 0f7F800000;
	@%p1125 bra 	$L__BB2_741;
	bra.uni 	$L__BB2_739;

$L__BB2_741:
	add.f32 	%f3323, %f410, 0f40000000;
	bra.uni 	$L__BB2_742;

$L__BB2_739:
	setp.neu.f32 	%p1126, %f411, 0f7F800000;
	@%p1126 bra 	$L__BB2_742;

	selp.f32 	%f3323, 0fFF800000, 0f7F800000, %p73;

$L__BB2_742:
	mul.f32 	%f2210, %f3323, 0fBF000000;
	setp.eq.f32 	%p1127, %f410, 0f3F800000;
	selp.f32 	%f2211, 0fBF000000, %f2210, %p1127;
	fma.rn.f32 	%f2214, %f2211, %f2012, %f1833;
	cvt.sat.f32.f32 	%f2217, %f2214;
	fma.rm.f32 	%f2219, %f2217, %f2015, %f2017;
	add.f32 	%f2220, %f2219, 0fCB40007F;
	neg.f32 	%f2221, %f2220;
	fma.rn.f32 	%f2222, %f2211, %f1988, %f2221;
	fma.rn.f32 	%f2224, %f2211, %f2022, %f2222;
	mov.b32 	%r1197, %f2219;
	shl.b32 	%r1198, %r1197, 23;
	mov.b32 	%f2225, %r1198;
	ex2.approx.ftz.f32 	%f2226, %f2224;
	mul.f32 	%f422, %f2226, %f2225;
	div.rn.f32 	%f423, %f377, %f359;
	abs.f32 	%f424, %f423;
	setp.lt.f32 	%p1128, %f424, 0f00800000;
	mul.f32 	%f2227, %f424, 0f4B800000;
	selp.f32 	%f2228, %f2227, %f424, %p1128;
	selp.f32 	%f2229, 0fC3170000, 0fC2FE0000, %p1128;
	mov.b32 	%r1199, %f2228;
	and.b32  	%r1200, %r1199, 8388607;
	or.b32  	%r1201, %r1200, 1065353216;
	mov.b32 	%f2230, %r1201;
	shr.u32 	%r1202, %r1199, 23;
	cvt.rn.f32.u32 	%f2231, %r1202;
	add.f32 	%f2232, %f2229, %f2231;
	setp.gt.f32 	%p1129, %f2230, 0f3FB504F3;
	mul.f32 	%f2233, %f2230, 0f3F000000;
	add.f32 	%f2234, %f2232, 0f3F800000;
	selp.f32 	%f2235, %f2234, %f2232, %p1129;
	selp.f32 	%f2236, %f2233, %f2230, %p1129;
	add.f32 	%f2237, %f2236, 0fBF800000;
	add.f32 	%f2238, %f2236, 0f3F800000;
	rcp.approx.ftz.f32 	%f2239, %f2238;
	add.f32 	%f2240, %f2237, %f2237;
	mul.f32 	%f2242, %f2240, %f2239;
	mul.f32 	%f2243, %f2242, %f2242;
	fma.rn.f32 	%f2246, %f1945, %f2243, %f1944;
	fma.rn.f32 	%f2248, %f2246, %f2243, %f1947;
	mul.rn.f32 	%f2249, %f2248, %f2243;
	mul.rn.f32 	%f2250, %f2249, %f2242;
	sub.f32 	%f2251, %f2237, %f2242;
	add.f32 	%f2252, %f2251, %f2251;
	neg.f32 	%f2253, %f2242;
	fma.rn.f32 	%f2254, %f2253, %f2237, %f2252;
	mul.rn.f32 	%f2255, %f2239, %f2254;
	add.f32 	%f2256, %f2250, %f2242;
	sub.f32 	%f2257, %f2242, %f2256;
	add.f32 	%f2258, %f2250, %f2257;
	add.f32 	%f2259, %f2255, %f2258;
	add.f32 	%f2260, %f2256, %f2259;
	sub.f32 	%f2261, %f2256, %f2260;
	add.f32 	%f2262, %f2259, %f2261;
	mul.rn.f32 	%f2264, %f2235, %f1963;
	mul.rn.f32 	%f2266, %f2235, %f1965;
	add.f32 	%f2267, %f2264, %f2260;
	sub.f32 	%f2268, %f2264, %f2267;
	add.f32 	%f2269, %f2260, %f2268;
	add.f32 	%f2270, %f2262, %f2269;
	add.f32 	%f2271, %f2266, %f2270;
	add.f32 	%f2272, %f2267, %f2271;
	sub.f32 	%f2273, %f2267, %f2272;
	add.f32 	%f2274, %f2271, %f2273;
	mul.rn.f32 	%f2275, %f1814, %f2272;
	neg.f32 	%f2276, %f2275;
	fma.rn.f32 	%f2277, %f1814, %f2272, %f2276;
	fma.rn.f32 	%f2278, %f1814, %f2274, %f2277;
	fma.rn.f32 	%f2280, %f1979, %f2272, %f2278;
	add.rn.f32 	%f2281, %f2275, %f2280;
	neg.f32 	%f2282, %f2281;
	add.rn.f32 	%f2283, %f2275, %f2282;
	add.rn.f32 	%f2284, %f2283, %f2280;
	mov.b32 	%r1203, %f2281;
	setp.eq.s32 	%p1130, %r1203, 1118925336;
	add.s32 	%r1204, %r1203, -1;
	mov.b32 	%f2285, %r1204;
	add.f32 	%f2286, %f2284, 0f37000000;
	selp.f32 	%f425, %f2286, %f2284, %p1130;
	selp.f32 	%f2287, %f2285, %f2281, %p1130;
	mul.rn.f32 	%f2288, %f2287, %f1988;
	cvt.rzi.f32.f32 	%f2289, %f2288;
	abs.f32 	%f2290, %f2289;
	setp.gt.f32 	%p1131, %f2290, 0f42FC0000;
	mov.b32 	%r1205, %f2289;
	and.b32  	%r1206, %r1205, -2147483648;
	or.b32  	%r1207, %r1206, 1123811328;
	mov.b32 	%f2291, %r1207;
	selp.f32 	%f2292, %f2291, %f2289, %p1131;
	fma.rn.f32 	%f2294, %f2292, %f1994, %f2287;
	fma.rn.f32 	%f2296, %f2292, %f1996, %f2294;
	mul.f32 	%f2297, %f2296, 0f3FB8AA3B;
	add.f32 	%f2298, %f2292, 0f4B40007F;
	mov.b32 	%r1208, %f2298;
	shl.b32 	%r1209, %r1208, 23;
	mov.b32 	%f2299, %r1209;
	ex2.approx.ftz.f32 	%f2300, %f2297;
	mul.f32 	%f426, %f2300, %f2299;
	setp.eq.f32 	%p1132, %f426, 0f7F800000;
	mov.f32 	%f3324, 0f7F800000;
	@%p1132 bra 	$L__BB2_744;

	fma.rn.f32 	%f3324, %f426, %f425, %f426;

$L__BB2_744:
	setp.lt.f32 	%p1133, %f423, 0f00000000;
	and.pred  	%p74, %p1133, %p1089;
	setp.eq.f32 	%p1135, %f423, 0f00000000;
	@%p1135 bra 	$L__BB2_748;
	bra.uni 	$L__BB2_745;

$L__BB2_748:
	add.f32 	%f2305, %f423, %f423;
	selp.f32 	%f3326, %f2305, 0f00000000, %p1089;
	bra.uni 	$L__BB2_749;

$L__BB2_745:
	mov.b32 	%r1210, %f3324;
	xor.b32  	%r1211, %r1210, -2147483648;
	mov.b32 	%f2301, %r1211;
	selp.f32 	%f3326, %f2301, %f3324, %p74;
	setp.geu.f32 	%p1136, %f423, 0f00000000;
	@%p1136 bra 	$L__BB2_749;

	cvt.rzi.f32.f32 	%f2303, %f1814;
	setp.eq.f32 	%p1137, %f2303, 0f40000000;
	@%p1137 bra 	$L__BB2_749;

	mov.f32 	%f3326, 0f7FFFFFFF;

$L__BB2_749:
	add.f32 	%f2306, %f424, 0f40000000;
	mov.b32 	%r1212, %f2306;
	setp.lt.s32 	%p1139, %r1212, 2139095040;
	@%p1139 bra 	$L__BB2_754;

	setp.gtu.f32 	%p1140, %f424, 0f7F800000;
	@%p1140 bra 	$L__BB2_753;
	bra.uni 	$L__BB2_751;

$L__BB2_753:
	add.f32 	%f3326, %f423, 0f40000000;
	bra.uni 	$L__BB2_754;

$L__BB2_751:
	setp.neu.f32 	%p1141, %f424, 0f7F800000;
	@%p1141 bra 	$L__BB2_754;

	selp.f32 	%f3326, 0fFF800000, 0f7F800000, %p74;

$L__BB2_754:
	mul.f32 	%f2308, %f3326, 0fBF000000;
	setp.eq.f32 	%p1142, %f423, 0f3F800000;
	selp.f32 	%f2309, 0fBF000000, %f2308, %p1142;
	fma.rn.f32 	%f2312, %f2309, %f2012, %f1833;
	cvt.sat.f32.f32 	%f2315, %f2312;
	fma.rm.f32 	%f2317, %f2315, %f2015, %f2017;
	add.f32 	%f2318, %f2317, 0fCB40007F;
	neg.f32 	%f2319, %f2318;
	fma.rn.f32 	%f2320, %f2309, %f1988, %f2319;
	fma.rn.f32 	%f2322, %f2309, %f2022, %f2320;
	mov.b32 	%r1213, %f2317;
	shl.b32 	%r1214, %r1213, 23;
	mov.b32 	%f2323, %r1214;
	ex2.approx.ftz.f32 	%f2324, %f2322;
	mul.f32 	%f2325, %f2324, %f2323;
	sub.f32 	%f2326, %f422, %f2325;
	div.rn.f32 	%f435, %f314, %f359;
	mul.f32 	%f2327, %f435, %f2326;
	mul.f32 	%f436, %f369, %f2327;
	div.rn.f32 	%f437, %f338, %f357;
	abs.f32 	%f438, %f437;
	setp.lt.f32 	%p1143, %f438, 0f00800000;
	mul.f32 	%f2328, %f438, 0f4B800000;
	selp.f32 	%f2329, %f2328, %f438, %p1143;
	selp.f32 	%f2330, 0fC3170000, 0fC2FE0000, %p1143;
	mov.b32 	%r1215, %f2329;
	and.b32  	%r1216, %r1215, 8388607;
	or.b32  	%r1217, %r1216, 1065353216;
	mov.b32 	%f2331, %r1217;
	shr.u32 	%r1218, %r1215, 23;
	cvt.rn.f32.u32 	%f2332, %r1218;
	add.f32 	%f2333, %f2330, %f2332;
	setp.gt.f32 	%p1144, %f2331, 0f3FB504F3;
	mul.f32 	%f2334, %f2331, 0f3F000000;
	add.f32 	%f2335, %f2333, 0f3F800000;
	selp.f32 	%f2336, %f2335, %f2333, %p1144;
	selp.f32 	%f2337, %f2334, %f2331, %p1144;
	add.f32 	%f2338, %f2337, 0fBF800000;
	add.f32 	%f2339, %f2337, 0f3F800000;
	rcp.approx.ftz.f32 	%f2340, %f2339;
	add.f32 	%f2341, %f2338, %f2338;
	mul.f32 	%f2343, %f2341, %f2340;
	mul.f32 	%f2344, %f2343, %f2343;
	fma.rn.f32 	%f2347, %f1945, %f2344, %f1944;
	fma.rn.f32 	%f2349, %f2347, %f2344, %f1947;
	mul.rn.f32 	%f2350, %f2349, %f2344;
	mul.rn.f32 	%f2351, %f2350, %f2343;
	sub.f32 	%f2352, %f2338, %f2343;
	add.f32 	%f2353, %f2352, %f2352;
	neg.f32 	%f2354, %f2343;
	fma.rn.f32 	%f2355, %f2354, %f2338, %f2353;
	mul.rn.f32 	%f2356, %f2340, %f2355;
	add.f32 	%f2357, %f2351, %f2343;
	sub.f32 	%f2358, %f2343, %f2357;
	add.f32 	%f2359, %f2351, %f2358;
	add.f32 	%f2360, %f2356, %f2359;
	add.f32 	%f2361, %f2357, %f2360;
	sub.f32 	%f2362, %f2357, %f2361;
	add.f32 	%f2363, %f2360, %f2362;
	mul.rn.f32 	%f2365, %f2336, %f1963;
	mul.rn.f32 	%f2367, %f2336, %f1965;
	add.f32 	%f2368, %f2365, %f2361;
	sub.f32 	%f2369, %f2365, %f2368;
	add.f32 	%f2370, %f2361, %f2369;
	add.f32 	%f2371, %f2363, %f2370;
	add.f32 	%f2372, %f2367, %f2371;
	add.f32 	%f2373, %f2368, %f2372;
	sub.f32 	%f2374, %f2368, %f2373;
	add.f32 	%f2375, %f2372, %f2374;
	mul.rn.f32 	%f2376, %f1814, %f2373;
	neg.f32 	%f2377, %f2376;
	fma.rn.f32 	%f2378, %f1814, %f2373, %f2377;
	fma.rn.f32 	%f2379, %f1814, %f2375, %f2378;
	fma.rn.f32 	%f2381, %f1979, %f2373, %f2379;
	add.rn.f32 	%f2382, %f2376, %f2381;
	neg.f32 	%f2383, %f2382;
	add.rn.f32 	%f2384, %f2376, %f2383;
	add.rn.f32 	%f2385, %f2384, %f2381;
	mov.b32 	%r1219, %f2382;
	setp.eq.s32 	%p1145, %r1219, 1118925336;
	add.s32 	%r1220, %r1219, -1;
	mov.b32 	%f2386, %r1220;
	add.f32 	%f2387, %f2385, 0f37000000;
	selp.f32 	%f439, %f2387, %f2385, %p1145;
	selp.f32 	%f2388, %f2386, %f2382, %p1145;
	mul.rn.f32 	%f2389, %f2388, %f1988;
	cvt.rzi.f32.f32 	%f2390, %f2389;
	abs.f32 	%f2391, %f2390;
	setp.gt.f32 	%p1146, %f2391, 0f42FC0000;
	mov.b32 	%r1221, %f2390;
	and.b32  	%r1222, %r1221, -2147483648;
	or.b32  	%r1223, %r1222, 1123811328;
	mov.b32 	%f2392, %r1223;
	selp.f32 	%f2393, %f2392, %f2390, %p1146;
	fma.rn.f32 	%f2395, %f2393, %f1994, %f2388;
	fma.rn.f32 	%f2397, %f2393, %f1996, %f2395;
	mul.f32 	%f2398, %f2397, 0f3FB8AA3B;
	add.f32 	%f2399, %f2393, 0f4B40007F;
	mov.b32 	%r1224, %f2399;
	shl.b32 	%r1225, %r1224, 23;
	mov.b32 	%f2400, %r1225;
	ex2.approx.ftz.f32 	%f2401, %f2398;
	mul.f32 	%f440, %f2401, %f2400;
	setp.eq.f32 	%p1147, %f440, 0f7F800000;
	mov.f32 	%f3327, 0f7F800000;
	@%p1147 bra 	$L__BB2_756;

	fma.rn.f32 	%f3327, %f440, %f439, %f440;

$L__BB2_756:
	setp.lt.f32 	%p1148, %f437, 0f00000000;
	and.pred  	%p75, %p1148, %p1089;
	setp.eq.f32 	%p1150, %f437, 0f00000000;
	@%p1150 bra 	$L__BB2_760;
	bra.uni 	$L__BB2_757;

$L__BB2_760:
	add.f32 	%f2406, %f437, %f437;
	selp.f32 	%f3329, %f2406, 0f00000000, %p1089;
	bra.uni 	$L__BB2_761;

$L__BB2_757:
	mov.b32 	%r1226, %f3327;
	xor.b32  	%r1227, %r1226, -2147483648;
	mov.b32 	%f2402, %r1227;
	selp.f32 	%f3329, %f2402, %f3327, %p75;
	setp.geu.f32 	%p1151, %f437, 0f00000000;
	@%p1151 bra 	$L__BB2_761;

	cvt.rzi.f32.f32 	%f2404, %f1814;
	setp.eq.f32 	%p1152, %f2404, 0f40000000;
	@%p1152 bra 	$L__BB2_761;

	mov.f32 	%f3329, 0f7FFFFFFF;

$L__BB2_761:
	add.f32 	%f2407, %f438, 0f40000000;
	mov.b32 	%r1228, %f2407;
	setp.lt.s32 	%p1154, %r1228, 2139095040;
	@%p1154 bra 	$L__BB2_766;

	setp.gtu.f32 	%p1155, %f438, 0f7F800000;
	@%p1155 bra 	$L__BB2_765;
	bra.uni 	$L__BB2_763;

$L__BB2_765:
	add.f32 	%f3329, %f437, 0f40000000;
	bra.uni 	$L__BB2_766;

$L__BB2_763:
	setp.neu.f32 	%p1156, %f438, 0f7F800000;
	@%p1156 bra 	$L__BB2_766;

	selp.f32 	%f3329, 0fFF800000, 0f7F800000, %p75;

$L__BB2_766:
	mul.f32 	%f2409, %f3329, 0fBF000000;
	setp.eq.f32 	%p1157, %f437, 0f3F800000;
	selp.f32 	%f2410, 0fBF000000, %f2409, %p1157;
	fma.rn.f32 	%f2413, %f2410, %f2012, %f1833;
	cvt.sat.f32.f32 	%f2416, %f2413;
	fma.rm.f32 	%f2418, %f2416, %f2015, %f2017;
	add.f32 	%f2419, %f2418, 0fCB40007F;
	neg.f32 	%f2420, %f2419;
	fma.rn.f32 	%f2421, %f2410, %f1988, %f2420;
	fma.rn.f32 	%f2423, %f2410, %f2022, %f2421;
	mov.b32 	%r1229, %f2418;
	shl.b32 	%r1230, %r1229, 23;
	mov.b32 	%f2424, %r1230;
	ex2.approx.ftz.f32 	%f2425, %f2423;
	mul.f32 	%f449, %f2425, %f2424;
	div.rn.f32 	%f450, %f334, %f357;
	abs.f32 	%f451, %f450;
	setp.lt.f32 	%p1158, %f451, 0f00800000;
	mul.f32 	%f2426, %f451, 0f4B800000;
	selp.f32 	%f2427, %f2426, %f451, %p1158;
	selp.f32 	%f2428, 0fC3170000, 0fC2FE0000, %p1158;
	mov.b32 	%r1231, %f2427;
	and.b32  	%r1232, %r1231, 8388607;
	or.b32  	%r1233, %r1232, 1065353216;
	mov.b32 	%f2429, %r1233;
	shr.u32 	%r1234, %r1231, 23;
	cvt.rn.f32.u32 	%f2430, %r1234;
	add.f32 	%f2431, %f2428, %f2430;
	setp.gt.f32 	%p1159, %f2429, 0f3FB504F3;
	mul.f32 	%f2432, %f2429, 0f3F000000;
	add.f32 	%f2433, %f2431, 0f3F800000;
	selp.f32 	%f2434, %f2433, %f2431, %p1159;
	selp.f32 	%f2435, %f2432, %f2429, %p1159;
	add.f32 	%f2436, %f2435, 0fBF800000;
	add.f32 	%f2437, %f2435, 0f3F800000;
	rcp.approx.ftz.f32 	%f2438, %f2437;
	add.f32 	%f2439, %f2436, %f2436;
	mul.f32 	%f2441, %f2439, %f2438;
	mul.f32 	%f2442, %f2441, %f2441;
	fma.rn.f32 	%f2445, %f1945, %f2442, %f1944;
	fma.rn.f32 	%f2447, %f2445, %f2442, %f1947;
	mul.rn.f32 	%f2448, %f2447, %f2442;
	mul.rn.f32 	%f2449, %f2448, %f2441;
	sub.f32 	%f2450, %f2436, %f2441;
	add.f32 	%f2451, %f2450, %f2450;
	neg.f32 	%f2452, %f2441;
	fma.rn.f32 	%f2453, %f2452, %f2436, %f2451;
	mul.rn.f32 	%f2454, %f2438, %f2453;
	add.f32 	%f2455, %f2449, %f2441;
	sub.f32 	%f2456, %f2441, %f2455;
	add.f32 	%f2457, %f2449, %f2456;
	add.f32 	%f2458, %f2454, %f2457;
	add.f32 	%f2459, %f2455, %f2458;
	sub.f32 	%f2460, %f2455, %f2459;
	add.f32 	%f2461, %f2458, %f2460;
	mul.rn.f32 	%f2463, %f2434, %f1963;
	mul.rn.f32 	%f2465, %f2434, %f1965;
	add.f32 	%f2466, %f2463, %f2459;
	sub.f32 	%f2467, %f2463, %f2466;
	add.f32 	%f2468, %f2459, %f2467;
	add.f32 	%f2469, %f2461, %f2468;
	add.f32 	%f2470, %f2465, %f2469;
	add.f32 	%f2471, %f2466, %f2470;
	sub.f32 	%f2472, %f2466, %f2471;
	add.f32 	%f2473, %f2470, %f2472;
	mul.rn.f32 	%f2474, %f1814, %f2471;
	neg.f32 	%f2475, %f2474;
	fma.rn.f32 	%f2476, %f1814, %f2471, %f2475;
	fma.rn.f32 	%f2477, %f1814, %f2473, %f2476;
	fma.rn.f32 	%f2479, %f1979, %f2471, %f2477;
	add.rn.f32 	%f2480, %f2474, %f2479;
	neg.f32 	%f2481, %f2480;
	add.rn.f32 	%f2482, %f2474, %f2481;
	add.rn.f32 	%f2483, %f2482, %f2479;
	mov.b32 	%r1235, %f2480;
	setp.eq.s32 	%p1160, %r1235, 1118925336;
	add.s32 	%r1236, %r1235, -1;
	mov.b32 	%f2484, %r1236;
	add.f32 	%f2485, %f2483, 0f37000000;
	selp.f32 	%f452, %f2485, %f2483, %p1160;
	selp.f32 	%f2486, %f2484, %f2480, %p1160;
	mul.rn.f32 	%f2487, %f2486, %f1988;
	cvt.rzi.f32.f32 	%f2488, %f2487;
	abs.f32 	%f2489, %f2488;
	setp.gt.f32 	%p1161, %f2489, 0f42FC0000;
	mov.b32 	%r1237, %f2488;
	and.b32  	%r1238, %r1237, -2147483648;
	or.b32  	%r1239, %r1238, 1123811328;
	mov.b32 	%f2490, %r1239;
	selp.f32 	%f2491, %f2490, %f2488, %p1161;
	fma.rn.f32 	%f2493, %f2491, %f1994, %f2486;
	fma.rn.f32 	%f2495, %f2491, %f1996, %f2493;
	mul.f32 	%f2496, %f2495, 0f3FB8AA3B;
	add.f32 	%f2497, %f2491, 0f4B40007F;
	mov.b32 	%r1240, %f2497;
	shl.b32 	%r1241, %r1240, 23;
	mov.b32 	%f2498, %r1241;
	ex2.approx.ftz.f32 	%f2499, %f2496;
	mul.f32 	%f453, %f2499, %f2498;
	setp.eq.f32 	%p1162, %f453, 0f7F800000;
	mov.f32 	%f3330, 0f7F800000;
	@%p1162 bra 	$L__BB2_768;

	fma.rn.f32 	%f3330, %f453, %f452, %f453;

$L__BB2_768:
	setp.lt.f32 	%p1163, %f450, 0f00000000;
	and.pred  	%p76, %p1163, %p1089;
	setp.eq.f32 	%p1165, %f450, 0f00000000;
	@%p1165 bra 	$L__BB2_772;
	bra.uni 	$L__BB2_769;

$L__BB2_772:
	add.f32 	%f2504, %f450, %f450;
	selp.f32 	%f3332, %f2504, 0f00000000, %p1089;
	bra.uni 	$L__BB2_773;

$L__BB2_769:
	mov.b32 	%r1242, %f3330;
	xor.b32  	%r1243, %r1242, -2147483648;
	mov.b32 	%f2500, %r1243;
	selp.f32 	%f3332, %f2500, %f3330, %p76;
	setp.geu.f32 	%p1166, %f450, 0f00000000;
	@%p1166 bra 	$L__BB2_773;

	cvt.rzi.f32.f32 	%f2502, %f1814;
	setp.eq.f32 	%p1167, %f2502, 0f40000000;
	@%p1167 bra 	$L__BB2_773;

	mov.f32 	%f3332, 0f7FFFFFFF;

$L__BB2_773:
	add.f32 	%f2505, %f451, 0f40000000;
	mov.b32 	%r1244, %f2505;
	setp.lt.s32 	%p1169, %r1244, 2139095040;
	@%p1169 bra 	$L__BB2_778;

	setp.gtu.f32 	%p1170, %f451, 0f7F800000;
	@%p1170 bra 	$L__BB2_777;
	bra.uni 	$L__BB2_775;

$L__BB2_777:
	add.f32 	%f3332, %f450, 0f40000000;
	bra.uni 	$L__BB2_778;

$L__BB2_775:
	setp.neu.f32 	%p1171, %f451, 0f7F800000;
	@%p1171 bra 	$L__BB2_778;

	selp.f32 	%f3332, 0fFF800000, 0f7F800000, %p76;

$L__BB2_778:
	mul.f32 	%f2507, %f3332, 0fBF000000;
	setp.eq.f32 	%p1172, %f450, 0f3F800000;
	selp.f32 	%f2508, 0fBF000000, %f2507, %p1172;
	fma.rn.f32 	%f2511, %f2508, %f2012, %f1833;
	cvt.sat.f32.f32 	%f2514, %f2511;
	fma.rm.f32 	%f2516, %f2514, %f2015, %f2017;
	add.f32 	%f2517, %f2516, 0fCB40007F;
	neg.f32 	%f2518, %f2517;
	fma.rn.f32 	%f2519, %f2508, %f1988, %f2518;
	fma.rn.f32 	%f2521, %f2508, %f2022, %f2519;
	mov.b32 	%r1245, %f2516;
	shl.b32 	%r1246, %r1245, 23;
	mov.b32 	%f2522, %r1246;
	ex2.approx.ftz.f32 	%f2523, %f2521;
	mul.f32 	%f2524, %f2523, %f2522;
	mul.f32 	%f2525, %f334, %f2524;
	mul.f32 	%f2526, %f339, %f449;
	sub.f32 	%f2527, %f2526, %f2525;
	div.rn.f32 	%f2528, %f408, %f357;
	mul.f32 	%f2529, %f2528, %f2527;
	mul.f32 	%f462, %f382, %f2529;
	add.f32 	%f2530, %f370, 0f3F800000;
	sub.f32 	%f2531, %f2530, %f3277;
	div.rn.f32 	%f463, %f2531, %f359;
	abs.f32 	%f464, %f463;
	setp.lt.f32 	%p1173, %f464, 0f00800000;
	mul.f32 	%f2532, %f464, 0f4B800000;
	selp.f32 	%f2533, %f2532, %f464, %p1173;
	selp.f32 	%f2534, 0fC3170000, 0fC2FE0000, %p1173;
	mov.b32 	%r1247, %f2533;
	and.b32  	%r1248, %r1247, 8388607;
	or.b32  	%r1249, %r1248, 1065353216;
	mov.b32 	%f2535, %r1249;
	shr.u32 	%r1250, %r1247, 23;
	cvt.rn.f32.u32 	%f2536, %r1250;
	add.f32 	%f2537, %f2534, %f2536;
	setp.gt.f32 	%p1174, %f2535, 0f3FB504F3;
	mul.f32 	%f2538, %f2535, 0f3F000000;
	add.f32 	%f2539, %f2537, 0f3F800000;
	selp.f32 	%f2540, %f2539, %f2537, %p1174;
	selp.f32 	%f2541, %f2538, %f2535, %p1174;
	add.f32 	%f2542, %f2541, 0fBF800000;
	add.f32 	%f2543, %f2541, 0f3F800000;
	rcp.approx.ftz.f32 	%f2544, %f2543;
	add.f32 	%f2545, %f2542, %f2542;
	mul.f32 	%f2547, %f2545, %f2544;
	mul.f32 	%f2548, %f2547, %f2547;
	fma.rn.f32 	%f2551, %f1945, %f2548, %f1944;
	fma.rn.f32 	%f2553, %f2551, %f2548, %f1947;
	mul.rn.f32 	%f2554, %f2553, %f2548;
	mul.rn.f32 	%f2555, %f2554, %f2547;
	sub.f32 	%f2556, %f2542, %f2547;
	add.f32 	%f2557, %f2556, %f2556;
	neg.f32 	%f2558, %f2547;
	fma.rn.f32 	%f2559, %f2558, %f2542, %f2557;
	mul.rn.f32 	%f2560, %f2544, %f2559;
	add.f32 	%f2561, %f2555, %f2547;
	sub.f32 	%f2562, %f2547, %f2561;
	add.f32 	%f2563, %f2555, %f2562;
	add.f32 	%f2564, %f2560, %f2563;
	add.f32 	%f2565, %f2561, %f2564;
	sub.f32 	%f2566, %f2561, %f2565;
	add.f32 	%f2567, %f2564, %f2566;
	mul.rn.f32 	%f2569, %f2540, %f1963;
	mul.rn.f32 	%f2571, %f2540, %f1965;
	add.f32 	%f2572, %f2569, %f2565;
	sub.f32 	%f2573, %f2569, %f2572;
	add.f32 	%f2574, %f2565, %f2573;
	add.f32 	%f2575, %f2567, %f2574;
	add.f32 	%f2576, %f2571, %f2575;
	add.f32 	%f2577, %f2572, %f2576;
	sub.f32 	%f2578, %f2572, %f2577;
	add.f32 	%f2579, %f2576, %f2578;
	mul.rn.f32 	%f2580, %f1814, %f2577;
	neg.f32 	%f2581, %f2580;
	fma.rn.f32 	%f2582, %f1814, %f2577, %f2581;
	fma.rn.f32 	%f2583, %f1814, %f2579, %f2582;
	fma.rn.f32 	%f2585, %f1979, %f2577, %f2583;
	add.rn.f32 	%f2586, %f2580, %f2585;
	neg.f32 	%f2587, %f2586;
	add.rn.f32 	%f2588, %f2580, %f2587;
	add.rn.f32 	%f2589, %f2588, %f2585;
	mov.b32 	%r1251, %f2586;
	setp.eq.s32 	%p1175, %r1251, 1118925336;
	add.s32 	%r1252, %r1251, -1;
	mov.b32 	%f2590, %r1252;
	add.f32 	%f2591, %f2589, 0f37000000;
	selp.f32 	%f465, %f2591, %f2589, %p1175;
	selp.f32 	%f2592, %f2590, %f2586, %p1175;
	mul.rn.f32 	%f2593, %f2592, %f1988;
	cvt.rzi.f32.f32 	%f2594, %f2593;
	abs.f32 	%f2595, %f2594;
	setp.gt.f32 	%p1176, %f2595, 0f42FC0000;
	mov.b32 	%r1253, %f2594;
	and.b32  	%r1254, %r1253, -2147483648;
	or.b32  	%r1255, %r1254, 1123811328;
	mov.b32 	%f2596, %r1255;
	selp.f32 	%f2597, %f2596, %f2594, %p1176;
	fma.rn.f32 	%f2599, %f2597, %f1994, %f2592;
	fma.rn.f32 	%f2601, %f2597, %f1996, %f2599;
	mul.f32 	%f2602, %f2601, 0f3FB8AA3B;
	add.f32 	%f2603, %f2597, 0f4B40007F;
	mov.b32 	%r1256, %f2603;
	shl.b32 	%r1257, %r1256, 23;
	mov.b32 	%f2604, %r1257;
	ex2.approx.ftz.f32 	%f2605, %f2602;
	mul.f32 	%f466, %f2605, %f2604;
	setp.eq.f32 	%p1177, %f466, 0f7F800000;
	mov.f32 	%f3333, 0f7F800000;
	@%p1177 bra 	$L__BB2_780;

	fma.rn.f32 	%f3333, %f466, %f465, %f466;

$L__BB2_780:
	setp.lt.f32 	%p1178, %f463, 0f00000000;
	and.pred  	%p77, %p1178, %p1089;
	setp.eq.f32 	%p1180, %f463, 0f00000000;
	@%p1180 bra 	$L__BB2_784;
	bra.uni 	$L__BB2_781;

$L__BB2_784:
	add.f32 	%f2610, %f463, %f463;
	selp.f32 	%f3335, %f2610, 0f00000000, %p1089;
	bra.uni 	$L__BB2_785;

$L__BB2_781:
	mov.b32 	%r1258, %f3333;
	xor.b32  	%r1259, %r1258, -2147483648;
	mov.b32 	%f2606, %r1259;
	selp.f32 	%f3335, %f2606, %f3333, %p77;
	setp.geu.f32 	%p1181, %f463, 0f00000000;
	@%p1181 bra 	$L__BB2_785;

	cvt.rzi.f32.f32 	%f2608, %f1814;
	setp.eq.f32 	%p1182, %f2608, 0f40000000;
	@%p1182 bra 	$L__BB2_785;

	mov.f32 	%f3335, 0f7FFFFFFF;

$L__BB2_785:
	add.f32 	%f2611, %f464, 0f40000000;
	mov.b32 	%r1260, %f2611;
	setp.lt.s32 	%p1184, %r1260, 2139095040;
	@%p1184 bra 	$L__BB2_790;

	setp.gtu.f32 	%p1185, %f464, 0f7F800000;
	@%p1185 bra 	$L__BB2_789;
	bra.uni 	$L__BB2_787;

$L__BB2_789:
	add.f32 	%f3335, %f463, 0f40000000;
	bra.uni 	$L__BB2_790;

$L__BB2_787:
	setp.neu.f32 	%p1186, %f464, 0f7F800000;
	@%p1186 bra 	$L__BB2_790;

	selp.f32 	%f3335, 0fFF800000, 0f7F800000, %p77;

$L__BB2_790:
	mul.f32 	%f2613, %f3335, 0fBF000000;
	setp.eq.f32 	%p1187, %f463, 0f3F800000;
	selp.f32 	%f2614, 0fBF000000, %f2613, %p1187;
	fma.rn.f32 	%f2617, %f2614, %f2012, %f1833;
	cvt.sat.f32.f32 	%f2620, %f2617;
	fma.rm.f32 	%f2622, %f2620, %f2015, %f2017;
	add.f32 	%f2623, %f2622, 0fCB40007F;
	neg.f32 	%f2624, %f2623;
	fma.rn.f32 	%f2625, %f2614, %f1988, %f2624;
	fma.rn.f32 	%f2627, %f2614, %f2022, %f2625;
	mov.b32 	%r1261, %f2622;
	shl.b32 	%r1262, %r1261, 23;
	mov.b32 	%f2628, %r1262;
	ex2.approx.ftz.f32 	%f2629, %f2627;
	mul.f32 	%f475, %f2629, %f2628;
	div.rn.f32 	%f476, %f371, %f359;
	abs.f32 	%f477, %f476;
	setp.lt.f32 	%p1188, %f477, 0f00800000;
	mul.f32 	%f2630, %f477, 0f4B800000;
	selp.f32 	%f2631, %f2630, %f477, %p1188;
	selp.f32 	%f2632, 0fC3170000, 0fC2FE0000, %p1188;
	mov.b32 	%r1263, %f2631;
	and.b32  	%r1264, %r1263, 8388607;
	or.b32  	%r1265, %r1264, 1065353216;
	mov.b32 	%f2633, %r1265;
	shr.u32 	%r1266, %r1263, 23;
	cvt.rn.f32.u32 	%f2634, %r1266;
	add.f32 	%f2635, %f2632, %f2634;
	setp.gt.f32 	%p1189, %f2633, 0f3FB504F3;
	mul.f32 	%f2636, %f2633, 0f3F000000;
	add.f32 	%f2637, %f2635, 0f3F800000;
	selp.f32 	%f2638, %f2637, %f2635, %p1189;
	selp.f32 	%f2639, %f2636, %f2633, %p1189;
	add.f32 	%f2640, %f2639, 0fBF800000;
	add.f32 	%f2641, %f2639, 0f3F800000;
	rcp.approx.ftz.f32 	%f2642, %f2641;
	add.f32 	%f2643, %f2640, %f2640;
	mul.f32 	%f2645, %f2643, %f2642;
	mul.f32 	%f2646, %f2645, %f2645;
	fma.rn.f32 	%f2649, %f1945, %f2646, %f1944;
	fma.rn.f32 	%f2651, %f2649, %f2646, %f1947;
	mul.rn.f32 	%f2652, %f2651, %f2646;
	mul.rn.f32 	%f2653, %f2652, %f2645;
	sub.f32 	%f2654, %f2640, %f2645;
	add.f32 	%f2655, %f2654, %f2654;
	neg.f32 	%f2656, %f2645;
	fma.rn.f32 	%f2657, %f2656, %f2640, %f2655;
	mul.rn.f32 	%f2658, %f2642, %f2657;
	add.f32 	%f2659, %f2653, %f2645;
	sub.f32 	%f2660, %f2645, %f2659;
	add.f32 	%f2661, %f2653, %f2660;
	add.f32 	%f2662, %f2658, %f2661;
	add.f32 	%f2663, %f2659, %f2662;
	sub.f32 	%f2664, %f2659, %f2663;
	add.f32 	%f2665, %f2662, %f2664;
	mul.rn.f32 	%f2667, %f2638, %f1963;
	mul.rn.f32 	%f2669, %f2638, %f1965;
	add.f32 	%f2670, %f2667, %f2663;
	sub.f32 	%f2671, %f2667, %f2670;
	add.f32 	%f2672, %f2663, %f2671;
	add.f32 	%f2673, %f2665, %f2672;
	add.f32 	%f2674, %f2669, %f2673;
	add.f32 	%f2675, %f2670, %f2674;
	sub.f32 	%f2676, %f2670, %f2675;
	add.f32 	%f2677, %f2674, %f2676;
	mul.rn.f32 	%f2678, %f1814, %f2675;
	neg.f32 	%f2679, %f2678;
	fma.rn.f32 	%f2680, %f1814, %f2675, %f2679;
	fma.rn.f32 	%f2681, %f1814, %f2677, %f2680;
	fma.rn.f32 	%f2683, %f1979, %f2675, %f2681;
	add.rn.f32 	%f2684, %f2678, %f2683;
	neg.f32 	%f2685, %f2684;
	add.rn.f32 	%f2686, %f2678, %f2685;
	add.rn.f32 	%f2687, %f2686, %f2683;
	mov.b32 	%r1267, %f2684;
	setp.eq.s32 	%p1190, %r1267, 1118925336;
	add.s32 	%r1268, %r1267, -1;
	mov.b32 	%f2688, %r1268;
	add.f32 	%f2689, %f2687, 0f37000000;
	selp.f32 	%f478, %f2689, %f2687, %p1190;
	selp.f32 	%f2690, %f2688, %f2684, %p1190;
	mul.rn.f32 	%f2691, %f2690, %f1988;
	cvt.rzi.f32.f32 	%f2692, %f2691;
	abs.f32 	%f2693, %f2692;
	setp.gt.f32 	%p1191, %f2693, 0f42FC0000;
	mov.b32 	%r1269, %f2692;
	and.b32  	%r1270, %r1269, -2147483648;
	or.b32  	%r1271, %r1270, 1123811328;
	mov.b32 	%f2694, %r1271;
	selp.f32 	%f2695, %f2694, %f2692, %p1191;
	fma.rn.f32 	%f2697, %f2695, %f1994, %f2690;
	fma.rn.f32 	%f2699, %f2695, %f1996, %f2697;
	mul.f32 	%f2700, %f2699, 0f3FB8AA3B;
	add.f32 	%f2701, %f2695, 0f4B40007F;
	mov.b32 	%r1272, %f2701;
	shl.b32 	%r1273, %r1272, 23;
	mov.b32 	%f2702, %r1273;
	ex2.approx.ftz.f32 	%f2703, %f2700;
	mul.f32 	%f479, %f2703, %f2702;
	setp.eq.f32 	%p1192, %f479, 0f7F800000;
	mov.f32 	%f3336, 0f7F800000;
	@%p1192 bra 	$L__BB2_792;

	fma.rn.f32 	%f3336, %f479, %f478, %f479;

$L__BB2_792:
	setp.lt.f32 	%p1193, %f476, 0f00000000;
	and.pred  	%p78, %p1193, %p1089;
	setp.eq.f32 	%p1195, %f476, 0f00000000;
	@%p1195 bra 	$L__BB2_796;
	bra.uni 	$L__BB2_793;

$L__BB2_796:
	add.f32 	%f2708, %f476, %f476;
	selp.f32 	%f3338, %f2708, 0f00000000, %p1089;
	bra.uni 	$L__BB2_797;

$L__BB2_793:
	mov.b32 	%r1274, %f3336;
	xor.b32  	%r1275, %r1274, -2147483648;
	mov.b32 	%f2704, %r1275;
	selp.f32 	%f3338, %f2704, %f3336, %p78;
	setp.geu.f32 	%p1196, %f476, 0f00000000;
	@%p1196 bra 	$L__BB2_797;

	cvt.rzi.f32.f32 	%f2706, %f1814;
	setp.eq.f32 	%p1197, %f2706, 0f40000000;
	@%p1197 bra 	$L__BB2_797;

	mov.f32 	%f3338, 0f7FFFFFFF;

$L__BB2_797:
	add.f32 	%f2709, %f477, 0f40000000;
	mov.b32 	%r1276, %f2709;
	setp.lt.s32 	%p1199, %r1276, 2139095040;
	@%p1199 bra 	$L__BB2_802;

	setp.gtu.f32 	%p1200, %f477, 0f7F800000;
	@%p1200 bra 	$L__BB2_801;
	bra.uni 	$L__BB2_799;

$L__BB2_801:
	add.f32 	%f3338, %f476, 0f40000000;
	bra.uni 	$L__BB2_802;

$L__BB2_799:
	setp.neu.f32 	%p1201, %f477, 0f7F800000;
	@%p1201 bra 	$L__BB2_802;

	selp.f32 	%f3338, 0fFF800000, 0f7F800000, %p78;

$L__BB2_802:
	mul.f32 	%f2710, %f3338, 0fBF000000;
	setp.eq.f32 	%p1202, %f476, 0f3F800000;
	selp.f32 	%f2711, 0fBF000000, %f2710, %p1202;
	fma.rn.f32 	%f2714, %f2711, %f2012, %f1833;
	cvt.sat.f32.f32 	%f2717, %f2714;
	fma.rm.f32 	%f2719, %f2717, %f2015, %f2017;
	add.f32 	%f2720, %f2719, 0fCB40007F;
	neg.f32 	%f2721, %f2720;
	fma.rn.f32 	%f2722, %f2711, %f1988, %f2721;
	fma.rn.f32 	%f2724, %f2711, %f2022, %f2722;
	mov.b32 	%r1277, %f2719;
	shl.b32 	%r1278, %r1277, 23;
	mov.b32 	%f2725, %r1278;
	ex2.approx.ftz.f32 	%f2726, %f2724;
	mul.f32 	%f2727, %f2726, %f2725;
	add.f32 	%f2728, %f371, 0f3F800000;
	mul.f32 	%f2729, %f2728, %f475;
	mul.f32 	%f2730, %f371, %f2727;
	sub.f32 	%f2731, %f2729, %f2730;
	div.rn.f32 	%f2732, %f435, %f359;
	mul.f32 	%f488, %f2732, %f2731;
	not.pred 	%p1203, %p55;
	mov.f64 	%fd1205, %fd447;
	@%p1203 bra 	$L__BB2_804;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1279}, %fd447;
	}
	xor.b32  	%r1280, %r1279, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1281, %temp}, %fd447;
	}
	mov.b64 	%fd1205, {%r1281, %r1280};

$L__BB2_804:
	setp.eq.f32 	%p1204, %f310, 0f00000000;
	@%p1204 bra 	$L__BB2_808;
	bra.uni 	$L__BB2_805;

$L__BB2_808:
	mov.u32 	%r1282, 0;
	mov.b64 	%fd1205, {%r1282, %r153};
	bra.uni 	$L__BB2_809;

$L__BB2_805:
	setp.gt.s32 	%p1205, %r152, -1;
	@%p1205 bra 	$L__BB2_809;

	cvt.rzi.f64.f64 	%fd1004, %fd962;
	setp.eq.f64 	%p1206, %fd1004, 0d4000000000000000;
	@%p1206 bra 	$L__BB2_809;

	mov.f64 	%fd1205, 0dFFF8000000000000;

$L__BB2_809:
	selp.f64 	%fd1206, %fd1205, %fd429, %p986;
	@%p66 bra 	$L__BB2_814;

	setp.eq.s32 	%p1208, %r124, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1283, %temp}, %fd962;
	}
	setp.eq.s32 	%p1209, %r1283, 0;
	and.pred  	%p1210, %p1208, %p1209;
	@%p1210 bra 	$L__BB2_813;
	bra.uni 	$L__BB2_811;

$L__BB2_813:
	mov.u32 	%r1286, 0;
	mov.b64 	%fd1206, {%r1286, %r155};
	bra.uni 	$L__BB2_814;

$L__BB2_811:
	setp.ne.s32 	%p1211, %r156, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1284, %temp}, %fd428;
	}
	setp.ne.s32 	%p1212, %r1284, 0;
	or.pred  	%p1213, %p1211, %p1212;
	mov.f64 	%fd1206, %fd1205;
	@%p1213 bra 	$L__BB2_814;

	mov.u32 	%r1285, 0;
	mov.b64 	%fd1206, {%r1285, %r159};

$L__BB2_814:
	not.pred 	%p1214, %p56;
	mov.f64 	%fd1208, %fd448;
	@%p1214 bra 	$L__BB2_816;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1287}, %fd448;
	}
	xor.b32  	%r1288, %r1287, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1289, %temp}, %fd448;
	}
	mov.b64 	%fd1208, {%r1289, %r1288};

$L__BB2_816:
	@%p1204 bra 	$L__BB2_820;
	bra.uni 	$L__BB2_817;

$L__BB2_820:
	mov.u32 	%r1290, 0;
	mov.b64 	%fd1208, {%r1290, %r157};
	bra.uni 	$L__BB2_821;

$L__BB2_817:
	setp.gt.s32 	%p1216, %r152, -1;
	@%p1216 bra 	$L__BB2_821;

	cvt.rzi.f64.f64 	%fd1008, %fd963;
	setp.eq.f64 	%p1217, %fd1008, 0d4008000000000000;
	@%p1217 bra 	$L__BB2_821;

	mov.f64 	%fd1208, 0dFFF8000000000000;

$L__BB2_821:
	selp.f64 	%fd1209, %fd1208, %fd432, %p989;
	@%p67 bra 	$L__BB2_826;

	setp.eq.s32 	%p1219, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1291, %temp}, %fd963;
	}
	setp.eq.s32 	%p1220, %r1291, 0;
	and.pred  	%p1221, %p1219, %p1220;
	@%p1221 bra 	$L__BB2_825;
	bra.uni 	$L__BB2_823;

$L__BB2_825:
	mov.u32 	%r1294, 0;
	mov.b64 	%fd1209, {%r1294, %r161};
	bra.uni 	$L__BB2_826;

$L__BB2_823:
	setp.ne.s32 	%p1222, %r156, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1292, %temp}, %fd428;
	}
	setp.ne.s32 	%p1223, %r1292, 0;
	or.pred  	%p1224, %p1222, %p1223;
	mov.f64 	%fd1209, %fd1208;
	@%p1224 bra 	$L__BB2_826;

	mov.u32 	%r1293, 0;
	mov.b64 	%fd1209, {%r1293, %r164};

$L__BB2_826:
	not.pred 	%p1225, %p57;
	mov.f64 	%fd1211, %fd449;
	@%p1225 bra 	$L__BB2_828;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1295}, %fd449;
	}
	xor.b32  	%r1296, %r1295, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1297, %temp}, %fd449;
	}
	mov.b64 	%fd1211, {%r1297, %r1296};

$L__BB2_828:
	setp.eq.f32 	%p1226, %f541, 0f00000000;
	@%p1226 bra 	$L__BB2_832;
	bra.uni 	$L__BB2_829;

$L__BB2_832:
	mov.u32 	%r1298, 0;
	mov.b64 	%fd1211, {%r1298, %r162};
	bra.uni 	$L__BB2_833;

$L__BB2_829:
	setp.gt.s32 	%p1227, %r160, -1;
	@%p1227 bra 	$L__BB2_833;

	cvt.rzi.f64.f64 	%fd1012, %fd964;
	setp.eq.f64 	%p1228, %fd1012, 0d4010000000000000;
	@%p1228 bra 	$L__BB2_833;

	mov.f64 	%fd1211, 0dFFF8000000000000;

$L__BB2_833:
	selp.f64 	%fd1212, %fd1211, %fd434, %p992;
	@%p68 bra 	$L__BB2_838;

	setp.eq.s32 	%p1230, %r136, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1299, %temp}, %fd964;
	}
	setp.eq.s32 	%p1231, %r1299, 0;
	and.pred  	%p1232, %p1230, %p1231;
	@%p1232 bra 	$L__BB2_837;
	bra.uni 	$L__BB2_835;

$L__BB2_837:
	mov.u32 	%r1302, 0;
	mov.b64 	%fd1212, {%r1302, %r166};
	bra.uni 	$L__BB2_838;

$L__BB2_835:
	setp.ne.s32 	%p1233, %r167, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1300, %temp}, %fd433;
	}
	setp.ne.s32 	%p1234, %r1300, 0;
	or.pred  	%p1235, %p1233, %p1234;
	mov.f64 	%fd1212, %fd1211;
	@%p1235 bra 	$L__BB2_838;

	mov.u32 	%r1301, 0;
	mov.b64 	%fd1212, {%r1301, %r170};

$L__BB2_838:
	setp.eq.f32 	%p1236, %f541, 0f3F800000;
	selp.f64 	%fd1015, 0d3FF0000000000000, %fd1212, %p1236;
	setp.eq.f32 	%p1237, %f310, 0f3F800000;
	selp.f64 	%fd1016, 0d3FF0000000000000, %fd1209, %p1237;
	mul.f64 	%fd1017, %fd1016, %fd431;
	div.rn.f64 	%fd1018, %fd1017, %fd1015;
	selp.f64 	%fd1019, 0d3FF0000000000000, %fd1206, %p1237;
	mul.f64 	%fd1020, %fd1019, %fd427;
	div.rn.f64 	%fd1021, %fd1020, %fd430;
	add.f64 	%fd1022, %fd1021, %fd426;
	add.f64 	%fd1023, %fd1022, %fd1018;
	cvt.rn.f32.f64 	%f2733, %fd1023;
	div.rn.f32 	%f2734, %f315, %f356;
	mul.f32 	%f489, %f2734, %f2733;
	not.pred 	%p1238, %p58;
	mov.f64 	%fd1214, %fd450;
	@%p1238 bra 	$L__BB2_840;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1303}, %fd450;
	}
	xor.b32  	%r1304, %r1303, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1305, %temp}, %fd450;
	}
	mov.b64 	%fd1214, {%r1305, %r1304};

$L__BB2_840:
	setp.eq.f32 	%p1239, %f312, 0f00000000;
	@%p1239 bra 	$L__BB2_844;
	bra.uni 	$L__BB2_841;

$L__BB2_844:
	mov.u32 	%r1306, 0;
	mov.b64 	%fd1214, {%r1306, %r168};
	bra.uni 	$L__BB2_845;

$L__BB2_841:
	setp.gt.s32 	%p1240, %r165, -1;
	@%p1240 bra 	$L__BB2_845;

	cvt.rzi.f64.f64 	%fd1025, %fd962;
	setp.eq.f64 	%p1241, %fd1025, 0d4000000000000000;
	@%p1241 bra 	$L__BB2_845;

	mov.f64 	%fd1214, 0dFFF8000000000000;

$L__BB2_845:
	selp.f64 	%fd1215, %fd1214, %fd438, %p998;
	@%p69 bra 	$L__BB2_850;

	setp.eq.s32 	%p1243, %r124, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1307, %temp}, %fd962;
	}
	setp.eq.s32 	%p1244, %r1307, 0;
	and.pred  	%p1245, %p1243, %p1244;
	@%p1245 bra 	$L__BB2_849;
	bra.uni 	$L__BB2_847;

$L__BB2_849:
	mov.u32 	%r1310, 0;
	mov.b64 	%fd1215, {%r1310, %r171};
	bra.uni 	$L__BB2_850;

$L__BB2_847:
	setp.ne.s32 	%p1246, %r172, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1308, %temp}, %fd437;
	}
	setp.ne.s32 	%p1247, %r1308, 0;
	or.pred  	%p1248, %p1246, %p1247;
	mov.f64 	%fd1215, %fd1214;
	@%p1248 bra 	$L__BB2_850;

	mov.u32 	%r1309, 0;
	mov.b64 	%fd1215, {%r1309, %r175};

$L__BB2_850:
	not.pred 	%p1249, %p59;
	mov.f64 	%fd1217, %fd451;
	@%p1249 bra 	$L__BB2_852;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1311}, %fd451;
	}
	xor.b32  	%r1312, %r1311, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1313, %temp}, %fd451;
	}
	mov.b64 	%fd1217, {%r1313, %r1312};

$L__BB2_852:
	@%p1239 bra 	$L__BB2_856;
	bra.uni 	$L__BB2_853;

$L__BB2_856:
	mov.u32 	%r1314, 0;
	mov.b64 	%fd1217, {%r1314, %r173};
	bra.uni 	$L__BB2_857;

$L__BB2_853:
	setp.gt.s32 	%p1251, %r165, -1;
	@%p1251 bra 	$L__BB2_857;

	cvt.rzi.f64.f64 	%fd1029, %fd963;
	setp.eq.f64 	%p1252, %fd1029, 0d4008000000000000;
	@%p1252 bra 	$L__BB2_857;

	mov.f64 	%fd1217, 0dFFF8000000000000;

$L__BB2_857:
	selp.f64 	%fd1218, %fd1217, %fd440, %p1002;
	@%p70 bra 	$L__BB2_862;

	setp.eq.s32 	%p1254, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1315, %temp}, %fd963;
	}
	setp.eq.s32 	%p1255, %r1315, 0;
	and.pred  	%p1256, %p1254, %p1255;
	@%p1256 bra 	$L__BB2_861;
	bra.uni 	$L__BB2_859;

$L__BB2_861:
	mov.u32 	%r1318, 0;
	mov.b64 	%fd1218, {%r1318, %r176};
	bra.uni 	$L__BB2_862;

$L__BB2_859:
	setp.ne.s32 	%p1257, %r172, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1316, %temp}, %fd437;
	}
	setp.ne.s32 	%p1258, %r1316, 0;
	or.pred  	%p1259, %p1257, %p1258;
	mov.f64 	%fd1218, %fd1217;
	@%p1259 bra 	$L__BB2_862;

	mov.u32 	%r1317, 0;
	mov.b64 	%fd1218, {%r1317, %r177};

$L__BB2_862:
	mov.f64 	%fd1220, %fd449;
	@%p1225 bra 	$L__BB2_864;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1319}, %fd449;
	}
	xor.b32  	%r1320, %r1319, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1321, %temp}, %fd449;
	}
	mov.b64 	%fd1220, {%r1321, %r1320};

$L__BB2_864:
	@%p1226 bra 	$L__BB2_868;
	bra.uni 	$L__BB2_865;

$L__BB2_868:
	mov.u32 	%r1322, 0;
	mov.b64 	%fd1220, {%r1322, %r162};
	bra.uni 	$L__BB2_869;

$L__BB2_865:
	setp.gt.s32 	%p1262, %r160, -1;
	@%p1262 bra 	$L__BB2_869;

	cvt.rzi.f64.f64 	%fd1033, %fd964;
	setp.eq.f64 	%p1263, %fd1033, 0d4010000000000000;
	@%p1263 bra 	$L__BB2_869;

	mov.f64 	%fd1220, 0dFFF8000000000000;

$L__BB2_869:
	selp.f64 	%fd1221, %fd1220, %fd434, %p992;
	@%p68 bra 	$L__BB2_874;

	setp.eq.s32 	%p1265, %r136, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1323, %temp}, %fd964;
	}
	setp.eq.s32 	%p1266, %r1323, 0;
	and.pred  	%p1267, %p1265, %p1266;
	@%p1267 bra 	$L__BB2_873;
	bra.uni 	$L__BB2_871;

$L__BB2_873:
	mov.u32 	%r1326, 0;
	mov.b64 	%fd1221, {%r1326, %r166};
	bra.uni 	$L__BB2_874;

$L__BB2_871:
	setp.ne.s32 	%p1268, %r167, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1324, %temp}, %fd433;
	}
	setp.ne.s32 	%p1269, %r1324, 0;
	or.pred  	%p1270, %p1268, %p1269;
	mov.f64 	%fd1221, %fd1220;
	@%p1270 bra 	$L__BB2_874;

	mov.u32 	%r1325, 0;
	mov.b64 	%fd1221, {%r1325, %r170};

$L__BB2_874:
	selp.f64 	%fd1036, 0d3FF0000000000000, %fd1221, %p1236;
	setp.eq.f32 	%p1272, %f312, 0f3F800000;
	selp.f64 	%fd1037, 0d3FF0000000000000, %fd1218, %p1272;
	mul.f64 	%fd1038, %fd1037, %fd439;
	div.rn.f64 	%fd1039, %fd1038, %fd1036;
	selp.f64 	%fd1040, 0d3FF0000000000000, %fd1215, %p1272;
	mul.f64 	%fd1041, %fd1040, %fd436;
	div.rn.f64 	%fd1042, %fd1041, %fd430;
	add.f64 	%fd1043, %fd1042, %fd435;
	add.f64 	%fd1044, %fd1043, %fd1039;
	cvt.rn.f32.f64 	%f2735, %fd1044;
	div.rn.f32 	%f2736, %f316, %f358;
	mul.f32 	%f2737, %f2736, %f2735;
	mul.f32 	%f2738, %f369, %f488;
	mul.f32 	%f2739, %f2738, %f2737;
	fma.rn.f32 	%f2740, %f462, %f489, %f2739;
	mul.f32 	%f2741, %f369, %f3276;
	fma.rn.f32 	%f490, %f382, %f2741, %f3275;
	mad.lo.s32 	%r1327, %r1373, %r182, %r1372;
	add.s32 	%r1328, %r1327, %r2;
	mul.wide.s32 	%rd24, %r1328, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.f32 	%f491, [%rd25];
	mul.f32 	%f2742, %f409, %f409;
	div.rn.f32 	%f2743, %f2742, %f490;
	add.f32 	%f3306, %f3306, %f2743;
	mul.f32 	%f2744, %f436, %f409;
	div.rn.f32 	%f2745, %f2744, %f490;
	add.f32 	%f3305, %f3305, %f2745;
	mul.f32 	%f2746, %f369, %f382;
	mul.f32 	%f2747, %f2746, %f409;
	div.rn.f32 	%f2748, %f2747, %f490;
	add.f32 	%f3304, %f3304, %f2748;
	div.rn.f32 	%f2749, %f409, %f490;
	add.f32 	%f3303, %f3303, %f2749;
	mul.f32 	%f2750, %f2740, %f409;
	div.rn.f32 	%f2751, %f2750, %f490;
	add.f32 	%f3302, %f3302, %f2751;
	mul.f32 	%f2752, %f436, %f436;
	div.rn.f32 	%f2753, %f2752, %f490;
	add.f32 	%f3301, %f3301, %f2753;
	mul.f32 	%f2754, %f2746, %f436;
	div.rn.f32 	%f2755, %f2754, %f490;
	add.f32 	%f3300, %f3300, %f2755;
	div.rn.f32 	%f2756, %f436, %f490;
	add.f32 	%f3299, %f3299, %f2756;
	mul.f32 	%f2757, %f2740, %f436;
	div.rn.f32 	%f2758, %f2757, %f490;
	add.f32 	%f3298, %f3298, %f2758;
	mul.f32 	%f2759, %f2746, %f2746;
	div.rn.f32 	%f2760, %f2759, %f490;
	add.f32 	%f3297, %f3297, %f2760;
	div.rn.f32 	%f2761, %f2746, %f490;
	add.f32 	%f3296, %f3296, %f2761;
	mul.f32 	%f2762, %f2740, %f2746;
	div.rn.f32 	%f2763, %f2762, %f490;
	add.f32 	%f3295, %f3295, %f2763;
	rcp.rn.f32 	%f2764, %f490;
	add.f32 	%f3307, %f3307, %f2764;
	div.rn.f32 	%f2765, %f2740, %f490;
	add.f32 	%f3308, %f3308, %f2765;
	mul.f32 	%f2766, %f2740, %f2740;
	div.rn.f32 	%f2767, %f2766, %f490;
	add.f32 	%f3309, %f3309, %f2767;
	setp.leu.f32 	%p1273, %f490, 0f00000000;
	@%p1273 bra 	$L__BB2_882;

	setp.gt.f32 	%p1274, %f491, 0f00000000;
	@%p1274 bra 	$L__BB2_877;
	bra.uni 	$L__BB2_876;

$L__BB2_877:
	setp.lt.f32 	%p1275, %f490, 0f00800000;
	mul.f32 	%f2768, %f490, 0f4B000000;
	selp.f32 	%f508, %f2768, %f490, %p1275;
	selp.f32 	%f2769, 0fC1B80000, 0f00000000, %p1275;
	mov.b32 	%r1329, %f508;
	add.s32 	%r1330, %r1329, -1059760811;
	and.b32  	%r1331, %r1330, -8388608;
	sub.s32 	%r1332, %r1329, %r1331;
	mov.b32 	%f2770, %r1332;
	cvt.rn.f32.s32 	%f2771, %r1331;
	mov.f32 	%f2772, 0f34000000;
	fma.rn.f32 	%f2773, %f2771, %f2772, %f2769;
	add.f32 	%f2774, %f2770, 0fBF800000;
	mov.f32 	%f2775, 0f3E1039F6;
	mov.f32 	%f2776, 0fBE055027;
	fma.rn.f32 	%f2777, %f2776, %f2774, %f2775;
	mov.f32 	%f2778, 0fBDF8CDCC;
	fma.rn.f32 	%f2779, %f2777, %f2774, %f2778;
	mov.f32 	%f2780, 0f3E0F2955;
	fma.rn.f32 	%f2781, %f2779, %f2774, %f2780;
	mov.f32 	%f2782, 0fBE2AD8B9;
	fma.rn.f32 	%f2783, %f2781, %f2774, %f2782;
	mov.f32 	%f2784, 0f3E4CED0B;
	fma.rn.f32 	%f2785, %f2783, %f2774, %f2784;
	mov.f32 	%f2786, 0fBE7FFF22;
	fma.rn.f32 	%f2787, %f2785, %f2774, %f2786;
	mov.f32 	%f2788, 0f3EAAAA78;
	fma.rn.f32 	%f2789, %f2787, %f2774, %f2788;
	mov.f32 	%f2790, 0fBF000000;
	fma.rn.f32 	%f2791, %f2789, %f2774, %f2790;
	mul.f32 	%f2792, %f2774, %f2791;
	fma.rn.f32 	%f2793, %f2792, %f2774, %f2774;
	mov.f32 	%f2794, 0f3F317218;
	fma.rn.f32 	%f3339, %f2773, %f2794, %f2793;
	setp.lt.u32 	%p1276, %r1329, 2139095040;
	@%p1276 bra 	$L__BB2_879;

	mov.f32 	%f2795, 0f7F800000;
	fma.rn.f32 	%f3339, %f508, %f2795, %f2795;

$L__BB2_879:
	setp.eq.f32 	%p1277, %f508, 0f00000000;
	selp.f32 	%f2796, 0fFF800000, %f3339, %p1277;
	mul.f32 	%f2797, %f491, %f2796;
	sub.f32 	%f512, %f2797, %f490;
	mul.f32 	%f2798, %f491, 0f4B000000;
	setp.lt.f32 	%p1278, %f491, 0f00800000;
	selp.f32 	%f513, %f2798, %f491, %p1278;
	selp.f32 	%f2799, 0fC1B80000, 0f00000000, %p1278;
	mov.b32 	%r1333, %f513;
	add.s32 	%r1334, %r1333, -1059760811;
	and.b32  	%r1335, %r1334, -8388608;
	sub.s32 	%r1336, %r1333, %r1335;
	mov.b32 	%f2800, %r1336;
	cvt.rn.f32.s32 	%f2801, %r1335;
	fma.rn.f32 	%f2803, %f2801, %f2772, %f2799;
	add.f32 	%f2804, %f2800, 0fBF800000;
	fma.rn.f32 	%f2807, %f2776, %f2804, %f2775;
	fma.rn.f32 	%f2809, %f2807, %f2804, %f2778;
	fma.rn.f32 	%f2811, %f2809, %f2804, %f2780;
	fma.rn.f32 	%f2813, %f2811, %f2804, %f2782;
	fma.rn.f32 	%f2815, %f2813, %f2804, %f2784;
	fma.rn.f32 	%f2817, %f2815, %f2804, %f2786;
	fma.rn.f32 	%f2819, %f2817, %f2804, %f2788;
	fma.rn.f32 	%f2821, %f2819, %f2804, %f2790;
	mul.f32 	%f2822, %f2804, %f2821;
	fma.rn.f32 	%f2823, %f2822, %f2804, %f2804;
	fma.rn.f32 	%f3340, %f2803, %f2794, %f2823;
	setp.lt.u32 	%p1279, %r1333, 2139095040;
	@%p1279 bra 	$L__BB2_881;

	mov.f32 	%f2825, 0f7F800000;
	fma.rn.f32 	%f3340, %f513, %f2825, %f2825;

$L__BB2_881:
	setp.eq.f32 	%p1280, %f513, 0f00000000;
	selp.f32 	%f2826, 0fFF800000, %f3340, %p1280;
	mul.f32 	%f2827, %f491, %f2826;
	sub.f32 	%f2828, %f512, %f2827;
	add.f32 	%f2829, %f491, %f2828;
	add.f32 	%f3341, %f3341, %f2829;
	bra.uni 	$L__BB2_882;

$L__BB2_876:
	sub.f32 	%f3341, %f3341, %f490;

$L__BB2_882:
	add.s32 	%r1373, %r1373, 1;
	setp.lt.s32 	%p1281, %r1373, %r182;
	@%p1281 bra 	$L__BB2_626;

	add.s32 	%r1372, %r1372, 1;
	setp.lt.s32 	%p1282, %r1372, %r182;
	@%p1282 bra 	$L__BB2_625;

$L__BB2_884:
	ld.param.u64 	%rd46, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_13];
	ld.param.u64 	%rd45, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_12];
	ld.param.u32 	%r1360, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_14];
	ld.param.u64 	%rd44, [_Z20kernel_MLEFit_XYNBZ_PKfffffffffiiPfS1_S1_i_param_11];
	mov.u32 	%r1359, %tid.x;
	mov.u32 	%r1358, %ntid.x;
	mov.u32 	%r1357, %ctaid.x;
	mad.lo.s32 	%r1356, %r1357, %r1358, %r1359;
	rcp.rn.f32 	%f2830, %f3306;
	mov.f32 	%f2831, 0f3F800000;
	mul.f32 	%f2832, %f2830, %f3305;
	mul.f32 	%f2833, %f2830, %f3304;
	mul.f32 	%f2834, %f2830, %f3303;
	mul.f32 	%f2835, %f2830, %f3302;
	fma.rn.f32 	%f2836, %f2832, %f3305, 0f00000000;
	sub.f32 	%f2838, %f3301, %f2836;
	fma.rn.f32 	%f2839, %f2833, %f3305, 0f00000000;
	rcp.rn.f32 	%f2840, %f2838;
	sub.f32 	%f2841, %f3300, %f2839;
	mul.f32 	%f2842, %f2840, %f2841;
	fma.rn.f32 	%f2843, %f2834, %f3305, 0f00000000;
	sub.f32 	%f2844, %f3299, %f2843;
	mul.f32 	%f2845, %f2840, %f2844;
	fma.rn.f32 	%f2846, %f2835, %f3305, 0f00000000;
	sub.f32 	%f2847, %f3298, %f2846;
	mul.f32 	%f2848, %f2840, %f2847;
	fma.rn.f32 	%f2849, %f2832, %f3304, 0f00000000;
	sub.f32 	%f2850, %f3300, %f2849;
	fma.rn.f32 	%f2851, %f2833, %f3304, 0f00000000;
	fma.rn.f32 	%f2852, %f2842, %f2850, %f2851;
	sub.f32 	%f2853, %f3297, %f2852;
	fma.rn.f32 	%f2854, %f2834, %f3304, 0f00000000;
	fma.rn.f32 	%f2855, %f2845, %f2850, %f2854;
	rcp.rn.f32 	%f2856, %f2853;
	sub.f32 	%f2857, %f3296, %f2855;
	mul.f32 	%f2858, %f2856, %f2857;
	fma.rn.f32 	%f2859, %f2835, %f3304, 0f00000000;
	fma.rn.f32 	%f2860, %f2848, %f2850, %f2859;
	sub.f32 	%f2861, %f3295, %f2860;
	mul.f32 	%f2862, %f2856, %f2861;
	fma.rn.f32 	%f2863, %f2832, %f3303, 0f00000000;
	sub.f32 	%f2864, %f3299, %f2863;
	fma.rn.f32 	%f2865, %f2833, %f3303, 0f00000000;
	fma.rn.f32 	%f2866, %f2842, %f2864, %f2865;
	sub.f32 	%f2867, %f3296, %f2866;
	fma.rn.f32 	%f2868, %f2834, %f3303, 0f00000000;
	fma.rn.f32 	%f2869, %f2845, %f2864, %f2868;
	fma.rn.f32 	%f2870, %f2858, %f2867, %f2869;
	sub.f32 	%f2871, %f3307, %f2870;
	fma.rn.f32 	%f2872, %f2835, %f3303, 0f00000000;
	fma.rn.f32 	%f2873, %f2848, %f2864, %f2872;
	fma.rn.f32 	%f2874, %f2862, %f2867, %f2873;
	rcp.rn.f32 	%f2875, %f2871;
	sub.f32 	%f2876, %f3308, %f2874;
	mul.f32 	%f2877, %f2875, %f2876;
	fma.rn.f32 	%f2878, %f2832, %f3302, 0f00000000;
	sub.f32 	%f2879, %f3298, %f2878;
	fma.rn.f32 	%f2880, %f2833, %f3302, 0f00000000;
	fma.rn.f32 	%f2881, %f2842, %f2879, %f2880;
	sub.f32 	%f2882, %f3295, %f2881;
	fma.rn.f32 	%f2883, %f2834, %f3302, 0f00000000;
	fma.rn.f32 	%f2884, %f2845, %f2879, %f2883;
	fma.rn.f32 	%f2885, %f2858, %f2882, %f2884;
	sub.f32 	%f2886, %f3308, %f2885;
	fma.rn.f32 	%f2887, %f2835, %f3302, 0f00000000;
	fma.rn.f32 	%f2888, %f2848, %f2879, %f2887;
	fma.rn.f32 	%f2889, %f2862, %f2882, %f2888;
	fma.rn.f32 	%f2890, %f2877, %f2886, %f2889;
	sub.f32 	%f2891, %f3309, %f2890;
	add.f32 	%f2892, %f2832, 0f00000000;
	sub.f32 	%f2893, %f545, %f2892;
	add.f32 	%f2894, %f2833, 0f00000000;
	fma.rn.f32 	%f2895, %f2842, %f2893, %f2894;
	sub.f32 	%f2896, %f545, %f2895;
	add.f32 	%f2897, %f2834, 0f00000000;
	fma.rn.f32 	%f2898, %f2845, %f2893, %f2897;
	fma.rn.f32 	%f2899, %f2858, %f2896, %f2898;
	sub.f32 	%f2900, %f545, %f2899;
	add.f32 	%f2901, %f2835, 0f00000000;
	fma.rn.f32 	%f2902, %f2848, %f2893, %f2901;
	fma.rn.f32 	%f2903, %f2862, %f2896, %f2902;
	fma.rn.f32 	%f2904, %f2877, %f2900, %f2903;
	sub.f32 	%f2905, %f545, %f2904;
	div.rn.f32 	%f2906, %f2905, %f2891;
	fma.rn.f32 	%f2907, %f2886, %f2906, 0f00000000;
	sub.f32 	%f2908, %f2900, %f2907;
	mul.f32 	%f2909, %f2875, %f2908;
	fma.rn.f32 	%f2910, %f2867, %f2909, 0f00000000;
	fma.rn.f32 	%f2911, %f2882, %f2906, %f2910;
	sub.f32 	%f2912, %f2896, %f2911;
	mul.f32 	%f2913, %f2856, %f2912;
	fma.rn.f32 	%f2914, %f2850, %f2913, 0f00000000;
	fma.rn.f32 	%f2915, %f2864, %f2909, %f2914;
	fma.rn.f32 	%f2916, %f2879, %f2906, %f2915;
	sub.f32 	%f2917, %f2893, %f2916;
	mul.f32 	%f2918, %f2840, %f2917;
	fma.rn.f32 	%f2919, %f3305, %f2918, 0f00000000;
	fma.rn.f32 	%f2920, %f3304, %f2913, %f2919;
	fma.rn.f32 	%f2921, %f3303, %f2909, %f2920;
	fma.rn.f32 	%f2922, %f3302, %f2906, %f2921;
	sub.f32 	%f2923, %f2831, %f2922;
	mul.f32 	%f2924, %f2830, %f2923;
	fma.rn.f32 	%f2925, %f2832, 0f00000000, 0f00000000;
	sub.f32 	%f2926, %f2831, %f2925;
	fma.rn.f32 	%f2927, %f2833, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2928, %f2842, %f2926, %f2927;
	sub.f32 	%f2929, %f545, %f2928;
	fma.rn.f32 	%f2930, %f2834, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2931, %f2845, %f2926, %f2930;
	fma.rn.f32 	%f2932, %f2858, %f2929, %f2931;
	sub.f32 	%f2933, %f545, %f2932;
	fma.rn.f32 	%f2934, %f2835, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2935, %f2848, %f2926, %f2934;
	fma.rn.f32 	%f2936, %f2862, %f2929, %f2935;
	fma.rn.f32 	%f2937, %f2877, %f2933, %f2936;
	sub.f32 	%f2938, %f545, %f2937;
	div.rn.f32 	%f2939, %f2938, %f2891;
	fma.rn.f32 	%f2940, %f2886, %f2939, 0f00000000;
	sub.f32 	%f2941, %f2933, %f2940;
	mul.f32 	%f2942, %f2875, %f2941;
	fma.rn.f32 	%f2943, %f2867, %f2942, 0f00000000;
	fma.rn.f32 	%f2944, %f2882, %f2939, %f2943;
	sub.f32 	%f2945, %f2929, %f2944;
	mul.f32 	%f2946, %f2856, %f2945;
	fma.rn.f32 	%f2947, %f2850, %f2946, 0f00000000;
	fma.rn.f32 	%f2948, %f2864, %f2942, %f2947;
	fma.rn.f32 	%f2949, %f2879, %f2939, %f2948;
	sub.f32 	%f2950, %f2926, %f2949;
	mul.f32 	%f2951, %f2840, %f2950;
	sub.f32 	%f2952, %f545, %f2925;
	fma.rn.f32 	%f2953, %f2842, %f2952, %f2927;
	sub.f32 	%f2954, %f2831, %f2953;
	fma.rn.f32 	%f2955, %f2845, %f2952, %f2930;
	fma.rn.f32 	%f2956, %f2858, %f2954, %f2955;
	sub.f32 	%f2957, %f545, %f2956;
	fma.rn.f32 	%f2958, %f2848, %f2952, %f2934;
	fma.rn.f32 	%f2959, %f2862, %f2954, %f2958;
	fma.rn.f32 	%f2960, %f2877, %f2957, %f2959;
	sub.f32 	%f2961, %f545, %f2960;
	div.rn.f32 	%f2962, %f2961, %f2891;
	fma.rn.f32 	%f2963, %f2886, %f2962, 0f00000000;
	sub.f32 	%f2964, %f2957, %f2963;
	mul.f32 	%f2965, %f2875, %f2964;
	fma.rn.f32 	%f2966, %f2867, %f2965, 0f00000000;
	fma.rn.f32 	%f2967, %f2882, %f2962, %f2966;
	sub.f32 	%f2968, %f2954, %f2967;
	mul.f32 	%f2969, %f2856, %f2968;
	sub.f32 	%f2970, %f545, %f2953;
	fma.rn.f32 	%f2971, %f2858, %f2970, %f2955;
	sub.f32 	%f2972, %f2831, %f2971;
	fma.rn.f32 	%f2973, %f2862, %f2970, %f2958;
	fma.rn.f32 	%f2974, %f2877, %f2972, %f2973;
	sub.f32 	%f2975, %f545, %f2974;
	div.rn.f32 	%f2976, %f2975, %f2891;
	fma.rn.f32 	%f2977, %f2886, %f2976, 0f00000000;
	sub.f32 	%f2978, %f2972, %f2977;
	mul.f32 	%f2979, %f2875, %f2978;
	sub.f32 	%f2980, %f545, %f2971;
	fma.rn.f32 	%f2981, %f2877, %f2980, %f2973;
	sub.f32 	%f2982, %f2831, %f2981;
	div.rn.f32 	%f2983, %f2982, %f2891;
	cvta.to.global.u64 	%rd26, %rd44;
	mul.wide.s32 	%rd27, %r1356, 4;
	add.s64 	%rd28, %rd26, %rd27;
	st.global.f32 	[%rd28], %f3278;
	add.s32 	%r1341, %r1356, %r1360;
	mul.wide.s32 	%rd29, %r1360, 4;
	add.s64 	%rd30, %rd28, %rd29;
	st.global.f32 	[%rd30], %f3277;
	add.s32 	%r1342, %r1341, %r1360;
	shl.b32 	%r1343, %r1360, 3;
	cvt.s64.s32 	%rd31, %r1343;
	add.s64 	%rd32, %rd28, %rd31;
	st.global.f32 	[%rd32], %f3276;
	add.s32 	%r1344, %r1342, %r1360;
	mul.wide.s32 	%rd33, %r1344, 4;
	add.s64 	%rd34, %rd26, %rd33;
	st.global.f32 	[%rd34], %f3275;
	add.s64 	%rd35, %rd32, %rd31;
	st.global.f32 	[%rd35], %f3274;
	cvta.to.global.u64 	%rd36, %rd45;
	add.s64 	%rd37, %rd36, %rd27;
	st.global.f32 	[%rd37], %f2924;
	add.s64 	%rd38, %rd37, %rd29;
	st.global.f32 	[%rd38], %f2951;
	add.s64 	%rd39, %rd37, %rd31;
	st.global.f32 	[%rd39], %f2969;
	add.s64 	%rd40, %rd36, %rd33;
	st.global.f32 	[%rd40], %f2979;
	add.s64 	%rd41, %rd39, %rd31;
	st.global.f32 	[%rd41], %f2983;
	cvta.to.global.u64 	%rd42, %rd46;
	add.s64 	%rd43, %rd42, %rd27;
	st.global.f32 	[%rd43], %f3341;

$L__BB2_885:
	ret;

}
	// .globl	_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i
.visible .entry _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i(
	.param .u64 _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_0,
	.param .f32 _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_1,
	.param .u32 _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_2,
	.param .u32 _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_3,
	.param .u64 _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_4,
	.param .u64 _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_5,
	.param .u64 _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_6,
	.param .u32 _Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_7
)
{
	.reg .pred 	%p<746>;
	.reg .f32 	%f<3142>;
	.reg .b32 	%r<856>;
	.reg .f64 	%fd<643>;
	.reg .b64 	%rd<54>;


	ld.param.u64 	%rd7, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_0];
	ld.param.f32 	%f3043, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_1];
	ld.param.u32 	%r108, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_2];
	ld.param.u32 	%r110, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_7];
	cvta.to.global.u64 	%rd1, %rd7;
	mov.u32 	%r111, %ntid.x;
	mov.u32 	%r112, %ctaid.x;
	mov.u32 	%r113, %tid.x;
	mad.lo.s32 	%r1, %r112, %r111, %r113;
	setp.ge.s32 	%p43, %r1, %r110;
	@%p43 bra 	$L__BB3_463;

	mul.lo.s32 	%r114, %r108, %r108;
	mul.lo.s32 	%r2, %r114, %r1;
	setp.lt.s32 	%p44, %r108, 1;
	mov.f32 	%f2968, 0f00000000;
	mov.f32 	%f2959, %f2968;
	mov.f32 	%f2960, %f2968;
	mov.f32 	%f2961, %f2968;
	@%p44 bra 	$L__BB3_11;

	add.s32 	%r3, %r108, -1;
	and.b32  	%r4, %r108, 3;
	sub.s32 	%r5, %r108, %r4;
	shl.b32 	%r6, %r108, 2;
	mov.u32 	%r115, 0;
	setp.lt.u32 	%p45, %r3, 3;
	setp.eq.s32 	%p47, %r4, 0;
	setp.eq.s32 	%p48, %r4, 1;
	setp.eq.s32 	%p49, %r4, 2;
	cvt.s64.s32 	%rd13, %r6;
	mov.u32 	%r841, %r115;

$L__BB3_3:
	cvt.rn.f32.s32 	%f4, %r841;
	mov.u32 	%r844, %r115;
	@%p45 bra 	$L__BB3_6;

	mov.u32 	%r844, %r115;
	mov.u32 	%r843, %r5;

$L__BB3_5:
	mad.lo.s32 	%r118, %r844, %r108, %r841;
	add.s32 	%r119, %r118, %r2;
	mul.wide.s32 	%rd11, %r119, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.f32 	%f504, [%rd12];
	fma.rn.f32 	%f505, %f504, %f4, %f2959;
	cvt.rn.f32.s32 	%f506, %r844;
	fma.rn.f32 	%f507, %f504, %f506, %f2960;
	add.f32 	%f508, %f2961, %f504;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.f32 	%f509, [%rd14];
	fma.rn.f32 	%f510, %f509, %f4, %f505;
	add.s32 	%r120, %r844, 1;
	cvt.rn.f32.s32 	%f511, %r120;
	fma.rn.f32 	%f512, %f509, %f511, %f507;
	add.f32 	%f513, %f508, %f509;
	add.s64 	%rd15, %rd14, %rd13;
	ld.global.f32 	%f514, [%rd15];
	fma.rn.f32 	%f515, %f514, %f4, %f510;
	add.s32 	%r121, %r844, 2;
	cvt.rn.f32.s32 	%f516, %r121;
	fma.rn.f32 	%f517, %f514, %f516, %f512;
	add.f32 	%f518, %f513, %f514;
	add.s64 	%rd16, %rd15, %rd13;
	ld.global.f32 	%f519, [%rd16];
	fma.rn.f32 	%f2959, %f519, %f4, %f515;
	add.s32 	%r122, %r844, 3;
	cvt.rn.f32.s32 	%f520, %r122;
	fma.rn.f32 	%f2960, %f519, %f520, %f517;
	add.f32 	%f2961, %f518, %f519;
	add.s32 	%r844, %r844, 4;
	add.s32 	%r843, %r843, -4;
	setp.ne.s32 	%p46, %r843, 0;
	@%p46 bra 	$L__BB3_5;

$L__BB3_6:
	@%p47 bra 	$L__BB3_10;

	mad.lo.s32 	%r13, %r844, %r108, %r841;
	add.s32 	%r123, %r13, %r2;
	mul.wide.s32 	%rd17, %r123, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.f32 	%f521, [%rd18];
	fma.rn.f32 	%f2959, %f521, %f4, %f2959;
	cvt.rn.f32.s32 	%f522, %r844;
	fma.rn.f32 	%f2960, %f521, %f522, %f2960;
	add.f32 	%f2961, %f2961, %f521;
	@%p48 bra 	$L__BB3_10;

	add.s32 	%r14, %r13, %r108;
	add.s32 	%r124, %r14, %r2;
	mul.wide.s32 	%rd19, %r124, 4;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.f32 	%f523, [%rd20];
	fma.rn.f32 	%f2959, %f523, %f4, %f2959;
	add.s32 	%r125, %r844, 1;
	cvt.rn.f32.s32 	%f524, %r125;
	fma.rn.f32 	%f2960, %f523, %f524, %f2960;
	add.f32 	%f2961, %f2961, %f523;
	@%p49 bra 	$L__BB3_10;

	add.s32 	%r126, %r844, 2;
	add.s32 	%r127, %r14, %r108;
	add.s32 	%r128, %r127, %r2;
	mul.wide.s32 	%rd21, %r128, 4;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.f32 	%f525, [%rd22];
	fma.rn.f32 	%f2959, %f525, %f4, %f2959;
	cvt.rn.f32.s32 	%f526, %r126;
	fma.rn.f32 	%f2960, %f525, %f526, %f2960;
	add.f32 	%f2961, %f2961, %f525;

$L__BB3_10:
	add.s32 	%r841, %r841, 1;
	setp.lt.s32 	%p50, %r841, %r108;
	@%p50 bra 	$L__BB3_3;

$L__BB3_11:
	div.rn.f32 	%f3048, %f2959, %f2961;
	div.rn.f32 	%f3047, %f2960, %f2961;
	mov.f32 	%f3045, 0f51BA43B7;
	@%p44 bra 	$L__BB3_51;

	mov.f32 	%f531, 0f3F000000;
	div.rn.f32 	%f532, %f531, %f3043;
	div.rn.f32 	%f533, %f532, %f3043;
	cvt.f64.f32 	%fd1, %f533;
	mov.f64 	%fd246, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd246;
	}
	and.b32  	%r17, %r16, 2146435072;
	and.b32  	%r18, %r16, 2147483647;
	setp.gt.s32 	%p52, %r16, -1;
	selp.b32 	%r19, 2146435072, 0, %p52;
	mov.u32 	%r129, 0;
	or.b32  	%r20, %r19, -2147483648;
	mul.wide.s32 	%rd23, %r2, 4;
	add.s64 	%rd2, %rd1, %rd23;
	setp.eq.s32 	%p54, %r17, 1062207488;
	setp.lt.s32 	%p55, %r16, 0;
	setp.ne.s32 	%p60, %r18, 1071644672;
	setp.eq.s32 	%p87, %r18, 2146435072;
	mov.u32 	%r845, %r129;

$L__BB3_13:
	mov.u32 	%r846, %r129;

$L__BB3_14:
	mov.u32 	%r132, 1;
	sub.s32 	%r24, %r132, %r846;
	mov.f32 	%f2971, 0f00000000;
	mov.f32 	%f2972, %f2971;
	mov.u32 	%r847, %r129;

$L__BB3_15:
	add.s32 	%r849, %r846, -1;
	sub.s32 	%r26, %r847, %r845;
	cvt.rn.f32.s32 	%f536, %r26;
	cvt.f64.f32 	%fd2, %f536;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd2;
	}
	abs.f64 	%fd247, %fd2;
	{ // callseq 67, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd247;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd246;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 67
	setp.lt.s32 	%p53, %r27, 0;
	and.pred  	%p1, %p53, %p54;
	selp.b32 	%r134, %r27, 0, %p54;
	or.b32  	%r135, %r134, 2146435072;
	selp.b32 	%r28, %r135, %r134, %p55;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r136}, %fd4;
	}
	and.b32  	%r29, %r136, 2146435072;
	setp.ne.s32 	%p56, %r29, 2146435072;
	setp.gtu.f64 	%p57, %fd247, 0d7FF0000000000000;
	setp.gt.f64 	%p58, %fd247, 0d3FF0000000000000;
	selp.b32 	%r137, 2146435072, 0, %p58;
	xor.b32  	%r138, %r137, 2146435072;
	selp.b32 	%r139, %r138, %r137, %p55;
	setp.eq.s32 	%p59, %r26, -1;
	selp.b32 	%r30, 1072693248, %r139, %p59;
	and.b32  	%r31, %r27, 2147483647;
	and.pred  	%p61, %p60, %p1;
	selp.b32 	%r32, %r20, %r19, %p61;
	or.pred  	%p2, %p56, %p57;
	mul.lo.s32 	%r140, %r108, %r847;
	mul.wide.s32 	%rd24, %r140, 4;
	add.s64 	%rd53, %rd2, %rd24;
	mov.u32 	%r848, %r24;
	mov.u32 	%r850, %r129;

$L__BB3_16:
	not.pred 	%p62, %p1;
	mov.f64 	%fd578, %fd3;
	@%p62 bra 	$L__BB3_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r141}, %fd3;
	}
	xor.b32  	%r142, %r141, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r143, %temp}, %fd3;
	}
	mov.b64 	%fd578, {%r143, %r142};

$L__BB3_18:
	setp.eq.s32 	%p63, %r26, 0;
	@%p63 bra 	$L__BB3_22;

	setp.gt.s32 	%p64, %r27, -1;
	@%p64 bra 	$L__BB3_23;

	cvt.rzi.f64.f64 	%fd250, %fd246;
	setp.eq.f64 	%p65, %fd250, 0d4000000000000000;
	@%p65 bra 	$L__BB3_23;

	mov.f64 	%fd578, 0dFFF8000000000000;
	bra.uni 	$L__BB3_23;

$L__BB3_22:
	mov.u32 	%r144, 0;
	mov.b64 	%fd578, {%r144, %r28};

$L__BB3_23:
	selp.f64 	%fd579, %fd578, %fd4, %p56;
	@%p2 bra 	$L__BB3_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r145, %temp}, %fd246;
	}
	setp.eq.s32 	%p68, %r145, 0;
	and.pred  	%p69, %p87, %p68;
	@%p69 bra 	$L__BB3_27;
	bra.uni 	$L__BB3_25;

$L__BB3_27:
	mov.u32 	%r148, 0;
	mov.b64 	%fd579, {%r148, %r30};
	bra.uni 	$L__BB3_28;

$L__BB3_25:
	setp.ne.s32 	%p70, %r31, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r146, %temp}, %fd2;
	}
	setp.ne.s32 	%p71, %r146, 0;
	or.pred  	%p72, %p70, %p71;
	mov.f64 	%fd579, %fd578;
	@%p72 bra 	$L__BB3_28;

	mov.u32 	%r147, 0;
	mov.b64 	%fd579, {%r147, %r32};

$L__BB3_28:
	setp.eq.s32 	%p73, %r26, 1;
	selp.f64 	%fd253, 0d3FF0000000000000, %fd579, %p73;
	mov.f64 	%fd254, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd253, %fd1;
	neg.f64 	%fd255, %fd13;
	mov.f64 	%fd256, 0d4338000000000000;
	mov.f64 	%fd257, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd258, %fd255, %fd257, %fd256;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd258;
	}
	mov.f64 	%fd259, 0dC338000000000000;
	add.rn.f64 	%fd260, %fd258, %fd259;
	mov.f64 	%fd261, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd262, %fd260, %fd261, %fd255;
	mov.f64 	%fd263, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd264, %fd260, %fd263, %fd262;
	mov.f64 	%fd265, 0d3E928AF3FCA213EA;
	mov.f64 	%fd266, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd267, %fd266, %fd264, %fd265;
	mov.f64 	%fd268, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd269, %fd267, %fd264, %fd268;
	mov.f64 	%fd270, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd271, %fd269, %fd264, %fd270;
	mov.f64 	%fd272, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd273, %fd271, %fd264, %fd272;
	mov.f64 	%fd274, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd275, %fd273, %fd264, %fd274;
	mov.f64 	%fd276, 0d3F81111111122322;
	fma.rn.f64 	%fd277, %fd275, %fd264, %fd276;
	mov.f64 	%fd278, 0d3FA55555555502A1;
	fma.rn.f64 	%fd279, %fd277, %fd264, %fd278;
	mov.f64 	%fd280, 0d3FC5555555555511;
	fma.rn.f64 	%fd281, %fd279, %fd264, %fd280;
	mov.f64 	%fd282, 0d3FE000000000000B;
	fma.rn.f64 	%fd283, %fd281, %fd264, %fd282;
	fma.rn.f64 	%fd284, %fd283, %fd264, %fd254;
	fma.rn.f64 	%fd285, %fd284, %fd264, %fd254;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd285;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd285;
	}
	shl.b32 	%r149, %r36, 20;
	add.s32 	%r150, %r38, %r149;
	mov.b64 	%fd580, {%r37, %r150};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r151}, %fd255;
	}
	mov.b32 	%f537, %r151;
	abs.f32 	%f42, %f537;
	setp.lt.f32 	%p74, %f42, 0f4086232B;
	@%p74 bra 	$L__BB3_31;

	setp.gt.f64 	%p75, %fd13, 0d8000000000000000;
	mov.f64 	%fd286, 0d7FF0000000000000;
	sub.f64 	%fd287, %fd286, %fd13;
	selp.f64 	%fd580, 0d0000000000000000, %fd287, %p75;
	setp.geu.f32 	%p76, %f42, 0f40874800;
	@%p76 bra 	$L__BB3_31;

	shr.u32 	%r152, %r36, 31;
	add.s32 	%r153, %r36, %r152;
	shr.s32 	%r154, %r153, 1;
	shl.b32 	%r155, %r154, 20;
	add.s32 	%r156, %r38, %r155;
	mov.b64 	%fd288, {%r37, %r156};
	sub.s32 	%r157, %r36, %r154;
	shl.b32 	%r158, %r157, 20;
	add.s32 	%r159, %r158, 1072693248;
	mov.u32 	%r160, 0;
	mov.b64 	%fd289, {%r160, %r159};
	mul.f64 	%fd580, %fd288, %fd289;

$L__BB3_31:
	add.s32 	%r161, %r849, 1;
	cvt.rn.f32.s32 	%f538, %r161;
	cvt.f64.f32 	%fd18, %f538;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 68, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd246;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd582, [retval0+0];
	} // callseq 68
	setp.lt.s32 	%p77, %r39, 0;
	and.pred  	%p3, %p77, %p54;
	not.pred 	%p79, %p3;
	@%p79 bra 	$L__BB3_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r162}, %fd582;
	}
	xor.b32  	%r163, %r162, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r164, %temp}, %fd582;
	}
	mov.b64 	%fd582, {%r164, %r163};

$L__BB3_33:
	setp.eq.s32 	%p80, %r848, 1;
	@%p80 bra 	$L__BB3_37;
	bra.uni 	$L__BB3_34;

$L__BB3_37:
	mov.u32 	%r165, 0;
	selp.b32 	%r166, %r39, 0, %p54;
	or.b32  	%r167, %r166, 2146435072;
	selp.b32 	%r168, %r167, %r166, %p55;
	mov.b64 	%fd582, {%r165, %r168};
	bra.uni 	$L__BB3_38;

$L__BB3_34:
	setp.gt.s32 	%p81, %r39, -1;
	@%p81 bra 	$L__BB3_38;

	cvt.rzi.f64.f64 	%fd292, %fd246;
	setp.eq.f64 	%p82, %fd292, 0d4000000000000000;
	@%p82 bra 	$L__BB3_38;

	mov.f64 	%fd582, 0dFFF8000000000000;

$L__BB3_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r169}, %fd25;
	}
	and.b32  	%r170, %r169, 2146435072;
	setp.ne.s32 	%p85, %r170, 2146435072;
	mov.f64 	%fd583, %fd582;
	@%p85 bra 	$L__BB3_44;

	setp.gtu.f64 	%p86, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd583, %fd25;
	@%p86 bra 	$L__BB3_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r171, %temp}, %fd246;
	}
	setp.eq.s32 	%p88, %r171, 0;
	and.pred  	%p89, %p87, %p88;
	@%p89 bra 	$L__BB3_43;
	bra.uni 	$L__BB3_41;

$L__BB3_43:
	mov.u32 	%r176, 0;
	setp.gt.f64 	%p96, %fd19, 0d3FF0000000000000;
	selp.b32 	%r177, 2146435072, 0, %p96;
	xor.b32  	%r178, %r177, 2146435072;
	selp.b32 	%r179, %r178, %r177, %p55;
	setp.eq.s32 	%p97, %r849, -2;
	selp.b32 	%r180, 1072693248, %r179, %p97;
	mov.b64 	%fd583, {%r176, %r180};
	bra.uni 	$L__BB3_44;

$L__BB3_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r172, %temp}, %fd18;
	}
	and.b32  	%r173, %r39, 2147483647;
	setp.ne.s32 	%p90, %r173, 2146435072;
	setp.ne.s32 	%p91, %r172, 0;
	or.pred  	%p92, %p90, %p91;
	mov.f64 	%fd583, %fd582;
	@%p92 bra 	$L__BB3_44;

	and.pred  	%p94, %p60, %p3;
	selp.b32 	%r174, %r20, %r19, %p94;
	mov.u32 	%r175, 0;
	mov.b64 	%fd583, {%r175, %r174};

$L__BB3_44:
	mov.f64 	%fd576, 0d3FF0000000000000;
	mov.f64 	%fd575, 0d3FE000000000000B;
	mov.f64 	%fd574, 0d3FC5555555555511;
	mov.f64 	%fd573, 0d3FA55555555502A1;
	mov.f64 	%fd572, 0d3F81111111122322;
	mov.f64 	%fd571, 0d3F56C16C1852B7AF;
	mov.f64 	%fd570, 0d3F2A01A014761F65;
	mov.f64 	%fd569, 0d3EFA01997C89EB71;
	mov.f64 	%fd568, 0d3EC71DEE62401315;
	mov.f64 	%fd567, 0d3E928AF3FCA213EA;
	mov.f64 	%fd566, 0d3E5ADE1569CE2BDF;
	mov.f64 	%fd565, 0dBC7ABC9E3B39803F;
	mov.f64 	%fd564, 0dBFE62E42FEFA39EF;
	mov.f64 	%fd563, 0dC338000000000000;
	mov.f64 	%fd562, 0d4338000000000000;
	mov.f64 	%fd561, 0d3FF71547652B82FE;
	setp.eq.s32 	%p98, %r849, 0;
	selp.f64 	%fd295, 0d3FF0000000000000, %fd583, %p98;
	mul.f64 	%fd29, %fd295, %fd1;
	neg.f64 	%fd297, %fd29;
	fma.rn.f64 	%fd300, %fd297, %fd561, %fd562;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd300;
	}
	add.rn.f64 	%fd302, %fd300, %fd563;
	fma.rn.f64 	%fd304, %fd302, %fd564, %fd297;
	fma.rn.f64 	%fd306, %fd302, %fd565, %fd304;
	fma.rn.f64 	%fd309, %fd566, %fd306, %fd567;
	fma.rn.f64 	%fd311, %fd309, %fd306, %fd568;
	fma.rn.f64 	%fd313, %fd311, %fd306, %fd569;
	fma.rn.f64 	%fd315, %fd313, %fd306, %fd570;
	fma.rn.f64 	%fd317, %fd315, %fd306, %fd571;
	fma.rn.f64 	%fd319, %fd317, %fd306, %fd572;
	fma.rn.f64 	%fd321, %fd319, %fd306, %fd573;
	fma.rn.f64 	%fd323, %fd321, %fd306, %fd574;
	fma.rn.f64 	%fd325, %fd323, %fd306, %fd575;
	fma.rn.f64 	%fd326, %fd325, %fd306, %fd576;
	fma.rn.f64 	%fd327, %fd326, %fd306, %fd576;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd327;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd327;
	}
	shl.b32 	%r181, %r40, 20;
	add.s32 	%r182, %r42, %r181;
	mov.b64 	%fd584, {%r41, %r182};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r183}, %fd297;
	}
	mov.b32 	%f539, %r183;
	abs.f32 	%f43, %f539;
	setp.lt.f32 	%p99, %f43, 0f4086232B;
	@%p99 bra 	$L__BB3_47;

	setp.gt.f64 	%p100, %fd29, 0d8000000000000000;
	mov.f64 	%fd328, 0d7FF0000000000000;
	sub.f64 	%fd329, %fd328, %fd29;
	selp.f64 	%fd584, 0d0000000000000000, %fd329, %p100;
	setp.geu.f32 	%p101, %f43, 0f40874800;
	@%p101 bra 	$L__BB3_47;

	shr.u32 	%r184, %r40, 31;
	add.s32 	%r185, %r40, %r184;
	shr.s32 	%r186, %r185, 1;
	shl.b32 	%r187, %r186, 20;
	add.s32 	%r188, %r42, %r187;
	mov.b64 	%fd330, {%r41, %r188};
	sub.s32 	%r189, %r40, %r186;
	shl.b32 	%r190, %r189, 20;
	add.s32 	%r191, %r190, 1072693248;
	mov.u32 	%r192, 0;
	mov.b64 	%fd331, {%r192, %r191};
	mul.f64 	%fd584, %fd330, %fd331;

$L__BB3_47:
	ld.global.f32 	%f540, [%rd53];
	cvt.f64.f32 	%fd332, %f540;
	mul.f64 	%fd333, %fd580, %fd584;
	cvt.f64.f32 	%fd334, %f2972;
	fma.rn.f64 	%fd335, %fd333, %fd332, %fd334;
	cvt.rn.f32.f64 	%f2972, %fd335;
	cvt.f64.f32 	%fd336, %f2971;
	add.f64 	%fd337, %fd333, %fd336;
	cvt.rn.f32.f64 	%f2971, %fd337;
	add.s32 	%r849, %r849, -1;
	add.s32 	%r848, %r848, 1;
	add.s64 	%rd53, %rd53, 4;
	add.s32 	%r850, %r850, 1;
	setp.lt.s32 	%p102, %r850, %r108;
	@%p102 bra 	$L__BB3_16;

	add.s32 	%r847, %r847, 1;
	setp.lt.s32 	%p103, %r847, %r108;
	@%p103 bra 	$L__BB3_15;

	div.rn.f32 	%f541, %f2972, %f2971;
	max.f32 	%f2968, %f2968, %f541;
	min.f32 	%f3045, %f3045, %f541;
	add.s32 	%r846, %r846, 1;
	setp.lt.s32 	%p104, %r846, %r108;
	@%p104 bra 	$L__BB3_14;

	add.s32 	%r845, %r845, 1;
	setp.lt.s32 	%p105, %r845, %r108;
	@%p105 bra 	$L__BB3_13;

$L__BB3_51:
	ld.param.u32 	%r839, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_3];
	mov.f32 	%f2946, 0f00000000;
	sub.f32 	%f542, %f2968, %f3045;
	add.f32 	%f543, %f542, %f542;
	fma.rn.f32 	%f544, %f542, 0f40000000, %f543;
	mul.f32 	%f545, %f544, 0f40490FD8;
	mul.f32 	%f546, %f545, %f3043;
	mul.f32 	%f547, %f546, %f3043;
	max.f32 	%f3046, %f2946, %f547;
	setp.lt.s32 	%p106, %r839, 1;
	mov.f32 	%f3044, %f3043;
	@%p106 bra 	$L__BB3_373;

	cvt.rn.f32.s32 	%f549, %r108;
	mul.f32 	%f51, %f549, 0f3F000000;
	mov.u32 	%r851, 0;
	mov.f64 	%fd339, 0d4008000000000000;
	mov.f64 	%fd345, 0d4014000000000000;
	mov.f32 	%f3044, %f3043;

$L__BB3_53:
	mov.f32 	%f2993, 0f00000000;
	mov.f32 	%f2994, %f2993;
	mov.f32 	%f2995, %f2993;
	mov.f32 	%f2996, %f2993;
	mov.f32 	%f2997, %f2993;
	mov.f32 	%f2998, %f2993;
	mov.f32 	%f2999, %f2993;
	mov.f32 	%f3000, %f2993;
	mov.f32 	%f3001, %f2993;
	mov.f32 	%f3002, %f2993;
	mov.f32 	%f3003, %f2993;
	mov.f32 	%f3004, %f2993;
	@%p44 bra 	$L__BB3_372;

	mov.f32 	%f2993, 0f00000000;
	mov.f32 	%f574, 0f3F000000;
	div.rn.f32 	%f575, %f574, %f3044;
	div.rn.f32 	%f58, %f575, %f3044;
	div.rn.f32 	%f576, %f574, %f3043;
	div.rn.f32 	%f59, %f576, %f3043;
	div.rn.f32 	%f577, %f3046, 0fC0206C98;
	div.rn.f32 	%f60, %f577, %f3044;
	cvt.f64.f32 	%fd34, %f577;
	div.rn.f32 	%f61, %f577, %f3043;
	div.rn.f32 	%f62, %f60, %f3044;
	mov.f32 	%f578, 0fC0000000;
	div.rn.f32 	%f63, %f578, %f3044;
	div.rn.f32 	%f579, %f3046, 0f40206C98;
	cvt.f64.f32 	%fd35, %f579;
	div.rn.f32 	%f64, %f61, %f3043;
	div.rn.f32 	%f65, %f578, %f3043;
	mov.u32 	%r852, 0;

$L__BB3_55:
	mov.u32 	%r853, 0;
	mov.f32 	%f2820, 0f00000000;
	cvt.rn.f32.s32 	%f580, %r852;
	sub.f32 	%f78, %f580, %f3048;
	add.f32 	%f79, %f78, 0f3F000000;
	sqrt.rn.f32 	%f581, %f58;
	mul.f32 	%f582, %f79, %f581;
	abs.f32 	%f80, %f582;
	setp.ge.f32 	%p108, %f80, 0f3F8060FE;
	mul.f32 	%f583, %f582, %f582;
	selp.f32 	%f584, %f80, %f583, %p108;
	selp.f32 	%f585, 0f3789CA3C, 0f38B1E96A, %p108;
	selp.f32 	%f586, 0fB9F560B9, 0fBA574D20, %p108;
	fma.rn.f32 	%f587, %f585, %f584, %f586;
	selp.f32 	%f588, 0f3BAC840B, 0f3BAAD5EA, %p108;
	fma.rn.f32 	%f589, %f587, %f584, %f588;
	selp.f32 	%f590, 0fBD0C8162, 0fBCDC1BE7, %p108;
	fma.rn.f32 	%f591, %f589, %f584, %f590;
	selp.f32 	%f592, 0f3E1CF906, 0f3DE718AF, %p108;
	fma.rn.f32 	%f593, %f591, %f584, %f592;
	selp.f32 	%f594, 0f3F6A937E, 0fBEC093AC, %p108;
	fma.rn.f32 	%f595, %f593, %f584, %f594;
	selp.f32 	%f596, 0f3F20D842, 0f3E0375D3, %p108;
	fma.rn.f32 	%f597, %f595, %f584, %f596;
	neg.f32 	%f598, %f80;
	selp.f32 	%f599, %f598, %f582, %p108;
	fma.rn.f32 	%f81, %f597, %f599, %f599;
	mov.b32 	%r196, %f582;
	and.b32  	%r51, %r196, -2147483648;
	add.f32 	%f82, %f78, 0fBF000000;
	mul.f32 	%f600, %f82, %f581;
	abs.f32 	%f83, %f600;
	setp.ge.f32 	%p109, %f83, 0f3F8060FE;
	mul.f32 	%f601, %f600, %f600;
	selp.f32 	%f602, %f83, %f601, %p109;
	selp.f32 	%f603, 0f3789CA3C, 0f38B1E96A, %p109;
	selp.f32 	%f604, 0fB9F560B9, 0fBA574D20, %p109;
	fma.rn.f32 	%f605, %f603, %f602, %f604;
	selp.f32 	%f606, 0f3BAC840B, 0f3BAAD5EA, %p109;
	fma.rn.f32 	%f607, %f605, %f602, %f606;
	selp.f32 	%f608, 0fBD0C8162, 0fBCDC1BE7, %p109;
	fma.rn.f32 	%f609, %f607, %f602, %f608;
	selp.f32 	%f610, 0f3E1CF906, 0f3DE718AF, %p109;
	fma.rn.f32 	%f611, %f609, %f602, %f610;
	selp.f32 	%f612, 0f3F6A937E, 0fBEC093AC, %p109;
	fma.rn.f32 	%f613, %f611, %f602, %f612;
	selp.f32 	%f614, 0f3F20D842, 0f3E0375D3, %p109;
	fma.rn.f32 	%f615, %f613, %f602, %f614;
	neg.f32 	%f616, %f83;
	selp.f32 	%f617, %f616, %f600, %p109;
	fma.rn.f32 	%f84, %f615, %f617, %f617;
	mov.b32 	%r197, %f600;
	and.b32  	%r52, %r197, -2147483648;
	sqrt.rn.f32 	%f85, %f59;
	add.f32 	%f618, %f580, 0f3F000000;
	sub.f32 	%f86, %f618, %f3048;
	div.rn.f32 	%f87, %f86, %f3044;
	mov.f32 	%f619, 0f3F800000;
	cvt.rzi.f32.f32 	%f620, %f619;
	add.f32 	%f621, %f620, %f620;
	mov.f32 	%f622, 0f40000000;
	sub.f32 	%f623, %f622, %f621;
	abs.f32 	%f88, %f623;
	setp.eq.f32 	%p110, %f88, 0f3F800000;
	abs.f32 	%f89, %f87;
	setp.lt.f32 	%p111, %f89, 0f00800000;
	mul.f32 	%f624, %f89, 0f4B800000;
	selp.f32 	%f625, %f624, %f89, %p111;
	selp.f32 	%f626, 0fC3170000, 0fC2FE0000, %p111;
	mov.b32 	%r198, %f625;
	and.b32  	%r199, %r198, 8388607;
	or.b32  	%r200, %r199, 1065353216;
	mov.b32 	%f627, %r200;
	shr.u32 	%r201, %r198, 23;
	cvt.rn.f32.u32 	%f628, %r201;
	add.f32 	%f629, %f626, %f628;
	setp.gt.f32 	%p112, %f627, 0f3FB504F3;
	mul.f32 	%f630, %f627, 0f3F000000;
	add.f32 	%f631, %f629, 0f3F800000;
	selp.f32 	%f632, %f631, %f629, %p112;
	selp.f32 	%f633, %f630, %f627, %p112;
	add.f32 	%f634, %f633, 0fBF800000;
	add.f32 	%f635, %f633, 0f3F800000;
	rcp.approx.ftz.f32 	%f636, %f635;
	add.f32 	%f637, %f634, %f634;
	mul.f32 	%f638, %f637, %f636;
	mul.f32 	%f639, %f638, %f638;
	mov.f32 	%f640, 0f3C4CAF63;
	mov.f32 	%f641, 0f3B18F0FE;
	fma.rn.f32 	%f642, %f641, %f639, %f640;
	mov.f32 	%f643, 0f3DAAAABD;
	fma.rn.f32 	%f644, %f642, %f639, %f643;
	mul.rn.f32 	%f645, %f644, %f639;
	mul.rn.f32 	%f646, %f645, %f638;
	sub.f32 	%f647, %f634, %f638;
	add.f32 	%f648, %f647, %f647;
	neg.f32 	%f649, %f638;
	fma.rn.f32 	%f650, %f649, %f634, %f648;
	mul.rn.f32 	%f651, %f636, %f650;
	add.f32 	%f652, %f646, %f638;
	sub.f32 	%f653, %f638, %f652;
	add.f32 	%f654, %f646, %f653;
	add.f32 	%f655, %f651, %f654;
	add.f32 	%f656, %f652, %f655;
	sub.f32 	%f657, %f652, %f656;
	add.f32 	%f658, %f655, %f657;
	mov.f32 	%f659, 0f3F317200;
	mul.rn.f32 	%f660, %f632, %f659;
	mov.f32 	%f661, 0f35BFBE8E;
	mul.rn.f32 	%f662, %f632, %f661;
	add.f32 	%f663, %f660, %f656;
	sub.f32 	%f664, %f660, %f663;
	add.f32 	%f665, %f656, %f664;
	add.f32 	%f666, %f658, %f665;
	add.f32 	%f667, %f662, %f666;
	add.f32 	%f668, %f663, %f667;
	sub.f32 	%f669, %f663, %f668;
	add.f32 	%f670, %f667, %f669;
	mul.rn.f32 	%f671, %f622, %f668;
	neg.f32 	%f672, %f671;
	fma.rn.f32 	%f673, %f622, %f668, %f672;
	fma.rn.f32 	%f674, %f622, %f670, %f673;
	fma.rn.f32 	%f676, %f2820, %f668, %f674;
	add.rn.f32 	%f677, %f671, %f676;
	neg.f32 	%f678, %f677;
	add.rn.f32 	%f679, %f671, %f678;
	add.rn.f32 	%f680, %f679, %f676;
	mov.b32 	%r202, %f677;
	setp.eq.s32 	%p113, %r202, 1118925336;
	add.s32 	%r203, %r202, -1;
	mov.b32 	%f681, %r203;
	add.f32 	%f682, %f680, 0f37000000;
	selp.f32 	%f90, %f682, %f680, %p113;
	selp.f32 	%f683, %f681, %f677, %p113;
	mov.f32 	%f684, 0f3FB8AA3B;
	mul.rn.f32 	%f685, %f683, %f684;
	cvt.rzi.f32.f32 	%f686, %f685;
	abs.f32 	%f687, %f686;
	setp.gt.f32 	%p114, %f687, 0f42FC0000;
	mov.b32 	%r204, %f686;
	and.b32  	%r205, %r204, -2147483648;
	or.b32  	%r206, %r205, 1123811328;
	mov.b32 	%f688, %r206;
	selp.f32 	%f689, %f688, %f686, %p114;
	mov.f32 	%f690, 0fBF317218;
	fma.rn.f32 	%f691, %f689, %f690, %f683;
	mov.f32 	%f692, 0f3102E308;
	fma.rn.f32 	%f693, %f689, %f692, %f691;
	mul.f32 	%f694, %f693, 0f3FB8AA3B;
	add.f32 	%f695, %f689, 0f4B40007F;
	mov.b32 	%r207, %f695;
	shl.b32 	%r208, %r207, 23;
	mov.b32 	%f696, %r208;
	ex2.approx.ftz.f32 	%f697, %f694;
	mul.f32 	%f91, %f697, %f696;
	setp.lt.f32 	%p115, %f87, 0f00000000;
	and.pred  	%p4, %p115, %p110;
	div.rn.f32 	%f92, %f82, %f3044;
	abs.f32 	%f93, %f92;
	setp.lt.f32 	%p116, %f93, 0f00800000;
	mul.f32 	%f698, %f93, 0f4B800000;
	selp.f32 	%f699, %f698, %f93, %p116;
	selp.f32 	%f700, 0fC3170000, 0fC2FE0000, %p116;
	mov.b32 	%r209, %f699;
	and.b32  	%r210, %r209, 8388607;
	or.b32  	%r211, %r210, 1065353216;
	mov.b32 	%f701, %r211;
	shr.u32 	%r212, %r209, 23;
	cvt.rn.f32.u32 	%f702, %r212;
	add.f32 	%f703, %f700, %f702;
	setp.gt.f32 	%p117, %f701, 0f3FB504F3;
	mul.f32 	%f704, %f701, 0f3F000000;
	add.f32 	%f705, %f703, 0f3F800000;
	selp.f32 	%f706, %f705, %f703, %p117;
	selp.f32 	%f707, %f704, %f701, %p117;
	add.f32 	%f708, %f707, 0fBF800000;
	add.f32 	%f709, %f707, 0f3F800000;
	rcp.approx.ftz.f32 	%f710, %f709;
	add.f32 	%f711, %f708, %f708;
	mul.f32 	%f712, %f711, %f710;
	mul.f32 	%f713, %f712, %f712;
	fma.rn.f32 	%f714, %f641, %f713, %f640;
	fma.rn.f32 	%f715, %f714, %f713, %f643;
	mul.rn.f32 	%f716, %f715, %f713;
	mul.rn.f32 	%f717, %f716, %f712;
	sub.f32 	%f718, %f708, %f712;
	add.f32 	%f719, %f718, %f718;
	neg.f32 	%f720, %f712;
	fma.rn.f32 	%f721, %f720, %f708, %f719;
	mul.rn.f32 	%f722, %f710, %f721;
	add.f32 	%f723, %f717, %f712;
	sub.f32 	%f724, %f712, %f723;
	add.f32 	%f725, %f717, %f724;
	add.f32 	%f726, %f722, %f725;
	add.f32 	%f727, %f723, %f726;
	sub.f32 	%f728, %f723, %f727;
	add.f32 	%f729, %f726, %f728;
	mul.rn.f32 	%f730, %f706, %f659;
	mul.rn.f32 	%f731, %f706, %f661;
	add.f32 	%f732, %f730, %f727;
	sub.f32 	%f733, %f730, %f732;
	add.f32 	%f734, %f727, %f733;
	add.f32 	%f735, %f729, %f734;
	add.f32 	%f736, %f731, %f735;
	add.f32 	%f737, %f732, %f736;
	sub.f32 	%f738, %f732, %f737;
	add.f32 	%f739, %f736, %f738;
	mul.rn.f32 	%f740, %f622, %f737;
	neg.f32 	%f741, %f740;
	fma.rn.f32 	%f742, %f622, %f737, %f741;
	fma.rn.f32 	%f743, %f622, %f739, %f742;
	fma.rn.f32 	%f744, %f2820, %f737, %f743;
	add.rn.f32 	%f745, %f740, %f744;
	neg.f32 	%f746, %f745;
	add.rn.f32 	%f747, %f740, %f746;
	add.rn.f32 	%f748, %f747, %f744;
	mov.b32 	%r213, %f745;
	setp.eq.s32 	%p118, %r213, 1118925336;
	add.s32 	%r214, %r213, -1;
	mov.b32 	%f749, %r214;
	add.f32 	%f750, %f748, 0f37000000;
	selp.f32 	%f94, %f750, %f748, %p118;
	selp.f32 	%f751, %f749, %f745, %p118;
	mul.rn.f32 	%f752, %f751, %f684;
	cvt.rzi.f32.f32 	%f753, %f752;
	abs.f32 	%f754, %f753;
	setp.gt.f32 	%p119, %f754, 0f42FC0000;
	mov.b32 	%r215, %f753;
	and.b32  	%r216, %r215, -2147483648;
	or.b32  	%r217, %r216, 1123811328;
	mov.b32 	%f755, %r217;
	selp.f32 	%f756, %f755, %f753, %p119;
	fma.rn.f32 	%f757, %f756, %f690, %f751;
	fma.rn.f32 	%f758, %f756, %f692, %f757;
	mul.f32 	%f759, %f758, 0f3FB8AA3B;
	add.f32 	%f760, %f756, 0f4B40007F;
	mov.b32 	%r218, %f760;
	shl.b32 	%r219, %r218, 23;
	mov.b32 	%f761, %r219;
	ex2.approx.ftz.f32 	%f762, %f759;
	mul.f32 	%f95, %f762, %f761;
	cvt.f64.f32 	%fd338, %f3044;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd338;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd339;
	}
	and.b32  	%r55, %r54, 2146435072;
	setp.eq.s32 	%p121, %r55, 1073741824;
	abs.f64 	%fd340, %fd338;
	{ // callseq 69, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd340;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd36, [retval0+0];
	} // callseq 69
	setp.lt.s32 	%p122, %r53, 0;
	and.pred  	%p6, %p122, %p121;
	setp.lt.s32 	%p123, %r54, 0;
	add.f64 	%fd341, %fd338, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r220}, %fd341;
	}
	and.b32  	%r56, %r220, 2146435072;
	setp.ne.s32 	%p124, %r56, 2146435072;
	setp.gtu.f64 	%p125, %fd340, 0d7FF0000000000000;
	and.b32  	%r57, %r54, 2147483647;
	setp.gt.f64 	%p126, %fd340, 0d3FF0000000000000;
	selp.b32 	%r221, 2146435072, 0, %p126;
	xor.b32  	%r222, %r221, 2146435072;
	selp.b32 	%r223, %r222, %r221, %p123;
	setp.eq.f32 	%p127, %f3044, 0fBF800000;
	selp.b32 	%r58, 1072693248, %r223, %p127;
	setp.gt.s32 	%p128, %r54, -1;
	selp.b32 	%r59, 2146435072, 0, %p128;
	cvt.f64.f32 	%fd342, %f3043;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r60}, %fd342;
	}
	abs.f64 	%fd343, %fd342;
	{ // callseq 70, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd37, [retval0+0];
	} // callseq 70
	setp.lt.s32 	%p129, %r60, 0;
	and.pred  	%p7, %p129, %p121;
	add.f64 	%fd344, %fd342, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r224}, %fd344;
	}
	and.b32  	%r61, %r224, 2146435072;
	setp.ne.s32 	%p130, %r61, 2146435072;
	setp.gtu.f64 	%p131, %fd343, 0d7FF0000000000000;
	add.f32 	%f763, %f580, 0f3F800000;
	sub.f32 	%f764, %f763, %f3048;
	div.rn.f32 	%f96, %f764, %f3044;
	abs.f32 	%f97, %f96;
	setp.lt.f32 	%p132, %f97, 0f00800000;
	mul.f32 	%f765, %f97, 0f4B800000;
	selp.f32 	%f766, %f765, %f97, %p132;
	selp.f32 	%f767, 0fC3170000, 0fC2FE0000, %p132;
	mov.b32 	%r225, %f766;
	and.b32  	%r226, %r225, 8388607;
	or.b32  	%r227, %r226, 1065353216;
	mov.b32 	%f768, %r227;
	shr.u32 	%r228, %r225, 23;
	cvt.rn.f32.u32 	%f769, %r228;
	add.f32 	%f770, %f767, %f769;
	setp.gt.f32 	%p133, %f768, 0f3FB504F3;
	mul.f32 	%f771, %f768, 0f3F000000;
	add.f32 	%f772, %f770, 0f3F800000;
	selp.f32 	%f773, %f772, %f770, %p133;
	selp.f32 	%f774, %f771, %f768, %p133;
	add.f32 	%f775, %f774, 0fBF800000;
	add.f32 	%f776, %f774, 0f3F800000;
	rcp.approx.ftz.f32 	%f777, %f776;
	add.f32 	%f778, %f775, %f775;
	mul.f32 	%f779, %f778, %f777;
	mul.f32 	%f780, %f779, %f779;
	fma.rn.f32 	%f781, %f641, %f780, %f640;
	fma.rn.f32 	%f782, %f781, %f780, %f643;
	mul.rn.f32 	%f783, %f782, %f780;
	mul.rn.f32 	%f784, %f783, %f779;
	sub.f32 	%f785, %f775, %f779;
	add.f32 	%f786, %f785, %f785;
	neg.f32 	%f787, %f779;
	fma.rn.f32 	%f788, %f787, %f775, %f786;
	mul.rn.f32 	%f789, %f777, %f788;
	add.f32 	%f790, %f784, %f779;
	sub.f32 	%f791, %f779, %f790;
	add.f32 	%f792, %f784, %f791;
	add.f32 	%f793, %f789, %f792;
	add.f32 	%f794, %f790, %f793;
	sub.f32 	%f795, %f790, %f794;
	add.f32 	%f796, %f793, %f795;
	mul.rn.f32 	%f797, %f773, %f659;
	mul.rn.f32 	%f798, %f773, %f661;
	add.f32 	%f799, %f797, %f794;
	sub.f32 	%f800, %f797, %f799;
	add.f32 	%f801, %f794, %f800;
	add.f32 	%f802, %f796, %f801;
	add.f32 	%f803, %f798, %f802;
	add.f32 	%f804, %f799, %f803;
	sub.f32 	%f805, %f799, %f804;
	add.f32 	%f806, %f803, %f805;
	mul.rn.f32 	%f807, %f622, %f804;
	neg.f32 	%f808, %f807;
	fma.rn.f32 	%f809, %f622, %f804, %f808;
	fma.rn.f32 	%f810, %f622, %f806, %f809;
	fma.rn.f32 	%f811, %f2820, %f804, %f810;
	add.rn.f32 	%f812, %f807, %f811;
	neg.f32 	%f813, %f812;
	add.rn.f32 	%f814, %f807, %f813;
	add.rn.f32 	%f815, %f814, %f811;
	mov.b32 	%r229, %f812;
	setp.eq.s32 	%p134, %r229, 1118925336;
	add.s32 	%r230, %r229, -1;
	mov.b32 	%f816, %r230;
	add.f32 	%f817, %f815, 0f37000000;
	selp.f32 	%f98, %f817, %f815, %p134;
	selp.f32 	%f818, %f816, %f812, %p134;
	mul.rn.f32 	%f819, %f818, %f684;
	cvt.rzi.f32.f32 	%f820, %f819;
	abs.f32 	%f821, %f820;
	setp.gt.f32 	%p135, %f821, 0f42FC0000;
	mov.b32 	%r231, %f820;
	and.b32  	%r232, %r231, -2147483648;
	or.b32  	%r233, %r232, 1123811328;
	mov.b32 	%f822, %r233;
	selp.f32 	%f823, %f822, %f820, %p135;
	fma.rn.f32 	%f824, %f823, %f690, %f818;
	fma.rn.f32 	%f825, %f823, %f692, %f824;
	mul.f32 	%f826, %f825, 0f3FB8AA3B;
	add.f32 	%f827, %f823, 0f4B40007F;
	mov.b32 	%r234, %f827;
	shl.b32 	%r235, %r234, 23;
	mov.b32 	%f828, %r235;
	ex2.approx.ftz.f32 	%f829, %f826;
	mul.f32 	%f99, %f829, %f828;
	setp.gt.f64 	%p137, %fd343, 0d3FF0000000000000;
	selp.b32 	%r236, 2146435072, 0, %p137;
	xor.b32  	%r237, %r236, 2146435072;
	selp.b32 	%r238, %r237, %r236, %p123;
	setp.eq.f32 	%p138, %f3043, 0fBF800000;
	selp.b32 	%r62, 1072693248, %r238, %p138;
	div.rn.f32 	%f100, %f78, %f3044;
	abs.f32 	%f101, %f100;
	setp.lt.f32 	%p139, %f101, 0f00800000;
	mul.f32 	%f830, %f101, 0f4B800000;
	selp.f32 	%f831, %f830, %f101, %p139;
	selp.f32 	%f832, 0fC3170000, 0fC2FE0000, %p139;
	mov.b32 	%r239, %f831;
	and.b32  	%r240, %r239, 8388607;
	or.b32  	%r241, %r240, 1065353216;
	mov.b32 	%f833, %r241;
	shr.u32 	%r242, %r239, 23;
	cvt.rn.f32.u32 	%f834, %r242;
	add.f32 	%f835, %f832, %f834;
	setp.gt.f32 	%p140, %f833, 0f3FB504F3;
	mul.f32 	%f836, %f833, 0f3F000000;
	add.f32 	%f837, %f835, 0f3F800000;
	selp.f32 	%f838, %f837, %f835, %p140;
	selp.f32 	%f839, %f836, %f833, %p140;
	add.f32 	%f840, %f839, 0fBF800000;
	add.f32 	%f841, %f839, 0f3F800000;
	rcp.approx.ftz.f32 	%f842, %f841;
	add.f32 	%f843, %f840, %f840;
	mul.f32 	%f844, %f843, %f842;
	mul.f32 	%f845, %f844, %f844;
	fma.rn.f32 	%f846, %f641, %f845, %f640;
	fma.rn.f32 	%f847, %f846, %f845, %f643;
	mul.rn.f32 	%f848, %f847, %f845;
	mul.rn.f32 	%f849, %f848, %f844;
	sub.f32 	%f850, %f840, %f844;
	add.f32 	%f851, %f850, %f850;
	neg.f32 	%f852, %f844;
	fma.rn.f32 	%f853, %f852, %f840, %f851;
	mul.rn.f32 	%f854, %f842, %f853;
	add.f32 	%f855, %f849, %f844;
	sub.f32 	%f856, %f844, %f855;
	add.f32 	%f857, %f849, %f856;
	add.f32 	%f858, %f854, %f857;
	add.f32 	%f859, %f855, %f858;
	sub.f32 	%f860, %f855, %f859;
	add.f32 	%f861, %f858, %f860;
	mul.rn.f32 	%f862, %f838, %f659;
	mul.rn.f32 	%f863, %f838, %f661;
	add.f32 	%f864, %f862, %f859;
	sub.f32 	%f865, %f862, %f864;
	add.f32 	%f866, %f859, %f865;
	add.f32 	%f867, %f861, %f866;
	add.f32 	%f868, %f863, %f867;
	add.f32 	%f869, %f864, %f868;
	sub.f32 	%f870, %f864, %f869;
	add.f32 	%f871, %f868, %f870;
	mul.rn.f32 	%f872, %f622, %f869;
	neg.f32 	%f873, %f872;
	fma.rn.f32 	%f874, %f622, %f869, %f873;
	fma.rn.f32 	%f875, %f622, %f871, %f874;
	fma.rn.f32 	%f876, %f2820, %f869, %f875;
	add.rn.f32 	%f877, %f872, %f876;
	neg.f32 	%f878, %f877;
	add.rn.f32 	%f879, %f872, %f878;
	add.rn.f32 	%f880, %f879, %f876;
	mov.b32 	%r243, %f877;
	setp.eq.s32 	%p141, %r243, 1118925336;
	add.s32 	%r244, %r243, -1;
	mov.b32 	%f881, %r244;
	add.f32 	%f882, %f880, 0f37000000;
	selp.f32 	%f102, %f882, %f880, %p141;
	selp.f32 	%f883, %f881, %f877, %p141;
	mul.rn.f32 	%f884, %f883, %f684;
	cvt.rzi.f32.f32 	%f885, %f884;
	abs.f32 	%f886, %f885;
	setp.gt.f32 	%p142, %f886, 0f42FC0000;
	mov.b32 	%r245, %f885;
	and.b32  	%r246, %r245, -2147483648;
	or.b32  	%r247, %r246, 1123811328;
	mov.b32 	%f887, %r247;
	selp.f32 	%f888, %f887, %f885, %p142;
	fma.rn.f32 	%f889, %f888, %f690, %f883;
	fma.rn.f32 	%f890, %f888, %f692, %f889;
	mul.f32 	%f891, %f890, 0f3FB8AA3B;
	add.f32 	%f892, %f888, 0f4B40007F;
	mov.b32 	%r248, %f892;
	shl.b32 	%r249, %r248, 23;
	mov.b32 	%f893, %r249;
	ex2.approx.ftz.f32 	%f894, %f891;
	mul.f32 	%f103, %f894, %f893;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r250}, %fd345;
	}
	and.b32  	%r251, %r250, 2146435072;
	setp.eq.s32 	%p144, %r251, 1074790400;
	{ // callseq 71, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd340;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd345;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd38, [retval0+0];
	} // callseq 71
	and.pred  	%p10, %p122, %p144;
	selp.b32 	%r252, %r53, 0, %p144;
	setp.lt.s32 	%p145, %r250, 0;
	or.b32  	%r253, %r252, 2146435072;
	selp.b32 	%r63, %r253, %r252, %p145;
	add.f64 	%fd346, %fd338, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r254}, %fd346;
	}
	and.b32  	%r64, %r254, 2146435072;
	setp.ne.s32 	%p146, %r64, 2146435072;
	cvt.f64.f32 	%fd39, %f79;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd39;
	}
	abs.f64 	%fd347, %fd39;
	{ // callseq 72, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd347;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd40, [retval0+0];
	} // callseq 72
	setp.lt.s32 	%p147, %r65, 0;
	and.pred  	%p11, %p147, %p121;
	and.b32  	%r66, %r250, 2147483647;
	selp.b32 	%r255, %r222, %r221, %p145;
	selp.b32 	%r67, 1072693248, %r255, %p127;
	add.f64 	%fd41, %fd39, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r256}, %fd41;
	}
	and.b32  	%r68, %r256, 2146435072;
	setp.ne.s32 	%p148, %r68, 2146435072;
	setp.gt.s32 	%p149, %r250, -1;
	selp.b32 	%r257, 2146435072, 0, %p149;
	setp.ne.s32 	%p150, %r66, 1071644672;
	and.pred  	%p151, %p150, %p10;
	or.b32  	%r258, %r257, -2147483648;
	selp.b32 	%r69, %r258, %r257, %p151;
	setp.gtu.f64 	%p152, %fd347, 0d7FF0000000000000;
	cvt.f64.f32 	%fd42, %f82;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd42;
	}
	abs.f64 	%fd348, %fd42;
	{ // callseq 73, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd348;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd43, [retval0+0];
	} // callseq 73
	setp.lt.s32 	%p153, %r70, 0;
	and.pred  	%p12, %p153, %p121;
	setp.gt.f64 	%p154, %fd347, 0d3FF0000000000000;
	selp.b32 	%r259, 2146435072, 0, %p154;
	xor.b32  	%r260, %r259, 2146435072;
	selp.b32 	%r261, %r260, %r259, %p123;
	setp.eq.f32 	%p155, %f79, 0fBF800000;
	selp.b32 	%r71, 1072693248, %r261, %p155;
	add.f64 	%fd44, %fd42, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r262}, %fd44;
	}
	and.b32  	%r72, %r262, 2146435072;
	setp.ne.s32 	%p156, %r72, 2146435072;
	setp.gtu.f64 	%p157, %fd348, 0d7FF0000000000000;
	setp.gt.f64 	%p158, %fd348, 0d3FF0000000000000;
	selp.b32 	%r263, 2146435072, 0, %p158;
	xor.b32  	%r264, %r263, 2146435072;
	selp.b32 	%r265, %r264, %r263, %p123;
	setp.eq.f32 	%p159, %f82, 0fBF800000;
	selp.b32 	%r73, 1072693248, %r265, %p159;
	{ // callseq 74, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd345;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd45, [retval0+0];
	} // callseq 74
	and.pred  	%p13, %p129, %p144;
	selp.b32 	%r266, %r60, 0, %p144;
	or.b32  	%r267, %r266, 2146435072;
	selp.b32 	%r74, %r267, %r266, %p145;
	add.f64 	%fd349, %fd342, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r268}, %fd349;
	}
	and.b32  	%r75, %r268, 2146435072;
	setp.ne.s32 	%p160, %r75, 2146435072;
	selp.b32 	%r269, %r237, %r236, %p145;
	selp.b32 	%r76, 1072693248, %r269, %p138;
	and.pred  	%p161, %p150, %p13;
	selp.b32 	%r77, %r258, %r257, %p161;
	mov.f64 	%fd350, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd350;
	}
	and.b32  	%r79, %r78, 2147483647;
	setp.gt.s32 	%p162, %r78, -1;
	selp.b32 	%r80, 2146435072, 0, %p162;
	or.pred  	%p16, %p124, %p125;
	or.pred  	%p17, %p130, %p131;
	or.pred  	%p20, %p146, %p125;
	or.pred  	%p21, %p148, %p152;
	or.pred  	%p22, %p156, %p157;
	or.pred  	%p23, %p160, %p131;
	shr.s32 	%r270, %r78, 31;
	and.b32  	%r81, %r270, 2146435072;

$L__BB3_56:
	cvt.rn.f32.s32 	%f2825, %r852;
	sub.f32 	%f2824, %f2825, %f3048;
	add.f32 	%f2823, %f2824, 0f3F000000;
	mul.f32 	%f2822, %f2823, %f581;
	abs.f32 	%f2821, %f2822;
	setp.ltu.f32 	%p163, %f2821, 0f3F8060FE;
	mov.f32 	%f3005, %f81;
	@%p163 bra 	$L__BB3_58;

	mov.f32 	%f2930, 0f3F800000;
	ex2.approx.ftz.f32 	%f895, %f81;
	sub.f32 	%f897, %f2930, %f895;
	mov.b32 	%r271, %f897;
	or.b32  	%r272, %r51, %r271;
	mov.b32 	%f3005, %r272;

$L__BB3_58:
	cvt.rn.f32.s32 	%f2830, %r852;
	sub.f32 	%f2829, %f2830, %f3048;
	add.f32 	%f2828, %f2829, 0fBF000000;
	mul.f32 	%f2827, %f2828, %f581;
	abs.f32 	%f2826, %f2827;
	setp.ltu.f32 	%p164, %f2826, 0f3F8060FE;
	mov.f32 	%f3006, %f84;
	@%p164 bra 	$L__BB3_60;

	mov.f32 	%f2929, 0f3F800000;
	ex2.approx.ftz.f32 	%f898, %f84;
	sub.f32 	%f900, %f2929, %f898;
	mov.b32 	%r273, %f900;
	or.b32  	%r274, %r52, %r273;
	mov.b32 	%f3006, %r274;

$L__BB3_60:
	sub.f32 	%f901, %f3005, %f3006;
	mul.f32 	%f120, %f901, 0f3F000000;
	cvt.rn.f32.s32 	%f121, %r853;
	sub.f32 	%f122, %f121, %f3047;
	add.f32 	%f123, %f122, 0f3F000000;
	mul.f32 	%f124, %f123, %f85;
	abs.f32 	%f902, %f124;
	setp.ltu.f32 	%p165, %f902, 0f3F8060FE;
	setp.ge.f32 	%p166, %f902, 0f3F8060FE;
	mul.f32 	%f903, %f124, %f124;
	selp.f32 	%f904, %f902, %f903, %p166;
	selp.f32 	%f905, 0f3789CA3C, 0f38B1E96A, %p166;
	selp.f32 	%f906, 0fB9F560B9, 0fBA574D20, %p166;
	fma.rn.f32 	%f907, %f905, %f904, %f906;
	selp.f32 	%f908, 0f3BAC840B, 0f3BAAD5EA, %p166;
	fma.rn.f32 	%f909, %f907, %f904, %f908;
	selp.f32 	%f910, 0fBD0C8162, 0fBCDC1BE7, %p166;
	fma.rn.f32 	%f911, %f909, %f904, %f910;
	selp.f32 	%f912, 0f3E1CF906, 0f3DE718AF, %p166;
	fma.rn.f32 	%f913, %f911, %f904, %f912;
	selp.f32 	%f914, 0f3F6A937E, 0fBEC093AC, %p166;
	fma.rn.f32 	%f915, %f913, %f904, %f914;
	selp.f32 	%f916, 0f3F20D842, 0f3E0375D3, %p166;
	fma.rn.f32 	%f917, %f915, %f904, %f916;
	neg.f32 	%f918, %f902;
	selp.f32 	%f919, %f918, %f124, %p166;
	fma.rn.f32 	%f3007, %f917, %f919, %f919;
	@%p165 bra 	$L__BB3_62;

	mov.f32 	%f2928, 0f3F800000;
	ex2.approx.ftz.f32 	%f920, %f3007;
	sub.f32 	%f922, %f2928, %f920;
	mov.b32 	%r275, %f922;
	mov.b32 	%r276, %f124;
	and.b32  	%r277, %r276, -2147483648;
	or.b32  	%r278, %r277, %r275;
	mov.b32 	%f3007, %r278;

$L__BB3_62:
	cvt.rn.f32.s32 	%f2832, %r853;
	sub.f32 	%f2831, %f2832, %f3047;
	add.f32 	%f128, %f2831, 0fBF000000;
	mul.f32 	%f129, %f128, %f85;
	abs.f32 	%f923, %f129;
	setp.ltu.f32 	%p167, %f923, 0f3F8060FE;
	setp.ge.f32 	%p168, %f923, 0f3F8060FE;
	mul.f32 	%f924, %f129, %f129;
	selp.f32 	%f925, %f923, %f924, %p168;
	selp.f32 	%f926, 0f3789CA3C, 0f38B1E96A, %p168;
	selp.f32 	%f927, 0fB9F560B9, 0fBA574D20, %p168;
	fma.rn.f32 	%f928, %f926, %f925, %f927;
	selp.f32 	%f929, 0f3BAC840B, 0f3BAAD5EA, %p168;
	fma.rn.f32 	%f930, %f928, %f925, %f929;
	selp.f32 	%f931, 0fBD0C8162, 0fBCDC1BE7, %p168;
	fma.rn.f32 	%f932, %f930, %f925, %f931;
	selp.f32 	%f933, 0f3E1CF906, 0f3DE718AF, %p168;
	fma.rn.f32 	%f934, %f932, %f925, %f933;
	selp.f32 	%f935, 0f3F6A937E, 0fBEC093AC, %p168;
	fma.rn.f32 	%f936, %f934, %f925, %f935;
	selp.f32 	%f937, 0f3F20D842, 0f3E0375D3, %p168;
	fma.rn.f32 	%f938, %f936, %f925, %f937;
	neg.f32 	%f939, %f923;
	selp.f32 	%f940, %f939, %f129, %p168;
	fma.rn.f32 	%f3008, %f938, %f940, %f940;
	@%p167 bra 	$L__BB3_64;

	mov.f32 	%f2927, 0f3F800000;
	ex2.approx.ftz.f32 	%f941, %f3008;
	sub.f32 	%f943, %f2927, %f941;
	mov.b32 	%r279, %f943;
	mov.b32 	%r280, %f129;
	and.b32  	%r281, %r280, -2147483648;
	or.b32  	%r282, %r281, %r279;
	mov.b32 	%f3008, %r282;

$L__BB3_64:
	sub.f32 	%f945, %f3007, %f3008;
	mul.f32 	%f133, %f945, 0f3F000000;
	mul.f32 	%f946, %f120, %f3046;
	fma.rn.f32 	%f134, %f133, %f946, %f3045;
	mad.lo.s32 	%r283, %r853, %r108, %r852;
	add.s32 	%r284, %r283, %r2;
	mul.wide.s32 	%rd26, %r284, 4;
	add.s64 	%rd27, %rd1, %rd26;
	ld.global.f32 	%f135, [%rd27];
	setp.eq.f32 	%p169, %f91, 0f7F800000;
	mov.f32 	%f3009, 0f7F800000;
	@%p169 bra 	$L__BB3_66;

	fma.rn.f32 	%f3009, %f91, %f90, %f91;

$L__BB3_66:
	setp.geu.f32 	%p728, %f87, 0f00000000;
	mov.b32 	%r285, %f3009;
	xor.b32  	%r286, %r285, -2147483648;
	mov.b32 	%f947, %r286;
	selp.f32 	%f138, %f947, %f3009, %p4;
	add.f32 	%f948, %f87, %f87;
	selp.f32 	%f949, %f948, 0f00000000, %p110;
	setp.eq.f32 	%p171, %f87, 0f00000000;
	selp.f32 	%f3010, %f949, %f138, %p171;
	@%p728 bra 	$L__BB3_69;

	cvt.rzi.f32.f32 	%f951, %f622;
	setp.eq.f32 	%p172, %f951, 0f40000000;
	mov.f32 	%f3010, %f138;
	@%p172 bra 	$L__BB3_69;

	mov.f32 	%f3010, 0f7FFFFFFF;

$L__BB3_69:
	mov.f32 	%f2835, 0f3FB8AA3B;
	mov.f32 	%f2834, 0f3F000000;
	abs.f32 	%f2833, %f87;
	add.f32 	%f954, %f2833, 0f40000000;
	mov.b32 	%r287, %f954;
	setp.gt.s32 	%p173, %r287, 2139095039;
	add.f32 	%f955, %f87, 0f40000000;
	setp.gtu.f32 	%p174, %f2833, 0f7F800000;
	mov.f32 	%f3011, 0f7F800000;
	selp.f32 	%f956, %f955, %f3010, %p174;
	selp.f32 	%f957, 0fFF800000, 0f7F800000, %p4;
	setp.neu.f32 	%p175, %f2833, 0f7F800000;
	selp.f32 	%f958, %f956, %f957, %p175;
	selp.f32 	%f959, %f958, %f3010, %p173;
	mul.f32 	%f960, %f959, 0fBF000000;
	setp.eq.f32 	%p176, %f87, 0f3F800000;
	selp.f32 	%f961, 0fBF000000, %f960, %p176;
	mov.f32 	%f963, 0f3BBB989D;
	fma.rn.f32 	%f964, %f961, %f963, %f2834;
	mov.f32 	%f966, 0f437C0000;
	cvt.sat.f32.f32 	%f967, %f964;
	mov.f32 	%f968, 0f4B400001;
	fma.rm.f32 	%f969, %f967, %f966, %f968;
	add.f32 	%f970, %f969, 0fCB40007F;
	neg.f32 	%f971, %f970;
	fma.rn.f32 	%f972, %f961, %f2835, %f971;
	mov.f32 	%f973, 0f32A57060;
	fma.rn.f32 	%f974, %f961, %f973, %f972;
	mov.b32 	%r288, %f969;
	shl.b32 	%r289, %r288, 23;
	mov.b32 	%f975, %r289;
	ex2.approx.ftz.f32 	%f976, %f974;
	mul.f32 	%f141, %f976, %f975;
	setp.eq.f32 	%p177, %f95, 0f7F800000;
	@%p177 bra 	$L__BB3_71;

	fma.rn.f32 	%f3011, %f95, %f94, %f95;

$L__BB3_71:
	setp.geu.f32 	%p731, %f92, 0f00000000;
	setp.lt.f32 	%p730, %f92, 0f00000000;
	and.pred  	%p729, %p730, %p110;
	mov.b32 	%r290, %f3011;
	xor.b32  	%r291, %r290, -2147483648;
	mov.b32 	%f977, %r291;
	selp.f32 	%f144, %f977, %f3011, %p729;
	add.f32 	%f978, %f92, %f92;
	selp.f32 	%f979, %f978, 0f00000000, %p110;
	setp.eq.f32 	%p179, %f92, 0f00000000;
	selp.f32 	%f3012, %f979, %f144, %p179;
	@%p731 bra 	$L__BB3_74;

	cvt.rzi.f32.f32 	%f981, %f622;
	setp.eq.f32 	%p180, %f981, 0f40000000;
	mov.f32 	%f3012, %f144;
	@%p180 bra 	$L__BB3_74;

	mov.f32 	%f3012, 0f7FFFFFFF;

$L__BB3_74:
	mov.f32 	%f2842, 0f32A57060;
	mov.f32 	%f2841, 0f4B400001;
	mov.f32 	%f2840, 0f437C0000;
	mov.f32 	%f2839, 0f3BBB989D;
	abs.f32 	%f2838, %f92;
	setp.lt.f32 	%p733, %f92, 0f00000000;
	and.pred  	%p732, %p733, %p110;
	mov.f32 	%f2837, 0f3FB8AA3B;
	mov.f32 	%f2836, 0f3F000000;
	add.f32 	%f983, %f2838, 0f40000000;
	mov.b32 	%r292, %f983;
	setp.gt.s32 	%p181, %r292, 2139095039;
	add.f32 	%f984, %f92, 0f40000000;
	setp.gtu.f32 	%p182, %f2838, 0f7F800000;
	selp.f32 	%f985, %f984, %f3012, %p182;
	selp.f32 	%f986, 0fFF800000, 0f7F800000, %p732;
	setp.neu.f32 	%p183, %f2838, 0f7F800000;
	selp.f32 	%f987, %f985, %f986, %p183;
	selp.f32 	%f988, %f987, %f3012, %p181;
	mul.f32 	%f989, %f988, 0fBF000000;
	setp.eq.f32 	%p184, %f92, 0f3F800000;
	selp.f32 	%f990, 0fBF000000, %f989, %p184;
	fma.rn.f32 	%f993, %f990, %f2839, %f2836;
	cvt.sat.f32.f32 	%f996, %f993;
	fma.rm.f32 	%f998, %f996, %f2840, %f2841;
	add.f32 	%f999, %f998, 0fCB40007F;
	neg.f32 	%f1000, %f999;
	fma.rn.f32 	%f1001, %f990, %f2837, %f1000;
	fma.rn.f32 	%f1003, %f990, %f2842, %f1001;
	mov.b32 	%r293, %f998;
	shl.b32 	%r294, %r293, 23;
	mov.b32 	%f1004, %r294;
	ex2.approx.ftz.f32 	%f1005, %f1003;
	mul.f32 	%f147, %f1005, %f1004;
	sub.f32 	%f1006, %f141, %f147;
	mul.f32 	%f1007, %f60, %f1006;
	mul.f32 	%f148, %f133, %f1007;
	not.pred 	%p185, %p6;
	mov.f64 	%fd586, %fd36;
	@%p185 bra 	$L__BB3_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r295}, %fd36;
	}
	xor.b32  	%r296, %r295, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r297, %temp}, %fd36;
	}
	mov.b64 	%fd586, {%r297, %r296};

$L__BB3_76:
	setp.eq.f32 	%p186, %f3044, 0f00000000;
	@%p186 bra 	$L__BB3_80;
	bra.uni 	$L__BB3_77;

$L__BB3_80:
	mov.u32 	%r298, 0;
	selp.b32 	%r300, %r53, 0, %p121;
	or.b32  	%r301, %r300, 2146435072;
	selp.b32 	%r302, %r301, %r300, %p123;
	mov.b64 	%fd586, {%r298, %r302};
	bra.uni 	$L__BB3_81;

$L__BB3_77:
	setp.gt.s32 	%p187, %r53, -1;
	@%p187 bra 	$L__BB3_81;

	cvt.rzi.f64.f64 	%fd352, %fd339;
	setp.eq.f64 	%p188, %fd352, 0d4008000000000000;
	@%p188 bra 	$L__BB3_81;

	mov.f64 	%fd586, 0dFFF8000000000000;

$L__BB3_81:
	cvt.f64.f32 	%fd550, %f3044;
	add.f64 	%fd549, %fd550, 0d4008000000000000;
	selp.f64 	%fd587, %fd586, %fd549, %p124;
	@%p16 bra 	$L__BB3_86;

	setp.eq.s32 	%p192, %r57, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r303, %temp}, %fd339;
	}
	setp.eq.s32 	%p193, %r303, 0;
	and.pred  	%p194, %p192, %p193;
	@%p194 bra 	$L__BB3_85;
	bra.uni 	$L__BB3_83;

$L__BB3_85:
	mov.u32 	%r310, 0;
	mov.b64 	%fd587, {%r310, %r58};
	bra.uni 	$L__BB3_86;

$L__BB3_83:
	cvt.f64.f32 	%fd551, %f3044;
	and.b32  	%r304, %r53, 2147483647;
	setp.ne.s32 	%p195, %r304, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r305, %temp}, %fd551;
	}
	setp.ne.s32 	%p196, %r305, 0;
	or.pred  	%p197, %p195, %p196;
	mov.f64 	%fd587, %fd586;
	@%p197 bra 	$L__BB3_86;

	setp.ne.s32 	%p198, %r57, 1071644672;
	and.pred  	%p199, %p198, %p6;
	or.b32  	%r307, %r59, -2147483648;
	selp.b32 	%r308, %r307, %r59, %p199;
	mov.u32 	%r309, 0;
	mov.b64 	%fd587, {%r309, %r308};

$L__BB3_86:
	mov.f32 	%f2853, 0f3102E308;
	mov.f32 	%f2852, 0fBF317218;
	mov.f32 	%f2851, 0f35BFBE8E;
	mov.f32 	%f2850, 0f3F317200;
	mov.f32 	%f2849, 0f3DAAAABD;
	mov.f32 	%f2848, 0f3C4CAF63;
	mov.f32 	%f2847, 0f3B18F0FE;
	cvt.rn.f32.s32 	%f2846, %r852;
	add.f32 	%f2845, %f2846, 0f3F000000;
	sub.f32 	%f2844, %f2845, %f3048;
	mov.f32 	%f2843, 0f3FB8AA3B;
	setp.eq.f32 	%p200, %f3044, 0f3F800000;
	selp.f64 	%fd358, 0d3FF0000000000000, %fd587, %p200;
	div.rn.f64 	%fd359, %fd34, %fd358;
	mul.f32 	%f1009, %f82, %f147;
	mul.f32 	%f1010, %f2844, %f141;
	sub.f32 	%f1011, %f1010, %f1009;
	cvt.f64.f32 	%fd360, %f1011;
	mul.f64 	%fd361, %fd359, %fd360;
	cvt.f64.f32 	%fd54, %f133;
	mul.f64 	%fd362, %fd361, %fd54;
	cvt.rn.f32.f64 	%f149, %fd362;
	add.f32 	%f1012, %f121, 0f3F000000;
	sub.f32 	%f150, %f1012, %f3047;
	div.rn.f32 	%f151, %f150, %f3043;
	abs.f32 	%f152, %f151;
	setp.lt.f32 	%p201, %f152, 0f00800000;
	mul.f32 	%f1013, %f152, 0f4B800000;
	selp.f32 	%f1014, %f1013, %f152, %p201;
	selp.f32 	%f1015, 0fC3170000, 0fC2FE0000, %p201;
	mov.b32 	%r311, %f1014;
	and.b32  	%r312, %r311, 8388607;
	or.b32  	%r313, %r312, 1065353216;
	mov.b32 	%f1016, %r313;
	shr.u32 	%r314, %r311, 23;
	cvt.rn.f32.u32 	%f1017, %r314;
	add.f32 	%f1018, %f1015, %f1017;
	setp.gt.f32 	%p202, %f1016, 0f3FB504F3;
	mul.f32 	%f1019, %f1016, 0f3F000000;
	add.f32 	%f1020, %f1018, 0f3F800000;
	selp.f32 	%f1021, %f1020, %f1018, %p202;
	selp.f32 	%f1022, %f1019, %f1016, %p202;
	add.f32 	%f1023, %f1022, 0fBF800000;
	add.f32 	%f1024, %f1022, 0f3F800000;
	rcp.approx.ftz.f32 	%f1025, %f1024;
	add.f32 	%f1026, %f1023, %f1023;
	mul.f32 	%f1028, %f1026, %f1025;
	mul.f32 	%f1029, %f1028, %f1028;
	fma.rn.f32 	%f1032, %f2847, %f1029, %f2848;
	fma.rn.f32 	%f1034, %f1032, %f1029, %f2849;
	mul.rn.f32 	%f1035, %f1034, %f1029;
	mul.rn.f32 	%f1036, %f1035, %f1028;
	sub.f32 	%f1037, %f1023, %f1028;
	add.f32 	%f1038, %f1037, %f1037;
	neg.f32 	%f1039, %f1028;
	fma.rn.f32 	%f1040, %f1039, %f1023, %f1038;
	mul.rn.f32 	%f1041, %f1025, %f1040;
	add.f32 	%f1042, %f1036, %f1028;
	sub.f32 	%f1043, %f1028, %f1042;
	add.f32 	%f1044, %f1036, %f1043;
	add.f32 	%f1045, %f1041, %f1044;
	add.f32 	%f1046, %f1042, %f1045;
	sub.f32 	%f1047, %f1042, %f1046;
	add.f32 	%f1048, %f1045, %f1047;
	mul.rn.f32 	%f1050, %f1021, %f2850;
	mul.rn.f32 	%f1052, %f1021, %f2851;
	add.f32 	%f1053, %f1050, %f1046;
	sub.f32 	%f1054, %f1050, %f1053;
	add.f32 	%f1055, %f1046, %f1054;
	add.f32 	%f1056, %f1048, %f1055;
	add.f32 	%f1057, %f1052, %f1056;
	add.f32 	%f1058, %f1053, %f1057;
	sub.f32 	%f1059, %f1053, %f1058;
	add.f32 	%f1060, %f1057, %f1059;
	mul.rn.f32 	%f1061, %f622, %f1058;
	neg.f32 	%f1062, %f1061;
	fma.rn.f32 	%f1063, %f622, %f1058, %f1062;
	fma.rn.f32 	%f1064, %f622, %f1060, %f1063;
	mov.f32 	%f1065, 0f00000000;
	fma.rn.f32 	%f1066, %f1065, %f1058, %f1064;
	add.rn.f32 	%f1067, %f1061, %f1066;
	neg.f32 	%f1068, %f1067;
	add.rn.f32 	%f1069, %f1061, %f1068;
	add.rn.f32 	%f1070, %f1069, %f1066;
	mov.b32 	%r315, %f1067;
	setp.eq.s32 	%p203, %r315, 1118925336;
	add.s32 	%r316, %r315, -1;
	mov.b32 	%f1071, %r316;
	add.f32 	%f1072, %f1070, 0f37000000;
	selp.f32 	%f153, %f1072, %f1070, %p203;
	selp.f32 	%f1073, %f1071, %f1067, %p203;
	mul.rn.f32 	%f1075, %f1073, %f2843;
	cvt.rzi.f32.f32 	%f1076, %f1075;
	abs.f32 	%f1077, %f1076;
	setp.gt.f32 	%p204, %f1077, 0f42FC0000;
	mov.b32 	%r317, %f1076;
	and.b32  	%r318, %r317, -2147483648;
	or.b32  	%r319, %r318, 1123811328;
	mov.b32 	%f1078, %r319;
	selp.f32 	%f1079, %f1078, %f1076, %p204;
	fma.rn.f32 	%f1081, %f1079, %f2852, %f1073;
	fma.rn.f32 	%f1083, %f1079, %f2853, %f1081;
	mul.f32 	%f1084, %f1083, 0f3FB8AA3B;
	add.f32 	%f1085, %f1079, 0f4B40007F;
	mov.b32 	%r320, %f1085;
	shl.b32 	%r321, %r320, 23;
	mov.b32 	%f1086, %r321;
	ex2.approx.ftz.f32 	%f1087, %f1084;
	mul.f32 	%f154, %f1087, %f1086;
	setp.eq.f32 	%p205, %f154, 0f7F800000;
	mov.f32 	%f3013, 0f7F800000;
	@%p205 bra 	$L__BB3_88;

	fma.rn.f32 	%f3013, %f154, %f153, %f154;

$L__BB3_88:
	setp.lt.f32 	%p206, %f151, 0f00000000;
	and.pred  	%p24, %p206, %p110;
	setp.eq.f32 	%p208, %f151, 0f00000000;
	@%p208 bra 	$L__BB3_92;
	bra.uni 	$L__BB3_89;

$L__BB3_92:
	add.f32 	%f1092, %f151, %f151;
	selp.f32 	%f3015, %f1092, 0f00000000, %p110;
	bra.uni 	$L__BB3_93;

$L__BB3_89:
	mov.b32 	%r322, %f3013;
	xor.b32  	%r323, %r322, -2147483648;
	mov.b32 	%f1088, %r323;
	selp.f32 	%f3015, %f1088, %f3013, %p24;
	setp.geu.f32 	%p209, %f151, 0f00000000;
	@%p209 bra 	$L__BB3_93;

	cvt.rzi.f32.f32 	%f1090, %f622;
	setp.eq.f32 	%p210, %f1090, 0f40000000;
	@%p210 bra 	$L__BB3_93;

	mov.f32 	%f3015, 0f7FFFFFFF;

$L__BB3_93:
	abs.f32 	%f2933, %f151;
	add.f32 	%f1093, %f2933, 0f40000000;
	mov.b32 	%r324, %f1093;
	setp.lt.s32 	%p212, %r324, 2139095040;
	@%p212 bra 	$L__BB3_98;

	abs.f32 	%f2938, %f151;
	setp.gtu.f32 	%p213, %f2938, 0f7F800000;
	@%p213 bra 	$L__BB3_97;
	bra.uni 	$L__BB3_95;

$L__BB3_97:
	add.f32 	%f3015, %f151, 0f40000000;
	bra.uni 	$L__BB3_98;

$L__BB3_95:
	abs.f32 	%f2939, %f151;
	setp.neu.f32 	%p214, %f2939, 0f7F800000;
	@%p214 bra 	$L__BB3_98;

	selp.f32 	%f3015, 0fFF800000, 0f7F800000, %p24;

$L__BB3_98:
	mov.f32 	%f2867, 0f00000000;
	mov.f32 	%f2866, 0f3102E308;
	mov.f32 	%f2865, 0fBF317218;
	mov.f32 	%f2864, 0f35BFBE8E;
	mov.f32 	%f2863, 0f3F317200;
	mov.f32 	%f2862, 0f3DAAAABD;
	mov.f32 	%f2861, 0f3C4CAF63;
	mov.f32 	%f2860, 0f3B18F0FE;
	mov.f32 	%f2859, 0f32A57060;
	mov.f32 	%f2858, 0f4B400001;
	mov.f32 	%f2857, 0f437C0000;
	mov.f32 	%f2856, 0f3BBB989D;
	mov.f32 	%f2855, 0f3FB8AA3B;
	mov.f32 	%f2854, 0f3F000000;
	mul.f32 	%f1095, %f3015, 0fBF000000;
	setp.eq.f32 	%p215, %f151, 0f3F800000;
	selp.f32 	%f1096, 0fBF000000, %f1095, %p215;
	fma.rn.f32 	%f1099, %f1096, %f2856, %f2854;
	cvt.sat.f32.f32 	%f1102, %f1099;
	fma.rm.f32 	%f1104, %f1102, %f2857, %f2858;
	add.f32 	%f1105, %f1104, 0fCB40007F;
	neg.f32 	%f1106, %f1105;
	fma.rn.f32 	%f1107, %f1096, %f2855, %f1106;
	fma.rn.f32 	%f1109, %f1096, %f2859, %f1107;
	mov.b32 	%r325, %f1104;
	shl.b32 	%r326, %r325, 23;
	mov.b32 	%f1110, %r326;
	ex2.approx.ftz.f32 	%f1111, %f1109;
	mul.f32 	%f163, %f1111, %f1110;
	div.rn.f32 	%f164, %f128, %f3043;
	abs.f32 	%f165, %f164;
	setp.lt.f32 	%p216, %f165, 0f00800000;
	mul.f32 	%f1112, %f165, 0f4B800000;
	selp.f32 	%f1113, %f1112, %f165, %p216;
	selp.f32 	%f1114, 0fC3170000, 0fC2FE0000, %p216;
	mov.b32 	%r327, %f1113;
	and.b32  	%r328, %r327, 8388607;
	or.b32  	%r329, %r328, 1065353216;
	mov.b32 	%f1115, %r329;
	shr.u32 	%r330, %r327, 23;
	cvt.rn.f32.u32 	%f1116, %r330;
	add.f32 	%f1117, %f1114, %f1116;
	setp.gt.f32 	%p217, %f1115, 0f3FB504F3;
	mul.f32 	%f1118, %f1115, 0f3F000000;
	add.f32 	%f1119, %f1117, 0f3F800000;
	selp.f32 	%f1120, %f1119, %f1117, %p217;
	selp.f32 	%f1121, %f1118, %f1115, %p217;
	add.f32 	%f1122, %f1121, 0fBF800000;
	add.f32 	%f1123, %f1121, 0f3F800000;
	rcp.approx.ftz.f32 	%f1124, %f1123;
	add.f32 	%f1125, %f1122, %f1122;
	mul.f32 	%f1127, %f1125, %f1124;
	mul.f32 	%f1128, %f1127, %f1127;
	fma.rn.f32 	%f1131, %f2860, %f1128, %f2861;
	fma.rn.f32 	%f1133, %f1131, %f1128, %f2862;
	mul.rn.f32 	%f1134, %f1133, %f1128;
	mul.rn.f32 	%f1135, %f1134, %f1127;
	sub.f32 	%f1136, %f1122, %f1127;
	add.f32 	%f1137, %f1136, %f1136;
	neg.f32 	%f1138, %f1127;
	fma.rn.f32 	%f1139, %f1138, %f1122, %f1137;
	mul.rn.f32 	%f1140, %f1124, %f1139;
	add.f32 	%f1141, %f1135, %f1127;
	sub.f32 	%f1142, %f1127, %f1141;
	add.f32 	%f1143, %f1135, %f1142;
	add.f32 	%f1144, %f1140, %f1143;
	add.f32 	%f1145, %f1141, %f1144;
	sub.f32 	%f1146, %f1141, %f1145;
	add.f32 	%f1147, %f1144, %f1146;
	mul.rn.f32 	%f1149, %f1120, %f2863;
	mul.rn.f32 	%f1151, %f1120, %f2864;
	add.f32 	%f1152, %f1149, %f1145;
	sub.f32 	%f1153, %f1149, %f1152;
	add.f32 	%f1154, %f1145, %f1153;
	add.f32 	%f1155, %f1147, %f1154;
	add.f32 	%f1156, %f1151, %f1155;
	add.f32 	%f1157, %f1152, %f1156;
	sub.f32 	%f1158, %f1152, %f1157;
	add.f32 	%f1159, %f1156, %f1158;
	mul.rn.f32 	%f1160, %f622, %f1157;
	neg.f32 	%f1161, %f1160;
	fma.rn.f32 	%f1162, %f622, %f1157, %f1161;
	fma.rn.f32 	%f1163, %f622, %f1159, %f1162;
	fma.rn.f32 	%f1165, %f2867, %f1157, %f1163;
	add.rn.f32 	%f1166, %f1160, %f1165;
	neg.f32 	%f1167, %f1166;
	add.rn.f32 	%f1168, %f1160, %f1167;
	add.rn.f32 	%f1169, %f1168, %f1165;
	mov.b32 	%r331, %f1166;
	setp.eq.s32 	%p218, %r331, 1118925336;
	add.s32 	%r332, %r331, -1;
	mov.b32 	%f1170, %r332;
	add.f32 	%f1171, %f1169, 0f37000000;
	selp.f32 	%f166, %f1171, %f1169, %p218;
	selp.f32 	%f1172, %f1170, %f1166, %p218;
	mul.rn.f32 	%f1173, %f1172, %f2855;
	cvt.rzi.f32.f32 	%f1174, %f1173;
	abs.f32 	%f1175, %f1174;
	setp.gt.f32 	%p219, %f1175, 0f42FC0000;
	mov.b32 	%r333, %f1174;
	and.b32  	%r334, %r333, -2147483648;
	or.b32  	%r335, %r334, 1123811328;
	mov.b32 	%f1176, %r335;
	selp.f32 	%f1177, %f1176, %f1174, %p219;
	fma.rn.f32 	%f1179, %f1177, %f2865, %f1172;
	fma.rn.f32 	%f1181, %f1177, %f2866, %f1179;
	mul.f32 	%f1182, %f1181, 0f3FB8AA3B;
	add.f32 	%f1183, %f1177, 0f4B40007F;
	mov.b32 	%r336, %f1183;
	shl.b32 	%r337, %r336, 23;
	mov.b32 	%f1184, %r337;
	ex2.approx.ftz.f32 	%f1185, %f1182;
	mul.f32 	%f167, %f1185, %f1184;
	setp.eq.f32 	%p220, %f167, 0f7F800000;
	mov.f32 	%f3016, 0f7F800000;
	@%p220 bra 	$L__BB3_100;

	fma.rn.f32 	%f3016, %f167, %f166, %f167;

$L__BB3_100:
	setp.lt.f32 	%p221, %f164, 0f00000000;
	and.pred  	%p25, %p221, %p110;
	setp.eq.f32 	%p223, %f164, 0f00000000;
	@%p223 bra 	$L__BB3_104;
	bra.uni 	$L__BB3_101;

$L__BB3_104:
	add.f32 	%f1190, %f164, %f164;
	selp.f32 	%f3018, %f1190, 0f00000000, %p110;
	bra.uni 	$L__BB3_105;

$L__BB3_101:
	mov.b32 	%r338, %f3016;
	xor.b32  	%r339, %r338, -2147483648;
	mov.b32 	%f1186, %r339;
	selp.f32 	%f3018, %f1186, %f3016, %p25;
	setp.geu.f32 	%p224, %f164, 0f00000000;
	@%p224 bra 	$L__BB3_105;

	cvt.rzi.f32.f32 	%f1188, %f622;
	setp.eq.f32 	%p225, %f1188, 0f40000000;
	@%p225 bra 	$L__BB3_105;

	mov.f32 	%f3018, 0f7FFFFFFF;

$L__BB3_105:
	abs.f32 	%f2940, %f164;
	add.f32 	%f1191, %f2940, 0f40000000;
	mov.b32 	%r340, %f1191;
	setp.lt.s32 	%p227, %r340, 2139095040;
	@%p227 bra 	$L__BB3_110;

	abs.f32 	%f2941, %f164;
	setp.gtu.f32 	%p228, %f2941, 0f7F800000;
	@%p228 bra 	$L__BB3_109;
	bra.uni 	$L__BB3_107;

$L__BB3_109:
	add.f32 	%f3018, %f164, 0f40000000;
	bra.uni 	$L__BB3_110;

$L__BB3_107:
	abs.f32 	%f2942, %f164;
	setp.neu.f32 	%p229, %f2942, 0f7F800000;
	@%p229 bra 	$L__BB3_110;

	selp.f32 	%f3018, 0fFF800000, 0f7F800000, %p25;

$L__BB3_110:
	mov.f32 	%f2873, 0f32A57060;
	mov.f32 	%f2872, 0f4B400001;
	mov.f32 	%f2871, 0f437C0000;
	mov.f32 	%f2870, 0f3BBB989D;
	mov.f32 	%f2869, 0f3FB8AA3B;
	mov.f32 	%f2868, 0f3F000000;
	mul.f32 	%f1192, %f3018, 0fBF000000;
	setp.eq.f32 	%p230, %f164, 0f3F800000;
	selp.f32 	%f1193, 0fBF000000, %f1192, %p230;
	fma.rn.f32 	%f1196, %f1193, %f2870, %f2868;
	cvt.sat.f32.f32 	%f1199, %f1196;
	fma.rm.f32 	%f1201, %f1199, %f2871, %f2872;
	add.f32 	%f1202, %f1201, 0fCB40007F;
	neg.f32 	%f1203, %f1202;
	fma.rn.f32 	%f1204, %f1193, %f2869, %f1203;
	fma.rn.f32 	%f1206, %f1193, %f2873, %f1204;
	mov.b32 	%r341, %f1201;
	shl.b32 	%r342, %r341, 23;
	mov.b32 	%f1207, %r342;
	ex2.approx.ftz.f32 	%f1208, %f1206;
	mul.f32 	%f176, %f1208, %f1207;
	sub.f32 	%f1209, %f163, %f176;
	mul.f32 	%f1210, %f61, %f1209;
	mul.f32 	%f177, %f120, %f1210;
	not.pred 	%p231, %p7;
	mov.f64 	%fd589, %fd37;
	@%p231 bra 	$L__BB3_112;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r343}, %fd37;
	}
	xor.b32  	%r344, %r343, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r345, %temp}, %fd37;
	}
	mov.b64 	%fd589, {%r345, %r344};

$L__BB3_112:
	setp.eq.f32 	%p232, %f3043, 0f00000000;
	@%p232 bra 	$L__BB3_116;
	bra.uni 	$L__BB3_113;

$L__BB3_116:
	mov.u32 	%r346, 0;
	selp.b32 	%r348, %r60, 0, %p121;
	or.b32  	%r349, %r348, 2146435072;
	selp.b32 	%r350, %r349, %r348, %p123;
	mov.b64 	%fd589, {%r346, %r350};
	bra.uni 	$L__BB3_117;

$L__BB3_113:
	setp.gt.s32 	%p233, %r60, -1;
	@%p233 bra 	$L__BB3_117;

	cvt.rzi.f64.f64 	%fd364, %fd339;
	setp.eq.f64 	%p234, %fd364, 0d4008000000000000;
	@%p234 bra 	$L__BB3_117;

	mov.f64 	%fd589, 0dFFF8000000000000;

$L__BB3_117:
	cvt.f64.f32 	%fd553, %f3043;
	add.f64 	%fd552, %fd553, 0d4008000000000000;
	selp.f64 	%fd590, %fd589, %fd552, %p130;
	@%p17 bra 	$L__BB3_122;

	setp.eq.s32 	%p238, %r57, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r351, %temp}, %fd339;
	}
	setp.eq.s32 	%p239, %r351, 0;
	and.pred  	%p240, %p238, %p239;
	@%p240 bra 	$L__BB3_121;
	bra.uni 	$L__BB3_119;

$L__BB3_121:
	mov.u32 	%r358, 0;
	mov.b64 	%fd590, {%r358, %r62};
	bra.uni 	$L__BB3_122;

$L__BB3_119:
	cvt.f64.f32 	%fd554, %f3043;
	and.b32  	%r352, %r60, 2147483647;
	setp.ne.s32 	%p241, %r352, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r353, %temp}, %fd554;
	}
	setp.ne.s32 	%p242, %r353, 0;
	or.pred  	%p243, %p241, %p242;
	mov.f64 	%fd590, %fd589;
	@%p243 bra 	$L__BB3_122;

	setp.ne.s32 	%p244, %r57, 1071644672;
	and.pred  	%p245, %p244, %p7;
	or.b32  	%r355, %r59, -2147483648;
	selp.b32 	%r356, %r355, %r59, %p245;
	mov.u32 	%r357, 0;
	mov.b64 	%fd590, {%r357, %r356};

$L__BB3_122:
	cvt.rn.f32.s32 	%f2936, %r853;
	add.f32 	%f2935, %f2936, 0f3F000000;
	sub.f32 	%f2934, %f2935, %f3047;
	setp.eq.f32 	%p246, %f3043, 0f3F800000;
	selp.f64 	%fd370, 0d3FF0000000000000, %fd590, %p246;
	div.rn.f64 	%fd371, %fd34, %fd370;
	mul.f32 	%f1212, %f128, %f176;
	mul.f32 	%f1213, %f2934, %f163;
	sub.f32 	%f1214, %f1213, %f1212;
	cvt.f64.f32 	%fd372, %f1214;
	mul.f64 	%fd373, %fd371, %fd372;
	cvt.f64.f32 	%fd374, %f120;
	mul.f64 	%fd375, %fd373, %fd374;
	cvt.rn.f32.f64 	%f178, %fd375;
	setp.eq.f32 	%p247, %f99, 0f7F800000;
	mov.f32 	%f3019, 0f7F800000;
	@%p247 bra 	$L__BB3_124;

	fma.rn.f32 	%f3019, %f99, %f98, %f99;

$L__BB3_124:
	setp.geu.f32 	%p736, %f96, 0f00000000;
	setp.lt.f32 	%p735, %f96, 0f00000000;
	and.pred  	%p734, %p735, %p110;
	mov.b32 	%r359, %f3019;
	xor.b32  	%r360, %r359, -2147483648;
	mov.b32 	%f1215, %r360;
	selp.f32 	%f181, %f1215, %f3019, %p734;
	add.f32 	%f1216, %f96, %f96;
	selp.f32 	%f1217, %f1216, 0f00000000, %p110;
	setp.eq.f32 	%p249, %f96, 0f00000000;
	selp.f32 	%f3020, %f1217, %f181, %p249;
	@%p736 bra 	$L__BB3_127;

	cvt.rzi.f32.f32 	%f1219, %f622;
	setp.eq.f32 	%p250, %f1219, 0f40000000;
	mov.f32 	%f3020, %f181;
	@%p250 bra 	$L__BB3_127;

	mov.f32 	%f3020, 0f7FFFFFFF;

$L__BB3_127:
	abs.f32 	%f2880, %f96;
	setp.lt.f32 	%p738, %f96, 0f00000000;
	and.pred  	%p737, %p738, %p110;
	mov.f32 	%f2879, 0f32A57060;
	mov.f32 	%f2878, 0f4B400001;
	mov.f32 	%f2877, 0f437C0000;
	mov.f32 	%f2876, 0f3BBB989D;
	mov.f32 	%f2875, 0f3FB8AA3B;
	mov.f32 	%f2874, 0f3F000000;
	add.f32 	%f1222, %f2880, 0f40000000;
	mov.b32 	%r361, %f1222;
	setp.gt.s32 	%p251, %r361, 2139095039;
	add.f32 	%f1223, %f96, 0f40000000;
	setp.gtu.f32 	%p252, %f2880, 0f7F800000;
	mov.f32 	%f3021, 0f7F800000;
	selp.f32 	%f1224, %f1223, %f3020, %p252;
	selp.f32 	%f1225, 0fFF800000, 0f7F800000, %p737;
	setp.neu.f32 	%p253, %f2880, 0f7F800000;
	selp.f32 	%f1226, %f1224, %f1225, %p253;
	selp.f32 	%f1227, %f1226, %f3020, %p251;
	mul.f32 	%f1228, %f1227, 0fBF000000;
	setp.eq.f32 	%p254, %f96, 0f3F800000;
	selp.f32 	%f1229, 0fBF000000, %f1228, %p254;
	fma.rn.f32 	%f1232, %f1229, %f2876, %f2874;
	cvt.sat.f32.f32 	%f1235, %f1232;
	fma.rm.f32 	%f1237, %f1235, %f2877, %f2878;
	add.f32 	%f1238, %f1237, 0fCB40007F;
	neg.f32 	%f1239, %f1238;
	fma.rn.f32 	%f1240, %f1229, %f2875, %f1239;
	fma.rn.f32 	%f1242, %f1229, %f2879, %f1240;
	mov.b32 	%r362, %f1237;
	shl.b32 	%r363, %r362, 23;
	mov.b32 	%f1243, %r363;
	ex2.approx.ftz.f32 	%f1244, %f1242;
	mul.f32 	%f184, %f1244, %f1243;
	setp.eq.f32 	%p255, %f103, 0f7F800000;
	@%p255 bra 	$L__BB3_129;

	fma.rn.f32 	%f3021, %f103, %f102, %f103;

$L__BB3_129:
	setp.geu.f32 	%p741, %f100, 0f00000000;
	setp.lt.f32 	%p740, %f100, 0f00000000;
	and.pred  	%p739, %p740, %p110;
	mov.b32 	%r364, %f3021;
	xor.b32  	%r365, %r364, -2147483648;
	mov.b32 	%f1245, %r365;
	selp.f32 	%f187, %f1245, %f3021, %p739;
	add.f32 	%f1246, %f100, %f100;
	selp.f32 	%f1247, %f1246, 0f00000000, %p110;
	setp.eq.f32 	%p257, %f100, 0f00000000;
	selp.f32 	%f3022, %f1247, %f187, %p257;
	@%p741 bra 	$L__BB3_132;

	cvt.rzi.f32.f32 	%f1249, %f622;
	setp.eq.f32 	%p258, %f1249, 0f40000000;
	mov.f32 	%f3022, %f187;
	@%p258 bra 	$L__BB3_132;

	mov.f32 	%f3022, 0f7FFFFFFF;

$L__BB3_132:
	cvt.rn.f32.s32 	%f2889, %r852;
	sub.f32 	%f2888, %f2889, %f3048;
	abs.f32 	%f2887, %f100;
	setp.lt.f32 	%p743, %f100, 0f00000000;
	and.pred  	%p742, %p743, %p110;
	mov.f32 	%f2886, 0f32A57060;
	mov.f32 	%f2885, 0f4B400001;
	mov.f32 	%f2884, 0f437C0000;
	mov.f32 	%f2883, 0f3BBB989D;
	mov.f32 	%f2882, 0f3FB8AA3B;
	mov.f32 	%f2881, 0f3F000000;
	add.f32 	%f1251, %f2887, 0f40000000;
	mov.b32 	%r366, %f1251;
	setp.gt.s32 	%p259, %r366, 2139095039;
	add.f32 	%f1252, %f100, 0f40000000;
	setp.gtu.f32 	%p260, %f2887, 0f7F800000;
	selp.f32 	%f1253, %f1252, %f3022, %p260;
	selp.f32 	%f1254, 0fFF800000, 0f7F800000, %p742;
	setp.neu.f32 	%p261, %f2887, 0f7F800000;
	selp.f32 	%f1255, %f1253, %f1254, %p261;
	selp.f32 	%f1256, %f1255, %f3022, %p259;
	mul.f32 	%f1257, %f1256, 0fBF000000;
	setp.eq.f32 	%p262, %f100, 0f3F800000;
	selp.f32 	%f1258, 0fBF000000, %f1257, %p262;
	fma.rn.f32 	%f1261, %f1258, %f2883, %f2881;
	cvt.sat.f32.f32 	%f1264, %f1261;
	fma.rm.f32 	%f1266, %f1264, %f2884, %f2885;
	add.f32 	%f1267, %f1266, 0fCB40007F;
	neg.f32 	%f1268, %f1267;
	fma.rn.f32 	%f1269, %f1258, %f2882, %f1268;
	fma.rn.f32 	%f1271, %f1258, %f2886, %f1269;
	mov.b32 	%r367, %f1266;
	shl.b32 	%r368, %r367, 23;
	mov.b32 	%f1272, %r368;
	ex2.approx.ftz.f32 	%f1273, %f1271;
	mul.f32 	%f190, %f1273, %f1272;
	add.f32 	%f1274, %f2888, 0f3F800000;
	mul.f32 	%f1275, %f1274, %f184;
	mul.f32 	%f1276, %f2888, %f190;
	sub.f32 	%f1277, %f1275, %f1276;
	mul.f32 	%f1278, %f62, %f1277;
	mul.f32 	%f191, %f133, %f1278;
	not.pred 	%p263, %p10;
	mov.f64 	%fd592, %fd38;
	@%p263 bra 	$L__BB3_134;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r369}, %fd38;
	}
	xor.b32  	%r370, %r369, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r371, %temp}, %fd38;
	}
	mov.b64 	%fd592, {%r371, %r370};

$L__BB3_134:
	setp.eq.f32 	%p744, %f3044, 0f00000000;
	@%p744 bra 	$L__BB3_138;
	bra.uni 	$L__BB3_135;

$L__BB3_138:
	mov.u32 	%r372, 0;
	mov.b64 	%fd592, {%r372, %r63};
	bra.uni 	$L__BB3_139;

$L__BB3_135:
	setp.gt.s32 	%p265, %r53, -1;
	@%p265 bra 	$L__BB3_139;

	cvt.rzi.f64.f64 	%fd377, %fd345;
	setp.eq.f64 	%p266, %fd377, 0d4014000000000000;
	@%p266 bra 	$L__BB3_139;

	mov.f64 	%fd592, 0dFFF8000000000000;

$L__BB3_139:
	cvt.f64.f32 	%fd556, %f3044;
	add.f64 	%fd555, %fd556, 0d4014000000000000;
	selp.f64 	%fd593, %fd592, %fd555, %p146;
	@%p20 bra 	$L__BB3_144;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r838}, %fd345;
	}
	and.b32  	%r837, %r838, 2147483647;
	setp.eq.s32 	%p268, %r837, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r373, %temp}, %fd345;
	}
	setp.eq.s32 	%p269, %r373, 0;
	and.pred  	%p270, %p268, %p269;
	@%p270 bra 	$L__BB3_143;
	bra.uni 	$L__BB3_141;

$L__BB3_143:
	mov.u32 	%r377, 0;
	mov.b64 	%fd593, {%r377, %r67};
	bra.uni 	$L__BB3_144;

$L__BB3_141:
	cvt.f64.f32 	%fd557, %f3044;
	and.b32  	%r374, %r53, 2147483647;
	setp.ne.s32 	%p271, %r374, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r375, %temp}, %fd557;
	}
	setp.ne.s32 	%p272, %r375, 0;
	or.pred  	%p273, %p271, %p272;
	mov.f64 	%fd593, %fd592;
	@%p273 bra 	$L__BB3_144;

	mov.u32 	%r376, 0;
	mov.b64 	%fd593, {%r376, %r69};

$L__BB3_144:
	not.pred 	%p274, %p11;
	mov.f64 	%fd595, %fd40;
	@%p274 bra 	$L__BB3_146;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r378}, %fd40;
	}
	xor.b32  	%r379, %r378, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r380, %temp}, %fd40;
	}
	mov.b64 	%fd595, {%r380, %r379};

$L__BB3_146:
	cvt.rn.f32.s32 	%f2892, %r852;
	sub.f32 	%f2891, %f2892, %f3048;
	add.f32 	%f2890, %f2891, 0f3F000000;
	setp.eq.f32 	%p275, %f2890, 0f00000000;
	@%p275 bra 	$L__BB3_150;
	bra.uni 	$L__BB3_147;

$L__BB3_150:
	mov.u32 	%r381, 0;
	selp.b32 	%r383, %r65, 0, %p121;
	or.b32  	%r384, %r383, 2146435072;
	selp.b32 	%r385, %r384, %r383, %p123;
	mov.b64 	%fd595, {%r381, %r385};
	bra.uni 	$L__BB3_151;

$L__BB3_147:
	setp.gt.s32 	%p276, %r65, -1;
	@%p276 bra 	$L__BB3_151;

	cvt.rzi.f64.f64 	%fd384, %fd339;
	setp.eq.f64 	%p277, %fd384, 0d4008000000000000;
	@%p277 bra 	$L__BB3_151;

	mov.f64 	%fd595, 0dFFF8000000000000;

$L__BB3_151:
	selp.f64 	%fd596, %fd595, %fd41, %p148;
	@%p21 bra 	$L__BB3_156;

	setp.eq.s32 	%p281, %r57, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r386, %temp}, %fd339;
	}
	setp.eq.s32 	%p282, %r386, 0;
	and.pred  	%p283, %p281, %p282;
	@%p283 bra 	$L__BB3_155;
	bra.uni 	$L__BB3_153;

$L__BB3_155:
	mov.u32 	%r393, 0;
	mov.b64 	%fd596, {%r393, %r71};
	bra.uni 	$L__BB3_156;

$L__BB3_153:
	cvt.rn.f32.s32 	%f2895, %r852;
	sub.f32 	%f2894, %f2895, %f3048;
	add.f32 	%f2893, %f2894, 0f3F000000;
	cvt.f64.f32 	%fd558, %f2893;
	and.b32  	%r387, %r65, 2147483647;
	setp.ne.s32 	%p284, %r387, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r388, %temp}, %fd558;
	}
	setp.ne.s32 	%p285, %r388, 0;
	or.pred  	%p286, %p284, %p285;
	mov.f64 	%fd596, %fd595;
	@%p286 bra 	$L__BB3_156;

	setp.ne.s32 	%p287, %r57, 1071644672;
	and.pred  	%p288, %p287, %p11;
	or.b32  	%r390, %r59, -2147483648;
	selp.b32 	%r391, %r390, %r59, %p288;
	mov.u32 	%r392, 0;
	mov.b64 	%fd596, {%r392, %r391};

$L__BB3_156:
	cvt.rn.f32.s32 	%f2898, %r852;
	sub.f32 	%f2897, %f2898, %f3048;
	add.f32 	%f2896, %f2897, 0f3F000000;
	setp.eq.f32 	%p289, %f2896, 0f3F800000;
	selp.f64 	%fd387, 0d3FF0000000000000, %fd596, %p289;
	cvt.f64.f32 	%fd388, %f184;
	mul.f64 	%fd79, %fd387, %fd388;
	not.pred 	%p290, %p12;
	mov.f64 	%fd598, %fd43;
	@%p290 bra 	$L__BB3_158;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r394}, %fd43;
	}
	xor.b32  	%r395, %r394, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r396, %temp}, %fd43;
	}
	mov.b64 	%fd598, {%r396, %r395};

$L__BB3_158:
	setp.eq.f32 	%p291, %f82, 0f00000000;
	@%p291 bra 	$L__BB3_162;
	bra.uni 	$L__BB3_159;

$L__BB3_162:
	mov.u32 	%r397, 0;
	selp.b32 	%r399, %r70, 0, %p121;
	or.b32  	%r400, %r399, 2146435072;
	selp.b32 	%r401, %r400, %r399, %p123;
	mov.b64 	%fd598, {%r397, %r401};
	bra.uni 	$L__BB3_163;

$L__BB3_159:
	setp.gt.s32 	%p292, %r70, -1;
	@%p292 bra 	$L__BB3_163;

	cvt.rzi.f64.f64 	%fd390, %fd339;
	setp.eq.f64 	%p293, %fd390, 0d4008000000000000;
	@%p293 bra 	$L__BB3_163;

	mov.f64 	%fd598, 0dFFF8000000000000;

$L__BB3_163:
	selp.f64 	%fd599, %fd598, %fd44, %p156;
	@%p22 bra 	$L__BB3_168;

	setp.eq.s32 	%p297, %r57, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r402, %temp}, %fd339;
	}
	setp.eq.s32 	%p298, %r402, 0;
	and.pred  	%p299, %p297, %p298;
	@%p299 bra 	$L__BB3_167;
	bra.uni 	$L__BB3_165;

$L__BB3_167:
	mov.u32 	%r409, 0;
	mov.b64 	%fd599, {%r409, %r73};
	bra.uni 	$L__BB3_168;

$L__BB3_165:
	cvt.rn.f32.s32 	%f2901, %r852;
	sub.f32 	%f2900, %f2901, %f3048;
	add.f32 	%f2899, %f2900, 0fBF000000;
	cvt.f64.f32 	%fd559, %f2899;
	and.b32  	%r403, %r70, 2147483647;
	setp.ne.s32 	%p300, %r403, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r404, %temp}, %fd559;
	}
	setp.ne.s32 	%p301, %r404, 0;
	or.pred  	%p302, %p300, %p301;
	mov.f64 	%fd599, %fd598;
	@%p302 bra 	$L__BB3_168;

	setp.ne.s32 	%p303, %r57, 1071644672;
	and.pred  	%p304, %p303, %p12;
	or.b32  	%r406, %r59, -2147483648;
	selp.b32 	%r407, %r406, %r59, %p304;
	mov.u32 	%r408, 0;
	mov.b64 	%fd599, {%r408, %r407};

$L__BB3_168:
	cvt.f64.f32 	%fd560, %f133;
	setp.eq.f32 	%p745, %f3044, 0f3F800000;
	cvt.rn.f32.s32 	%f2937, %r853;
	mov.f32 	%f2910, 0f00000000;
	mov.f32 	%f2909, 0f3102E308;
	mov.f32 	%f2908, 0fBF317218;
	mov.f32 	%f2907, 0f35BFBE8E;
	mov.f32 	%f2906, 0f3F317200;
	mov.f32 	%f2905, 0f3DAAAABD;
	mov.f32 	%f2904, 0f3C4CAF63;
	mov.f32 	%f2903, 0f3B18F0FE;
	mov.f32 	%f2902, 0f3FB8AA3B;
	setp.eq.f32 	%p305, %f82, 0f3F800000;
	selp.f64 	%fd393, 0d3FF0000000000000, %fd599, %p305;
	cvt.f64.f32 	%fd394, %f190;
	mul.f64 	%fd395, %fd393, %fd394;
	sub.f64 	%fd396, %fd79, %fd395;
	selp.f64 	%fd397, 0d3FF0000000000000, %fd593, %p745;
	div.rn.f64 	%fd398, %fd35, %fd397;
	mul.f64 	%fd399, %fd398, %fd396;
	mul.f64 	%fd400, %fd399, %fd560;
	mul.f32 	%f1280, %f63, %f191;
	cvt.f64.f32 	%fd401, %f1280;
	sub.f64 	%fd402, %fd401, %fd400;
	cvt.rn.f32.f64 	%f192, %fd402;
	add.f32 	%f1281, %f2937, 0f3F800000;
	sub.f32 	%f1282, %f1281, %f3047;
	div.rn.f32 	%f193, %f1282, %f3043;
	abs.f32 	%f194, %f193;
	setp.lt.f32 	%p307, %f194, 0f00800000;
	mul.f32 	%f1283, %f194, 0f4B800000;
	selp.f32 	%f1284, %f1283, %f194, %p307;
	selp.f32 	%f1285, 0fC3170000, 0fC2FE0000, %p307;
	mov.b32 	%r410, %f1284;
	and.b32  	%r411, %r410, 8388607;
	or.b32  	%r412, %r411, 1065353216;
	mov.b32 	%f1286, %r412;
	shr.u32 	%r413, %r410, 23;
	cvt.rn.f32.u32 	%f1287, %r413;
	add.f32 	%f1288, %f1285, %f1287;
	setp.gt.f32 	%p308, %f1286, 0f3FB504F3;
	mul.f32 	%f1289, %f1286, 0f3F000000;
	add.f32 	%f1290, %f1288, 0f3F800000;
	selp.f32 	%f1291, %f1290, %f1288, %p308;
	selp.f32 	%f1292, %f1289, %f1286, %p308;
	add.f32 	%f1293, %f1292, 0fBF800000;
	add.f32 	%f1294, %f1292, 0f3F800000;
	rcp.approx.ftz.f32 	%f1295, %f1294;
	add.f32 	%f1296, %f1293, %f1293;
	mul.f32 	%f1298, %f1296, %f1295;
	mul.f32 	%f1299, %f1298, %f1298;
	fma.rn.f32 	%f1302, %f2903, %f1299, %f2904;
	fma.rn.f32 	%f1304, %f1302, %f1299, %f2905;
	mul.rn.f32 	%f1305, %f1304, %f1299;
	mul.rn.f32 	%f1306, %f1305, %f1298;
	sub.f32 	%f1307, %f1293, %f1298;
	add.f32 	%f1308, %f1307, %f1307;
	neg.f32 	%f1309, %f1298;
	fma.rn.f32 	%f1310, %f1309, %f1293, %f1308;
	mul.rn.f32 	%f1311, %f1295, %f1310;
	add.f32 	%f1312, %f1306, %f1298;
	sub.f32 	%f1313, %f1298, %f1312;
	add.f32 	%f1314, %f1306, %f1313;
	add.f32 	%f1315, %f1311, %f1314;
	add.f32 	%f1316, %f1312, %f1315;
	sub.f32 	%f1317, %f1312, %f1316;
	add.f32 	%f1318, %f1315, %f1317;
	mul.rn.f32 	%f1320, %f1291, %f2906;
	mul.rn.f32 	%f1322, %f1291, %f2907;
	add.f32 	%f1323, %f1320, %f1316;
	sub.f32 	%f1324, %f1320, %f1323;
	add.f32 	%f1325, %f1316, %f1324;
	add.f32 	%f1326, %f1318, %f1325;
	add.f32 	%f1327, %f1322, %f1326;
	add.f32 	%f1328, %f1323, %f1327;
	sub.f32 	%f1329, %f1323, %f1328;
	add.f32 	%f1330, %f1327, %f1329;
	mul.rn.f32 	%f1331, %f622, %f1328;
	neg.f32 	%f1332, %f1331;
	fma.rn.f32 	%f1333, %f622, %f1328, %f1332;
	fma.rn.f32 	%f1334, %f622, %f1330, %f1333;
	fma.rn.f32 	%f1336, %f2910, %f1328, %f1334;
	add.rn.f32 	%f1337, %f1331, %f1336;
	neg.f32 	%f1338, %f1337;
	add.rn.f32 	%f1339, %f1331, %f1338;
	add.rn.f32 	%f1340, %f1339, %f1336;
	mov.b32 	%r414, %f1337;
	setp.eq.s32 	%p309, %r414, 1118925336;
	add.s32 	%r415, %r414, -1;
	mov.b32 	%f1341, %r415;
	add.f32 	%f1342, %f1340, 0f37000000;
	selp.f32 	%f195, %f1342, %f1340, %p309;
	selp.f32 	%f1343, %f1341, %f1337, %p309;
	mul.rn.f32 	%f1345, %f1343, %f2902;
	cvt.rzi.f32.f32 	%f1346, %f1345;
	abs.f32 	%f1347, %f1346;
	setp.gt.f32 	%p310, %f1347, 0f42FC0000;
	mov.b32 	%r416, %f1346;
	and.b32  	%r417, %r416, -2147483648;
	or.b32  	%r418, %r417, 1123811328;
	mov.b32 	%f1348, %r418;
	selp.f32 	%f1349, %f1348, %f1346, %p310;
	fma.rn.f32 	%f1351, %f1349, %f2908, %f1343;
	fma.rn.f32 	%f1353, %f1349, %f2909, %f1351;
	mul.f32 	%f1354, %f1353, 0f3FB8AA3B;
	add.f32 	%f1355, %f1349, 0f4B40007F;
	mov.b32 	%r419, %f1355;
	shl.b32 	%r420, %r419, 23;
	mov.b32 	%f1356, %r420;
	ex2.approx.ftz.f32 	%f1357, %f1354;
	mul.f32 	%f196, %f1357, %f1356;
	setp.eq.f32 	%p311, %f196, 0f7F800000;
	mov.f32 	%f3023, 0f7F800000;
	@%p311 bra 	$L__BB3_170;

	fma.rn.f32 	%f3023, %f196, %f195, %f196;

$L__BB3_170:
	setp.lt.f32 	%p312, %f193, 0f00000000;
	and.pred  	%p26, %p312, %p110;
	setp.eq.f32 	%p314, %f193, 0f00000000;
	@%p314 bra 	$L__BB3_174;
	bra.uni 	$L__BB3_171;

$L__BB3_174:
	add.f32 	%f1362, %f193, %f193;
	selp.f32 	%f3025, %f1362, 0f00000000, %p110;
	bra.uni 	$L__BB3_175;

$L__BB3_171:
	mov.b32 	%r421, %f3023;
	xor.b32  	%r422, %r421, -2147483648;
	mov.b32 	%f1358, %r422;
	selp.f32 	%f3025, %f1358, %f3023, %p26;
	setp.geu.f32 	%p315, %f193, 0f00000000;
	@%p315 bra 	$L__BB3_175;

	cvt.rzi.f32.f32 	%f1360, %f622;
	setp.eq.f32 	%p316, %f1360, 0f40000000;
	@%p316 bra 	$L__BB3_175;

	mov.f32 	%f3025, 0f7FFFFFFF;

$L__BB3_175:
	abs.f32 	%f2943, %f193;
	add.f32 	%f1363, %f2943, 0f40000000;
	mov.b32 	%r423, %f1363;
	setp.lt.s32 	%p318, %r423, 2139095040;
	@%p318 bra 	$L__BB3_180;

	abs.f32 	%f2944, %f193;
	setp.gtu.f32 	%p319, %f2944, 0f7F800000;
	@%p319 bra 	$L__BB3_179;
	bra.uni 	$L__BB3_177;

$L__BB3_179:
	add.f32 	%f3025, %f193, 0f40000000;
	bra.uni 	$L__BB3_180;

$L__BB3_177:
	abs.f32 	%f2945, %f193;
	setp.neu.f32 	%p320, %f2945, 0f7F800000;
	@%p320 bra 	$L__BB3_180;

	selp.f32 	%f3025, 0fFF800000, 0f7F800000, %p26;

$L__BB3_180:
	mov.f32 	%f2926, 0f00000000;
	mov.f32 	%f2925, 0f3102E308;
	mov.f32 	%f2924, 0fBF317218;
	mov.f32 	%f2923, 0f35BFBE8E;
	mov.f32 	%f2922, 0f3F317200;
	mov.f32 	%f2921, 0f3DAAAABD;
	mov.f32 	%f2920, 0f3C4CAF63;
	mov.f32 	%f2919, 0f3B18F0FE;
	mov.f32 	%f2918, 0f32A57060;
	mov.f32 	%f2917, 0f4B400001;
	mov.f32 	%f2916, 0f437C0000;
	mov.f32 	%f2915, 0f3BBB989D;
	mov.f32 	%f2914, 0f3FB8AA3B;
	mov.f32 	%f2913, 0f3F000000;
	cvt.rn.f32.s32 	%f2912, %r853;
	sub.f32 	%f2911, %f2912, %f3047;
	mul.f32 	%f1365, %f3025, 0fBF000000;
	setp.eq.f32 	%p321, %f193, 0f3F800000;
	selp.f32 	%f1366, 0fBF000000, %f1365, %p321;
	fma.rn.f32 	%f1369, %f1366, %f2915, %f2913;
	cvt.sat.f32.f32 	%f1372, %f1369;
	fma.rm.f32 	%f1374, %f1372, %f2916, %f2917;
	add.f32 	%f1375, %f1374, 0fCB40007F;
	neg.f32 	%f1376, %f1375;
	fma.rn.f32 	%f1377, %f1366, %f2914, %f1376;
	fma.rn.f32 	%f1379, %f1366, %f2918, %f1377;
	mov.b32 	%r424, %f1374;
	shl.b32 	%r425, %r424, 23;
	mov.b32 	%f1380, %r425;
	ex2.approx.ftz.f32 	%f1381, %f1379;
	mul.f32 	%f205, %f1381, %f1380;
	div.rn.f32 	%f206, %f2911, %f3043;
	abs.f32 	%f207, %f206;
	setp.lt.f32 	%p322, %f207, 0f00800000;
	mul.f32 	%f1382, %f207, 0f4B800000;
	selp.f32 	%f1383, %f1382, %f207, %p322;
	selp.f32 	%f1384, 0fC3170000, 0fC2FE0000, %p322;
	mov.b32 	%r426, %f1383;
	and.b32  	%r427, %r426, 8388607;
	or.b32  	%r428, %r427, 1065353216;
	mov.b32 	%f1385, %r428;
	shr.u32 	%r429, %r426, 23;
	cvt.rn.f32.u32 	%f1386, %r429;
	add.f32 	%f1387, %f1384, %f1386;
	setp.gt.f32 	%p323, %f1385, 0f3FB504F3;
	mul.f32 	%f1388, %f1385, 0f3F000000;
	add.f32 	%f1389, %f1387, 0f3F800000;
	selp.f32 	%f1390, %f1389, %f1387, %p323;
	selp.f32 	%f1391, %f1388, %f1385, %p323;
	add.f32 	%f1392, %f1391, 0fBF800000;
	add.f32 	%f1393, %f1391, 0f3F800000;
	rcp.approx.ftz.f32 	%f1394, %f1393;
	add.f32 	%f1395, %f1392, %f1392;
	mul.f32 	%f1397, %f1395, %f1394;
	mul.f32 	%f1398, %f1397, %f1397;
	fma.rn.f32 	%f1401, %f2919, %f1398, %f2920;
	fma.rn.f32 	%f1403, %f1401, %f1398, %f2921;
	mul.rn.f32 	%f1404, %f1403, %f1398;
	mul.rn.f32 	%f1405, %f1404, %f1397;
	sub.f32 	%f1406, %f1392, %f1397;
	add.f32 	%f1407, %f1406, %f1406;
	neg.f32 	%f1408, %f1397;
	fma.rn.f32 	%f1409, %f1408, %f1392, %f1407;
	mul.rn.f32 	%f1410, %f1394, %f1409;
	add.f32 	%f1411, %f1405, %f1397;
	sub.f32 	%f1412, %f1397, %f1411;
	add.f32 	%f1413, %f1405, %f1412;
	add.f32 	%f1414, %f1410, %f1413;
	add.f32 	%f1415, %f1411, %f1414;
	sub.f32 	%f1416, %f1411, %f1415;
	add.f32 	%f1417, %f1414, %f1416;
	mul.rn.f32 	%f1419, %f1390, %f2922;
	mul.rn.f32 	%f1421, %f1390, %f2923;
	add.f32 	%f1422, %f1419, %f1415;
	sub.f32 	%f1423, %f1419, %f1422;
	add.f32 	%f1424, %f1415, %f1423;
	add.f32 	%f1425, %f1417, %f1424;
	add.f32 	%f1426, %f1421, %f1425;
	add.f32 	%f1427, %f1422, %f1426;
	sub.f32 	%f1428, %f1422, %f1427;
	add.f32 	%f1429, %f1426, %f1428;
	mul.rn.f32 	%f1430, %f622, %f1427;
	neg.f32 	%f1431, %f1430;
	fma.rn.f32 	%f1432, %f622, %f1427, %f1431;
	fma.rn.f32 	%f1433, %f622, %f1429, %f1432;
	fma.rn.f32 	%f1435, %f2926, %f1427, %f1433;
	add.rn.f32 	%f1436, %f1430, %f1435;
	neg.f32 	%f1437, %f1436;
	add.rn.f32 	%f1438, %f1430, %f1437;
	add.rn.f32 	%f1439, %f1438, %f1435;
	mov.b32 	%r430, %f1436;
	setp.eq.s32 	%p324, %r430, 1118925336;
	add.s32 	%r431, %r430, -1;
	mov.b32 	%f1440, %r431;
	add.f32 	%f1441, %f1439, 0f37000000;
	selp.f32 	%f208, %f1441, %f1439, %p324;
	selp.f32 	%f1442, %f1440, %f1436, %p324;
	mul.rn.f32 	%f1443, %f1442, %f2914;
	cvt.rzi.f32.f32 	%f1444, %f1443;
	abs.f32 	%f1445, %f1444;
	setp.gt.f32 	%p325, %f1445, 0f42FC0000;
	mov.b32 	%r432, %f1444;
	and.b32  	%r433, %r432, -2147483648;
	or.b32  	%r434, %r433, 1123811328;
	mov.b32 	%f1446, %r434;
	selp.f32 	%f1447, %f1446, %f1444, %p325;
	fma.rn.f32 	%f1449, %f1447, %f2924, %f1442;
	fma.rn.f32 	%f1451, %f1447, %f2925, %f1449;
	mul.f32 	%f1452, %f1451, 0f3FB8AA3B;
	add.f32 	%f1453, %f1447, 0f4B40007F;
	mov.b32 	%r435, %f1453;
	shl.b32 	%r436, %r435, 23;
	mov.b32 	%f1454, %r436;
	ex2.approx.ftz.f32 	%f1455, %f1452;
	mul.f32 	%f209, %f1455, %f1454;
	setp.eq.f32 	%p326, %f209, 0f7F800000;
	mov.f32 	%f3026, 0f7F800000;
	@%p326 bra 	$L__BB3_182;

	fma.rn.f32 	%f3026, %f209, %f208, %f209;

$L__BB3_182:
	setp.lt.f32 	%p327, %f206, 0f00000000;
	and.pred  	%p27, %p327, %p110;
	setp.eq.f32 	%p329, %f206, 0f00000000;
	@%p329 bra 	$L__BB3_186;
	bra.uni 	$L__BB3_183;

$L__BB3_186:
	add.f32 	%f1460, %f206, %f206;
	selp.f32 	%f3028, %f1460, 0f00000000, %p110;
	bra.uni 	$L__BB3_187;

$L__BB3_183:
	mov.b32 	%r437, %f3026;
	xor.b32  	%r438, %r437, -2147483648;
	mov.b32 	%f1456, %r438;
	selp.f32 	%f3028, %f1456, %f3026, %p27;
	setp.geu.f32 	%p330, %f206, 0f00000000;
	@%p330 bra 	$L__BB3_187;

	cvt.rzi.f32.f32 	%f1458, %f622;
	setp.eq.f32 	%p331, %f1458, 0f40000000;
	@%p331 bra 	$L__BB3_187;

	mov.f32 	%f3028, 0f7FFFFFFF;

$L__BB3_187:
	abs.f32 	%f2808, %f206;
	add.f32 	%f1461, %f2808, 0f40000000;
	mov.b32 	%r439, %f1461;
	setp.lt.s32 	%p333, %r439, 2139095040;
	@%p333 bra 	$L__BB3_192;

	abs.f32 	%f2931, %f206;
	setp.gtu.f32 	%p334, %f2931, 0f7F800000;
	@%p334 bra 	$L__BB3_191;
	bra.uni 	$L__BB3_189;

$L__BB3_191:
	add.f32 	%f3028, %f206, 0f40000000;
	bra.uni 	$L__BB3_192;

$L__BB3_189:
	abs.f32 	%f2932, %f206;
	setp.neu.f32 	%p335, %f2932, 0f7F800000;
	@%p335 bra 	$L__BB3_192;

	selp.f32 	%f3028, 0fFF800000, 0f7F800000, %p27;

$L__BB3_192:
	mov.f32 	%f2816, 0f32A57060;
	mov.f32 	%f2815, 0f4B400001;
	mov.f32 	%f2814, 0f437C0000;
	mov.f32 	%f2813, 0f3BBB989D;
	mov.f32 	%f2812, 0f3FB8AA3B;
	mov.f32 	%f2811, 0f3F000000;
	cvt.rn.f32.s32 	%f2810, %r853;
	sub.f32 	%f2809, %f2810, %f3047;
	mul.f32 	%f1462, %f3028, 0fBF000000;
	setp.eq.f32 	%p336, %f206, 0f3F800000;
	selp.f32 	%f1463, 0fBF000000, %f1462, %p336;
	fma.rn.f32 	%f1466, %f1463, %f2813, %f2811;
	cvt.sat.f32.f32 	%f1469, %f1466;
	fma.rm.f32 	%f1471, %f1469, %f2814, %f2815;
	add.f32 	%f1472, %f1471, 0fCB40007F;
	neg.f32 	%f1473, %f1472;
	fma.rn.f32 	%f1474, %f1463, %f2812, %f1473;
	fma.rn.f32 	%f1476, %f1463, %f2816, %f1474;
	mov.b32 	%r440, %f1471;
	shl.b32 	%r441, %r440, 23;
	mov.b32 	%f1477, %r441;
	ex2.approx.ftz.f32 	%f1478, %f1476;
	mul.f32 	%f218, %f1478, %f1477;
	add.f32 	%f1479, %f2809, 0f3F800000;
	mul.f32 	%f1480, %f1479, %f205;
	mul.f32 	%f1481, %f2809, %f218;
	sub.f32 	%f1482, %f1480, %f1481;
	mul.f32 	%f1483, %f64, %f1482;
	mul.f32 	%f219, %f120, %f1483;
	not.pred 	%p337, %p13;
	mov.f64 	%fd601, %fd45;
	@%p337 bra 	$L__BB3_194;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r442}, %fd45;
	}
	xor.b32  	%r443, %r442, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r444, %temp}, %fd45;
	}
	mov.b64 	%fd601, {%r444, %r443};

$L__BB3_194:
	setp.eq.f32 	%p726, %f3043, 0f00000000;
	@%p726 bra 	$L__BB3_198;
	bra.uni 	$L__BB3_195;

$L__BB3_198:
	mov.u32 	%r445, 0;
	mov.b64 	%fd601, {%r445, %r74};
	bra.uni 	$L__BB3_199;

$L__BB3_195:
	setp.gt.s32 	%p339, %r60, -1;
	@%p339 bra 	$L__BB3_199;

	cvt.rzi.f64.f64 	%fd404, %fd345;
	setp.eq.f64 	%p340, %fd404, 0d4014000000000000;
	@%p340 bra 	$L__BB3_199;

	mov.f64 	%fd601, 0dFFF8000000000000;

$L__BB3_199:
	cvt.f64.f32 	%fd546, %f3043;
	add.f64 	%fd545, %fd546, 0d4014000000000000;
	selp.f64 	%fd602, %fd601, %fd545, %p160;
	@%p23 bra 	$L__BB3_204;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r829}, %fd345;
	}
	and.b32  	%r828, %r829, 2147483647;
	setp.eq.s32 	%p342, %r828, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r446, %temp}, %fd345;
	}
	setp.eq.s32 	%p343, %r446, 0;
	and.pred  	%p344, %p342, %p343;
	@%p344 bra 	$L__BB3_203;
	bra.uni 	$L__BB3_201;

$L__BB3_203:
	mov.u32 	%r450, 0;
	mov.b64 	%fd602, {%r450, %r76};
	bra.uni 	$L__BB3_204;

$L__BB3_201:
	cvt.f64.f32 	%fd547, %f3043;
	and.b32  	%r447, %r60, 2147483647;
	setp.ne.s32 	%p345, %r447, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r448, %temp}, %fd547;
	}
	setp.ne.s32 	%p346, %r448, 0;
	or.pred  	%p347, %p345, %p346;
	mov.f64 	%fd602, %fd601;
	@%p347 bra 	$L__BB3_204;

	mov.u32 	%r449, 0;
	mov.b64 	%fd602, {%r449, %r77};

$L__BB3_204:
	cvt.f64.f32 	%fd410, %f123;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd410;
	}
	abs.f64 	%fd96, %fd410;
	{ // callseq 75, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd604, [retval0+0];
	} // callseq 75
	setp.lt.s32 	%p348, %r83, 0;
	and.pred  	%p28, %p348, %p121;
	not.pred 	%p350, %p28;
	@%p350 bra 	$L__BB3_206;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r451}, %fd604;
	}
	xor.b32  	%r452, %r451, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r453, %temp}, %fd604;
	}
	mov.b64 	%fd604, {%r453, %r452};

$L__BB3_206:
	setp.eq.f32 	%p351, %f123, 0f00000000;
	@%p351 bra 	$L__BB3_210;
	bra.uni 	$L__BB3_207;

$L__BB3_210:
	mov.u32 	%r454, 0;
	selp.b32 	%r455, %r83, 0, %p121;
	or.b32  	%r456, %r455, 2146435072;
	selp.b32 	%r457, %r456, %r455, %p123;
	mov.b64 	%fd604, {%r454, %r457};
	bra.uni 	$L__BB3_211;

$L__BB3_207:
	setp.gt.s32 	%p352, %r83, -1;
	@%p352 bra 	$L__BB3_211;

	cvt.rzi.f64.f64 	%fd413, %fd339;
	setp.eq.f64 	%p353, %fd413, 0d4008000000000000;
	@%p353 bra 	$L__BB3_211;

	mov.f64 	%fd604, 0dFFF8000000000000;

$L__BB3_211:
	add.f64 	%fd102, %fd410, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r458}, %fd102;
	}
	and.b32  	%r459, %r458, 2146435072;
	setp.ne.s32 	%p356, %r459, 2146435072;
	mov.f64 	%fd605, %fd604;
	@%p356 bra 	$L__BB3_217;

	setp.gtu.f64 	%p357, %fd96, 0d7FF0000000000000;
	mov.f64 	%fd605, %fd102;
	@%p357 bra 	$L__BB3_217;

	setp.eq.s32 	%p358, %r57, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r460, %temp}, %fd339;
	}
	setp.eq.s32 	%p359, %r460, 0;
	and.pred  	%p360, %p358, %p359;
	@%p360 bra 	$L__BB3_216;
	bra.uni 	$L__BB3_214;

$L__BB3_216:
	mov.u32 	%r467, 0;
	setp.gt.f64 	%p368, %fd96, 0d3FF0000000000000;
	selp.b32 	%r468, 2146435072, 0, %p368;
	xor.b32  	%r469, %r468, 2146435072;
	selp.b32 	%r470, %r469, %r468, %p123;
	setp.eq.f32 	%p369, %f123, 0fBF800000;
	selp.b32 	%r471, 1072693248, %r470, %p369;
	mov.b64 	%fd605, {%r467, %r471};
	bra.uni 	$L__BB3_217;

$L__BB3_214:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r461, %temp}, %fd410;
	}
	and.b32  	%r462, %r83, 2147483647;
	setp.ne.s32 	%p361, %r462, 2146435072;
	setp.ne.s32 	%p362, %r461, 0;
	or.pred  	%p363, %p361, %p362;
	mov.f64 	%fd605, %fd604;
	@%p363 bra 	$L__BB3_217;

	setp.ne.s32 	%p364, %r57, 1071644672;
	and.pred  	%p365, %p364, %p28;
	mov.u32 	%r464, 0;
	or.b32  	%r465, %r59, -2147483648;
	selp.b32 	%r466, %r465, %r59, %p365;
	mov.b64 	%fd605, {%r464, %r466};

$L__BB3_217:
	setp.eq.f32 	%p370, %f123, 0f3F800000;
	selp.f64 	%fd418, 0d3FF0000000000000, %fd605, %p370;
	cvt.f64.f32 	%fd419, %f205;
	mul.f64 	%fd106, %fd418, %fd419;
	cvt.f64.f32 	%fd107, %f128;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd107;
	}
	abs.f64 	%fd108, %fd107;
	{ // callseq 76, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd607, [retval0+0];
	} // callseq 76
	setp.lt.s32 	%p371, %r84, 0;
	and.pred  	%p29, %p371, %p121;
	not.pred 	%p373, %p29;
	@%p373 bra 	$L__BB3_219;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r472}, %fd607;
	}
	xor.b32  	%r473, %r472, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r474, %temp}, %fd607;
	}
	mov.b64 	%fd607, {%r474, %r473};

$L__BB3_219:
	setp.eq.f32 	%p374, %f128, 0f00000000;
	@%p374 bra 	$L__BB3_223;
	bra.uni 	$L__BB3_220;

$L__BB3_223:
	mov.u32 	%r475, 0;
	selp.b32 	%r476, %r84, 0, %p121;
	or.b32  	%r477, %r476, 2146435072;
	selp.b32 	%r478, %r477, %r476, %p123;
	mov.b64 	%fd607, {%r475, %r478};
	bra.uni 	$L__BB3_224;

$L__BB3_220:
	setp.gt.s32 	%p375, %r84, -1;
	@%p375 bra 	$L__BB3_224;

	cvt.rzi.f64.f64 	%fd422, %fd339;
	setp.eq.f64 	%p376, %fd422, 0d4008000000000000;
	@%p376 bra 	$L__BB3_224;

	mov.f64 	%fd607, 0dFFF8000000000000;

$L__BB3_224:
	add.f64 	%fd114, %fd107, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r479}, %fd114;
	}
	and.b32  	%r480, %r479, 2146435072;
	setp.ne.s32 	%p379, %r480, 2146435072;
	mov.f64 	%fd608, %fd607;
	@%p379 bra 	$L__BB3_230;

	setp.gtu.f64 	%p380, %fd108, 0d7FF0000000000000;
	mov.f64 	%fd608, %fd114;
	@%p380 bra 	$L__BB3_230;

	setp.eq.s32 	%p381, %r57, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r481, %temp}, %fd339;
	}
	setp.eq.s32 	%p382, %r481, 0;
	and.pred  	%p383, %p381, %p382;
	@%p383 bra 	$L__BB3_229;
	bra.uni 	$L__BB3_227;

$L__BB3_229:
	mov.u32 	%r488, 0;
	setp.gt.f64 	%p391, %fd108, 0d3FF0000000000000;
	selp.b32 	%r489, 2146435072, 0, %p391;
	xor.b32  	%r490, %r489, 2146435072;
	selp.b32 	%r491, %r490, %r489, %p123;
	setp.eq.f32 	%p392, %f128, 0fBF800000;
	selp.b32 	%r492, 1072693248, %r491, %p392;
	mov.b64 	%fd608, {%r488, %r492};
	bra.uni 	$L__BB3_230;

$L__BB3_227:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r482, %temp}, %fd107;
	}
	and.b32  	%r483, %r84, 2147483647;
	setp.ne.s32 	%p384, %r483, 2146435072;
	setp.ne.s32 	%p385, %r482, 0;
	or.pred  	%p386, %p384, %p385;
	mov.f64 	%fd608, %fd607;
	@%p386 bra 	$L__BB3_230;

	setp.ne.s32 	%p387, %r57, 1071644672;
	and.pred  	%p388, %p387, %p29;
	mov.u32 	%r485, 0;
	or.b32  	%r486, %r59, -2147483648;
	selp.b32 	%r487, %r486, %r59, %p388;
	mov.b64 	%fd608, {%r485, %r487};

$L__BB3_230:
	cvt.f64.f32 	%fd548, %f120;
	setp.eq.f32 	%p727, %f3043, 0f3F800000;
	mov.f32 	%f3029, 0f00000000;
	setp.eq.f32 	%p393, %f128, 0f3F800000;
	selp.f64 	%fd425, 0d3FF0000000000000, %fd608, %p393;
	cvt.f64.f32 	%fd426, %f218;
	mul.f64 	%fd427, %fd425, %fd426;
	sub.f64 	%fd428, %fd106, %fd427;
	selp.f64 	%fd429, 0d3FF0000000000000, %fd602, %p727;
	div.rn.f64 	%fd430, %fd35, %fd429;
	mul.f64 	%fd431, %fd430, %fd428;
	mul.f64 	%fd433, %fd431, %fd548;
	mul.f32 	%f1485, %f65, %f219;
	cvt.f64.f32 	%fd434, %f1485;
	sub.f64 	%fd435, %fd434, %fd433;
	cvt.rn.f32.f64 	%f220, %fd435;
	mul.f32 	%f221, %f120, %f133;
	setp.leu.f32 	%p395, %f134, 0f3C23D70A;
	@%p395 bra 	$L__BB3_232;

	div.rn.f32 	%f1486, %f135, %f134;
	add.f32 	%f3029, %f1486, 0fBF800000;

$L__BB3_232:
	mov.f32 	%f3030, 0f00000000;
	@%p395 bra 	$L__BB3_247;

	and.b32  	%r493, %r78, 2146435072;
	setp.eq.s32 	%p397, %r493, 1062207488;
	cvt.f64.f32 	%fd118, %f134;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd118;
	}
	abs.f64 	%fd119, %fd118;
	{ // callseq 77, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd119;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd610, [retval0+0];
	} // callseq 77
	setp.lt.s32 	%p398, %r85, 0;
	and.pred  	%p30, %p398, %p397;
	not.pred 	%p399, %p30;
	@%p399 bra 	$L__BB3_235;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r494}, %fd610;
	}
	xor.b32  	%r495, %r494, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r496, %temp}, %fd610;
	}
	mov.b64 	%fd610, {%r496, %r495};

$L__BB3_235:
	setp.eq.f32 	%p400, %f134, 0f00000000;
	@%p400 bra 	$L__BB3_239;
	bra.uni 	$L__BB3_236;

$L__BB3_239:
	setp.lt.s32 	%p403, %r78, 0;
	mov.u32 	%r497, 0;
	selp.b32 	%r499, %r85, 0, %p397;
	or.b32  	%r500, %r499, 2146435072;
	selp.b32 	%r501, %r500, %r499, %p403;
	mov.b64 	%fd610, {%r497, %r501};
	bra.uni 	$L__BB3_240;

$L__BB3_236:
	setp.gt.s32 	%p401, %r85, -1;
	@%p401 bra 	$L__BB3_240;

	cvt.rzi.f64.f64 	%fd438, %fd350;
	setp.eq.f64 	%p402, %fd438, 0d4000000000000000;
	@%p402 bra 	$L__BB3_240;

	mov.f64 	%fd610, 0dFFF8000000000000;

$L__BB3_240:
	add.f64 	%fd125, %fd118, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r502}, %fd125;
	}
	and.b32  	%r503, %r502, 2146435072;
	setp.ne.s32 	%p405, %r503, 2146435072;
	mov.f64 	%fd611, %fd610;
	@%p405 bra 	$L__BB3_246;

	setp.gtu.f64 	%p406, %fd119, 0d7FF0000000000000;
	mov.f64 	%fd611, %fd125;
	@%p406 bra 	$L__BB3_246;

	setp.eq.s32 	%p407, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r504, %temp}, %fd350;
	}
	setp.eq.s32 	%p408, %r504, 0;
	and.pred  	%p409, %p407, %p408;
	@%p409 bra 	$L__BB3_245;
	bra.uni 	$L__BB3_243;

$L__BB3_245:
	setp.lt.s32 	%p415, %r78, 0;
	mov.u32 	%r510, 0;
	setp.gt.f64 	%p416, %fd119, 0d3FF0000000000000;
	selp.b32 	%r511, 2146435072, 0, %p416;
	xor.b32  	%r512, %r511, 2146435072;
	selp.b32 	%r513, %r512, %r511, %p415;
	setp.eq.f32 	%p417, %f134, 0fBF800000;
	selp.b32 	%r514, 1072693248, %r513, %p417;
	mov.b64 	%fd611, {%r510, %r514};
	bra.uni 	$L__BB3_246;

$L__BB3_243:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r505, %temp}, %fd118;
	}
	and.b32  	%r506, %r85, 2147483647;
	setp.ne.s32 	%p410, %r506, 2146435072;
	setp.ne.s32 	%p411, %r505, 0;
	or.pred  	%p412, %p410, %p411;
	mov.f64 	%fd611, %fd610;
	@%p412 bra 	$L__BB3_246;

	setp.ne.s32 	%p413, %r79, 1071644672;
	and.pred  	%p414, %p413, %p30;
	or.b32  	%r507, %r80, -2147483648;
	selp.b32 	%r508, %r507, %r80, %p414;
	mov.u32 	%r509, 0;
	mov.b64 	%fd611, {%r509, %r508};

$L__BB3_246:
	setp.eq.f32 	%p418, %f134, 0f3F800000;
	selp.f64 	%fd441, 0d3FF0000000000000, %fd611, %p418;
	cvt.f64.f32 	%fd442, %f135;
	div.rn.f64 	%fd443, %fd442, %fd441;
	cvt.rn.f32.f64 	%f3030, %fd443;

$L__BB3_247:
	and.b32  	%r515, %r78, 2146435072;
	setp.eq.s32 	%p419, %r515, 1062207488;
	mov.f32 	%f1488, 0f47C35000;
	min.f32 	%f1489, %f3030, %f1488;
	cvt.f64.f32 	%fd129, %f1489;
	min.f32 	%f226, %f3029, %f1488;
	fma.rn.f32 	%f2998, %f226, %f148, %f2998;
	mul.f32 	%f1490, %f226, %f149;
	cvt.f64.f32 	%fd130, %f1490;
	cvt.f64.f32 	%fd131, %f148;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd131;
	}
	abs.f64 	%fd132, %fd131;
	{ // callseq 78, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd132;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd612, [retval0+0];
	} // callseq 78
	@%p419 bra 	$L__BB3_304;
	bra.uni 	$L__BB3_248;

$L__BB3_304:
	setp.gt.s32 	%p495, %r86, -1;
	@%p495 bra 	$L__BB3_306;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r576}, %fd612;
	}
	xor.b32  	%r577, %r576, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r578, %temp}, %fd612;
	}
	mov.b64 	%fd612, {%r578, %r577};

$L__BB3_306:
	setp.eq.f32 	%p496, %f148, 0f00000000;
	@%p496 bra 	$L__BB3_310;
	bra.uni 	$L__BB3_307;

$L__BB3_310:
	setp.lt.s32 	%p499, %r78, 0;
	mov.u32 	%r579, 0;
	or.b32  	%r580, %r86, 2146435072;
	selp.b32 	%r581, %r580, %r86, %p499;
	mov.b64 	%fd612, {%r579, %r581};
	bra.uni 	$L__BB3_311;

$L__BB3_248:
	setp.eq.f32 	%p420, %f148, 0f00000000;
	@%p420 bra 	$L__BB3_252;
	bra.uni 	$L__BB3_249;

$L__BB3_252:
	mov.u32 	%r516, 0;
	mov.b64 	%fd612, {%r516, %r81};
	bra.uni 	$L__BB3_253;

$L__BB3_307:
	@%p495 bra 	$L__BB3_311;

	cvt.rzi.f64.f64 	%fd496, %fd350;
	setp.eq.f64 	%p498, %fd496, 0d4000000000000000;
	@%p498 bra 	$L__BB3_311;

	mov.f64 	%fd612, 0dFFF8000000000000;

$L__BB3_311:
	add.f64 	%fd186, %fd131, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r582}, %fd186;
	}
	and.b32  	%r583, %r582, 2146435072;
	setp.ne.s32 	%p500, %r583, 2146435072;
	mov.f64 	%fd624, %fd612;
	@%p500 bra 	$L__BB3_317;

	setp.gtu.f64 	%p501, %fd132, 0d7FF0000000000000;
	mov.f64 	%fd624, %fd186;
	@%p501 bra 	$L__BB3_317;

	setp.eq.s32 	%p502, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r584, %temp}, %fd350;
	}
	setp.eq.s32 	%p503, %r584, 0;
	and.pred  	%p504, %p502, %p503;
	@%p504 bra 	$L__BB3_316;
	bra.uni 	$L__BB3_314;

$L__BB3_316:
	setp.lt.s32 	%p511, %r78, 0;
	mov.u32 	%r590, 0;
	setp.gt.f64 	%p512, %fd132, 0d3FF0000000000000;
	selp.b32 	%r591, 2146435072, 0, %p512;
	xor.b32  	%r592, %r591, 2146435072;
	selp.b32 	%r593, %r592, %r591, %p511;
	setp.eq.f32 	%p513, %f148, 0fBF800000;
	selp.b32 	%r594, 1072693248, %r593, %p513;
	mov.b64 	%fd624, {%r590, %r594};
	bra.uni 	$L__BB3_317;

$L__BB3_249:
	setp.gt.s32 	%p421, %r86, -1;
	@%p421 bra 	$L__BB3_253;

	cvt.rzi.f64.f64 	%fd446, %fd350;
	setp.eq.f64 	%p422, %fd446, 0d4000000000000000;
	@%p422 bra 	$L__BB3_253;

	mov.f64 	%fd612, 0dFFF8000000000000;

$L__BB3_253:
	add.f64 	%fd136, %fd131, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r517}, %fd136;
	}
	and.b32  	%r518, %r517, 2146435072;
	setp.ne.s32 	%p423, %r518, 2146435072;
	mov.f64 	%fd613, %fd612;
	@%p423 bra 	$L__BB3_259;

	setp.gtu.f64 	%p424, %fd132, 0d7FF0000000000000;
	mov.f64 	%fd613, %fd136;
	@%p424 bra 	$L__BB3_259;

	setp.eq.s32 	%p425, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r519, %temp}, %fd350;
	}
	setp.eq.s32 	%p426, %r519, 0;
	and.pred  	%p427, %p425, %p426;
	@%p427 bra 	$L__BB3_258;
	bra.uni 	$L__BB3_256;

$L__BB3_258:
	setp.lt.s32 	%p431, %r78, 0;
	mov.u32 	%r523, 0;
	setp.gt.f64 	%p432, %fd132, 0d3FF0000000000000;
	selp.b32 	%r524, 2146435072, 0, %p432;
	xor.b32  	%r525, %r524, 2146435072;
	selp.b32 	%r526, %r525, %r524, %p431;
	setp.eq.f32 	%p433, %f148, 0fBF800000;
	selp.b32 	%r527, 1072693248, %r526, %p433;
	mov.b64 	%fd613, {%r523, %r527};
	bra.uni 	$L__BB3_259;

$L__BB3_314:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r585, %temp}, %fd131;
	}
	and.b32  	%r586, %r86, 2147483647;
	setp.ne.s32 	%p505, %r586, 2146435072;
	setp.ne.s32 	%p506, %r585, 0;
	or.pred  	%p507, %p505, %p506;
	mov.f64 	%fd624, %fd612;
	@%p507 bra 	$L__BB3_317;

	setp.lt.s32 	%p508, %r86, 0;
	mov.u32 	%r587, 0;
	setp.ne.s32 	%p509, %r79, 1071644672;
	and.pred  	%p510, %p509, %p508;
	or.b32  	%r588, %r80, -2147483648;
	selp.b32 	%r589, %r588, %r80, %p510;
	mov.b64 	%fd624, {%r587, %r589};

$L__BB3_317:
	setp.eq.f32 	%p514, %f148, 0f3F800000;
	selp.f64 	%fd499, 0d3FF0000000000000, %fd624, %p514;
	mul.f64 	%fd500, %fd499, %fd129;
	sub.f64 	%fd501, %fd130, %fd500;
	cvt.f64.f32 	%fd502, %f3004;
	add.f64 	%fd642, %fd501, %fd502;
	cvt.f64.f32 	%fd191, %f177;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd191;
	}
	abs.f64 	%fd192, %fd191;
	{ // callseq 83, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd192;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd626, [retval0+0];
	} // callseq 83
	setp.gt.s32 	%p515, %r91, -1;
	@%p515 bra 	$L__BB3_319;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r595}, %fd626;
	}
	xor.b32  	%r596, %r595, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r597, %temp}, %fd626;
	}
	mov.b64 	%fd626, {%r597, %r596};

$L__BB3_319:
	setp.eq.f32 	%p516, %f177, 0f00000000;
	@%p516 bra 	$L__BB3_323;
	bra.uni 	$L__BB3_320;

$L__BB3_323:
	setp.lt.s32 	%p519, %r78, 0;
	mov.u32 	%r598, 0;
	or.b32  	%r599, %r91, 2146435072;
	selp.b32 	%r600, %r599, %r91, %p519;
	mov.b64 	%fd626, {%r598, %r600};
	bra.uni 	$L__BB3_324;

$L__BB3_320:
	@%p515 bra 	$L__BB3_324;

	cvt.rzi.f64.f64 	%fd505, %fd350;
	setp.eq.f64 	%p518, %fd505, 0d4000000000000000;
	@%p518 bra 	$L__BB3_324;

	mov.f64 	%fd626, 0dFFF8000000000000;

$L__BB3_324:
	add.f64 	%fd198, %fd191, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r601}, %fd198;
	}
	and.b32  	%r602, %r601, 2146435072;
	setp.ne.s32 	%p520, %r602, 2146435072;
	mov.f64 	%fd627, %fd626;
	@%p520 bra 	$L__BB3_330;

	setp.gtu.f64 	%p521, %fd192, 0d7FF0000000000000;
	mov.f64 	%fd627, %fd198;
	@%p521 bra 	$L__BB3_330;

	setp.eq.s32 	%p522, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r603, %temp}, %fd350;
	}
	setp.eq.s32 	%p523, %r603, 0;
	and.pred  	%p524, %p522, %p523;
	@%p524 bra 	$L__BB3_329;
	bra.uni 	$L__BB3_327;

$L__BB3_329:
	setp.lt.s32 	%p531, %r78, 0;
	mov.u32 	%r609, 0;
	setp.gt.f64 	%p532, %fd192, 0d3FF0000000000000;
	selp.b32 	%r610, 2146435072, 0, %p532;
	xor.b32  	%r611, %r610, 2146435072;
	selp.b32 	%r612, %r611, %r610, %p531;
	setp.eq.f32 	%p533, %f177, 0fBF800000;
	selp.b32 	%r613, 1072693248, %r612, %p533;
	mov.b64 	%fd627, {%r609, %r613};
	bra.uni 	$L__BB3_330;

$L__BB3_256:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r520, %temp}, %fd131;
	}
	and.b32  	%r521, %r86, 2147483647;
	setp.ne.s32 	%p428, %r521, 2146435072;
	setp.ne.s32 	%p429, %r520, 0;
	or.pred  	%p430, %p428, %p429;
	mov.f64 	%fd613, %fd612;
	@%p430 bra 	$L__BB3_259;

	mov.u32 	%r522, 0;
	mov.b64 	%fd613, {%r522, %r80};

$L__BB3_259:
	setp.eq.f32 	%p434, %f148, 0f3F800000;
	selp.f64 	%fd449, 0d3FF0000000000000, %fd613, %p434;
	mul.f64 	%fd450, %fd449, %fd129;
	sub.f64 	%fd451, %fd130, %fd450;
	cvt.f64.f32 	%fd452, %f3004;
	add.f64 	%fd642, %fd451, %fd452;
	cvt.f64.f32 	%fd141, %f177;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd141;
	}
	abs.f64 	%fd142, %fd141;
	setp.eq.f32 	%p435, %f177, 0f00000000;
	@%p435 bra 	$L__BB3_263;
	bra.uni 	$L__BB3_260;

$L__BB3_263:
	mov.u32 	%r528, 0;
	mov.b64 	%fd614, {%r528, %r81};
	bra.uni 	$L__BB3_264;

$L__BB3_260:
	{ // callseq 79, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd142;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd614, [retval0+0];
	} // callseq 79
	setp.gt.s32 	%p436, %r87, -1;
	@%p436 bra 	$L__BB3_264;

	cvt.rzi.f64.f64 	%fd455, %fd350;
	setp.eq.f64 	%p437, %fd455, 0d4000000000000000;
	@%p437 bra 	$L__BB3_264;

	mov.f64 	%fd614, 0dFFF8000000000000;

$L__BB3_264:
	add.f64 	%fd146, %fd141, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r529}, %fd146;
	}
	and.b32  	%r530, %r529, 2146435072;
	setp.ne.s32 	%p438, %r530, 2146435072;
	mov.f64 	%fd615, %fd614;
	@%p438 bra 	$L__BB3_270;

	setp.gtu.f64 	%p439, %fd142, 0d7FF0000000000000;
	mov.f64 	%fd615, %fd146;
	@%p439 bra 	$L__BB3_270;

	setp.eq.s32 	%p440, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r531, %temp}, %fd350;
	}
	setp.eq.s32 	%p441, %r531, 0;
	and.pred  	%p442, %p440, %p441;
	@%p442 bra 	$L__BB3_269;
	bra.uni 	$L__BB3_267;

$L__BB3_269:
	setp.lt.s32 	%p446, %r78, 0;
	mov.u32 	%r535, 0;
	setp.gt.f64 	%p447, %fd142, 0d3FF0000000000000;
	selp.b32 	%r536, 2146435072, 0, %p447;
	xor.b32  	%r537, %r536, 2146435072;
	selp.b32 	%r538, %r537, %r536, %p446;
	setp.eq.f32 	%p448, %f177, 0fBF800000;
	selp.b32 	%r539, 1072693248, %r538, %p448;
	mov.b64 	%fd615, {%r535, %r539};
	bra.uni 	$L__BB3_270;

$L__BB3_327:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r604, %temp}, %fd191;
	}
	and.b32  	%r605, %r91, 2147483647;
	setp.ne.s32 	%p525, %r605, 2146435072;
	setp.ne.s32 	%p526, %r604, 0;
	or.pred  	%p527, %p525, %p526;
	mov.f64 	%fd627, %fd626;
	@%p527 bra 	$L__BB3_330;

	setp.lt.s32 	%p528, %r91, 0;
	mov.u32 	%r606, 0;
	setp.ne.s32 	%p529, %r79, 1071644672;
	and.pred  	%p530, %p529, %p528;
	or.b32  	%r607, %r80, -2147483648;
	selp.b32 	%r608, %r607, %r80, %p530;
	mov.b64 	%fd627, {%r606, %r608};

$L__BB3_330:
	setp.eq.f32 	%p534, %f177, 0f3F800000;
	selp.f64 	%fd508, 0d3FF0000000000000, %fd627, %p534;
	mul.f64 	%fd509, %fd508, %fd129;
	mul.f32 	%f1495, %f226, %f178;
	cvt.f64.f32 	%fd510, %f1495;
	sub.f64 	%fd511, %fd510, %fd509;
	cvt.f64.f32 	%fd512, %f3003;
	add.f64 	%fd641, %fd511, %fd512;
	cvt.f64.f32 	%fd203, %f221;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r92}, %fd203;
	}
	abs.f64 	%fd204, %fd203;
	{ // callseq 84, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd204;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd629, [retval0+0];
	} // callseq 84
	setp.gt.s32 	%p535, %r92, -1;
	@%p535 bra 	$L__BB3_332;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r614}, %fd629;
	}
	xor.b32  	%r615, %r614, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r616, %temp}, %fd629;
	}
	mov.b64 	%fd629, {%r616, %r615};

$L__BB3_332:
	setp.eq.f32 	%p536, %f221, 0f00000000;
	@%p536 bra 	$L__BB3_336;
	bra.uni 	$L__BB3_333;

$L__BB3_336:
	setp.lt.s32 	%p539, %r78, 0;
	mov.u32 	%r617, 0;
	or.b32  	%r618, %r92, 2146435072;
	selp.b32 	%r619, %r618, %r92, %p539;
	mov.b64 	%fd629, {%r617, %r619};
	bra.uni 	$L__BB3_337;

$L__BB3_333:
	@%p535 bra 	$L__BB3_337;

	cvt.rzi.f64.f64 	%fd515, %fd350;
	setp.eq.f64 	%p538, %fd515, 0d4000000000000000;
	@%p538 bra 	$L__BB3_337;

	mov.f64 	%fd629, 0dFFF8000000000000;

$L__BB3_337:
	add.f64 	%fd210, %fd203, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r620}, %fd210;
	}
	and.b32  	%r621, %r620, 2146435072;
	setp.ne.s32 	%p540, %r621, 2146435072;
	mov.f64 	%fd630, %fd629;
	@%p540 bra 	$L__BB3_343;

	setp.gtu.f64 	%p541, %fd204, 0d7FF0000000000000;
	mov.f64 	%fd630, %fd210;
	@%p541 bra 	$L__BB3_343;

	setp.eq.s32 	%p542, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r622, %temp}, %fd350;
	}
	setp.eq.s32 	%p543, %r622, 0;
	and.pred  	%p544, %p542, %p543;
	@%p544 bra 	$L__BB3_342;
	bra.uni 	$L__BB3_340;

$L__BB3_342:
	setp.lt.s32 	%p551, %r78, 0;
	mov.u32 	%r628, 0;
	setp.gt.f64 	%p552, %fd204, 0d3FF0000000000000;
	selp.b32 	%r629, 2146435072, 0, %p552;
	xor.b32  	%r630, %r629, 2146435072;
	selp.b32 	%r631, %r630, %r629, %p551;
	setp.eq.f32 	%p553, %f221, 0fBF800000;
	selp.b32 	%r632, 1072693248, %r631, %p553;
	mov.b64 	%fd630, {%r628, %r632};
	bra.uni 	$L__BB3_343;

$L__BB3_267:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r532, %temp}, %fd141;
	}
	and.b32  	%r533, %r87, 2147483647;
	setp.ne.s32 	%p443, %r533, 2146435072;
	setp.ne.s32 	%p444, %r532, 0;
	or.pred  	%p445, %p443, %p444;
	mov.f64 	%fd615, %fd614;
	@%p445 bra 	$L__BB3_270;

	mov.u32 	%r534, 0;
	mov.b64 	%fd615, {%r534, %r80};

$L__BB3_270:
	setp.eq.f32 	%p449, %f177, 0f3F800000;
	selp.f64 	%fd458, 0d3FF0000000000000, %fd615, %p449;
	mul.f64 	%fd459, %fd458, %fd129;
	mul.f32 	%f1491, %f226, %f178;
	cvt.f64.f32 	%fd460, %f1491;
	sub.f64 	%fd461, %fd460, %fd459;
	cvt.f64.f32 	%fd462, %f3003;
	add.f64 	%fd641, %fd461, %fd462;
	cvt.f64.f32 	%fd151, %f221;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd151;
	}
	abs.f64 	%fd152, %fd151;
	setp.eq.f32 	%p450, %f221, 0f00000000;
	@%p450 bra 	$L__BB3_274;
	bra.uni 	$L__BB3_271;

$L__BB3_274:
	mov.u32 	%r540, 0;
	mov.b64 	%fd616, {%r540, %r81};
	bra.uni 	$L__BB3_275;

$L__BB3_271:
	{ // callseq 80, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd152;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd616, [retval0+0];
	} // callseq 80
	setp.gt.s32 	%p451, %r88, -1;
	@%p451 bra 	$L__BB3_275;

	cvt.rzi.f64.f64 	%fd465, %fd350;
	setp.eq.f64 	%p452, %fd465, 0d4000000000000000;
	@%p452 bra 	$L__BB3_275;

	mov.f64 	%fd616, 0dFFF8000000000000;

$L__BB3_275:
	add.f64 	%fd156, %fd151, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r541}, %fd156;
	}
	and.b32  	%r542, %r541, 2146435072;
	setp.ne.s32 	%p453, %r542, 2146435072;
	mov.f64 	%fd617, %fd616;
	@%p453 bra 	$L__BB3_281;

	setp.gtu.f64 	%p454, %fd152, 0d7FF0000000000000;
	mov.f64 	%fd617, %fd156;
	@%p454 bra 	$L__BB3_281;

	setp.eq.s32 	%p455, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r543, %temp}, %fd350;
	}
	setp.eq.s32 	%p456, %r543, 0;
	and.pred  	%p457, %p455, %p456;
	@%p457 bra 	$L__BB3_280;
	bra.uni 	$L__BB3_278;

$L__BB3_280:
	setp.lt.s32 	%p461, %r78, 0;
	mov.u32 	%r547, 0;
	setp.gt.f64 	%p462, %fd152, 0d3FF0000000000000;
	selp.b32 	%r548, 2146435072, 0, %p462;
	xor.b32  	%r549, %r548, 2146435072;
	selp.b32 	%r550, %r549, %r548, %p461;
	setp.eq.f32 	%p463, %f221, 0fBF800000;
	selp.b32 	%r551, 1072693248, %r550, %p463;
	mov.b64 	%fd617, {%r547, %r551};
	bra.uni 	$L__BB3_281;

$L__BB3_340:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r623, %temp}, %fd203;
	}
	and.b32  	%r624, %r92, 2147483647;
	setp.ne.s32 	%p545, %r624, 2146435072;
	setp.ne.s32 	%p546, %r623, 0;
	or.pred  	%p547, %p545, %p546;
	mov.f64 	%fd630, %fd629;
	@%p547 bra 	$L__BB3_343;

	setp.lt.s32 	%p548, %r92, 0;
	mov.u32 	%r625, 0;
	setp.ne.s32 	%p549, %r79, 1071644672;
	and.pred  	%p550, %p549, %p548;
	or.b32  	%r626, %r80, -2147483648;
	selp.b32 	%r627, %r626, %r80, %p550;
	mov.b64 	%fd630, {%r625, %r627};

$L__BB3_343:
	mul.f32 	%f1496, %f226, 0f00000000;
	cvt.f64.f32 	%fd518, %f1496;
	setp.eq.f32 	%p554, %f221, 0f3F800000;
	selp.f64 	%fd519, 0d3FF0000000000000, %fd630, %p554;
	mul.f64 	%fd520, %fd519, %fd129;
	sub.f64 	%fd521, %fd518, %fd520;
	cvt.f64.f32 	%fd522, %f3002;
	add.f64 	%fd640, %fd521, %fd522;
	cvt.f64.f32 	%fd523, %f3001;
	sub.f64 	%fd524, %fd518, %fd129;
	add.f64 	%fd639, %fd524, %fd523;
	cvt.f64.f32 	%fd216, %f191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r93}, %fd216;
	}
	abs.f64 	%fd217, %fd216;
	{ // callseq 85, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd217;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd632, [retval0+0];
	} // callseq 85
	setp.gt.s32 	%p555, %r93, -1;
	@%p555 bra 	$L__BB3_345;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r633}, %fd632;
	}
	xor.b32  	%r634, %r633, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r635, %temp}, %fd632;
	}
	mov.b64 	%fd632, {%r635, %r634};

$L__BB3_345:
	setp.eq.f32 	%p556, %f191, 0f00000000;
	@%p556 bra 	$L__BB3_349;
	bra.uni 	$L__BB3_346;

$L__BB3_349:
	setp.lt.s32 	%p559, %r78, 0;
	mov.u32 	%r636, 0;
	or.b32  	%r637, %r93, 2146435072;
	selp.b32 	%r638, %r637, %r93, %p559;
	mov.b64 	%fd632, {%r636, %r638};
	bra.uni 	$L__BB3_350;

$L__BB3_346:
	@%p555 bra 	$L__BB3_350;

	cvt.rzi.f64.f64 	%fd527, %fd350;
	setp.eq.f64 	%p558, %fd527, 0d4000000000000000;
	@%p558 bra 	$L__BB3_350;

	mov.f64 	%fd632, 0dFFF8000000000000;

$L__BB3_350:
	add.f64 	%fd223, %fd216, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r639}, %fd223;
	}
	and.b32  	%r640, %r639, 2146435072;
	setp.ne.s32 	%p560, %r640, 2146435072;
	mov.f64 	%fd633, %fd632;
	@%p560 bra 	$L__BB3_356;

	setp.gtu.f64 	%p561, %fd217, 0d7FF0000000000000;
	mov.f64 	%fd633, %fd223;
	@%p561 bra 	$L__BB3_356;

	setp.eq.s32 	%p562, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r641, %temp}, %fd350;
	}
	setp.eq.s32 	%p563, %r641, 0;
	and.pred  	%p564, %p562, %p563;
	@%p564 bra 	$L__BB3_355;
	bra.uni 	$L__BB3_353;

$L__BB3_355:
	setp.lt.s32 	%p571, %r78, 0;
	mov.u32 	%r647, 0;
	setp.gt.f64 	%p572, %fd217, 0d3FF0000000000000;
	selp.b32 	%r648, 2146435072, 0, %p572;
	xor.b32  	%r649, %r648, 2146435072;
	selp.b32 	%r650, %r649, %r648, %p571;
	setp.eq.f32 	%p573, %f191, 0fBF800000;
	selp.b32 	%r651, 1072693248, %r650, %p573;
	mov.b64 	%fd633, {%r647, %r651};
	bra.uni 	$L__BB3_356;

$L__BB3_278:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r544, %temp}, %fd151;
	}
	and.b32  	%r545, %r88, 2147483647;
	setp.ne.s32 	%p458, %r545, 2146435072;
	setp.ne.s32 	%p459, %r544, 0;
	or.pred  	%p460, %p458, %p459;
	mov.f64 	%fd617, %fd616;
	@%p460 bra 	$L__BB3_281;

	mov.u32 	%r546, 0;
	mov.b64 	%fd617, {%r546, %r80};

$L__BB3_281:
	mul.f32 	%f1492, %f226, 0f00000000;
	cvt.f64.f32 	%fd468, %f1492;
	setp.eq.f32 	%p464, %f221, 0f3F800000;
	selp.f64 	%fd469, 0d3FF0000000000000, %fd617, %p464;
	mul.f64 	%fd470, %fd469, %fd129;
	sub.f64 	%fd471, %fd468, %fd470;
	cvt.f64.f32 	%fd472, %f3002;
	add.f64 	%fd640, %fd471, %fd472;
	cvt.f64.f32 	%fd473, %f3001;
	sub.f64 	%fd474, %fd468, %fd129;
	add.f64 	%fd639, %fd474, %fd473;
	cvt.f64.f32 	%fd162, %f191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r89}, %fd162;
	}
	abs.f64 	%fd163, %fd162;
	setp.eq.f32 	%p465, %f191, 0f00000000;
	@%p465 bra 	$L__BB3_285;
	bra.uni 	$L__BB3_282;

$L__BB3_285:
	mov.u32 	%r552, 0;
	mov.b64 	%fd618, {%r552, %r81};
	bra.uni 	$L__BB3_286;

$L__BB3_282:
	{ // callseq 81, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd163;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd618, [retval0+0];
	} // callseq 81
	setp.gt.s32 	%p466, %r89, -1;
	@%p466 bra 	$L__BB3_286;

	cvt.rzi.f64.f64 	%fd477, %fd350;
	setp.eq.f64 	%p467, %fd477, 0d4000000000000000;
	@%p467 bra 	$L__BB3_286;

	mov.f64 	%fd618, 0dFFF8000000000000;

$L__BB3_286:
	add.f64 	%fd167, %fd162, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r553}, %fd167;
	}
	and.b32  	%r554, %r553, 2146435072;
	setp.ne.s32 	%p468, %r554, 2146435072;
	mov.f64 	%fd619, %fd618;
	@%p468 bra 	$L__BB3_292;

	setp.gtu.f64 	%p469, %fd163, 0d7FF0000000000000;
	mov.f64 	%fd619, %fd167;
	@%p469 bra 	$L__BB3_292;

	setp.eq.s32 	%p470, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r555, %temp}, %fd350;
	}
	setp.eq.s32 	%p471, %r555, 0;
	and.pred  	%p472, %p470, %p471;
	@%p472 bra 	$L__BB3_291;
	bra.uni 	$L__BB3_289;

$L__BB3_291:
	setp.lt.s32 	%p476, %r78, 0;
	mov.u32 	%r559, 0;
	setp.gt.f64 	%p477, %fd163, 0d3FF0000000000000;
	selp.b32 	%r560, 2146435072, 0, %p477;
	xor.b32  	%r561, %r560, 2146435072;
	selp.b32 	%r562, %r561, %r560, %p476;
	setp.eq.f32 	%p478, %f191, 0fBF800000;
	selp.b32 	%r563, 1072693248, %r562, %p478;
	mov.b64 	%fd619, {%r559, %r563};
	bra.uni 	$L__BB3_292;

$L__BB3_353:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r642, %temp}, %fd216;
	}
	and.b32  	%r643, %r93, 2147483647;
	setp.ne.s32 	%p565, %r643, 2146435072;
	setp.ne.s32 	%p566, %r642, 0;
	or.pred  	%p567, %p565, %p566;
	mov.f64 	%fd633, %fd632;
	@%p567 bra 	$L__BB3_356;

	setp.lt.s32 	%p568, %r93, 0;
	mov.u32 	%r644, 0;
	setp.ne.s32 	%p569, %r79, 1071644672;
	and.pred  	%p570, %p569, %p568;
	or.b32  	%r645, %r80, -2147483648;
	selp.b32 	%r646, %r645, %r80, %p570;
	mov.b64 	%fd633, {%r644, %r646};

$L__BB3_356:
	setp.eq.f32 	%p574, %f191, 0f3F800000;
	selp.f64 	%fd530, 0d3FF0000000000000, %fd633, %p574;
	mul.f64 	%fd531, %fd530, %fd129;
	mul.f32 	%f1497, %f226, %f192;
	cvt.f64.f32 	%fd532, %f1497;
	sub.f64 	%fd533, %fd532, %fd531;
	cvt.f64.f32 	%fd534, %f3000;
	add.f64 	%fd638, %fd533, %fd534;
	cvt.f64.f32 	%fd228, %f219;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r94}, %fd228;
	}
	abs.f64 	%fd229, %fd228;
	{ // callseq 86, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd229;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd635, [retval0+0];
	} // callseq 86
	setp.gt.s32 	%p575, %r94, -1;
	@%p575 bra 	$L__BB3_358;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r652}, %fd635;
	}
	xor.b32  	%r653, %r652, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r654, %temp}, %fd635;
	}
	mov.b64 	%fd635, {%r654, %r653};

$L__BB3_358:
	setp.eq.f32 	%p576, %f219, 0f00000000;
	@%p576 bra 	$L__BB3_362;
	bra.uni 	$L__BB3_359;

$L__BB3_362:
	setp.lt.s32 	%p579, %r78, 0;
	mov.u32 	%r655, 0;
	or.b32  	%r656, %r94, 2146435072;
	selp.b32 	%r657, %r656, %r94, %p579;
	mov.b64 	%fd635, {%r655, %r657};
	bra.uni 	$L__BB3_363;

$L__BB3_359:
	@%p575 bra 	$L__BB3_363;

	cvt.rzi.f64.f64 	%fd537, %fd350;
	setp.eq.f64 	%p578, %fd537, 0d4000000000000000;
	@%p578 bra 	$L__BB3_363;

	mov.f64 	%fd635, 0dFFF8000000000000;

$L__BB3_363:
	add.f64 	%fd235, %fd228, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r658}, %fd235;
	}
	and.b32  	%r659, %r658, 2146435072;
	setp.ne.s32 	%p580, %r659, 2146435072;
	mov.f64 	%fd636, %fd635;
	@%p580 bra 	$L__BB3_369;

	setp.gtu.f64 	%p581, %fd229, 0d7FF0000000000000;
	mov.f64 	%fd636, %fd235;
	@%p581 bra 	$L__BB3_369;

	setp.eq.s32 	%p582, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r660, %temp}, %fd350;
	}
	setp.eq.s32 	%p583, %r660, 0;
	and.pred  	%p584, %p582, %p583;
	@%p584 bra 	$L__BB3_368;
	bra.uni 	$L__BB3_366;

$L__BB3_368:
	setp.lt.s32 	%p591, %r78, 0;
	mov.u32 	%r666, 0;
	setp.gt.f64 	%p592, %fd229, 0d3FF0000000000000;
	selp.b32 	%r667, 2146435072, 0, %p592;
	xor.b32  	%r668, %r667, 2146435072;
	selp.b32 	%r669, %r668, %r667, %p591;
	setp.eq.f32 	%p593, %f219, 0fBF800000;
	selp.b32 	%r670, 1072693248, %r669, %p593;
	mov.b64 	%fd636, {%r666, %r670};
	bra.uni 	$L__BB3_369;

$L__BB3_289:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r556, %temp}, %fd162;
	}
	and.b32  	%r557, %r89, 2147483647;
	setp.ne.s32 	%p473, %r557, 2146435072;
	setp.ne.s32 	%p474, %r556, 0;
	or.pred  	%p475, %p473, %p474;
	mov.f64 	%fd619, %fd618;
	@%p475 bra 	$L__BB3_292;

	mov.u32 	%r558, 0;
	mov.b64 	%fd619, {%r558, %r80};

$L__BB3_292:
	setp.eq.f32 	%p479, %f191, 0f3F800000;
	selp.f64 	%fd480, 0d3FF0000000000000, %fd619, %p479;
	mul.f64 	%fd481, %fd480, %fd129;
	mul.f32 	%f1493, %f226, %f192;
	cvt.f64.f32 	%fd482, %f1493;
	sub.f64 	%fd483, %fd482, %fd481;
	cvt.f64.f32 	%fd484, %f3000;
	add.f64 	%fd638, %fd483, %fd484;
	cvt.f64.f32 	%fd172, %f219;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd172;
	}
	abs.f64 	%fd173, %fd172;
	setp.eq.f32 	%p480, %f219, 0f00000000;
	@%p480 bra 	$L__BB3_296;
	bra.uni 	$L__BB3_293;

$L__BB3_296:
	mov.u32 	%r564, 0;
	mov.b64 	%fd620, {%r564, %r81};
	bra.uni 	$L__BB3_297;

$L__BB3_293:
	{ // callseq 82, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd173;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd620, [retval0+0];
	} // callseq 82
	setp.gt.s32 	%p481, %r90, -1;
	@%p481 bra 	$L__BB3_297;

	cvt.rzi.f64.f64 	%fd487, %fd350;
	setp.eq.f64 	%p482, %fd487, 0d4000000000000000;
	@%p482 bra 	$L__BB3_297;

	mov.f64 	%fd620, 0dFFF8000000000000;

$L__BB3_297:
	add.f64 	%fd177, %fd172, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r565}, %fd177;
	}
	and.b32  	%r566, %r565, 2146435072;
	setp.ne.s32 	%p483, %r566, 2146435072;
	mov.f64 	%fd621, %fd620;
	@%p483 bra 	$L__BB3_303;

	setp.gtu.f64 	%p484, %fd173, 0d7FF0000000000000;
	mov.f64 	%fd621, %fd177;
	@%p484 bra 	$L__BB3_303;

	setp.eq.s32 	%p485, %r79, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r567, %temp}, %fd350;
	}
	setp.eq.s32 	%p486, %r567, 0;
	and.pred  	%p487, %p485, %p486;
	@%p487 bra 	$L__BB3_302;
	bra.uni 	$L__BB3_300;

$L__BB3_302:
	setp.lt.s32 	%p491, %r78, 0;
	mov.u32 	%r571, 0;
	setp.gt.f64 	%p492, %fd173, 0d3FF0000000000000;
	selp.b32 	%r572, 2146435072, 0, %p492;
	xor.b32  	%r573, %r572, 2146435072;
	selp.b32 	%r574, %r573, %r572, %p491;
	setp.eq.f32 	%p493, %f219, 0fBF800000;
	selp.b32 	%r575, 1072693248, %r574, %p493;
	mov.b64 	%fd621, {%r571, %r575};
	bra.uni 	$L__BB3_303;

$L__BB3_366:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r661, %temp}, %fd228;
	}
	and.b32  	%r662, %r94, 2147483647;
	setp.ne.s32 	%p585, %r662, 2146435072;
	setp.ne.s32 	%p586, %r661, 0;
	or.pred  	%p587, %p585, %p586;
	mov.f64 	%fd636, %fd635;
	@%p587 bra 	$L__BB3_369;

	setp.lt.s32 	%p588, %r94, 0;
	mov.u32 	%r663, 0;
	setp.ne.s32 	%p589, %r79, 1071644672;
	and.pred  	%p590, %p589, %p588;
	or.b32  	%r664, %r80, -2147483648;
	selp.b32 	%r665, %r664, %r80, %p590;
	mov.b64 	%fd636, {%r663, %r665};

$L__BB3_369:
	setp.eq.f32 	%p594, %f219, 0f3F800000;
	selp.f64 	%fd540, 0d3FF0000000000000, %fd636, %p594;
	mul.f64 	%fd541, %fd540, %fd129;
	mul.f32 	%f1498, %f226, %f220;
	cvt.f64.f32 	%fd542, %f1498;
	sub.f64 	%fd543, %fd542, %fd541;
	cvt.f64.f32 	%fd544, %f2999;
	add.f64 	%fd637, %fd543, %fd544;
	bra.uni 	$L__BB3_370;

$L__BB3_300:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r568, %temp}, %fd172;
	}
	and.b32  	%r569, %r90, 2147483647;
	setp.ne.s32 	%p488, %r569, 2146435072;
	setp.ne.s32 	%p489, %r568, 0;
	or.pred  	%p490, %p488, %p489;
	mov.f64 	%fd621, %fd620;
	@%p490 bra 	$L__BB3_303;

	mov.u32 	%r570, 0;
	mov.b64 	%fd621, {%r570, %r80};

$L__BB3_303:
	setp.eq.f32 	%p494, %f219, 0f3F800000;
	selp.f64 	%fd490, 0d3FF0000000000000, %fd621, %p494;
	mul.f64 	%fd491, %fd490, %fd129;
	mul.f32 	%f1494, %f226, %f220;
	cvt.f64.f32 	%fd492, %f1494;
	sub.f64 	%fd493, %fd492, %fd491;
	cvt.f64.f32 	%fd494, %f2999;
	add.f64 	%fd637, %fd493, %fd494;

$L__BB3_370:
	cvt.rn.f32.f64 	%f3004, %fd642;
	cvt.rn.f32.f64 	%f3003, %fd641;
	cvt.rn.f32.f64 	%f3002, %fd640;
	cvt.rn.f32.f64 	%f3001, %fd639;
	cvt.rn.f32.f64 	%f3000, %fd638;
	cvt.rn.f32.f64 	%f2999, %fd637;
	fma.rn.f32 	%f2997, %f226, %f177, %f2997;
	fma.rn.f32 	%f2996, %f226, %f221, %f2996;
	add.f32 	%f2995, %f2995, %f226;
	fma.rn.f32 	%f2994, %f226, %f191, %f2994;
	fma.rn.f32 	%f2993, %f226, %f219, %f2993;
	add.s32 	%r853, %r853, 1;
	setp.lt.s32 	%p595, %r853, %r108;
	@%p595 bra 	$L__BB3_56;

	add.s32 	%r852, %r852, 1;
	setp.lt.s32 	%p596, %r852, %r108;
	@%p596 bra 	$L__BB3_55;

$L__BB3_372:
	ld.param.u32 	%r830, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_3];
	div.rn.f32 	%f1499, %f2998, %f3004;
	mov.f32 	%f1500, 0fBF800000;
	max.f32 	%f1501, %f1499, %f1500;
	mov.f32 	%f1502, 0f3F800000;
	min.f32 	%f1503, %f1501, %f1502;
	sub.f32 	%f3048, %f3048, %f1503;
	div.rn.f32 	%f1504, %f2997, %f3003;
	max.f32 	%f1505, %f1504, %f1500;
	min.f32 	%f1506, %f1505, %f1502;
	sub.f32 	%f3047, %f3047, %f1506;
	neg.f32 	%f1507, %f3046;
	div.rn.f32 	%f1508, %f2996, %f3002;
	max.f32 	%f1509, %f1508, %f1507;
	min.f32 	%f1510, %f1509, %f3046;
	sub.f32 	%f1511, %f3046, %f1510;
	neg.f32 	%f1512, %f3045;
	div.rn.f32 	%f1513, %f2995, %f3001;
	max.f32 	%f1514, %f1513, %f1512;
	min.f32 	%f1515, %f1514, %f3045;
	sub.f32 	%f1516, %f3045, %f1515;
	neg.f32 	%f1517, %f3044;
	div.rn.f32 	%f1518, %f2994, %f3000;
	max.f32 	%f1519, %f1518, %f1517;
	min.f32 	%f1520, %f1519, %f3044;
	sub.f32 	%f1521, %f3044, %f1520;
	neg.f32 	%f1522, %f3043;
	div.rn.f32 	%f1523, %f2993, %f2999;
	max.f32 	%f1524, %f1523, %f1522;
	min.f32 	%f1525, %f1524, %f3043;
	sub.f32 	%f1526, %f3043, %f1525;
	max.f32 	%f3046, %f1511, %f1502;
	mov.f32 	%f1527, 0f3C23D70A;
	max.f32 	%f3045, %f1516, %f1527;
	mov.f32 	%f1528, 0f3F000000;
	max.f32 	%f1529, %f1521, %f1528;
	min.f32 	%f3044, %f1529, %f51;
	max.f32 	%f1530, %f1526, %f1528;
	min.f32 	%f3043, %f1530, %f51;
	add.s32 	%r851, %r851, 1;
	setp.lt.s32 	%p597, %r851, %r830;
	@%p597 bra 	$L__BB3_53;

$L__BB3_373:
	mov.f32 	%f1552, 0f00000000;
	mov.f32 	%f3071, %f1552;
	mov.f32 	%f3072, %f1552;
	mov.f32 	%f3073, %f1552;
	mov.f32 	%f3076, %f1552;
	mov.f32 	%f3080, %f1552;
	mov.f32 	%f3085, %f1552;
	mov.f32 	%f3074, %f1552;
	mov.f32 	%f3075, %f1552;
	mov.f32 	%f3077, %f1552;
	mov.f32 	%f3081, %f1552;
	mov.f32 	%f3086, %f1552;
	mov.f32 	%f3078, %f1552;
	mov.f32 	%f3079, %f1552;
	mov.f32 	%f3082, %f1552;
	mov.f32 	%f3087, %f1552;
	mov.f32 	%f3083, %f1552;
	mov.f32 	%f3084, %f1552;
	mov.f32 	%f3088, %f1552;
	mov.f32 	%f3089, %f1552;
	mov.f32 	%f3090, %f1552;
	mov.f32 	%f3091, %f1552;
	mov.f32 	%f3119, %f1552;
	@%p44 bra 	$L__BB3_462;

	mov.f32 	%f1575, 0f3F000000;
	div.rn.f32 	%f1576, %f1575, %f3044;
	div.rn.f32 	%f1577, %f1576, %f3044;
	div.rn.f32 	%f1578, %f1575, %f3043;
	div.rn.f32 	%f1579, %f1578, %f3043;
	div.rn.f32 	%f1580, %f3046, 0fC0206C98;
	div.rn.f32 	%f263, %f1580, %f3044;
	div.rn.f32 	%f264, %f1580, %f3043;
	div.rn.f32 	%f265, %f263, %f3044;
	div.rn.f32 	%f266, %f264, %f3043;
	sqrt.rn.f32 	%f267, %f1577;
	sqrt.rn.f32 	%f268, %f1579;
	mov.f32 	%f1581, 0f3F800000;
	cvt.rzi.f32.f32 	%f1582, %f1581;
	add.f32 	%f1583, %f1582, %f1582;
	mov.f32 	%f1584, 0f40000000;
	sub.f32 	%f1585, %f1584, %f1583;
	abs.f32 	%f269, %f1585;
	mov.u32 	%r671, 0;
	setp.eq.f32 	%p606, %f269, 0f3F800000;
	mov.u32 	%r854, %r671;

$L__BB3_375:
	cvt.rn.f32.s32 	%f1586, %r854;
	sub.f32 	%f292, %f1586, %f3048;
	add.f32 	%f1587, %f292, 0f3F000000;
	mul.f32 	%f1588, %f1587, %f267;
	abs.f32 	%f293, %f1588;
	setp.ge.f32 	%p599, %f293, 0f3F8060FE;
	mul.f32 	%f1589, %f1588, %f1588;
	selp.f32 	%f1590, %f293, %f1589, %p599;
	selp.f32 	%f1591, 0f3789CA3C, 0f38B1E96A, %p599;
	selp.f32 	%f1592, 0fB9F560B9, 0fBA574D20, %p599;
	fma.rn.f32 	%f1593, %f1591, %f1590, %f1592;
	selp.f32 	%f1594, 0f3BAC840B, 0f3BAAD5EA, %p599;
	fma.rn.f32 	%f1595, %f1593, %f1590, %f1594;
	selp.f32 	%f1596, 0fBD0C8162, 0fBCDC1BE7, %p599;
	fma.rn.f32 	%f1597, %f1595, %f1590, %f1596;
	selp.f32 	%f1598, 0f3E1CF906, 0f3DE718AF, %p599;
	fma.rn.f32 	%f1599, %f1597, %f1590, %f1598;
	selp.f32 	%f1600, 0f3F6A937E, 0fBEC093AC, %p599;
	fma.rn.f32 	%f1601, %f1599, %f1590, %f1600;
	selp.f32 	%f1602, 0f3F20D842, 0f3E0375D3, %p599;
	fma.rn.f32 	%f1603, %f1601, %f1590, %f1602;
	neg.f32 	%f1604, %f293;
	selp.f32 	%f1605, %f1604, %f1588, %p599;
	fma.rn.f32 	%f294, %f1603, %f1605, %f1605;
	mov.b32 	%r673, %f1588;
	and.b32  	%r99, %r673, -2147483648;
	add.f32 	%f1606, %f292, 0fBF000000;
	mul.f32 	%f1607, %f1606, %f267;
	abs.f32 	%f295, %f1607;
	setp.ge.f32 	%p600, %f295, 0f3F8060FE;
	mul.f32 	%f1608, %f1607, %f1607;
	selp.f32 	%f1609, %f295, %f1608, %p600;
	selp.f32 	%f1610, 0f3789CA3C, 0f38B1E96A, %p600;
	selp.f32 	%f1611, 0fB9F560B9, 0fBA574D20, %p600;
	fma.rn.f32 	%f1612, %f1610, %f1609, %f1611;
	selp.f32 	%f1613, 0f3BAC840B, 0f3BAAD5EA, %p600;
	fma.rn.f32 	%f1614, %f1612, %f1609, %f1613;
	selp.f32 	%f1615, 0fBD0C8162, 0fBCDC1BE7, %p600;
	fma.rn.f32 	%f1616, %f1614, %f1609, %f1615;
	selp.f32 	%f1617, 0f3E1CF906, 0f3DE718AF, %p600;
	fma.rn.f32 	%f1618, %f1616, %f1609, %f1617;
	selp.f32 	%f1619, 0f3F6A937E, 0fBEC093AC, %p600;
	fma.rn.f32 	%f1620, %f1618, %f1609, %f1619;
	selp.f32 	%f1621, 0f3F20D842, 0f3E0375D3, %p600;
	fma.rn.f32 	%f1622, %f1620, %f1609, %f1621;
	neg.f32 	%f1623, %f295;
	selp.f32 	%f1624, %f1623, %f1607, %p600;
	fma.rn.f32 	%f296, %f1622, %f1624, %f1624;
	mov.b32 	%r674, %f1607;
	and.b32  	%r100, %r674, -2147483648;
	add.f32 	%f1625, %f1586, 0f3F000000;
	sub.f32 	%f1626, %f1625, %f3048;
	div.rn.f32 	%f297, %f1626, %f3044;
	abs.f32 	%f298, %f297;
	setp.lt.f32 	%p601, %f298, 0f00800000;
	mul.f32 	%f1627, %f298, 0f4B800000;
	selp.f32 	%f1628, %f1627, %f298, %p601;
	selp.f32 	%f1629, 0fC3170000, 0fC2FE0000, %p601;
	mov.b32 	%r675, %f1628;
	and.b32  	%r676, %r675, 8388607;
	or.b32  	%r677, %r676, 1065353216;
	mov.b32 	%f1630, %r677;
	shr.u32 	%r678, %r675, 23;
	cvt.rn.f32.u32 	%f1631, %r678;
	add.f32 	%f1632, %f1629, %f1631;
	setp.gt.f32 	%p602, %f1630, 0f3FB504F3;
	mul.f32 	%f1633, %f1630, 0f3F000000;
	add.f32 	%f1634, %f1632, 0f3F800000;
	selp.f32 	%f1635, %f1634, %f1632, %p602;
	selp.f32 	%f1636, %f1633, %f1630, %p602;
	add.f32 	%f1637, %f1636, 0fBF800000;
	add.f32 	%f1638, %f1636, 0f3F800000;
	rcp.approx.ftz.f32 	%f1639, %f1638;
	add.f32 	%f1640, %f1637, %f1637;
	mul.f32 	%f1642, %f1640, %f1639;
	mul.f32 	%f1643, %f1642, %f1642;
	mov.f32 	%f1644, 0f3C4CAF63;
	mov.f32 	%f1645, 0f3B18F0FE;
	fma.rn.f32 	%f1646, %f1645, %f1643, %f1644;
	mov.f32 	%f1647, 0f3DAAAABD;
	fma.rn.f32 	%f1648, %f1646, %f1643, %f1647;
	mul.rn.f32 	%f1649, %f1648, %f1643;
	mul.rn.f32 	%f1650, %f1649, %f1642;
	sub.f32 	%f1651, %f1637, %f1642;
	add.f32 	%f1652, %f1651, %f1651;
	neg.f32 	%f1653, %f1642;
	fma.rn.f32 	%f1654, %f1653, %f1637, %f1652;
	mul.rn.f32 	%f1655, %f1639, %f1654;
	add.f32 	%f1656, %f1650, %f1642;
	sub.f32 	%f1657, %f1642, %f1656;
	add.f32 	%f1658, %f1650, %f1657;
	add.f32 	%f1659, %f1655, %f1658;
	add.f32 	%f1660, %f1656, %f1659;
	sub.f32 	%f1661, %f1656, %f1660;
	add.f32 	%f1662, %f1659, %f1661;
	mov.f32 	%f1663, 0f3F317200;
	mul.rn.f32 	%f1664, %f1635, %f1663;
	mov.f32 	%f1665, 0f35BFBE8E;
	mul.rn.f32 	%f1666, %f1635, %f1665;
	add.f32 	%f1667, %f1664, %f1660;
	sub.f32 	%f1668, %f1664, %f1667;
	add.f32 	%f1669, %f1660, %f1668;
	add.f32 	%f1670, %f1662, %f1669;
	add.f32 	%f1671, %f1666, %f1670;
	add.f32 	%f1672, %f1667, %f1671;
	sub.f32 	%f1673, %f1667, %f1672;
	add.f32 	%f1674, %f1671, %f1673;
	mul.rn.f32 	%f1675, %f1584, %f1672;
	neg.f32 	%f1676, %f1675;
	fma.rn.f32 	%f1677, %f1584, %f1672, %f1676;
	fma.rn.f32 	%f1678, %f1584, %f1674, %f1677;
	fma.rn.f32 	%f1680, %f1552, %f1672, %f1678;
	add.rn.f32 	%f1681, %f1675, %f1680;
	neg.f32 	%f1682, %f1681;
	add.rn.f32 	%f1683, %f1675, %f1682;
	add.rn.f32 	%f1684, %f1683, %f1680;
	mov.b32 	%r679, %f1681;
	setp.eq.s32 	%p603, %r679, 1118925336;
	add.s32 	%r680, %r679, -1;
	mov.b32 	%f1685, %r680;
	add.f32 	%f1686, %f1684, 0f37000000;
	selp.f32 	%f299, %f1686, %f1684, %p603;
	selp.f32 	%f1687, %f1685, %f1681, %p603;
	mov.f32 	%f1688, 0f3FB8AA3B;
	mul.rn.f32 	%f1689, %f1687, %f1688;
	cvt.rzi.f32.f32 	%f1690, %f1689;
	abs.f32 	%f1691, %f1690;
	setp.gt.f32 	%p604, %f1691, 0f42FC0000;
	mov.b32 	%r681, %f1690;
	and.b32  	%r682, %r681, -2147483648;
	or.b32  	%r683, %r682, 1123811328;
	mov.b32 	%f1692, %r683;
	selp.f32 	%f1693, %f1692, %f1690, %p604;
	mov.f32 	%f1694, 0fBF317218;
	fma.rn.f32 	%f1695, %f1693, %f1694, %f1687;
	mov.f32 	%f1696, 0f3102E308;
	fma.rn.f32 	%f1697, %f1693, %f1696, %f1695;
	mul.f32 	%f1698, %f1697, 0f3FB8AA3B;
	add.f32 	%f1699, %f1693, 0f4B40007F;
	mov.b32 	%r684, %f1699;
	shl.b32 	%r685, %r684, 23;
	mov.b32 	%f1700, %r685;
	ex2.approx.ftz.f32 	%f1701, %f1698;
	mul.f32 	%f300, %f1701, %f1700;
	setp.lt.f32 	%p605, %f297, 0f00000000;
	and.pred  	%p31, %p605, %p606;
	add.f32 	%f1702, %f297, %f297;
	selp.f32 	%f301, %f1702, 0f00000000, %p606;
	add.f32 	%f1703, %f298, 0f40000000;
	mov.b32 	%r101, %f1703;
	div.rn.f32 	%f302, %f1606, %f3044;
	abs.f32 	%f303, %f302;
	setp.lt.f32 	%p607, %f303, 0f00800000;
	mul.f32 	%f1704, %f303, 0f4B800000;
	selp.f32 	%f1705, %f1704, %f303, %p607;
	selp.f32 	%f1706, 0fC3170000, 0fC2FE0000, %p607;
	mov.b32 	%r686, %f1705;
	and.b32  	%r687, %r686, 8388607;
	or.b32  	%r688, %r687, 1065353216;
	mov.b32 	%f1707, %r688;
	shr.u32 	%r689, %r686, 23;
	cvt.rn.f32.u32 	%f1708, %r689;
	add.f32 	%f1709, %f1706, %f1708;
	setp.gt.f32 	%p608, %f1707, 0f3FB504F3;
	mul.f32 	%f1710, %f1707, 0f3F000000;
	add.f32 	%f1711, %f1709, 0f3F800000;
	selp.f32 	%f1712, %f1711, %f1709, %p608;
	selp.f32 	%f1713, %f1710, %f1707, %p608;
	add.f32 	%f1714, %f1713, 0fBF800000;
	add.f32 	%f1715, %f1713, 0f3F800000;
	rcp.approx.ftz.f32 	%f1716, %f1715;
	add.f32 	%f1717, %f1714, %f1714;
	mul.f32 	%f1718, %f1717, %f1716;
	mul.f32 	%f1719, %f1718, %f1718;
	fma.rn.f32 	%f1720, %f1645, %f1719, %f1644;
	fma.rn.f32 	%f1721, %f1720, %f1719, %f1647;
	mul.rn.f32 	%f1722, %f1721, %f1719;
	mul.rn.f32 	%f1723, %f1722, %f1718;
	sub.f32 	%f1724, %f1714, %f1718;
	add.f32 	%f1725, %f1724, %f1724;
	neg.f32 	%f1726, %f1718;
	fma.rn.f32 	%f1727, %f1726, %f1714, %f1725;
	mul.rn.f32 	%f1728, %f1716, %f1727;
	add.f32 	%f1729, %f1723, %f1718;
	sub.f32 	%f1730, %f1718, %f1729;
	add.f32 	%f1731, %f1723, %f1730;
	add.f32 	%f1732, %f1728, %f1731;
	add.f32 	%f1733, %f1729, %f1732;
	sub.f32 	%f1734, %f1729, %f1733;
	add.f32 	%f1735, %f1732, %f1734;
	mul.rn.f32 	%f1736, %f1712, %f1663;
	mul.rn.f32 	%f1737, %f1712, %f1665;
	add.f32 	%f1738, %f1736, %f1733;
	sub.f32 	%f1739, %f1736, %f1738;
	add.f32 	%f1740, %f1733, %f1739;
	add.f32 	%f1741, %f1735, %f1740;
	add.f32 	%f1742, %f1737, %f1741;
	add.f32 	%f1743, %f1738, %f1742;
	sub.f32 	%f1744, %f1738, %f1743;
	add.f32 	%f1745, %f1742, %f1744;
	mul.rn.f32 	%f1746, %f1584, %f1743;
	neg.f32 	%f1747, %f1746;
	fma.rn.f32 	%f1748, %f1584, %f1743, %f1747;
	fma.rn.f32 	%f1749, %f1584, %f1745, %f1748;
	fma.rn.f32 	%f1750, %f1552, %f1743, %f1749;
	add.rn.f32 	%f1751, %f1746, %f1750;
	neg.f32 	%f1752, %f1751;
	add.rn.f32 	%f1753, %f1746, %f1752;
	add.rn.f32 	%f1754, %f1753, %f1750;
	mov.b32 	%r690, %f1751;
	setp.eq.s32 	%p609, %r690, 1118925336;
	add.s32 	%r691, %r690, -1;
	mov.b32 	%f1755, %r691;
	add.f32 	%f1756, %f1754, 0f37000000;
	selp.f32 	%f304, %f1756, %f1754, %p609;
	selp.f32 	%f1757, %f1755, %f1751, %p609;
	mul.rn.f32 	%f1758, %f1757, %f1688;
	cvt.rzi.f32.f32 	%f1759, %f1758;
	abs.f32 	%f1760, %f1759;
	setp.gt.f32 	%p610, %f1760, 0f42FC0000;
	mov.b32 	%r692, %f1759;
	and.b32  	%r693, %r692, -2147483648;
	or.b32  	%r694, %r693, 1123811328;
	mov.b32 	%f1761, %r694;
	selp.f32 	%f1762, %f1761, %f1759, %p610;
	fma.rn.f32 	%f1763, %f1762, %f1694, %f1757;
	fma.rn.f32 	%f1764, %f1762, %f1696, %f1763;
	mul.f32 	%f1765, %f1764, 0f3FB8AA3B;
	add.f32 	%f1766, %f1762, 0f4B40007F;
	mov.b32 	%r695, %f1766;
	shl.b32 	%r696, %r695, 23;
	mov.b32 	%f1767, %r696;
	ex2.approx.ftz.f32 	%f1768, %f1765;
	mul.f32 	%f305, %f1768, %f1767;
	add.f32 	%f306, %f297, 0f40000000;
	setp.lt.f32 	%p611, %f302, 0f00000000;
	and.pred  	%p32, %p611, %p606;
	selp.f32 	%f307, 0fFF800000, 0f7F800000, %p31;
	add.f32 	%f1769, %f302, %f302;
	selp.f32 	%f308, %f1769, 0f00000000, %p606;
	add.f32 	%f1770, %f303, 0f40000000;
	mov.b32 	%r102, %f1770;
	add.f32 	%f309, %f302, 0f40000000;
	selp.f32 	%f310, 0fFF800000, 0f7F800000, %p32;
	add.f32 	%f1771, %f1586, 0f3F800000;
	sub.f32 	%f1772, %f1771, %f3048;
	div.rn.f32 	%f311, %f1772, %f3044;
	abs.f32 	%f312, %f311;
	setp.lt.f32 	%p612, %f312, 0f00800000;
	mul.f32 	%f1773, %f312, 0f4B800000;
	selp.f32 	%f1774, %f1773, %f312, %p612;
	selp.f32 	%f1775, 0fC3170000, 0fC2FE0000, %p612;
	mov.b32 	%r697, %f1774;
	and.b32  	%r698, %r697, 8388607;
	or.b32  	%r699, %r698, 1065353216;
	mov.b32 	%f1776, %r699;
	shr.u32 	%r700, %r697, 23;
	cvt.rn.f32.u32 	%f1777, %r700;
	add.f32 	%f1778, %f1775, %f1777;
	setp.gt.f32 	%p613, %f1776, 0f3FB504F3;
	mul.f32 	%f1779, %f1776, 0f3F000000;
	add.f32 	%f1780, %f1778, 0f3F800000;
	selp.f32 	%f1781, %f1780, %f1778, %p613;
	selp.f32 	%f1782, %f1779, %f1776, %p613;
	add.f32 	%f1783, %f1782, 0fBF800000;
	add.f32 	%f1784, %f1782, 0f3F800000;
	rcp.approx.ftz.f32 	%f1785, %f1784;
	add.f32 	%f1786, %f1783, %f1783;
	mul.f32 	%f1787, %f1786, %f1785;
	mul.f32 	%f1788, %f1787, %f1787;
	fma.rn.f32 	%f1789, %f1645, %f1788, %f1644;
	fma.rn.f32 	%f1790, %f1789, %f1788, %f1647;
	mul.rn.f32 	%f1791, %f1790, %f1788;
	mul.rn.f32 	%f1792, %f1791, %f1787;
	sub.f32 	%f1793, %f1783, %f1787;
	add.f32 	%f1794, %f1793, %f1793;
	neg.f32 	%f1795, %f1787;
	fma.rn.f32 	%f1796, %f1795, %f1783, %f1794;
	mul.rn.f32 	%f1797, %f1785, %f1796;
	add.f32 	%f1798, %f1792, %f1787;
	sub.f32 	%f1799, %f1787, %f1798;
	add.f32 	%f1800, %f1792, %f1799;
	add.f32 	%f1801, %f1797, %f1800;
	add.f32 	%f1802, %f1798, %f1801;
	sub.f32 	%f1803, %f1798, %f1802;
	add.f32 	%f1804, %f1801, %f1803;
	mul.rn.f32 	%f1805, %f1781, %f1663;
	mul.rn.f32 	%f1806, %f1781, %f1665;
	add.f32 	%f1807, %f1805, %f1802;
	sub.f32 	%f1808, %f1805, %f1807;
	add.f32 	%f1809, %f1802, %f1808;
	add.f32 	%f1810, %f1804, %f1809;
	add.f32 	%f1811, %f1806, %f1810;
	add.f32 	%f1812, %f1807, %f1811;
	sub.f32 	%f1813, %f1807, %f1812;
	add.f32 	%f1814, %f1811, %f1813;
	mul.rn.f32 	%f1815, %f1584, %f1812;
	neg.f32 	%f1816, %f1815;
	fma.rn.f32 	%f1817, %f1584, %f1812, %f1816;
	fma.rn.f32 	%f1818, %f1584, %f1814, %f1817;
	fma.rn.f32 	%f1819, %f1552, %f1812, %f1818;
	add.rn.f32 	%f1820, %f1815, %f1819;
	neg.f32 	%f1821, %f1820;
	add.rn.f32 	%f1822, %f1815, %f1821;
	add.rn.f32 	%f1823, %f1822, %f1819;
	mov.b32 	%r701, %f1820;
	setp.eq.s32 	%p614, %r701, 1118925336;
	add.s32 	%r702, %r701, -1;
	mov.b32 	%f1824, %r702;
	add.f32 	%f1825, %f1823, 0f37000000;
	selp.f32 	%f313, %f1825, %f1823, %p614;
	selp.f32 	%f1826, %f1824, %f1820, %p614;
	mul.rn.f32 	%f1827, %f1826, %f1688;
	cvt.rzi.f32.f32 	%f1828, %f1827;
	abs.f32 	%f1829, %f1828;
	setp.gt.f32 	%p615, %f1829, 0f42FC0000;
	mov.b32 	%r703, %f1828;
	and.b32  	%r704, %r703, -2147483648;
	or.b32  	%r705, %r704, 1123811328;
	mov.b32 	%f1830, %r705;
	selp.f32 	%f1831, %f1830, %f1828, %p615;
	fma.rn.f32 	%f1832, %f1831, %f1694, %f1826;
	fma.rn.f32 	%f1833, %f1831, %f1696, %f1832;
	mul.f32 	%f1834, %f1833, 0f3FB8AA3B;
	add.f32 	%f1835, %f1831, 0f4B40007F;
	mov.b32 	%r706, %f1835;
	shl.b32 	%r707, %r706, 23;
	mov.b32 	%f1836, %r707;
	ex2.approx.ftz.f32 	%f1837, %f1834;
	mul.f32 	%f314, %f1837, %f1836;
	setp.lt.f32 	%p616, %f311, 0f00000000;
	and.pred  	%p33, %p616, %p606;
	add.f32 	%f1838, %f311, %f311;
	selp.f32 	%f315, %f1838, 0f00000000, %p606;
	add.f32 	%f1839, %f312, 0f40000000;
	mov.b32 	%r103, %f1839;
	div.rn.f32 	%f316, %f292, %f3044;
	abs.f32 	%f317, %f316;
	setp.lt.f32 	%p617, %f317, 0f00800000;
	mul.f32 	%f1840, %f317, 0f4B800000;
	selp.f32 	%f1841, %f1840, %f317, %p617;
	selp.f32 	%f1842, 0fC3170000, 0fC2FE0000, %p617;
	mov.b32 	%r708, %f1841;
	and.b32  	%r709, %r708, 8388607;
	or.b32  	%r710, %r709, 1065353216;
	mov.b32 	%f1843, %r710;
	shr.u32 	%r711, %r708, 23;
	cvt.rn.f32.u32 	%f1844, %r711;
	add.f32 	%f1845, %f1842, %f1844;
	setp.gt.f32 	%p618, %f1843, 0f3FB504F3;
	mul.f32 	%f1846, %f1843, 0f3F000000;
	add.f32 	%f1847, %f1845, 0f3F800000;
	selp.f32 	%f1848, %f1847, %f1845, %p618;
	selp.f32 	%f1849, %f1846, %f1843, %p618;
	add.f32 	%f1850, %f1849, 0fBF800000;
	add.f32 	%f1851, %f1849, 0f3F800000;
	rcp.approx.ftz.f32 	%f1852, %f1851;
	add.f32 	%f1853, %f1850, %f1850;
	mul.f32 	%f1854, %f1853, %f1852;
	mul.f32 	%f1855, %f1854, %f1854;
	fma.rn.f32 	%f1856, %f1645, %f1855, %f1644;
	fma.rn.f32 	%f1857, %f1856, %f1855, %f1647;
	mul.rn.f32 	%f1858, %f1857, %f1855;
	mul.rn.f32 	%f1859, %f1858, %f1854;
	sub.f32 	%f1860, %f1850, %f1854;
	add.f32 	%f1861, %f1860, %f1860;
	neg.f32 	%f1862, %f1854;
	fma.rn.f32 	%f1863, %f1862, %f1850, %f1861;
	mul.rn.f32 	%f1864, %f1852, %f1863;
	add.f32 	%f1865, %f1859, %f1854;
	sub.f32 	%f1866, %f1854, %f1865;
	add.f32 	%f1867, %f1859, %f1866;
	add.f32 	%f1868, %f1864, %f1867;
	add.f32 	%f1869, %f1865, %f1868;
	sub.f32 	%f1870, %f1865, %f1869;
	add.f32 	%f1871, %f1868, %f1870;
	mul.rn.f32 	%f1872, %f1848, %f1663;
	mul.rn.f32 	%f1873, %f1848, %f1665;
	add.f32 	%f1874, %f1872, %f1869;
	sub.f32 	%f1875, %f1872, %f1874;
	add.f32 	%f1876, %f1869, %f1875;
	add.f32 	%f1877, %f1871, %f1876;
	add.f32 	%f1878, %f1873, %f1877;
	add.f32 	%f1879, %f1874, %f1878;
	sub.f32 	%f1880, %f1874, %f1879;
	add.f32 	%f1881, %f1878, %f1880;
	mul.rn.f32 	%f1882, %f1584, %f1879;
	neg.f32 	%f1883, %f1882;
	fma.rn.f32 	%f1884, %f1584, %f1879, %f1883;
	fma.rn.f32 	%f1885, %f1584, %f1881, %f1884;
	fma.rn.f32 	%f1886, %f1552, %f1879, %f1885;
	add.rn.f32 	%f1887, %f1882, %f1886;
	neg.f32 	%f1888, %f1887;
	add.rn.f32 	%f1889, %f1882, %f1888;
	add.rn.f32 	%f1890, %f1889, %f1886;
	mov.b32 	%r712, %f1887;
	setp.eq.s32 	%p619, %r712, 1118925336;
	add.s32 	%r713, %r712, -1;
	mov.b32 	%f1891, %r713;
	add.f32 	%f1892, %f1890, 0f37000000;
	selp.f32 	%f318, %f1892, %f1890, %p619;
	selp.f32 	%f1893, %f1891, %f1887, %p619;
	mul.rn.f32 	%f1894, %f1893, %f1688;
	cvt.rzi.f32.f32 	%f1895, %f1894;
	abs.f32 	%f1896, %f1895;
	setp.gt.f32 	%p620, %f1896, 0f42FC0000;
	mov.b32 	%r714, %f1895;
	and.b32  	%r715, %r714, -2147483648;
	or.b32  	%r716, %r715, 1123811328;
	mov.b32 	%f1897, %r716;
	selp.f32 	%f1898, %f1897, %f1895, %p620;
	fma.rn.f32 	%f1899, %f1898, %f1694, %f1893;
	fma.rn.f32 	%f1900, %f1898, %f1696, %f1899;
	mul.f32 	%f1901, %f1900, 0f3FB8AA3B;
	add.f32 	%f1902, %f1898, 0f4B40007F;
	mov.b32 	%r717, %f1902;
	shl.b32 	%r718, %r717, 23;
	mov.b32 	%f1903, %r718;
	ex2.approx.ftz.f32 	%f1904, %f1901;
	mul.f32 	%f319, %f1904, %f1903;
	add.f32 	%f320, %f311, 0f40000000;
	setp.lt.f32 	%p621, %f316, 0f00000000;
	and.pred  	%p34, %p621, %p606;
	selp.f32 	%f321, 0fFF800000, 0f7F800000, %p33;
	add.f32 	%f1905, %f316, %f316;
	selp.f32 	%f322, %f1905, 0f00000000, %p606;
	add.f32 	%f1906, %f317, 0f40000000;
	mov.b32 	%r104, %f1906;
	add.f32 	%f323, %f292, 0f3F800000;
	add.f32 	%f324, %f316, 0f40000000;
	selp.f32 	%f325, 0fFF800000, 0f7F800000, %p34;
	setp.geu.f32 	%p35, %f297, 0f00000000;
	setp.geu.f32 	%p36, %f302, 0f00000000;
	setp.geu.f32 	%p37, %f311, 0f00000000;
	setp.geu.f32 	%p38, %f316, 0f00000000;
	mov.u32 	%r855, %r671;

$L__BB3_376:
	setp.ltu.f32 	%p622, %f293, 0f3F8060FE;
	mov.f32 	%f3093, %f294;
	@%p622 bra 	$L__BB3_378;

	ex2.approx.ftz.f32 	%f1907, %f294;
	sub.f32 	%f1909, %f1581, %f1907;
	mov.b32 	%r719, %f1909;
	or.b32  	%r720, %r99, %r719;
	mov.b32 	%f3093, %r720;

$L__BB3_378:
	setp.ltu.f32 	%p623, %f295, 0f3F8060FE;
	mov.f32 	%f3094, %f296;
	@%p623 bra 	$L__BB3_380;

	ex2.approx.ftz.f32 	%f1910, %f296;
	sub.f32 	%f1912, %f1581, %f1910;
	mov.b32 	%r721, %f1912;
	or.b32  	%r722, %r100, %r721;
	mov.b32 	%f3094, %r722;

$L__BB3_380:
	sub.f32 	%f1913, %f3093, %f3094;
	mul.f32 	%f352, %f1913, 0f3F000000;
	cvt.rn.f32.s32 	%f353, %r855;
	sub.f32 	%f354, %f353, %f3047;
	add.f32 	%f1914, %f354, 0f3F000000;
	mul.f32 	%f355, %f1914, %f268;
	abs.f32 	%f1915, %f355;
	setp.ltu.f32 	%p624, %f1915, 0f3F8060FE;
	setp.ge.f32 	%p625, %f1915, 0f3F8060FE;
	mul.f32 	%f1916, %f355, %f355;
	selp.f32 	%f1917, %f1915, %f1916, %p625;
	selp.f32 	%f1918, 0f3789CA3C, 0f38B1E96A, %p625;
	selp.f32 	%f1919, 0fB9F560B9, 0fBA574D20, %p625;
	fma.rn.f32 	%f1920, %f1918, %f1917, %f1919;
	selp.f32 	%f1921, 0f3BAC840B, 0f3BAAD5EA, %p625;
	fma.rn.f32 	%f1922, %f1920, %f1917, %f1921;
	selp.f32 	%f1923, 0fBD0C8162, 0fBCDC1BE7, %p625;
	fma.rn.f32 	%f1924, %f1922, %f1917, %f1923;
	selp.f32 	%f1925, 0f3E1CF906, 0f3DE718AF, %p625;
	fma.rn.f32 	%f1926, %f1924, %f1917, %f1925;
	selp.f32 	%f1927, 0f3F6A937E, 0fBEC093AC, %p625;
	fma.rn.f32 	%f1928, %f1926, %f1917, %f1927;
	selp.f32 	%f1929, 0f3F20D842, 0f3E0375D3, %p625;
	fma.rn.f32 	%f1930, %f1928, %f1917, %f1929;
	neg.f32 	%f1931, %f1915;
	selp.f32 	%f1932, %f1931, %f355, %p625;
	fma.rn.f32 	%f3095, %f1930, %f1932, %f1932;
	@%p624 bra 	$L__BB3_382;

	ex2.approx.ftz.f32 	%f1933, %f3095;
	sub.f32 	%f1935, %f1581, %f1933;
	mov.b32 	%r723, %f1935;
	mov.b32 	%r724, %f355;
	and.b32  	%r725, %r724, -2147483648;
	or.b32  	%r726, %r725, %r723;
	mov.b32 	%f3095, %r726;

$L__BB3_382:
	add.f32 	%f359, %f354, 0fBF000000;
	mul.f32 	%f360, %f359, %f268;
	abs.f32 	%f1936, %f360;
	setp.ltu.f32 	%p626, %f1936, 0f3F8060FE;
	setp.ge.f32 	%p627, %f1936, 0f3F8060FE;
	mul.f32 	%f1937, %f360, %f360;
	selp.f32 	%f1938, %f1936, %f1937, %p627;
	selp.f32 	%f1939, 0f3789CA3C, 0f38B1E96A, %p627;
	selp.f32 	%f1940, 0fB9F560B9, 0fBA574D20, %p627;
	fma.rn.f32 	%f1941, %f1939, %f1938, %f1940;
	selp.f32 	%f1942, 0f3BAC840B, 0f3BAAD5EA, %p627;
	fma.rn.f32 	%f1943, %f1941, %f1938, %f1942;
	selp.f32 	%f1944, 0fBD0C8162, 0fBCDC1BE7, %p627;
	fma.rn.f32 	%f1945, %f1943, %f1938, %f1944;
	selp.f32 	%f1946, 0f3E1CF906, 0f3DE718AF, %p627;
	fma.rn.f32 	%f1947, %f1945, %f1938, %f1946;
	selp.f32 	%f1948, 0f3F6A937E, 0fBEC093AC, %p627;
	fma.rn.f32 	%f1949, %f1947, %f1938, %f1948;
	selp.f32 	%f1950, 0f3F20D842, 0f3E0375D3, %p627;
	fma.rn.f32 	%f1951, %f1949, %f1938, %f1950;
	neg.f32 	%f1952, %f1936;
	selp.f32 	%f1953, %f1952, %f360, %p627;
	fma.rn.f32 	%f3096, %f1951, %f1953, %f1953;
	@%p626 bra 	$L__BB3_384;

	ex2.approx.ftz.f32 	%f1954, %f3096;
	sub.f32 	%f1956, %f1581, %f1954;
	mov.b32 	%r727, %f1956;
	mov.b32 	%r728, %f360;
	and.b32  	%r729, %r728, -2147483648;
	or.b32  	%r730, %r729, %r727;
	mov.b32 	%f3096, %r730;

$L__BB3_384:
	sub.f32 	%f1958, %f3095, %f3096;
	mul.f32 	%f364, %f1958, 0f3F000000;
	mul.f32 	%f1959, %f352, %f3046;
	fma.rn.f32 	%f365, %f364, %f1959, %f3045;
	mad.lo.s32 	%r731, %r855, %r108, %r854;
	add.s32 	%r732, %r731, %r2;
	mul.wide.s32 	%rd28, %r732, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.f32 	%f366, [%rd29];
	setp.eq.f32 	%p628, %f300, 0f7F800000;
	mov.f32 	%f3097, 0f7F800000;
	@%p628 bra 	$L__BB3_386;

	fma.rn.f32 	%f3097, %f300, %f299, %f300;

$L__BB3_386:
	mov.b32 	%r733, %f3097;
	xor.b32  	%r734, %r733, -2147483648;
	mov.b32 	%f1960, %r734;
	selp.f32 	%f369, %f1960, %f3097, %p31;
	setp.eq.f32 	%p629, %f297, 0f00000000;
	selp.f32 	%f3098, %f301, %f369, %p629;
	@%p35 bra 	$L__BB3_389;

	cvt.rzi.f32.f32 	%f1962, %f1584;
	setp.eq.f32 	%p630, %f1962, 0f40000000;
	mov.f32 	%f3098, %f369;
	@%p630 bra 	$L__BB3_389;

	mov.f32 	%f3098, 0f7FFFFFFF;

$L__BB3_389:
	setp.eq.f32 	%p631, %f305, 0f7F800000;
	mov.f32 	%f3099, 0f7F800000;
	@%p631 bra 	$L__BB3_391;

	fma.rn.f32 	%f3099, %f305, %f304, %f305;

$L__BB3_391:
	mov.b32 	%r735, %f3099;
	xor.b32  	%r736, %r735, -2147483648;
	mov.b32 	%f1965, %r736;
	selp.f32 	%f374, %f1965, %f3099, %p32;
	setp.eq.f32 	%p632, %f302, 0f00000000;
	selp.f32 	%f3100, %f308, %f374, %p632;
	@%p36 bra 	$L__BB3_394;

	cvt.rzi.f32.f32 	%f1967, %f1584;
	setp.eq.f32 	%p633, %f1967, 0f40000000;
	mov.f32 	%f3100, %f374;
	@%p633 bra 	$L__BB3_394;

	mov.f32 	%f3100, 0f7FFFFFFF;

$L__BB3_394:
	setp.gtu.f32 	%p634, %f298, 0f7F800000;
	mov.f32 	%f3101, 0f7F800000;
	selp.f32 	%f1970, %f306, %f3098, %p634;
	setp.neu.f32 	%p635, %f298, 0f7F800000;
	selp.f32 	%f1971, %f1970, %f307, %p635;
	setp.gt.s32 	%p636, %r101, 2139095039;
	selp.f32 	%f1972, %f1971, %f3098, %p636;
	mul.f32 	%f1973, %f1972, 0fBF000000;
	setp.eq.f32 	%p637, %f297, 0f3F800000;
	selp.f32 	%f1974, 0fBF000000, %f1973, %p637;
	mov.f32 	%f1976, 0f3BBB989D;
	fma.rn.f32 	%f1977, %f1974, %f1976, %f1575;
	mov.f32 	%f1979, 0f437C0000;
	cvt.sat.f32.f32 	%f1980, %f1977;
	mov.f32 	%f1981, 0f4B400001;
	fma.rm.f32 	%f1982, %f1980, %f1979, %f1981;
	setp.gtu.f32 	%p638, %f303, 0f7F800000;
	selp.f32 	%f1983, %f309, %f3100, %p638;
	setp.neu.f32 	%p639, %f303, 0f7F800000;
	selp.f32 	%f1984, %f1983, %f310, %p639;
	setp.gt.s32 	%p640, %r102, 2139095039;
	selp.f32 	%f1985, %f1984, %f3100, %p640;
	mul.f32 	%f1986, %f1985, 0fBF000000;
	setp.eq.f32 	%p641, %f302, 0f3F800000;
	selp.f32 	%f1987, 0fBF000000, %f1986, %p641;
	fma.rn.f32 	%f1988, %f1987, %f1976, %f1575;
	cvt.sat.f32.f32 	%f1989, %f1988;
	fma.rm.f32 	%f1990, %f1989, %f1979, %f1981;
	add.f32 	%f1991, %f1990, 0fCB40007F;
	neg.f32 	%f1992, %f1991;
	fma.rn.f32 	%f1993, %f1987, %f1688, %f1992;
	mov.f32 	%f1994, 0f32A57060;
	fma.rn.f32 	%f1995, %f1987, %f1994, %f1993;
	mov.b32 	%r737, %f1990;
	shl.b32 	%r738, %r737, 23;
	mov.b32 	%f1996, %r738;
	ex2.approx.ftz.f32 	%f1997, %f1995;
	mul.f32 	%f1998, %f1997, %f1996;
	mov.b32 	%r739, %f1982;
	shl.b32 	%r740, %r739, 23;
	mov.b32 	%f1999, %r740;
	add.f32 	%f2000, %f1982, 0fCB40007F;
	neg.f32 	%f2001, %f2000;
	fma.rn.f32 	%f2002, %f1974, %f1688, %f2001;
	fma.rn.f32 	%f2003, %f1974, %f1994, %f2002;
	ex2.approx.ftz.f32 	%f2004, %f2003;
	mul.f32 	%f2005, %f2004, %f1999;
	sub.f32 	%f2006, %f2005, %f1998;
	mul.f32 	%f2007, %f263, %f2006;
	mul.f32 	%f377, %f364, %f2007;
	add.f32 	%f2008, %f353, 0f3F000000;
	sub.f32 	%f2009, %f2008, %f3047;
	div.rn.f32 	%f378, %f2009, %f3043;
	abs.f32 	%f379, %f378;
	setp.lt.f32 	%p642, %f379, 0f00800000;
	mul.f32 	%f2010, %f379, 0f4B800000;
	selp.f32 	%f2011, %f2010, %f379, %p642;
	selp.f32 	%f2012, 0fC3170000, 0fC2FE0000, %p642;
	mov.b32 	%r741, %f2011;
	and.b32  	%r742, %r741, 8388607;
	or.b32  	%r743, %r742, 1065353216;
	mov.b32 	%f2013, %r743;
	shr.u32 	%r744, %r741, 23;
	cvt.rn.f32.u32 	%f2014, %r744;
	add.f32 	%f2015, %f2012, %f2014;
	setp.gt.f32 	%p643, %f2013, 0f3FB504F3;
	mul.f32 	%f2016, %f2013, 0f3F000000;
	add.f32 	%f2017, %f2015, 0f3F800000;
	selp.f32 	%f2018, %f2017, %f2015, %p643;
	selp.f32 	%f2019, %f2016, %f2013, %p643;
	add.f32 	%f2020, %f2019, 0fBF800000;
	add.f32 	%f2021, %f2019, 0f3F800000;
	rcp.approx.ftz.f32 	%f2022, %f2021;
	add.f32 	%f2023, %f2020, %f2020;
	mul.f32 	%f2025, %f2023, %f2022;
	mul.f32 	%f2026, %f2025, %f2025;
	fma.rn.f32 	%f2029, %f1645, %f2026, %f1644;
	fma.rn.f32 	%f2031, %f2029, %f2026, %f1647;
	mul.rn.f32 	%f2032, %f2031, %f2026;
	mul.rn.f32 	%f2033, %f2032, %f2025;
	sub.f32 	%f2034, %f2020, %f2025;
	add.f32 	%f2035, %f2034, %f2034;
	neg.f32 	%f2036, %f2025;
	fma.rn.f32 	%f2037, %f2036, %f2020, %f2035;
	mul.rn.f32 	%f2038, %f2022, %f2037;
	add.f32 	%f2039, %f2033, %f2025;
	sub.f32 	%f2040, %f2025, %f2039;
	add.f32 	%f2041, %f2033, %f2040;
	add.f32 	%f2042, %f2038, %f2041;
	add.f32 	%f2043, %f2039, %f2042;
	sub.f32 	%f2044, %f2039, %f2043;
	add.f32 	%f2045, %f2042, %f2044;
	mul.rn.f32 	%f2047, %f2018, %f1663;
	mul.rn.f32 	%f2049, %f2018, %f1665;
	add.f32 	%f2050, %f2047, %f2043;
	sub.f32 	%f2051, %f2047, %f2050;
	add.f32 	%f2052, %f2043, %f2051;
	add.f32 	%f2053, %f2045, %f2052;
	add.f32 	%f2054, %f2049, %f2053;
	add.f32 	%f2055, %f2050, %f2054;
	sub.f32 	%f2056, %f2050, %f2055;
	add.f32 	%f2057, %f2054, %f2056;
	mul.rn.f32 	%f2058, %f1584, %f2055;
	neg.f32 	%f2059, %f2058;
	fma.rn.f32 	%f2060, %f1584, %f2055, %f2059;
	fma.rn.f32 	%f2061, %f1584, %f2057, %f2060;
	mov.f32 	%f2062, 0f00000000;
	fma.rn.f32 	%f2063, %f2062, %f2055, %f2061;
	add.rn.f32 	%f2064, %f2058, %f2063;
	neg.f32 	%f2065, %f2064;
	add.rn.f32 	%f2066, %f2058, %f2065;
	add.rn.f32 	%f2067, %f2066, %f2063;
	mov.b32 	%r745, %f2064;
	setp.eq.s32 	%p644, %r745, 1118925336;
	add.s32 	%r746, %r745, -1;
	mov.b32 	%f2068, %r746;
	add.f32 	%f2069, %f2067, 0f37000000;
	selp.f32 	%f380, %f2069, %f2067, %p644;
	selp.f32 	%f2070, %f2068, %f2064, %p644;
	mul.rn.f32 	%f2071, %f2070, %f1688;
	cvt.rzi.f32.f32 	%f2072, %f2071;
	abs.f32 	%f2073, %f2072;
	setp.gt.f32 	%p645, %f2073, 0f42FC0000;
	mov.b32 	%r747, %f2072;
	and.b32  	%r748, %r747, -2147483648;
	or.b32  	%r749, %r748, 1123811328;
	mov.b32 	%f2074, %r749;
	selp.f32 	%f2075, %f2074, %f2072, %p645;
	fma.rn.f32 	%f2077, %f2075, %f1694, %f2070;
	fma.rn.f32 	%f2079, %f2075, %f1696, %f2077;
	mul.f32 	%f2080, %f2079, 0f3FB8AA3B;
	add.f32 	%f2081, %f2075, 0f4B40007F;
	mov.b32 	%r750, %f2081;
	shl.b32 	%r751, %r750, 23;
	mov.b32 	%f2082, %r751;
	ex2.approx.ftz.f32 	%f2083, %f2080;
	mul.f32 	%f381, %f2083, %f2082;
	setp.eq.f32 	%p646, %f381, 0f7F800000;
	@%p646 bra 	$L__BB3_396;

	fma.rn.f32 	%f3101, %f381, %f380, %f381;

$L__BB3_396:
	setp.lt.f32 	%p647, %f378, 0f00000000;
	and.pred  	%p39, %p647, %p606;
	setp.eq.f32 	%p649, %f378, 0f00000000;
	@%p649 bra 	$L__BB3_400;
	bra.uni 	$L__BB3_397;

$L__BB3_400:
	add.f32 	%f2088, %f378, %f378;
	selp.f32 	%f3103, %f2088, 0f00000000, %p606;
	bra.uni 	$L__BB3_401;

$L__BB3_397:
	mov.b32 	%r752, %f3101;
	xor.b32  	%r753, %r752, -2147483648;
	mov.b32 	%f2084, %r753;
	selp.f32 	%f3103, %f2084, %f3101, %p39;
	setp.geu.f32 	%p650, %f378, 0f00000000;
	@%p650 bra 	$L__BB3_401;

	cvt.rzi.f32.f32 	%f2086, %f1584;
	setp.eq.f32 	%p651, %f2086, 0f40000000;
	@%p651 bra 	$L__BB3_401;

	mov.f32 	%f3103, 0f7FFFFFFF;

$L__BB3_401:
	add.f32 	%f2089, %f379, 0f40000000;
	mov.b32 	%r754, %f2089;
	setp.lt.s32 	%p653, %r754, 2139095040;
	@%p653 bra 	$L__BB3_406;

	setp.gtu.f32 	%p654, %f379, 0f7F800000;
	@%p654 bra 	$L__BB3_405;
	bra.uni 	$L__BB3_403;

$L__BB3_405:
	add.f32 	%f3103, %f378, 0f40000000;
	bra.uni 	$L__BB3_406;

$L__BB3_403:
	setp.neu.f32 	%p655, %f379, 0f7F800000;
	@%p655 bra 	$L__BB3_406;

	selp.f32 	%f3103, 0fFF800000, 0f7F800000, %p39;

$L__BB3_406:
	mul.f32 	%f2091, %f3103, 0fBF000000;
	setp.eq.f32 	%p656, %f378, 0f3F800000;
	selp.f32 	%f2092, 0fBF000000, %f2091, %p656;
	fma.rn.f32 	%f2095, %f2092, %f1976, %f1575;
	cvt.sat.f32.f32 	%f2098, %f2095;
	fma.rm.f32 	%f2100, %f2098, %f1979, %f1981;
	add.f32 	%f2101, %f2100, 0fCB40007F;
	neg.f32 	%f2102, %f2101;
	fma.rn.f32 	%f2103, %f2092, %f1688, %f2102;
	fma.rn.f32 	%f2105, %f2092, %f1994, %f2103;
	mov.b32 	%r755, %f2100;
	shl.b32 	%r756, %r755, 23;
	mov.b32 	%f2106, %r756;
	ex2.approx.ftz.f32 	%f2107, %f2105;
	mul.f32 	%f390, %f2107, %f2106;
	div.rn.f32 	%f391, %f359, %f3043;
	abs.f32 	%f392, %f391;
	setp.lt.f32 	%p657, %f392, 0f00800000;
	mul.f32 	%f2108, %f392, 0f4B800000;
	selp.f32 	%f2109, %f2108, %f392, %p657;
	selp.f32 	%f2110, 0fC3170000, 0fC2FE0000, %p657;
	mov.b32 	%r757, %f2109;
	and.b32  	%r758, %r757, 8388607;
	or.b32  	%r759, %r758, 1065353216;
	mov.b32 	%f2111, %r759;
	shr.u32 	%r760, %r757, 23;
	cvt.rn.f32.u32 	%f2112, %r760;
	add.f32 	%f2113, %f2110, %f2112;
	setp.gt.f32 	%p658, %f2111, 0f3FB504F3;
	mul.f32 	%f2114, %f2111, 0f3F000000;
	add.f32 	%f2115, %f2113, 0f3F800000;
	selp.f32 	%f2116, %f2115, %f2113, %p658;
	selp.f32 	%f2117, %f2114, %f2111, %p658;
	add.f32 	%f2118, %f2117, 0fBF800000;
	add.f32 	%f2119, %f2117, 0f3F800000;
	rcp.approx.ftz.f32 	%f2120, %f2119;
	add.f32 	%f2121, %f2118, %f2118;
	mul.f32 	%f2123, %f2121, %f2120;
	mul.f32 	%f2124, %f2123, %f2123;
	fma.rn.f32 	%f2127, %f1645, %f2124, %f1644;
	fma.rn.f32 	%f2129, %f2127, %f2124, %f1647;
	mul.rn.f32 	%f2130, %f2129, %f2124;
	mul.rn.f32 	%f2131, %f2130, %f2123;
	sub.f32 	%f2132, %f2118, %f2123;
	add.f32 	%f2133, %f2132, %f2132;
	neg.f32 	%f2134, %f2123;
	fma.rn.f32 	%f2135, %f2134, %f2118, %f2133;
	mul.rn.f32 	%f2136, %f2120, %f2135;
	add.f32 	%f2137, %f2131, %f2123;
	sub.f32 	%f2138, %f2123, %f2137;
	add.f32 	%f2139, %f2131, %f2138;
	add.f32 	%f2140, %f2136, %f2139;
	add.f32 	%f2141, %f2137, %f2140;
	sub.f32 	%f2142, %f2137, %f2141;
	add.f32 	%f2143, %f2140, %f2142;
	mul.rn.f32 	%f2145, %f2116, %f1663;
	mul.rn.f32 	%f2147, %f2116, %f1665;
	add.f32 	%f2148, %f2145, %f2141;
	sub.f32 	%f2149, %f2145, %f2148;
	add.f32 	%f2150, %f2141, %f2149;
	add.f32 	%f2151, %f2143, %f2150;
	add.f32 	%f2152, %f2147, %f2151;
	add.f32 	%f2153, %f2148, %f2152;
	sub.f32 	%f2154, %f2148, %f2153;
	add.f32 	%f2155, %f2152, %f2154;
	mul.rn.f32 	%f2156, %f1584, %f2153;
	neg.f32 	%f2157, %f2156;
	fma.rn.f32 	%f2158, %f1584, %f2153, %f2157;
	fma.rn.f32 	%f2159, %f1584, %f2155, %f2158;
	fma.rn.f32 	%f2161, %f2062, %f2153, %f2159;
	add.rn.f32 	%f2162, %f2156, %f2161;
	neg.f32 	%f2163, %f2162;
	add.rn.f32 	%f2164, %f2156, %f2163;
	add.rn.f32 	%f2165, %f2164, %f2161;
	mov.b32 	%r761, %f2162;
	setp.eq.s32 	%p659, %r761, 1118925336;
	add.s32 	%r762, %r761, -1;
	mov.b32 	%f2166, %r762;
	add.f32 	%f2167, %f2165, 0f37000000;
	selp.f32 	%f393, %f2167, %f2165, %p659;
	selp.f32 	%f2168, %f2166, %f2162, %p659;
	mul.rn.f32 	%f2169, %f2168, %f1688;
	cvt.rzi.f32.f32 	%f2170, %f2169;
	abs.f32 	%f2171, %f2170;
	setp.gt.f32 	%p660, %f2171, 0f42FC0000;
	mov.b32 	%r763, %f2170;
	and.b32  	%r764, %r763, -2147483648;
	or.b32  	%r765, %r764, 1123811328;
	mov.b32 	%f2172, %r765;
	selp.f32 	%f2173, %f2172, %f2170, %p660;
	fma.rn.f32 	%f2175, %f2173, %f1694, %f2168;
	fma.rn.f32 	%f2177, %f2173, %f1696, %f2175;
	mul.f32 	%f2178, %f2177, 0f3FB8AA3B;
	add.f32 	%f2179, %f2173, 0f4B40007F;
	mov.b32 	%r766, %f2179;
	shl.b32 	%r767, %r766, 23;
	mov.b32 	%f2180, %r767;
	ex2.approx.ftz.f32 	%f2181, %f2178;
	mul.f32 	%f394, %f2181, %f2180;
	setp.eq.f32 	%p661, %f394, 0f7F800000;
	mov.f32 	%f3104, 0f7F800000;
	@%p661 bra 	$L__BB3_408;

	fma.rn.f32 	%f3104, %f394, %f393, %f394;

$L__BB3_408:
	setp.lt.f32 	%p662, %f391, 0f00000000;
	and.pred  	%p40, %p662, %p606;
	setp.eq.f32 	%p664, %f391, 0f00000000;
	@%p664 bra 	$L__BB3_412;
	bra.uni 	$L__BB3_409;

$L__BB3_412:
	add.f32 	%f2186, %f391, %f391;
	selp.f32 	%f3106, %f2186, 0f00000000, %p606;
	bra.uni 	$L__BB3_413;

$L__BB3_409:
	mov.b32 	%r768, %f3104;
	xor.b32  	%r769, %r768, -2147483648;
	mov.b32 	%f2182, %r769;
	selp.f32 	%f3106, %f2182, %f3104, %p40;
	setp.geu.f32 	%p665, %f391, 0f00000000;
	@%p665 bra 	$L__BB3_413;

	cvt.rzi.f32.f32 	%f2184, %f1584;
	setp.eq.f32 	%p666, %f2184, 0f40000000;
	@%p666 bra 	$L__BB3_413;

	mov.f32 	%f3106, 0f7FFFFFFF;

$L__BB3_413:
	add.f32 	%f2187, %f392, 0f40000000;
	mov.b32 	%r770, %f2187;
	setp.lt.s32 	%p668, %r770, 2139095040;
	@%p668 bra 	$L__BB3_418;

	setp.gtu.f32 	%p669, %f392, 0f7F800000;
	@%p669 bra 	$L__BB3_417;
	bra.uni 	$L__BB3_415;

$L__BB3_417:
	add.f32 	%f3106, %f391, 0f40000000;
	bra.uni 	$L__BB3_418;

$L__BB3_415:
	setp.neu.f32 	%p670, %f392, 0f7F800000;
	@%p670 bra 	$L__BB3_418;

	selp.f32 	%f3106, 0fFF800000, 0f7F800000, %p40;

$L__BB3_418:
	mul.f32 	%f2189, %f3106, 0fBF000000;
	setp.eq.f32 	%p671, %f391, 0f3F800000;
	selp.f32 	%f2190, 0fBF000000, %f2189, %p671;
	fma.rn.f32 	%f2193, %f2190, %f1976, %f1575;
	cvt.sat.f32.f32 	%f2196, %f2193;
	fma.rm.f32 	%f2198, %f2196, %f1979, %f1981;
	add.f32 	%f2199, %f2198, 0fCB40007F;
	neg.f32 	%f2200, %f2199;
	fma.rn.f32 	%f2201, %f2190, %f1688, %f2200;
	fma.rn.f32 	%f2203, %f2190, %f1994, %f2201;
	mov.b32 	%r771, %f2198;
	shl.b32 	%r772, %r771, 23;
	mov.b32 	%f2204, %r772;
	ex2.approx.ftz.f32 	%f2205, %f2203;
	mul.f32 	%f2206, %f2205, %f2204;
	sub.f32 	%f403, %f390, %f2206;
	setp.eq.f32 	%p672, %f314, 0f7F800000;
	mov.f32 	%f3107, 0f7F800000;
	@%p672 bra 	$L__BB3_420;

	fma.rn.f32 	%f3107, %f314, %f313, %f314;

$L__BB3_420:
	mov.b32 	%r773, %f3107;
	xor.b32  	%r774, %r773, -2147483648;
	mov.b32 	%f2207, %r774;
	selp.f32 	%f406, %f2207, %f3107, %p33;
	setp.eq.f32 	%p673, %f311, 0f00000000;
	selp.f32 	%f3108, %f315, %f406, %p673;
	@%p37 bra 	$L__BB3_423;

	cvt.rzi.f32.f32 	%f2209, %f1584;
	setp.eq.f32 	%p674, %f2209, 0f40000000;
	mov.f32 	%f3108, %f406;
	@%p674 bra 	$L__BB3_423;

	mov.f32 	%f3108, 0f7FFFFFFF;

$L__BB3_423:
	setp.eq.f32 	%p675, %f319, 0f7F800000;
	mov.f32 	%f3109, 0f7F800000;
	@%p675 bra 	$L__BB3_425;

	fma.rn.f32 	%f3109, %f319, %f318, %f319;

$L__BB3_425:
	mov.b32 	%r775, %f3109;
	xor.b32  	%r776, %r775, -2147483648;
	mov.b32 	%f2212, %r776;
	selp.f32 	%f411, %f2212, %f3109, %p34;
	setp.eq.f32 	%p676, %f316, 0f00000000;
	selp.f32 	%f3110, %f322, %f411, %p676;
	@%p38 bra 	$L__BB3_428;

	cvt.rzi.f32.f32 	%f2214, %f1584;
	setp.eq.f32 	%p677, %f2214, 0f40000000;
	mov.f32 	%f3110, %f411;
	@%p677 bra 	$L__BB3_428;

	mov.f32 	%f3110, 0f7FFFFFFF;

$L__BB3_428:
	mul.f32 	%f2217, %f264, %f403;
	mul.f32 	%f414, %f352, %f2217;
	setp.gtu.f32 	%p678, %f312, 0f7F800000;
	mov.f32 	%f3111, 0f7F800000;
	selp.f32 	%f2218, %f320, %f3108, %p678;
	setp.neu.f32 	%p679, %f312, 0f7F800000;
	selp.f32 	%f2219, %f2218, %f321, %p679;
	setp.gt.s32 	%p680, %r103, 2139095039;
	selp.f32 	%f2220, %f2219, %f3108, %p680;
	mul.f32 	%f2221, %f2220, 0fBF000000;
	setp.eq.f32 	%p681, %f311, 0f3F800000;
	selp.f32 	%f2222, 0fBF000000, %f2221, %p681;
	fma.rn.f32 	%f2225, %f2222, %f1976, %f1575;
	cvt.sat.f32.f32 	%f2228, %f2225;
	fma.rm.f32 	%f2230, %f2228, %f1979, %f1981;
	setp.gtu.f32 	%p682, %f317, 0f7F800000;
	selp.f32 	%f2231, %f324, %f3110, %p682;
	setp.neu.f32 	%p683, %f317, 0f7F800000;
	selp.f32 	%f2232, %f2231, %f325, %p683;
	setp.gt.s32 	%p684, %r104, 2139095039;
	selp.f32 	%f2233, %f2232, %f3110, %p684;
	mul.f32 	%f2234, %f2233, 0fBF000000;
	setp.eq.f32 	%p685, %f316, 0f3F800000;
	selp.f32 	%f2235, 0fBF000000, %f2234, %p685;
	fma.rn.f32 	%f2236, %f2235, %f1976, %f1575;
	cvt.sat.f32.f32 	%f2237, %f2236;
	fma.rm.f32 	%f2238, %f2237, %f1979, %f1981;
	add.f32 	%f2239, %f2238, 0fCB40007F;
	neg.f32 	%f2240, %f2239;
	fma.rn.f32 	%f2241, %f2235, %f1688, %f2240;
	fma.rn.f32 	%f2243, %f2235, %f1994, %f2241;
	mov.b32 	%r777, %f2238;
	shl.b32 	%r778, %r777, 23;
	mov.b32 	%f2244, %r778;
	ex2.approx.ftz.f32 	%f2245, %f2243;
	mul.f32 	%f2246, %f2245, %f2244;
	mul.f32 	%f2247, %f292, %f2246;
	mov.b32 	%r779, %f2230;
	shl.b32 	%r780, %r779, 23;
	mov.b32 	%f2248, %r780;
	add.f32 	%f2249, %f2230, 0fCB40007F;
	neg.f32 	%f2250, %f2249;
	fma.rn.f32 	%f2251, %f2222, %f1688, %f2250;
	fma.rn.f32 	%f2252, %f2222, %f1994, %f2251;
	ex2.approx.ftz.f32 	%f2253, %f2252;
	mul.f32 	%f2254, %f2253, %f2248;
	mul.f32 	%f2255, %f323, %f2254;
	sub.f32 	%f2256, %f2255, %f2247;
	mul.f32 	%f2257, %f265, %f2256;
	mul.f32 	%f415, %f364, %f2257;
	add.f32 	%f2258, %f353, 0f3F800000;
	sub.f32 	%f2259, %f2258, %f3047;
	div.rn.f32 	%f416, %f2259, %f3043;
	abs.f32 	%f417, %f416;
	setp.lt.f32 	%p686, %f417, 0f00800000;
	mul.f32 	%f2260, %f417, 0f4B800000;
	selp.f32 	%f2261, %f2260, %f417, %p686;
	selp.f32 	%f2262, 0fC3170000, 0fC2FE0000, %p686;
	mov.b32 	%r781, %f2261;
	and.b32  	%r782, %r781, 8388607;
	or.b32  	%r783, %r782, 1065353216;
	mov.b32 	%f2263, %r783;
	shr.u32 	%r784, %r781, 23;
	cvt.rn.f32.u32 	%f2264, %r784;
	add.f32 	%f2265, %f2262, %f2264;
	setp.gt.f32 	%p687, %f2263, 0f3FB504F3;
	mul.f32 	%f2266, %f2263, 0f3F000000;
	add.f32 	%f2267, %f2265, 0f3F800000;
	selp.f32 	%f2268, %f2267, %f2265, %p687;
	selp.f32 	%f2269, %f2266, %f2263, %p687;
	add.f32 	%f2270, %f2269, 0fBF800000;
	add.f32 	%f2271, %f2269, 0f3F800000;
	rcp.approx.ftz.f32 	%f2272, %f2271;
	add.f32 	%f2273, %f2270, %f2270;
	mul.f32 	%f2275, %f2273, %f2272;
	mul.f32 	%f2276, %f2275, %f2275;
	fma.rn.f32 	%f2279, %f1645, %f2276, %f1644;
	fma.rn.f32 	%f2281, %f2279, %f2276, %f1647;
	mul.rn.f32 	%f2282, %f2281, %f2276;
	mul.rn.f32 	%f2283, %f2282, %f2275;
	sub.f32 	%f2284, %f2270, %f2275;
	add.f32 	%f2285, %f2284, %f2284;
	neg.f32 	%f2286, %f2275;
	fma.rn.f32 	%f2287, %f2286, %f2270, %f2285;
	mul.rn.f32 	%f2288, %f2272, %f2287;
	add.f32 	%f2289, %f2283, %f2275;
	sub.f32 	%f2290, %f2275, %f2289;
	add.f32 	%f2291, %f2283, %f2290;
	add.f32 	%f2292, %f2288, %f2291;
	add.f32 	%f2293, %f2289, %f2292;
	sub.f32 	%f2294, %f2289, %f2293;
	add.f32 	%f2295, %f2292, %f2294;
	mul.rn.f32 	%f2297, %f2268, %f1663;
	mul.rn.f32 	%f2299, %f2268, %f1665;
	add.f32 	%f2300, %f2297, %f2293;
	sub.f32 	%f2301, %f2297, %f2300;
	add.f32 	%f2302, %f2293, %f2301;
	add.f32 	%f2303, %f2295, %f2302;
	add.f32 	%f2304, %f2299, %f2303;
	add.f32 	%f2305, %f2300, %f2304;
	sub.f32 	%f2306, %f2300, %f2305;
	add.f32 	%f2307, %f2304, %f2306;
	mul.rn.f32 	%f2308, %f1584, %f2305;
	neg.f32 	%f2309, %f2308;
	fma.rn.f32 	%f2310, %f1584, %f2305, %f2309;
	fma.rn.f32 	%f2311, %f1584, %f2307, %f2310;
	fma.rn.f32 	%f2313, %f2062, %f2305, %f2311;
	add.rn.f32 	%f2314, %f2308, %f2313;
	neg.f32 	%f2315, %f2314;
	add.rn.f32 	%f2316, %f2308, %f2315;
	add.rn.f32 	%f2317, %f2316, %f2313;
	mov.b32 	%r785, %f2314;
	setp.eq.s32 	%p688, %r785, 1118925336;
	add.s32 	%r786, %r785, -1;
	mov.b32 	%f2318, %r786;
	add.f32 	%f2319, %f2317, 0f37000000;
	selp.f32 	%f418, %f2319, %f2317, %p688;
	selp.f32 	%f2320, %f2318, %f2314, %p688;
	mul.rn.f32 	%f2321, %f2320, %f1688;
	cvt.rzi.f32.f32 	%f2322, %f2321;
	abs.f32 	%f2323, %f2322;
	setp.gt.f32 	%p689, %f2323, 0f42FC0000;
	mov.b32 	%r787, %f2322;
	and.b32  	%r788, %r787, -2147483648;
	or.b32  	%r789, %r788, 1123811328;
	mov.b32 	%f2324, %r789;
	selp.f32 	%f2325, %f2324, %f2322, %p689;
	fma.rn.f32 	%f2327, %f2325, %f1694, %f2320;
	fma.rn.f32 	%f2329, %f2325, %f1696, %f2327;
	mul.f32 	%f2330, %f2329, 0f3FB8AA3B;
	add.f32 	%f2331, %f2325, 0f4B40007F;
	mov.b32 	%r790, %f2331;
	shl.b32 	%r791, %r790, 23;
	mov.b32 	%f2332, %r791;
	ex2.approx.ftz.f32 	%f2333, %f2330;
	mul.f32 	%f419, %f2333, %f2332;
	setp.eq.f32 	%p690, %f419, 0f7F800000;
	@%p690 bra 	$L__BB3_430;

	fma.rn.f32 	%f3111, %f419, %f418, %f419;

$L__BB3_430:
	setp.lt.f32 	%p691, %f416, 0f00000000;
	and.pred  	%p41, %p691, %p606;
	setp.eq.f32 	%p693, %f416, 0f00000000;
	@%p693 bra 	$L__BB3_434;
	bra.uni 	$L__BB3_431;

$L__BB3_434:
	add.f32 	%f2338, %f416, %f416;
	selp.f32 	%f3113, %f2338, 0f00000000, %p606;
	bra.uni 	$L__BB3_435;

$L__BB3_431:
	mov.b32 	%r792, %f3111;
	xor.b32  	%r793, %r792, -2147483648;
	mov.b32 	%f2334, %r793;
	selp.f32 	%f3113, %f2334, %f3111, %p41;
	setp.geu.f32 	%p694, %f416, 0f00000000;
	@%p694 bra 	$L__BB3_435;

	cvt.rzi.f32.f32 	%f2336, %f1584;
	setp.eq.f32 	%p695, %f2336, 0f40000000;
	@%p695 bra 	$L__BB3_435;

	mov.f32 	%f3113, 0f7FFFFFFF;

$L__BB3_435:
	add.f32 	%f2339, %f417, 0f40000000;
	mov.b32 	%r794, %f2339;
	setp.lt.s32 	%p697, %r794, 2139095040;
	@%p697 bra 	$L__BB3_440;

	setp.gtu.f32 	%p698, %f417, 0f7F800000;
	@%p698 bra 	$L__BB3_439;
	bra.uni 	$L__BB3_437;

$L__BB3_439:
	add.f32 	%f3113, %f416, 0f40000000;
	bra.uni 	$L__BB3_440;

$L__BB3_437:
	setp.neu.f32 	%p699, %f417, 0f7F800000;
	@%p699 bra 	$L__BB3_440;

	selp.f32 	%f3113, 0fFF800000, 0f7F800000, %p41;

$L__BB3_440:
	mul.f32 	%f2341, %f3113, 0fBF000000;
	setp.eq.f32 	%p700, %f416, 0f3F800000;
	selp.f32 	%f2342, 0fBF000000, %f2341, %p700;
	fma.rn.f32 	%f2345, %f2342, %f1976, %f1575;
	cvt.sat.f32.f32 	%f2348, %f2345;
	fma.rm.f32 	%f2350, %f2348, %f1979, %f1981;
	add.f32 	%f2351, %f2350, 0fCB40007F;
	neg.f32 	%f2352, %f2351;
	fma.rn.f32 	%f2353, %f2342, %f1688, %f2352;
	fma.rn.f32 	%f2355, %f2342, %f1994, %f2353;
	mov.b32 	%r795, %f2350;
	shl.b32 	%r796, %r795, 23;
	mov.b32 	%f2356, %r796;
	ex2.approx.ftz.f32 	%f2357, %f2355;
	mul.f32 	%f428, %f2357, %f2356;
	div.rn.f32 	%f429, %f354, %f3043;
	abs.f32 	%f430, %f429;
	setp.lt.f32 	%p701, %f430, 0f00800000;
	mul.f32 	%f2358, %f430, 0f4B800000;
	selp.f32 	%f2359, %f2358, %f430, %p701;
	selp.f32 	%f2360, 0fC3170000, 0fC2FE0000, %p701;
	mov.b32 	%r797, %f2359;
	and.b32  	%r798, %r797, 8388607;
	or.b32  	%r799, %r798, 1065353216;
	mov.b32 	%f2361, %r799;
	shr.u32 	%r800, %r797, 23;
	cvt.rn.f32.u32 	%f2362, %r800;
	add.f32 	%f2363, %f2360, %f2362;
	setp.gt.f32 	%p702, %f2361, 0f3FB504F3;
	mul.f32 	%f2364, %f2361, 0f3F000000;
	add.f32 	%f2365, %f2363, 0f3F800000;
	selp.f32 	%f2366, %f2365, %f2363, %p702;
	selp.f32 	%f2367, %f2364, %f2361, %p702;
	add.f32 	%f2368, %f2367, 0fBF800000;
	add.f32 	%f2369, %f2367, 0f3F800000;
	rcp.approx.ftz.f32 	%f2370, %f2369;
	add.f32 	%f2371, %f2368, %f2368;
	mul.f32 	%f2373, %f2371, %f2370;
	mul.f32 	%f2374, %f2373, %f2373;
	fma.rn.f32 	%f2377, %f1645, %f2374, %f1644;
	fma.rn.f32 	%f2379, %f2377, %f2374, %f1647;
	mul.rn.f32 	%f2380, %f2379, %f2374;
	mul.rn.f32 	%f2381, %f2380, %f2373;
	sub.f32 	%f2382, %f2368, %f2373;
	add.f32 	%f2383, %f2382, %f2382;
	neg.f32 	%f2384, %f2373;
	fma.rn.f32 	%f2385, %f2384, %f2368, %f2383;
	mul.rn.f32 	%f2386, %f2370, %f2385;
	add.f32 	%f2387, %f2381, %f2373;
	sub.f32 	%f2388, %f2373, %f2387;
	add.f32 	%f2389, %f2381, %f2388;
	add.f32 	%f2390, %f2386, %f2389;
	add.f32 	%f2391, %f2387, %f2390;
	sub.f32 	%f2392, %f2387, %f2391;
	add.f32 	%f2393, %f2390, %f2392;
	mul.rn.f32 	%f2395, %f2366, %f1663;
	mul.rn.f32 	%f2397, %f2366, %f1665;
	add.f32 	%f2398, %f2395, %f2391;
	sub.f32 	%f2399, %f2395, %f2398;
	add.f32 	%f2400, %f2391, %f2399;
	add.f32 	%f2401, %f2393, %f2400;
	add.f32 	%f2402, %f2397, %f2401;
	add.f32 	%f2403, %f2398, %f2402;
	sub.f32 	%f2404, %f2398, %f2403;
	add.f32 	%f2405, %f2402, %f2404;
	mul.rn.f32 	%f2406, %f1584, %f2403;
	neg.f32 	%f2407, %f2406;
	fma.rn.f32 	%f2408, %f1584, %f2403, %f2407;
	fma.rn.f32 	%f2409, %f1584, %f2405, %f2408;
	fma.rn.f32 	%f2411, %f2062, %f2403, %f2409;
	add.rn.f32 	%f2412, %f2406, %f2411;
	neg.f32 	%f2413, %f2412;
	add.rn.f32 	%f2414, %f2406, %f2413;
	add.rn.f32 	%f2415, %f2414, %f2411;
	mov.b32 	%r801, %f2412;
	setp.eq.s32 	%p703, %r801, 1118925336;
	add.s32 	%r802, %r801, -1;
	mov.b32 	%f2416, %r802;
	add.f32 	%f2417, %f2415, 0f37000000;
	selp.f32 	%f431, %f2417, %f2415, %p703;
	selp.f32 	%f2418, %f2416, %f2412, %p703;
	mul.rn.f32 	%f2419, %f2418, %f1688;
	cvt.rzi.f32.f32 	%f2420, %f2419;
	abs.f32 	%f2421, %f2420;
	setp.gt.f32 	%p704, %f2421, 0f42FC0000;
	mov.b32 	%r803, %f2420;
	and.b32  	%r804, %r803, -2147483648;
	or.b32  	%r805, %r804, 1123811328;
	mov.b32 	%f2422, %r805;
	selp.f32 	%f2423, %f2422, %f2420, %p704;
	fma.rn.f32 	%f2425, %f2423, %f1694, %f2418;
	fma.rn.f32 	%f2427, %f2423, %f1696, %f2425;
	mul.f32 	%f2428, %f2427, 0f3FB8AA3B;
	add.f32 	%f2429, %f2423, 0f4B40007F;
	mov.b32 	%r806, %f2429;
	shl.b32 	%r807, %r806, 23;
	mov.b32 	%f2430, %r807;
	ex2.approx.ftz.f32 	%f2431, %f2428;
	mul.f32 	%f432, %f2431, %f2430;
	setp.eq.f32 	%p705, %f432, 0f7F800000;
	mov.f32 	%f3114, 0f7F800000;
	@%p705 bra 	$L__BB3_442;

	fma.rn.f32 	%f3114, %f432, %f431, %f432;

$L__BB3_442:
	setp.lt.f32 	%p706, %f429, 0f00000000;
	and.pred  	%p42, %p706, %p606;
	setp.eq.f32 	%p708, %f429, 0f00000000;
	@%p708 bra 	$L__BB3_446;
	bra.uni 	$L__BB3_443;

$L__BB3_446:
	add.f32 	%f2436, %f429, %f429;
	selp.f32 	%f3116, %f2436, 0f00000000, %p606;
	bra.uni 	$L__BB3_447;

$L__BB3_443:
	mov.b32 	%r808, %f3114;
	xor.b32  	%r809, %r808, -2147483648;
	mov.b32 	%f2432, %r809;
	selp.f32 	%f3116, %f2432, %f3114, %p42;
	setp.geu.f32 	%p709, %f429, 0f00000000;
	@%p709 bra 	$L__BB3_447;

	cvt.rzi.f32.f32 	%f2434, %f1584;
	setp.eq.f32 	%p710, %f2434, 0f40000000;
	@%p710 bra 	$L__BB3_447;

	mov.f32 	%f3116, 0f7FFFFFFF;

$L__BB3_447:
	add.f32 	%f2437, %f430, 0f40000000;
	mov.b32 	%r810, %f2437;
	setp.lt.s32 	%p712, %r810, 2139095040;
	@%p712 bra 	$L__BB3_452;

	setp.gtu.f32 	%p713, %f430, 0f7F800000;
	@%p713 bra 	$L__BB3_451;
	bra.uni 	$L__BB3_449;

$L__BB3_451:
	add.f32 	%f3116, %f429, 0f40000000;
	bra.uni 	$L__BB3_452;

$L__BB3_449:
	setp.neu.f32 	%p714, %f430, 0f7F800000;
	@%p714 bra 	$L__BB3_452;

	selp.f32 	%f3116, 0fFF800000, 0f7F800000, %p42;

$L__BB3_452:
	mul.f32 	%f2438, %f3116, 0fBF000000;
	setp.eq.f32 	%p715, %f429, 0f3F800000;
	selp.f32 	%f2439, 0fBF000000, %f2438, %p715;
	fma.rn.f32 	%f2442, %f2439, %f1976, %f1575;
	cvt.sat.f32.f32 	%f2445, %f2442;
	fma.rm.f32 	%f2447, %f2445, %f1979, %f1981;
	add.f32 	%f2448, %f2447, 0fCB40007F;
	neg.f32 	%f2449, %f2448;
	fma.rn.f32 	%f2450, %f2439, %f1688, %f2449;
	fma.rn.f32 	%f2452, %f2439, %f1994, %f2450;
	mov.b32 	%r811, %f2447;
	shl.b32 	%r812, %r811, 23;
	mov.b32 	%f2453, %r812;
	ex2.approx.ftz.f32 	%f2454, %f2452;
	mul.f32 	%f2455, %f2454, %f2453;
	add.f32 	%f2456, %f354, 0f3F800000;
	mul.f32 	%f2457, %f2456, %f428;
	mul.f32 	%f2458, %f354, %f2455;
	sub.f32 	%f2459, %f2457, %f2458;
	mul.f32 	%f2460, %f266, %f2459;
	mul.f32 	%f2461, %f352, %f2460;
	mul.f32 	%f2462, %f377, %f377;
	div.rn.f32 	%f2463, %f2462, %f365;
	add.f32 	%f3088, %f3088, %f2463;
	mul.f32 	%f2464, %f414, %f377;
	div.rn.f32 	%f2465, %f2464, %f365;
	add.f32 	%f3087, %f3087, %f2465;
	mul.f32 	%f2466, %f352, %f364;
	mul.f32 	%f2467, %f2466, %f377;
	div.rn.f32 	%f2468, %f2467, %f365;
	add.f32 	%f3086, %f3086, %f2468;
	div.rn.f32 	%f2469, %f377, %f365;
	add.f32 	%f3085, %f3085, %f2469;
	mul.f32 	%f2470, %f415, %f377;
	div.rn.f32 	%f2471, %f2470, %f365;
	add.f32 	%f3084, %f3084, %f2471;
	mul.f32 	%f2472, %f2461, %f377;
	div.rn.f32 	%f2473, %f2472, %f365;
	add.f32 	%f3083, %f3083, %f2473;
	mul.f32 	%f2474, %f414, %f414;
	div.rn.f32 	%f2475, %f2474, %f365;
	add.f32 	%f3082, %f3082, %f2475;
	mul.f32 	%f2476, %f2466, %f414;
	div.rn.f32 	%f2477, %f2476, %f365;
	add.f32 	%f3081, %f3081, %f2477;
	div.rn.f32 	%f2478, %f414, %f365;
	add.f32 	%f3080, %f3080, %f2478;
	mul.f32 	%f2479, %f415, %f414;
	div.rn.f32 	%f2480, %f2479, %f365;
	add.f32 	%f3079, %f3079, %f2480;
	mul.f32 	%f2481, %f2461, %f414;
	div.rn.f32 	%f2482, %f2481, %f365;
	add.f32 	%f3078, %f3078, %f2482;
	mul.f32 	%f2483, %f2466, %f2466;
	div.rn.f32 	%f2484, %f2483, %f365;
	add.f32 	%f3077, %f3077, %f2484;
	div.rn.f32 	%f2485, %f2466, %f365;
	add.f32 	%f3076, %f3076, %f2485;
	mul.f32 	%f2486, %f415, %f2466;
	div.rn.f32 	%f2487, %f2486, %f365;
	add.f32 	%f3075, %f3075, %f2487;
	mul.f32 	%f2488, %f2461, %f2466;
	div.rn.f32 	%f2489, %f2488, %f365;
	add.f32 	%f3074, %f3074, %f2489;
	rcp.rn.f32 	%f2490, %f365;
	add.f32 	%f3073, %f3073, %f2490;
	div.rn.f32 	%f2491, %f415, %f365;
	add.f32 	%f3072, %f3072, %f2491;
	div.rn.f32 	%f2492, %f2461, %f365;
	add.f32 	%f3071, %f3071, %f2492;
	mul.f32 	%f2493, %f415, %f415;
	div.rn.f32 	%f2494, %f2493, %f365;
	add.f32 	%f3089, %f3089, %f2494;
	mul.f32 	%f2495, %f2461, %f415;
	div.rn.f32 	%f2496, %f2495, %f365;
	add.f32 	%f3090, %f3090, %f2496;
	mul.f32 	%f2497, %f2461, %f2461;
	div.rn.f32 	%f2498, %f2497, %f365;
	add.f32 	%f3091, %f3091, %f2498;
	setp.leu.f32 	%p716, %f365, 0f00000000;
	@%p716 bra 	$L__BB3_460;

	setp.gt.f32 	%p717, %f366, 0f00000000;
	@%p717 bra 	$L__BB3_455;
	bra.uni 	$L__BB3_454;

$L__BB3_455:
	setp.lt.f32 	%p718, %f365, 0f00800000;
	mul.f32 	%f2499, %f365, 0f4B000000;
	selp.f32 	%f463, %f2499, %f365, %p718;
	selp.f32 	%f2500, 0fC1B80000, 0f00000000, %p718;
	mov.b32 	%r813, %f463;
	add.s32 	%r814, %r813, -1059760811;
	and.b32  	%r815, %r814, -8388608;
	sub.s32 	%r816, %r813, %r815;
	mov.b32 	%f2501, %r816;
	cvt.rn.f32.s32 	%f2502, %r815;
	mov.f32 	%f2503, 0f34000000;
	fma.rn.f32 	%f2504, %f2502, %f2503, %f2500;
	add.f32 	%f2505, %f2501, 0fBF800000;
	mov.f32 	%f2506, 0f3E1039F6;
	mov.f32 	%f2507, 0fBE055027;
	fma.rn.f32 	%f2508, %f2507, %f2505, %f2506;
	mov.f32 	%f2509, 0fBDF8CDCC;
	fma.rn.f32 	%f2510, %f2508, %f2505, %f2509;
	mov.f32 	%f2511, 0f3E0F2955;
	fma.rn.f32 	%f2512, %f2510, %f2505, %f2511;
	mov.f32 	%f2513, 0fBE2AD8B9;
	fma.rn.f32 	%f2514, %f2512, %f2505, %f2513;
	mov.f32 	%f2515, 0f3E4CED0B;
	fma.rn.f32 	%f2516, %f2514, %f2505, %f2515;
	mov.f32 	%f2517, 0fBE7FFF22;
	fma.rn.f32 	%f2518, %f2516, %f2505, %f2517;
	mov.f32 	%f2519, 0f3EAAAA78;
	fma.rn.f32 	%f2520, %f2518, %f2505, %f2519;
	mov.f32 	%f2521, 0fBF000000;
	fma.rn.f32 	%f2522, %f2520, %f2505, %f2521;
	mul.f32 	%f2523, %f2505, %f2522;
	fma.rn.f32 	%f2524, %f2523, %f2505, %f2505;
	mov.f32 	%f2525, 0f3F317218;
	fma.rn.f32 	%f3117, %f2504, %f2525, %f2524;
	setp.lt.u32 	%p719, %r813, 2139095040;
	@%p719 bra 	$L__BB3_457;

	mov.f32 	%f2526, 0f7F800000;
	fma.rn.f32 	%f3117, %f463, %f2526, %f2526;

$L__BB3_457:
	setp.eq.f32 	%p720, %f463, 0f00000000;
	selp.f32 	%f2527, 0fFF800000, %f3117, %p720;
	mul.f32 	%f2528, %f366, %f2527;
	sub.f32 	%f467, %f2528, %f365;
	mul.f32 	%f2529, %f366, 0f4B000000;
	setp.lt.f32 	%p721, %f366, 0f00800000;
	selp.f32 	%f468, %f2529, %f366, %p721;
	selp.f32 	%f2530, 0fC1B80000, 0f00000000, %p721;
	mov.b32 	%r817, %f468;
	add.s32 	%r818, %r817, -1059760811;
	and.b32  	%r819, %r818, -8388608;
	sub.s32 	%r820, %r817, %r819;
	mov.b32 	%f2531, %r820;
	cvt.rn.f32.s32 	%f2532, %r819;
	fma.rn.f32 	%f2534, %f2532, %f2503, %f2530;
	add.f32 	%f2535, %f2531, 0fBF800000;
	fma.rn.f32 	%f2538, %f2507, %f2535, %f2506;
	fma.rn.f32 	%f2540, %f2538, %f2535, %f2509;
	fma.rn.f32 	%f2542, %f2540, %f2535, %f2511;
	fma.rn.f32 	%f2544, %f2542, %f2535, %f2513;
	fma.rn.f32 	%f2546, %f2544, %f2535, %f2515;
	fma.rn.f32 	%f2548, %f2546, %f2535, %f2517;
	fma.rn.f32 	%f2550, %f2548, %f2535, %f2519;
	fma.rn.f32 	%f2552, %f2550, %f2535, %f2521;
	mul.f32 	%f2553, %f2535, %f2552;
	fma.rn.f32 	%f2554, %f2553, %f2535, %f2535;
	fma.rn.f32 	%f3118, %f2534, %f2525, %f2554;
	setp.lt.u32 	%p722, %r817, 2139095040;
	@%p722 bra 	$L__BB3_459;

	mov.f32 	%f2556, 0f7F800000;
	fma.rn.f32 	%f3118, %f468, %f2556, %f2556;

$L__BB3_459:
	setp.eq.f32 	%p723, %f468, 0f00000000;
	selp.f32 	%f2557, 0fFF800000, %f3118, %p723;
	mul.f32 	%f2558, %f366, %f2557;
	sub.f32 	%f2559, %f467, %f2558;
	add.f32 	%f2560, %f366, %f2559;
	add.f32 	%f3119, %f3119, %f2560;
	bra.uni 	$L__BB3_460;

$L__BB3_454:
	sub.f32 	%f3119, %f3119, %f365;

$L__BB3_460:
	add.s32 	%r855, %r855, 1;
	setp.lt.s32 	%p724, %r855, %r108;
	@%p724 bra 	$L__BB3_376;

	add.s32 	%r854, %r854, 1;
	setp.lt.s32 	%p725, %r854, %r108;
	@%p725 bra 	$L__BB3_375;

$L__BB3_462:
	ld.param.u64 	%rd52, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_6];
	ld.param.u64 	%rd51, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_5];
	ld.param.u32 	%r835, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_7];
	ld.param.u64 	%rd50, [_Z23kernel_MLEFit_XYNBSXSY_PKffiiPfS1_S1_i_param_4];
	mov.u32 	%r834, %tid.x;
	mov.u32 	%r833, %ntid.x;
	mov.u32 	%r832, %ctaid.x;
	mad.lo.s32 	%r831, %r832, %r833, %r834;
	rcp.rn.f32 	%f2561, %f3088;
	mov.f32 	%f2562, 0f3F800000;
	mul.f32 	%f2563, %f2561, %f3087;
	mul.f32 	%f2564, %f2561, %f3086;
	mul.f32 	%f2565, %f2561, %f3085;
	mul.f32 	%f2566, %f2561, %f3084;
	mul.f32 	%f2567, %f2561, %f3083;
	fma.rn.f32 	%f2568, %f2563, %f3087, 0f00000000;
	sub.f32 	%f2570, %f3082, %f2568;
	fma.rn.f32 	%f2571, %f2564, %f3087, 0f00000000;
	rcp.rn.f32 	%f2572, %f2570;
	sub.f32 	%f2573, %f3081, %f2571;
	mul.f32 	%f2574, %f2572, %f2573;
	fma.rn.f32 	%f2575, %f2565, %f3087, 0f00000000;
	sub.f32 	%f2576, %f3080, %f2575;
	mul.f32 	%f2577, %f2572, %f2576;
	fma.rn.f32 	%f2578, %f2566, %f3087, 0f00000000;
	sub.f32 	%f2579, %f3079, %f2578;
	mul.f32 	%f2580, %f2572, %f2579;
	fma.rn.f32 	%f2581, %f2567, %f3087, 0f00000000;
	sub.f32 	%f2582, %f3078, %f2581;
	mul.f32 	%f2583, %f2572, %f2582;
	fma.rn.f32 	%f2584, %f2563, %f3086, 0f00000000;
	sub.f32 	%f2585, %f3081, %f2584;
	fma.rn.f32 	%f2586, %f2564, %f3086, 0f00000000;
	fma.rn.f32 	%f2587, %f2574, %f2585, %f2586;
	sub.f32 	%f2588, %f3077, %f2587;
	fma.rn.f32 	%f2589, %f2565, %f3086, 0f00000000;
	fma.rn.f32 	%f2590, %f2577, %f2585, %f2589;
	rcp.rn.f32 	%f2591, %f2588;
	sub.f32 	%f2592, %f3076, %f2590;
	mul.f32 	%f2593, %f2591, %f2592;
	fma.rn.f32 	%f2594, %f2566, %f3086, 0f00000000;
	fma.rn.f32 	%f2595, %f2580, %f2585, %f2594;
	sub.f32 	%f2596, %f3075, %f2595;
	mul.f32 	%f2597, %f2591, %f2596;
	fma.rn.f32 	%f2598, %f2567, %f3086, 0f00000000;
	fma.rn.f32 	%f2599, %f2583, %f2585, %f2598;
	sub.f32 	%f2600, %f3074, %f2599;
	mul.f32 	%f2601, %f2591, %f2600;
	fma.rn.f32 	%f2602, %f2563, %f3085, 0f00000000;
	sub.f32 	%f2603, %f3080, %f2602;
	fma.rn.f32 	%f2604, %f2564, %f3085, 0f00000000;
	fma.rn.f32 	%f2605, %f2574, %f2603, %f2604;
	sub.f32 	%f2606, %f3076, %f2605;
	fma.rn.f32 	%f2607, %f2565, %f3085, 0f00000000;
	fma.rn.f32 	%f2608, %f2577, %f2603, %f2607;
	fma.rn.f32 	%f2609, %f2593, %f2606, %f2608;
	sub.f32 	%f2610, %f3073, %f2609;
	fma.rn.f32 	%f2611, %f2566, %f3085, 0f00000000;
	fma.rn.f32 	%f2612, %f2580, %f2603, %f2611;
	fma.rn.f32 	%f2613, %f2597, %f2606, %f2612;
	rcp.rn.f32 	%f2614, %f2610;
	sub.f32 	%f2615, %f3072, %f2613;
	mul.f32 	%f2616, %f2614, %f2615;
	fma.rn.f32 	%f2617, %f2567, %f3085, 0f00000000;
	fma.rn.f32 	%f2618, %f2583, %f2603, %f2617;
	fma.rn.f32 	%f2619, %f2601, %f2606, %f2618;
	sub.f32 	%f2620, %f3071, %f2619;
	mul.f32 	%f2621, %f2614, %f2620;
	fma.rn.f32 	%f2622, %f2563, %f3084, 0f00000000;
	sub.f32 	%f2623, %f3079, %f2622;
	fma.rn.f32 	%f2624, %f2564, %f3084, 0f00000000;
	fma.rn.f32 	%f2625, %f2574, %f2623, %f2624;
	sub.f32 	%f2626, %f3075, %f2625;
	fma.rn.f32 	%f2627, %f2565, %f3084, 0f00000000;
	fma.rn.f32 	%f2628, %f2577, %f2623, %f2627;
	fma.rn.f32 	%f2629, %f2593, %f2626, %f2628;
	sub.f32 	%f2630, %f3072, %f2629;
	fma.rn.f32 	%f2631, %f2566, %f3084, 0f00000000;
	fma.rn.f32 	%f2632, %f2580, %f2623, %f2631;
	fma.rn.f32 	%f2633, %f2597, %f2626, %f2632;
	fma.rn.f32 	%f2634, %f2616, %f2630, %f2633;
	sub.f32 	%f2635, %f3089, %f2634;
	fma.rn.f32 	%f2636, %f2567, %f3084, 0f00000000;
	fma.rn.f32 	%f2637, %f2583, %f2623, %f2636;
	fma.rn.f32 	%f2638, %f2601, %f2626, %f2637;
	fma.rn.f32 	%f2639, %f2621, %f2630, %f2638;
	rcp.rn.f32 	%f2640, %f2635;
	sub.f32 	%f2641, %f3090, %f2639;
	mul.f32 	%f2642, %f2640, %f2641;
	fma.rn.f32 	%f2643, %f2563, %f3083, 0f00000000;
	sub.f32 	%f2644, %f3078, %f2643;
	fma.rn.f32 	%f2645, %f2564, %f3083, 0f00000000;
	fma.rn.f32 	%f2646, %f2574, %f2644, %f2645;
	sub.f32 	%f2647, %f3074, %f2646;
	fma.rn.f32 	%f2648, %f2565, %f3083, 0f00000000;
	fma.rn.f32 	%f2649, %f2577, %f2644, %f2648;
	fma.rn.f32 	%f2650, %f2593, %f2647, %f2649;
	sub.f32 	%f2651, %f3071, %f2650;
	fma.rn.f32 	%f2652, %f2566, %f3083, 0f00000000;
	fma.rn.f32 	%f2653, %f2580, %f2644, %f2652;
	fma.rn.f32 	%f2654, %f2597, %f2647, %f2653;
	fma.rn.f32 	%f2655, %f2616, %f2651, %f2654;
	sub.f32 	%f2656, %f3090, %f2655;
	fma.rn.f32 	%f2657, %f2567, %f3083, 0f00000000;
	fma.rn.f32 	%f2658, %f2583, %f2644, %f2657;
	fma.rn.f32 	%f2659, %f2601, %f2647, %f2658;
	fma.rn.f32 	%f2660, %f2621, %f2651, %f2659;
	fma.rn.f32 	%f2661, %f2642, %f2656, %f2660;
	sub.f32 	%f2662, %f3091, %f2661;
	add.f32 	%f2663, %f2563, 0f00000000;
	sub.f32 	%f2664, %f1552, %f2663;
	add.f32 	%f2665, %f2564, 0f00000000;
	fma.rn.f32 	%f2666, %f2574, %f2664, %f2665;
	sub.f32 	%f2667, %f1552, %f2666;
	add.f32 	%f2668, %f2565, 0f00000000;
	fma.rn.f32 	%f2669, %f2577, %f2664, %f2668;
	fma.rn.f32 	%f2670, %f2593, %f2667, %f2669;
	sub.f32 	%f2671, %f1552, %f2670;
	add.f32 	%f2672, %f2566, 0f00000000;
	fma.rn.f32 	%f2673, %f2580, %f2664, %f2672;
	fma.rn.f32 	%f2674, %f2597, %f2667, %f2673;
	fma.rn.f32 	%f2675, %f2616, %f2671, %f2674;
	sub.f32 	%f2676, %f1552, %f2675;
	add.f32 	%f2677, %f2567, 0f00000000;
	fma.rn.f32 	%f2678, %f2583, %f2664, %f2677;
	fma.rn.f32 	%f2679, %f2601, %f2667, %f2678;
	fma.rn.f32 	%f2680, %f2621, %f2671, %f2679;
	fma.rn.f32 	%f2681, %f2642, %f2676, %f2680;
	sub.f32 	%f2682, %f1552, %f2681;
	div.rn.f32 	%f2683, %f2682, %f2662;
	fma.rn.f32 	%f2684, %f2656, %f2683, 0f00000000;
	sub.f32 	%f2685, %f2676, %f2684;
	mul.f32 	%f2686, %f2640, %f2685;
	fma.rn.f32 	%f2687, %f2630, %f2686, 0f00000000;
	fma.rn.f32 	%f2688, %f2651, %f2683, %f2687;
	sub.f32 	%f2689, %f2671, %f2688;
	mul.f32 	%f2690, %f2614, %f2689;
	fma.rn.f32 	%f2691, %f2606, %f2690, 0f00000000;
	fma.rn.f32 	%f2692, %f2626, %f2686, %f2691;
	fma.rn.f32 	%f2693, %f2647, %f2683, %f2692;
	sub.f32 	%f2694, %f2667, %f2693;
	mul.f32 	%f2695, %f2591, %f2694;
	fma.rn.f32 	%f2696, %f2585, %f2695, 0f00000000;
	fma.rn.f32 	%f2697, %f2603, %f2690, %f2696;
	fma.rn.f32 	%f2698, %f2623, %f2686, %f2697;
	fma.rn.f32 	%f2699, %f2644, %f2683, %f2698;
	sub.f32 	%f2700, %f2664, %f2699;
	mul.f32 	%f2701, %f2572, %f2700;
	fma.rn.f32 	%f2702, %f3087, %f2701, 0f00000000;
	fma.rn.f32 	%f2703, %f3086, %f2695, %f2702;
	fma.rn.f32 	%f2704, %f3085, %f2690, %f2703;
	fma.rn.f32 	%f2705, %f3084, %f2686, %f2704;
	fma.rn.f32 	%f2706, %f3083, %f2683, %f2705;
	sub.f32 	%f2707, %f2562, %f2706;
	mul.f32 	%f2708, %f2561, %f2707;
	fma.rn.f32 	%f2709, %f2563, 0f00000000, 0f00000000;
	sub.f32 	%f2710, %f2562, %f2709;
	fma.rn.f32 	%f2711, %f2564, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2712, %f2574, %f2710, %f2711;
	sub.f32 	%f2713, %f1552, %f2712;
	fma.rn.f32 	%f2714, %f2565, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2715, %f2577, %f2710, %f2714;
	fma.rn.f32 	%f2716, %f2593, %f2713, %f2715;
	sub.f32 	%f2717, %f1552, %f2716;
	fma.rn.f32 	%f2718, %f2566, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2719, %f2580, %f2710, %f2718;
	fma.rn.f32 	%f2720, %f2597, %f2713, %f2719;
	fma.rn.f32 	%f2721, %f2616, %f2717, %f2720;
	sub.f32 	%f2722, %f1552, %f2721;
	fma.rn.f32 	%f2723, %f2567, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2724, %f2583, %f2710, %f2723;
	fma.rn.f32 	%f2725, %f2601, %f2713, %f2724;
	fma.rn.f32 	%f2726, %f2621, %f2717, %f2725;
	fma.rn.f32 	%f2727, %f2642, %f2722, %f2726;
	sub.f32 	%f2728, %f1552, %f2727;
	div.rn.f32 	%f2729, %f2728, %f2662;
	fma.rn.f32 	%f2730, %f2656, %f2729, 0f00000000;
	sub.f32 	%f2731, %f2722, %f2730;
	mul.f32 	%f2732, %f2640, %f2731;
	fma.rn.f32 	%f2733, %f2630, %f2732, 0f00000000;
	fma.rn.f32 	%f2734, %f2651, %f2729, %f2733;
	sub.f32 	%f2735, %f2717, %f2734;
	mul.f32 	%f2736, %f2614, %f2735;
	fma.rn.f32 	%f2737, %f2606, %f2736, 0f00000000;
	fma.rn.f32 	%f2738, %f2626, %f2732, %f2737;
	fma.rn.f32 	%f2739, %f2647, %f2729, %f2738;
	sub.f32 	%f2740, %f2713, %f2739;
	mul.f32 	%f2741, %f2591, %f2740;
	fma.rn.f32 	%f2742, %f2585, %f2741, 0f00000000;
	fma.rn.f32 	%f2743, %f2603, %f2736, %f2742;
	fma.rn.f32 	%f2744, %f2623, %f2732, %f2743;
	fma.rn.f32 	%f2745, %f2644, %f2729, %f2744;
	sub.f32 	%f2746, %f2710, %f2745;
	mul.f32 	%f2747, %f2572, %f2746;
	sub.f32 	%f2748, %f1552, %f2709;
	fma.rn.f32 	%f2749, %f2574, %f2748, %f2711;
	sub.f32 	%f2750, %f2562, %f2749;
	fma.rn.f32 	%f2751, %f2577, %f2748, %f2714;
	fma.rn.f32 	%f2752, %f2593, %f2750, %f2751;
	sub.f32 	%f2753, %f1552, %f2752;
	fma.rn.f32 	%f2754, %f2580, %f2748, %f2718;
	fma.rn.f32 	%f2755, %f2597, %f2750, %f2754;
	fma.rn.f32 	%f2756, %f2616, %f2753, %f2755;
	sub.f32 	%f2757, %f1552, %f2756;
	fma.rn.f32 	%f2758, %f2583, %f2748, %f2723;
	fma.rn.f32 	%f2759, %f2601, %f2750, %f2758;
	fma.rn.f32 	%f2760, %f2621, %f2753, %f2759;
	fma.rn.f32 	%f2761, %f2642, %f2757, %f2760;
	sub.f32 	%f2762, %f1552, %f2761;
	div.rn.f32 	%f2763, %f2762, %f2662;
	fma.rn.f32 	%f2764, %f2656, %f2763, 0f00000000;
	sub.f32 	%f2765, %f2757, %f2764;
	mul.f32 	%f2766, %f2640, %f2765;
	fma.rn.f32 	%f2767, %f2630, %f2766, 0f00000000;
	fma.rn.f32 	%f2768, %f2651, %f2763, %f2767;
	sub.f32 	%f2769, %f2753, %f2768;
	mul.f32 	%f2770, %f2614, %f2769;
	fma.rn.f32 	%f2771, %f2606, %f2770, 0f00000000;
	fma.rn.f32 	%f2772, %f2626, %f2766, %f2771;
	fma.rn.f32 	%f2773, %f2647, %f2763, %f2772;
	sub.f32 	%f2774, %f2750, %f2773;
	mul.f32 	%f2775, %f2591, %f2774;
	sub.f32 	%f2776, %f1552, %f2749;
	fma.rn.f32 	%f2777, %f2593, %f2776, %f2751;
	sub.f32 	%f2778, %f2562, %f2777;
	fma.rn.f32 	%f2779, %f2597, %f2776, %f2754;
	fma.rn.f32 	%f2780, %f2616, %f2778, %f2779;
	sub.f32 	%f2781, %f1552, %f2780;
	fma.rn.f32 	%f2782, %f2601, %f2776, %f2758;
	fma.rn.f32 	%f2783, %f2621, %f2778, %f2782;
	fma.rn.f32 	%f2784, %f2642, %f2781, %f2783;
	sub.f32 	%f2785, %f1552, %f2784;
	div.rn.f32 	%f2786, %f2785, %f2662;
	fma.rn.f32 	%f2787, %f2656, %f2786, 0f00000000;
	sub.f32 	%f2788, %f2781, %f2787;
	mul.f32 	%f2789, %f2640, %f2788;
	fma.rn.f32 	%f2790, %f2630, %f2789, 0f00000000;
	fma.rn.f32 	%f2791, %f2651, %f2786, %f2790;
	sub.f32 	%f2792, %f2778, %f2791;
	mul.f32 	%f2793, %f2614, %f2792;
	sub.f32 	%f2794, %f1552, %f2777;
	fma.rn.f32 	%f2795, %f2616, %f2794, %f2779;
	sub.f32 	%f2796, %f2562, %f2795;
	fma.rn.f32 	%f2797, %f2621, %f2794, %f2782;
	fma.rn.f32 	%f2798, %f2642, %f2796, %f2797;
	sub.f32 	%f2799, %f1552, %f2798;
	div.rn.f32 	%f2800, %f2799, %f2662;
	fma.rn.f32 	%f2801, %f2656, %f2800, 0f00000000;
	sub.f32 	%f2802, %f2796, %f2801;
	mul.f32 	%f2803, %f2640, %f2802;
	sub.f32 	%f2804, %f1552, %f2795;
	fma.rn.f32 	%f2805, %f2642, %f2804, %f2797;
	sub.f32 	%f2806, %f2562, %f2805;
	div.rn.f32 	%f2807, %f2806, %f2662;
	cvta.to.global.u64 	%rd30, %rd50;
	mul.wide.s32 	%rd31, %r831, 4;
	add.s64 	%rd32, %rd30, %rd31;
	st.global.f32 	[%rd32], %f3048;
	add.s32 	%r825, %r831, %r835;
	mul.wide.s32 	%rd33, %r835, 4;
	add.s64 	%rd34, %rd32, %rd33;
	st.global.f32 	[%rd34], %f3047;
	add.s32 	%r826, %r825, %r835;
	mul.wide.s32 	%rd35, %r826, 4;
	add.s64 	%rd36, %rd30, %rd35;
	st.global.f32 	[%rd36], %f3046;
	shl.b32 	%r827, %r835, 2;
	cvt.s64.s32 	%rd37, %r827;
	add.s64 	%rd38, %rd36, %rd37;
	st.global.f32 	[%rd38], %f3045;
	add.s64 	%rd39, %rd38, %rd37;
	st.global.f32 	[%rd39], %f3044;
	add.s64 	%rd40, %rd39, %rd37;
	st.global.f32 	[%rd40], %f3043;
	cvta.to.global.u64 	%rd41, %rd51;
	add.s64 	%rd42, %rd41, %rd31;
	st.global.f32 	[%rd42], %f2708;
	add.s64 	%rd43, %rd42, %rd33;
	st.global.f32 	[%rd43], %f2747;
	add.s64 	%rd44, %rd41, %rd35;
	st.global.f32 	[%rd44], %f2775;
	add.s64 	%rd45, %rd44, %rd37;
	st.global.f32 	[%rd45], %f2793;
	add.s64 	%rd46, %rd45, %rd37;
	st.global.f32 	[%rd46], %f2803;
	add.s64 	%rd47, %rd46, %rd37;
	st.global.f32 	[%rd47], %f2807;
	cvta.to.global.u64 	%rd48, %rd52;
	add.s64 	%rd49, %rd48, %rd31;
	st.global.f32 	[%rd49], %f3119;

$L__BB3_463:
	ret;

}
	// .globl	_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i
.visible .entry _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i(
	.param .u64 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_0,
	.param .u64 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_1,
	.param .u64 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_2,
	.param .f32 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_3,
	.param .u32 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_4,
	.param .u32 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_5,
	.param .u32 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_6,
	.param .u64 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_7,
	.param .u64 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_8,
	.param .u64 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_9,
	.param .u32 _Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_10
)
{
	.reg .pred 	%p<382>;
	.reg .f32 	%f<1829>;
	.reg .b32 	%r<526>;
	.reg .f64 	%fd<359>;
	.reg .b64 	%rd<56>;


	ld.param.u64 	%rd11, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_0];
	ld.param.u64 	%rd6, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_1];
	ld.param.u64 	%rd7, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_2];
	ld.param.f32 	%f325, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_3];
	ld.param.u32 	%r85, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_4];
	ld.param.u32 	%r88, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_10];
	cvta.to.global.u64 	%rd1, %rd11;
	mov.u32 	%r89, %ntid.x;
	mov.u32 	%r90, %ctaid.x;
	mov.u32 	%r91, %tid.x;
	mad.lo.s32 	%r1, %r90, %r89, %r91;
	setp.ge.s32 	%p19, %r1, %r88;
	@%p19 bra 	$L__BB4_261;

	mul.lo.s32 	%r92, %r85, %r85;
	mul.lo.s32 	%r2, %r92, %r1;
	setp.lt.s32 	%p20, %r85, 1;
	mov.f32 	%f1721, 0f00000000;
	mov.f32 	%f1712, %f1721;
	mov.f32 	%f1713, %f1721;
	mov.f32 	%f1714, %f1721;
	@%p20 bra 	$L__BB4_11;

	add.s32 	%r3, %r85, -1;
	and.b32  	%r4, %r85, 3;
	sub.s32 	%r5, %r85, %r4;
	shl.b32 	%r6, %r85, 2;
	mov.u32 	%r93, 0;
	setp.lt.u32 	%p21, %r3, 3;
	setp.eq.s32 	%p23, %r4, 0;
	setp.eq.s32 	%p24, %r4, 1;
	setp.eq.s32 	%p25, %r4, 2;
	cvt.s64.s32 	%rd14, %r6;
	mov.u32 	%r511, %r93;

$L__BB4_3:
	cvt.rn.f32.s32 	%f4, %r511;
	mov.u32 	%r514, %r93;
	@%p21 bra 	$L__BB4_6;

	mov.u32 	%r514, %r93;
	mov.u32 	%r513, %r5;

$L__BB4_5:
	mad.lo.s32 	%r96, %r514, %r85, %r511;
	add.s32 	%r97, %r96, %r2;
	mul.wide.s32 	%rd12, %r97, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f32 	%f333, [%rd13];
	fma.rn.f32 	%f334, %f333, %f4, %f1712;
	cvt.rn.f32.s32 	%f335, %r514;
	fma.rn.f32 	%f336, %f333, %f335, %f1713;
	add.f32 	%f337, %f1714, %f333;
	add.s64 	%rd15, %rd13, %rd14;
	ld.global.f32 	%f338, [%rd15];
	fma.rn.f32 	%f339, %f338, %f4, %f334;
	add.s32 	%r98, %r514, 1;
	cvt.rn.f32.s32 	%f340, %r98;
	fma.rn.f32 	%f341, %f338, %f340, %f336;
	add.f32 	%f342, %f337, %f338;
	add.s64 	%rd16, %rd15, %rd14;
	ld.global.f32 	%f343, [%rd16];
	fma.rn.f32 	%f344, %f343, %f4, %f339;
	add.s32 	%r99, %r514, 2;
	cvt.rn.f32.s32 	%f345, %r99;
	fma.rn.f32 	%f346, %f343, %f345, %f341;
	add.f32 	%f347, %f342, %f343;
	add.s64 	%rd17, %rd16, %rd14;
	ld.global.f32 	%f348, [%rd17];
	fma.rn.f32 	%f1712, %f348, %f4, %f344;
	add.s32 	%r100, %r514, 3;
	cvt.rn.f32.s32 	%f349, %r100;
	fma.rn.f32 	%f1713, %f348, %f349, %f346;
	add.f32 	%f1714, %f347, %f348;
	add.s32 	%r514, %r514, 4;
	add.s32 	%r513, %r513, -4;
	setp.ne.s32 	%p22, %r513, 0;
	@%p22 bra 	$L__BB4_5;

$L__BB4_6:
	@%p23 bra 	$L__BB4_10;

	mad.lo.s32 	%r13, %r514, %r85, %r511;
	add.s32 	%r101, %r13, %r2;
	mul.wide.s32 	%rd18, %r101, 4;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.f32 	%f350, [%rd19];
	fma.rn.f32 	%f1712, %f350, %f4, %f1712;
	cvt.rn.f32.s32 	%f351, %r514;
	fma.rn.f32 	%f1713, %f350, %f351, %f1713;
	add.f32 	%f1714, %f1714, %f350;
	@%p24 bra 	$L__BB4_10;

	add.s32 	%r14, %r13, %r85;
	add.s32 	%r102, %r14, %r2;
	mul.wide.s32 	%rd20, %r102, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.f32 	%f352, [%rd21];
	fma.rn.f32 	%f1712, %f352, %f4, %f1712;
	add.s32 	%r103, %r514, 1;
	cvt.rn.f32.s32 	%f353, %r103;
	fma.rn.f32 	%f1713, %f352, %f353, %f1713;
	add.f32 	%f1714, %f1714, %f352;
	@%p25 bra 	$L__BB4_10;

	add.s32 	%r104, %r514, 2;
	add.s32 	%r105, %r14, %r85;
	add.s32 	%r106, %r105, %r2;
	mul.wide.s32 	%rd22, %r106, 4;
	add.s64 	%rd23, %rd1, %rd22;
	ld.global.f32 	%f354, [%rd23];
	fma.rn.f32 	%f1712, %f354, %f4, %f1712;
	cvt.rn.f32.s32 	%f355, %r104;
	fma.rn.f32 	%f1713, %f354, %f355, %f1713;
	add.f32 	%f1714, %f1714, %f354;

$L__BB4_10:
	add.s32 	%r511, %r511, 1;
	setp.lt.s32 	%p26, %r511, %r85;
	@%p26 bra 	$L__BB4_3;

$L__BB4_11:
	div.rn.f32 	%f1777, %f1712, %f1714;
	div.rn.f32 	%f1776, %f1713, %f1714;
	mov.f32 	%f358, 0f3F000000;
	div.rn.f32 	%f359, %f358, %f325;
	div.rn.f32 	%f34, %f359, %f325;
	mov.f32 	%f1774, 0f51BA43B7;
	@%p20 bra 	$L__BB4_51;

	cvt.f64.f32 	%fd1, %f34;
	mov.f64 	%fd128, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd128;
	}
	and.b32  	%r17, %r16, 2146435072;
	and.b32  	%r18, %r16, 2147483647;
	setp.gt.s32 	%p28, %r16, -1;
	selp.b32 	%r19, 2146435072, 0, %p28;
	mov.u32 	%r107, 0;
	or.b32  	%r20, %r19, -2147483648;
	mul.wide.s32 	%rd24, %r2, 4;
	add.s64 	%rd2, %rd1, %rd24;
	setp.eq.s32 	%p30, %r17, 1062207488;
	setp.lt.s32 	%p31, %r16, 0;
	setp.ne.s32 	%p36, %r18, 1071644672;
	setp.eq.s32 	%p63, %r18, 2146435072;
	mov.u32 	%r515, %r107;

$L__BB4_13:
	mov.u32 	%r516, %r107;

$L__BB4_14:
	mov.u32 	%r110, 1;
	sub.s32 	%r24, %r110, %r516;
	mov.f32 	%f1724, 0f00000000;
	mov.f32 	%f1725, %f1724;
	mov.u32 	%r517, %r107;

$L__BB4_15:
	add.s32 	%r519, %r516, -1;
	sub.s32 	%r26, %r517, %r515;
	cvt.rn.f32.s32 	%f364, %r26;
	cvt.f64.f32 	%fd2, %f364;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd2;
	}
	abs.f64 	%fd129, %fd2;
	{ // callseq 87, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd129;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd128;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 87
	setp.lt.s32 	%p29, %r27, 0;
	and.pred  	%p1, %p29, %p30;
	selp.b32 	%r112, %r27, 0, %p30;
	or.b32  	%r113, %r112, 2146435072;
	selp.b32 	%r28, %r113, %r112, %p31;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd4;
	}
	and.b32  	%r29, %r114, 2146435072;
	setp.ne.s32 	%p32, %r29, 2146435072;
	setp.gtu.f64 	%p33, %fd129, 0d7FF0000000000000;
	setp.gt.f64 	%p34, %fd129, 0d3FF0000000000000;
	selp.b32 	%r115, 2146435072, 0, %p34;
	xor.b32  	%r116, %r115, 2146435072;
	selp.b32 	%r117, %r116, %r115, %p31;
	setp.eq.s32 	%p35, %r26, -1;
	selp.b32 	%r30, 1072693248, %r117, %p35;
	and.b32  	%r31, %r27, 2147483647;
	and.pred  	%p37, %p36, %p1;
	selp.b32 	%r32, %r20, %r19, %p37;
	or.pred  	%p2, %p32, %p33;
	mul.lo.s32 	%r118, %r85, %r517;
	mul.wide.s32 	%rd25, %r118, 4;
	add.s64 	%rd55, %rd2, %rd25;
	mov.u32 	%r518, %r24;
	mov.u32 	%r520, %r107;

$L__BB4_16:
	not.pred 	%p38, %p1;
	mov.f64 	%fd327, %fd3;
	@%p38 bra 	$L__BB4_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r119}, %fd3;
	}
	xor.b32  	%r120, %r119, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd3;
	}
	mov.b64 	%fd327, {%r121, %r120};

$L__BB4_18:
	setp.eq.s32 	%p39, %r26, 0;
	@%p39 bra 	$L__BB4_22;

	setp.gt.s32 	%p40, %r27, -1;
	@%p40 bra 	$L__BB4_23;

	cvt.rzi.f64.f64 	%fd132, %fd128;
	setp.eq.f64 	%p41, %fd132, 0d4000000000000000;
	@%p41 bra 	$L__BB4_23;

	mov.f64 	%fd327, 0dFFF8000000000000;
	bra.uni 	$L__BB4_23;

$L__BB4_22:
	mov.u32 	%r122, 0;
	mov.b64 	%fd327, {%r122, %r28};

$L__BB4_23:
	selp.f64 	%fd328, %fd327, %fd4, %p32;
	@%p2 bra 	$L__BB4_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd128;
	}
	setp.eq.s32 	%p44, %r123, 0;
	and.pred  	%p45, %p63, %p44;
	@%p45 bra 	$L__BB4_27;
	bra.uni 	$L__BB4_25;

$L__BB4_27:
	mov.u32 	%r126, 0;
	mov.b64 	%fd328, {%r126, %r30};
	bra.uni 	$L__BB4_28;

$L__BB4_25:
	setp.ne.s32 	%p46, %r31, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd2;
	}
	setp.ne.s32 	%p47, %r124, 0;
	or.pred  	%p48, %p46, %p47;
	mov.f64 	%fd328, %fd327;
	@%p48 bra 	$L__BB4_28;

	mov.u32 	%r125, 0;
	mov.b64 	%fd328, {%r125, %r32};

$L__BB4_28:
	setp.eq.s32 	%p49, %r26, 1;
	selp.f64 	%fd135, 0d3FF0000000000000, %fd328, %p49;
	mov.f64 	%fd136, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd135, %fd1;
	neg.f64 	%fd137, %fd13;
	mov.f64 	%fd138, 0d4338000000000000;
	mov.f64 	%fd139, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd140, %fd137, %fd139, %fd138;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd140;
	}
	mov.f64 	%fd141, 0dC338000000000000;
	add.rn.f64 	%fd142, %fd140, %fd141;
	mov.f64 	%fd143, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd144, %fd142, %fd143, %fd137;
	mov.f64 	%fd145, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd146, %fd142, %fd145, %fd144;
	mov.f64 	%fd147, 0d3E928AF3FCA213EA;
	mov.f64 	%fd148, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd149, %fd148, %fd146, %fd147;
	mov.f64 	%fd150, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd151, %fd149, %fd146, %fd150;
	mov.f64 	%fd152, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd153, %fd151, %fd146, %fd152;
	mov.f64 	%fd154, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd155, %fd153, %fd146, %fd154;
	mov.f64 	%fd156, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd157, %fd155, %fd146, %fd156;
	mov.f64 	%fd158, 0d3F81111111122322;
	fma.rn.f64 	%fd159, %fd157, %fd146, %fd158;
	mov.f64 	%fd160, 0d3FA55555555502A1;
	fma.rn.f64 	%fd161, %fd159, %fd146, %fd160;
	mov.f64 	%fd162, 0d3FC5555555555511;
	fma.rn.f64 	%fd163, %fd161, %fd146, %fd162;
	mov.f64 	%fd164, 0d3FE000000000000B;
	fma.rn.f64 	%fd165, %fd163, %fd146, %fd164;
	fma.rn.f64 	%fd166, %fd165, %fd146, %fd136;
	fma.rn.f64 	%fd167, %fd166, %fd146, %fd136;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd167;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd167;
	}
	shl.b32 	%r127, %r36, 20;
	add.s32 	%r128, %r38, %r127;
	mov.b64 	%fd329, {%r37, %r128};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd137;
	}
	mov.b32 	%f365, %r129;
	abs.f32 	%f43, %f365;
	setp.lt.f32 	%p50, %f43, 0f4086232B;
	@%p50 bra 	$L__BB4_31;

	setp.gt.f64 	%p51, %fd13, 0d8000000000000000;
	mov.f64 	%fd168, 0d7FF0000000000000;
	sub.f64 	%fd169, %fd168, %fd13;
	selp.f64 	%fd329, 0d0000000000000000, %fd169, %p51;
	setp.geu.f32 	%p52, %f43, 0f40874800;
	@%p52 bra 	$L__BB4_31;

	shr.u32 	%r130, %r36, 31;
	add.s32 	%r131, %r36, %r130;
	shr.s32 	%r132, %r131, 1;
	shl.b32 	%r133, %r132, 20;
	add.s32 	%r134, %r38, %r133;
	mov.b64 	%fd170, {%r37, %r134};
	sub.s32 	%r135, %r36, %r132;
	shl.b32 	%r136, %r135, 20;
	add.s32 	%r137, %r136, 1072693248;
	mov.u32 	%r138, 0;
	mov.b64 	%fd171, {%r138, %r137};
	mul.f64 	%fd329, %fd170, %fd171;

$L__BB4_31:
	add.s32 	%r139, %r519, 1;
	cvt.rn.f32.s32 	%f366, %r139;
	cvt.f64.f32 	%fd18, %f366;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 88, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd128;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd331, [retval0+0];
	} // callseq 88
	setp.lt.s32 	%p53, %r39, 0;
	and.pred  	%p3, %p53, %p30;
	not.pred 	%p55, %p3;
	@%p55 bra 	$L__BB4_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd331;
	}
	xor.b32  	%r141, %r140, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd331;
	}
	mov.b64 	%fd331, {%r142, %r141};

$L__BB4_33:
	setp.eq.s32 	%p56, %r518, 1;
	@%p56 bra 	$L__BB4_37;
	bra.uni 	$L__BB4_34;

$L__BB4_37:
	mov.u32 	%r143, 0;
	selp.b32 	%r144, %r39, 0, %p30;
	or.b32  	%r145, %r144, 2146435072;
	selp.b32 	%r146, %r145, %r144, %p31;
	mov.b64 	%fd331, {%r143, %r146};
	bra.uni 	$L__BB4_38;

$L__BB4_34:
	setp.gt.s32 	%p57, %r39, -1;
	@%p57 bra 	$L__BB4_38;

	cvt.rzi.f64.f64 	%fd174, %fd128;
	setp.eq.f64 	%p58, %fd174, 0d4000000000000000;
	@%p58 bra 	$L__BB4_38;

	mov.f64 	%fd331, 0dFFF8000000000000;

$L__BB4_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd25;
	}
	and.b32  	%r148, %r147, 2146435072;
	setp.ne.s32 	%p61, %r148, 2146435072;
	mov.f64 	%fd332, %fd331;
	@%p61 bra 	$L__BB4_44;

	setp.gtu.f64 	%p62, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd332, %fd25;
	@%p62 bra 	$L__BB4_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r149, %temp}, %fd128;
	}
	setp.eq.s32 	%p64, %r149, 0;
	and.pred  	%p65, %p63, %p64;
	@%p65 bra 	$L__BB4_43;
	bra.uni 	$L__BB4_41;

$L__BB4_43:
	mov.u32 	%r154, 0;
	setp.gt.f64 	%p72, %fd19, 0d3FF0000000000000;
	selp.b32 	%r155, 2146435072, 0, %p72;
	xor.b32  	%r156, %r155, 2146435072;
	selp.b32 	%r157, %r156, %r155, %p31;
	setp.eq.s32 	%p73, %r519, -2;
	selp.b32 	%r158, 1072693248, %r157, %p73;
	mov.b64 	%fd332, {%r154, %r158};
	bra.uni 	$L__BB4_44;

$L__BB4_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd18;
	}
	and.b32  	%r151, %r39, 2147483647;
	setp.ne.s32 	%p66, %r151, 2146435072;
	setp.ne.s32 	%p67, %r150, 0;
	or.pred  	%p68, %p66, %p67;
	mov.f64 	%fd332, %fd331;
	@%p68 bra 	$L__BB4_44;

	and.pred  	%p70, %p36, %p3;
	selp.b32 	%r152, %r20, %r19, %p70;
	mov.u32 	%r153, 0;
	mov.b64 	%fd332, {%r153, %r152};

$L__BB4_44:
	mov.f64 	%fd325, 0d3FF0000000000000;
	mov.f64 	%fd324, 0d3FE000000000000B;
	mov.f64 	%fd323, 0d3FC5555555555511;
	mov.f64 	%fd322, 0d3FA55555555502A1;
	mov.f64 	%fd321, 0d3F81111111122322;
	mov.f64 	%fd320, 0d3F56C16C1852B7AF;
	mov.f64 	%fd319, 0d3F2A01A014761F65;
	mov.f64 	%fd318, 0d3EFA01997C89EB71;
	mov.f64 	%fd317, 0d3EC71DEE62401315;
	mov.f64 	%fd316, 0d3E928AF3FCA213EA;
	mov.f64 	%fd315, 0d3E5ADE1569CE2BDF;
	mov.f64 	%fd314, 0dBC7ABC9E3B39803F;
	mov.f64 	%fd313, 0dBFE62E42FEFA39EF;
	mov.f64 	%fd312, 0dC338000000000000;
	mov.f64 	%fd311, 0d4338000000000000;
	mov.f64 	%fd310, 0d3FF71547652B82FE;
	setp.eq.s32 	%p74, %r519, 0;
	selp.f64 	%fd177, 0d3FF0000000000000, %fd332, %p74;
	mul.f64 	%fd29, %fd177, %fd1;
	neg.f64 	%fd179, %fd29;
	fma.rn.f64 	%fd182, %fd179, %fd310, %fd311;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd182;
	}
	add.rn.f64 	%fd184, %fd182, %fd312;
	fma.rn.f64 	%fd186, %fd184, %fd313, %fd179;
	fma.rn.f64 	%fd188, %fd184, %fd314, %fd186;
	fma.rn.f64 	%fd191, %fd315, %fd188, %fd316;
	fma.rn.f64 	%fd193, %fd191, %fd188, %fd317;
	fma.rn.f64 	%fd195, %fd193, %fd188, %fd318;
	fma.rn.f64 	%fd197, %fd195, %fd188, %fd319;
	fma.rn.f64 	%fd199, %fd197, %fd188, %fd320;
	fma.rn.f64 	%fd201, %fd199, %fd188, %fd321;
	fma.rn.f64 	%fd203, %fd201, %fd188, %fd322;
	fma.rn.f64 	%fd205, %fd203, %fd188, %fd323;
	fma.rn.f64 	%fd207, %fd205, %fd188, %fd324;
	fma.rn.f64 	%fd208, %fd207, %fd188, %fd325;
	fma.rn.f64 	%fd209, %fd208, %fd188, %fd325;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd209;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd209;
	}
	shl.b32 	%r159, %r40, 20;
	add.s32 	%r160, %r42, %r159;
	mov.b64 	%fd333, {%r41, %r160};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r161}, %fd179;
	}
	mov.b32 	%f367, %r161;
	abs.f32 	%f44, %f367;
	setp.lt.f32 	%p75, %f44, 0f4086232B;
	@%p75 bra 	$L__BB4_47;

	setp.gt.f64 	%p76, %fd29, 0d8000000000000000;
	mov.f64 	%fd210, 0d7FF0000000000000;
	sub.f64 	%fd211, %fd210, %fd29;
	selp.f64 	%fd333, 0d0000000000000000, %fd211, %p76;
	setp.geu.f32 	%p77, %f44, 0f40874800;
	@%p77 bra 	$L__BB4_47;

	shr.u32 	%r162, %r40, 31;
	add.s32 	%r163, %r40, %r162;
	shr.s32 	%r164, %r163, 1;
	shl.b32 	%r165, %r164, 20;
	add.s32 	%r166, %r42, %r165;
	mov.b64 	%fd212, {%r41, %r166};
	sub.s32 	%r167, %r40, %r164;
	shl.b32 	%r168, %r167, 20;
	add.s32 	%r169, %r168, 1072693248;
	mov.u32 	%r170, 0;
	mov.b64 	%fd213, {%r170, %r169};
	mul.f64 	%fd333, %fd212, %fd213;

$L__BB4_47:
	ld.global.f32 	%f368, [%rd55];
	cvt.f64.f32 	%fd214, %f368;
	mul.f64 	%fd215, %fd329, %fd333;
	cvt.f64.f32 	%fd216, %f1725;
	fma.rn.f64 	%fd217, %fd215, %fd214, %fd216;
	cvt.rn.f32.f64 	%f1725, %fd217;
	cvt.f64.f32 	%fd218, %f1724;
	add.f64 	%fd219, %fd215, %fd218;
	cvt.rn.f32.f64 	%f1724, %fd219;
	add.s32 	%r519, %r519, -1;
	add.s32 	%r518, %r518, 1;
	add.s64 	%rd55, %rd55, 4;
	add.s32 	%r520, %r520, 1;
	setp.lt.s32 	%p78, %r520, %r85;
	@%p78 bra 	$L__BB4_16;

	add.s32 	%r517, %r517, 1;
	setp.lt.s32 	%p79, %r517, %r85;
	@%p79 bra 	$L__BB4_15;

	div.rn.f32 	%f369, %f1725, %f1724;
	max.f32 	%f1721, %f1721, %f369;
	min.f32 	%f1774, %f1774, %f369;
	add.s32 	%r516, %r516, 1;
	setp.lt.s32 	%p80, %r516, %r85;
	@%p80 bra 	$L__BB4_14;

	add.s32 	%r515, %r515, 1;
	setp.lt.s32 	%p81, %r515, %r85;
	@%p81 bra 	$L__BB4_13;

$L__BB4_51:
	ld.param.u32 	%r508, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_6];
	mov.f32 	%f1699, 0f00000000;
	sub.f32 	%f371, %f1721, %f1774;
	add.f32 	%f372, %f371, %f371;
	fma.rn.f32 	%f373, %f371, 0f40000000, %f372;
	mul.f32 	%f374, %f373, 0f40490FD8;
	mul.f32 	%f375, %f374, %f325;
	mul.f32 	%f376, %f375, %f325;
	max.f32 	%f1775, %f1699, %f376;
	setp.lt.s32 	%p82, %r508, 1;
	@%p82 bra 	$L__BB4_205;

	ld.param.u32 	%r509, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_5];
	cvt.rn.f32.s32 	%f52, %r509;
	cvt.f64.f32 	%fd220, %f325;
	add.f64 	%fd34, %fd220, 0d4008000000000000;
	mov.u32 	%r521, 0;
	cvta.to.global.u64 	%rd26, %rd6;
	mov.f64 	%fd222, 0d4008000000000000;
	abs.f64 	%fd223, %fd220;
	setp.gtu.f64 	%p101, %fd223, 0d7FF0000000000000;
	setp.gt.f64 	%p102, %fd223, 0d3FF0000000000000;
	setp.eq.f32 	%p103, %f325, 0fBF800000;
	cvta.to.global.u64 	%rd31, %rd7;

$L__BB4_53:
	mov.f32 	%f1741, 0f00000000;
	mov.f32 	%f1742, %f1741;
	mov.f32 	%f1743, %f1741;
	mov.f32 	%f1744, %f1741;
	mov.f32 	%f1745, %f1741;
	mov.f32 	%f1746, %f1741;
	mov.f32 	%f1747, %f1741;
	mov.f32 	%f1748, %f1741;
	@%p20 bra 	$L__BB4_204;

	mov.f32 	%f1741, 0f00000000;
	div.rn.f32 	%f395, %f1775, 0fC0206C98;
	div.rn.f32 	%f58, %f395, %f325;
	cvt.f64.f32 	%fd35, %f395;
	shl.b32 	%r177, %r1, 1;
	mul.wide.s32 	%rd27, %r177, 4;
	add.s64 	%rd28, %rd26, %rd27;
	ld.global.f32 	%f59, [%rd28+4];
	ld.global.f32 	%f60, [%rd28];
	mov.u32 	%r522, 0;

$L__BB4_55:
	mov.u32 	%r523, 0;
	mov.f32 	%f1646, 0f00000000;
	cvt.rn.f32.s32 	%f69, %r522;
	sub.f32 	%f396, %f69, %f1777;
	add.f32 	%f397, %f396, 0f3F000000;
	sqrt.rn.f32 	%f70, %f34;
	mul.f32 	%f398, %f70, %f397;
	abs.f32 	%f71, %f398;
	setp.ge.f32 	%p84, %f71, 0f3F8060FE;
	mul.f32 	%f399, %f398, %f398;
	selp.f32 	%f400, %f71, %f399, %p84;
	selp.f32 	%f401, 0f3789CA3C, 0f38B1E96A, %p84;
	selp.f32 	%f402, 0fB9F560B9, 0fBA574D20, %p84;
	fma.rn.f32 	%f403, %f401, %f400, %f402;
	selp.f32 	%f404, 0f3BAC840B, 0f3BAAD5EA, %p84;
	fma.rn.f32 	%f405, %f403, %f400, %f404;
	selp.f32 	%f406, 0fBD0C8162, 0fBCDC1BE7, %p84;
	fma.rn.f32 	%f407, %f405, %f400, %f406;
	selp.f32 	%f408, 0f3E1CF906, 0f3DE718AF, %p84;
	fma.rn.f32 	%f409, %f407, %f400, %f408;
	selp.f32 	%f410, 0f3F6A937E, 0fBEC093AC, %p84;
	fma.rn.f32 	%f411, %f409, %f400, %f410;
	selp.f32 	%f412, 0f3F20D842, 0f3E0375D3, %p84;
	fma.rn.f32 	%f413, %f411, %f400, %f412;
	neg.f32 	%f414, %f71;
	selp.f32 	%f415, %f414, %f398, %p84;
	fma.rn.f32 	%f72, %f413, %f415, %f415;
	mov.b32 	%r179, %f398;
	and.b32  	%r51, %r179, -2147483648;
	add.f32 	%f73, %f396, 0fBF000000;
	mul.f32 	%f416, %f70, %f73;
	abs.f32 	%f74, %f416;
	setp.ge.f32 	%p85, %f74, 0f3F8060FE;
	mul.f32 	%f417, %f416, %f416;
	selp.f32 	%f418, %f74, %f417, %p85;
	selp.f32 	%f419, 0f3789CA3C, 0f38B1E96A, %p85;
	selp.f32 	%f420, 0fB9F560B9, 0fBA574D20, %p85;
	fma.rn.f32 	%f421, %f419, %f418, %f420;
	selp.f32 	%f422, 0f3BAC840B, 0f3BAAD5EA, %p85;
	fma.rn.f32 	%f423, %f421, %f418, %f422;
	selp.f32 	%f424, 0fBD0C8162, 0fBCDC1BE7, %p85;
	fma.rn.f32 	%f425, %f423, %f418, %f424;
	selp.f32 	%f426, 0f3E1CF906, 0f3DE718AF, %p85;
	fma.rn.f32 	%f427, %f425, %f418, %f426;
	selp.f32 	%f428, 0f3F6A937E, 0fBEC093AC, %p85;
	fma.rn.f32 	%f429, %f427, %f418, %f428;
	selp.f32 	%f430, 0f3F20D842, 0f3E0375D3, %p85;
	fma.rn.f32 	%f431, %f429, %f418, %f430;
	neg.f32 	%f432, %f74;
	selp.f32 	%f433, %f432, %f416, %p85;
	fma.rn.f32 	%f75, %f431, %f433, %f433;
	mov.b32 	%r180, %f416;
	and.b32  	%r52, %r180, -2147483648;
	add.f32 	%f434, %f69, 0f3F000000;
	sub.f32 	%f76, %f434, %f1777;
	div.rn.f32 	%f77, %f76, %f325;
	mov.f32 	%f435, 0f3F800000;
	cvt.rzi.f32.f32 	%f436, %f435;
	add.f32 	%f437, %f436, %f436;
	mov.f32 	%f438, 0f40000000;
	sub.f32 	%f439, %f438, %f437;
	abs.f32 	%f78, %f439;
	setp.eq.f32 	%p86, %f78, 0f3F800000;
	abs.f32 	%f79, %f77;
	setp.lt.f32 	%p87, %f79, 0f00800000;
	mul.f32 	%f440, %f79, 0f4B800000;
	selp.f32 	%f441, %f440, %f79, %p87;
	selp.f32 	%f442, 0fC3170000, 0fC2FE0000, %p87;
	mov.b32 	%r181, %f441;
	and.b32  	%r182, %r181, 8388607;
	or.b32  	%r183, %r182, 1065353216;
	mov.b32 	%f443, %r183;
	shr.u32 	%r184, %r181, 23;
	cvt.rn.f32.u32 	%f444, %r184;
	add.f32 	%f445, %f442, %f444;
	setp.gt.f32 	%p88, %f443, 0f3FB504F3;
	mul.f32 	%f446, %f443, 0f3F000000;
	add.f32 	%f447, %f445, 0f3F800000;
	selp.f32 	%f448, %f447, %f445, %p88;
	selp.f32 	%f449, %f446, %f443, %p88;
	add.f32 	%f450, %f449, 0fBF800000;
	add.f32 	%f451, %f449, 0f3F800000;
	rcp.approx.ftz.f32 	%f452, %f451;
	add.f32 	%f453, %f450, %f450;
	mul.f32 	%f454, %f453, %f452;
	mul.f32 	%f455, %f454, %f454;
	mov.f32 	%f456, 0f3C4CAF63;
	mov.f32 	%f457, 0f3B18F0FE;
	fma.rn.f32 	%f458, %f457, %f455, %f456;
	mov.f32 	%f459, 0f3DAAAABD;
	fma.rn.f32 	%f460, %f458, %f455, %f459;
	mul.rn.f32 	%f461, %f460, %f455;
	mul.rn.f32 	%f462, %f461, %f454;
	sub.f32 	%f463, %f450, %f454;
	add.f32 	%f464, %f463, %f463;
	neg.f32 	%f465, %f454;
	fma.rn.f32 	%f466, %f465, %f450, %f464;
	mul.rn.f32 	%f467, %f452, %f466;
	add.f32 	%f468, %f462, %f454;
	sub.f32 	%f469, %f454, %f468;
	add.f32 	%f470, %f462, %f469;
	add.f32 	%f471, %f467, %f470;
	add.f32 	%f472, %f468, %f471;
	sub.f32 	%f473, %f468, %f472;
	add.f32 	%f474, %f471, %f473;
	mov.f32 	%f475, 0f3F317200;
	mul.rn.f32 	%f476, %f448, %f475;
	mov.f32 	%f477, 0f35BFBE8E;
	mul.rn.f32 	%f478, %f448, %f477;
	add.f32 	%f479, %f476, %f472;
	sub.f32 	%f480, %f476, %f479;
	add.f32 	%f481, %f472, %f480;
	add.f32 	%f482, %f474, %f481;
	add.f32 	%f483, %f478, %f482;
	add.f32 	%f484, %f479, %f483;
	sub.f32 	%f485, %f479, %f484;
	add.f32 	%f486, %f483, %f485;
	mul.rn.f32 	%f487, %f438, %f484;
	neg.f32 	%f488, %f487;
	fma.rn.f32 	%f489, %f438, %f484, %f488;
	fma.rn.f32 	%f490, %f438, %f486, %f489;
	fma.rn.f32 	%f492, %f1646, %f484, %f490;
	add.rn.f32 	%f493, %f487, %f492;
	neg.f32 	%f494, %f493;
	add.rn.f32 	%f495, %f487, %f494;
	add.rn.f32 	%f496, %f495, %f492;
	mov.b32 	%r185, %f493;
	setp.eq.s32 	%p89, %r185, 1118925336;
	add.s32 	%r186, %r185, -1;
	mov.b32 	%f497, %r186;
	add.f32 	%f498, %f496, 0f37000000;
	selp.f32 	%f80, %f498, %f496, %p89;
	selp.f32 	%f499, %f497, %f493, %p89;
	mov.f32 	%f500, 0f3FB8AA3B;
	mul.rn.f32 	%f501, %f499, %f500;
	cvt.rzi.f32.f32 	%f502, %f501;
	abs.f32 	%f503, %f502;
	setp.gt.f32 	%p90, %f503, 0f42FC0000;
	mov.b32 	%r187, %f502;
	and.b32  	%r188, %r187, -2147483648;
	or.b32  	%r189, %r188, 1123811328;
	mov.b32 	%f504, %r189;
	selp.f32 	%f505, %f504, %f502, %p90;
	mov.f32 	%f506, 0fBF317218;
	fma.rn.f32 	%f507, %f505, %f506, %f499;
	mov.f32 	%f508, 0f3102E308;
	fma.rn.f32 	%f509, %f505, %f508, %f507;
	mul.f32 	%f510, %f509, 0f3FB8AA3B;
	add.f32 	%f511, %f505, 0f4B40007F;
	mov.b32 	%r190, %f511;
	shl.b32 	%r191, %r190, 23;
	mov.b32 	%f512, %r191;
	ex2.approx.ftz.f32 	%f513, %f510;
	mul.f32 	%f81, %f513, %f512;
	setp.lt.f32 	%p91, %f77, 0f00000000;
	and.pred  	%p4, %p91, %p86;
	add.f32 	%f514, %f77, %f77;
	selp.f32 	%f82, %f514, 0f00000000, %p86;
	div.rn.f32 	%f83, %f73, %f325;
	abs.f32 	%f84, %f83;
	setp.lt.f32 	%p92, %f84, 0f00800000;
	mul.f32 	%f516, %f84, 0f4B800000;
	selp.f32 	%f517, %f516, %f84, %p92;
	selp.f32 	%f518, 0fC3170000, 0fC2FE0000, %p92;
	mov.b32 	%r192, %f517;
	and.b32  	%r193, %r192, 8388607;
	or.b32  	%r194, %r193, 1065353216;
	mov.b32 	%f519, %r194;
	shr.u32 	%r195, %r192, 23;
	cvt.rn.f32.u32 	%f520, %r195;
	add.f32 	%f521, %f518, %f520;
	setp.gt.f32 	%p93, %f519, 0f3FB504F3;
	mul.f32 	%f522, %f519, 0f3F000000;
	add.f32 	%f523, %f521, 0f3F800000;
	selp.f32 	%f524, %f523, %f521, %p93;
	selp.f32 	%f525, %f522, %f519, %p93;
	add.f32 	%f526, %f525, 0fBF800000;
	add.f32 	%f527, %f525, 0f3F800000;
	rcp.approx.ftz.f32 	%f528, %f527;
	add.f32 	%f529, %f526, %f526;
	mul.f32 	%f530, %f529, %f528;
	mul.f32 	%f531, %f530, %f530;
	fma.rn.f32 	%f532, %f457, %f531, %f456;
	fma.rn.f32 	%f533, %f532, %f531, %f459;
	mul.rn.f32 	%f534, %f533, %f531;
	mul.rn.f32 	%f535, %f534, %f530;
	sub.f32 	%f536, %f526, %f530;
	add.f32 	%f537, %f536, %f536;
	neg.f32 	%f538, %f530;
	fma.rn.f32 	%f539, %f538, %f526, %f537;
	mul.rn.f32 	%f540, %f528, %f539;
	add.f32 	%f541, %f535, %f530;
	sub.f32 	%f542, %f530, %f541;
	add.f32 	%f543, %f535, %f542;
	add.f32 	%f544, %f540, %f543;
	add.f32 	%f545, %f541, %f544;
	sub.f32 	%f546, %f541, %f545;
	add.f32 	%f547, %f544, %f546;
	mul.rn.f32 	%f548, %f524, %f475;
	mul.rn.f32 	%f549, %f524, %f477;
	add.f32 	%f550, %f548, %f545;
	sub.f32 	%f551, %f548, %f550;
	add.f32 	%f552, %f545, %f551;
	add.f32 	%f553, %f547, %f552;
	add.f32 	%f554, %f549, %f553;
	add.f32 	%f555, %f550, %f554;
	sub.f32 	%f556, %f550, %f555;
	add.f32 	%f557, %f554, %f556;
	mul.rn.f32 	%f558, %f438, %f555;
	neg.f32 	%f559, %f558;
	fma.rn.f32 	%f560, %f438, %f555, %f559;
	fma.rn.f32 	%f561, %f438, %f557, %f560;
	fma.rn.f32 	%f562, %f1646, %f555, %f561;
	add.rn.f32 	%f563, %f558, %f562;
	neg.f32 	%f564, %f563;
	add.rn.f32 	%f565, %f558, %f564;
	add.rn.f32 	%f566, %f565, %f562;
	mov.b32 	%r196, %f563;
	setp.eq.s32 	%p94, %r196, 1118925336;
	add.s32 	%r197, %r196, -1;
	mov.b32 	%f567, %r197;
	add.f32 	%f568, %f566, 0f37000000;
	selp.f32 	%f85, %f568, %f566, %p94;
	selp.f32 	%f569, %f567, %f563, %p94;
	mul.rn.f32 	%f570, %f569, %f500;
	cvt.rzi.f32.f32 	%f571, %f570;
	abs.f32 	%f572, %f571;
	setp.gt.f32 	%p95, %f572, 0f42FC0000;
	mov.b32 	%r198, %f571;
	and.b32  	%r199, %r198, -2147483648;
	or.b32  	%r200, %r199, 1123811328;
	mov.b32 	%f573, %r200;
	selp.f32 	%f574, %f573, %f571, %p95;
	fma.rn.f32 	%f575, %f574, %f506, %f569;
	fma.rn.f32 	%f576, %f574, %f508, %f575;
	mul.f32 	%f577, %f576, 0f3FB8AA3B;
	add.f32 	%f578, %f574, 0f4B40007F;
	mov.b32 	%r201, %f578;
	shl.b32 	%r202, %r201, 23;
	mov.b32 	%f579, %r202;
	ex2.approx.ftz.f32 	%f580, %f577;
	mul.f32 	%f86, %f580, %f579;
	setp.lt.f32 	%p96, %f83, 0f00000000;
	and.pred  	%p5, %p96, %p86;
	add.f32 	%f581, %f83, %f83;
	selp.f32 	%f87, %f581, 0f00000000, %p86;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd220;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r203}, %fd222;
	}
	and.b32  	%r204, %r203, 2146435072;
	setp.eq.s32 	%p97, %r204, 1073741824;
	{ // callseq 89, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd223;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd222;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd36, [retval0+0];
	} // callseq 89
	setp.lt.s32 	%p98, %r55, 0;
	and.pred  	%p6, %p98, %p97;
	selp.b32 	%r205, %r55, 0, %p97;
	setp.lt.s32 	%p99, %r203, 0;
	or.b32  	%r206, %r205, 2146435072;
	selp.b32 	%r56, %r206, %r205, %p99;
	and.b32  	%r58, %r203, 2147483647;
	setp.gt.s32 	%p104, %r203, -1;
	selp.b32 	%r211, 2146435072, 0, %p104;
	setp.ne.s32 	%p105, %r58, 1071644672;
	and.pred  	%p106, %p105, %p6;
	or.b32  	%r212, %r211, -2147483648;
	selp.b32 	%r60, %r212, %r211, %p106;
	mov.f64 	%fd224, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd224;
	}
	and.b32  	%r63, %r61, 2147483647;
	setp.gt.s32 	%p107, %r61, -1;
	selp.b32 	%r64, 2146435072, 0, %p107;
	or.b32  	%r65, %r64, -2147483648;

$L__BB4_56:
	cvt.rn.f32.s32 	%f1651, %r522;
	sub.f32 	%f1650, %f1651, %f1777;
	add.f32 	%f1649, %f1650, 0f3F000000;
	mul.f32 	%f1648, %f70, %f1649;
	abs.f32 	%f1647, %f1648;
	setp.ltu.f32 	%p108, %f1647, 0f3F8060FE;
	mov.f32 	%f1749, %f72;
	@%p108 bra 	$L__BB4_58;

	mov.f32 	%f1691, 0f3F800000;
	ex2.approx.ftz.f32 	%f583, %f72;
	sub.f32 	%f585, %f1691, %f583;
	mov.b32 	%r214, %f585;
	or.b32  	%r215, %r51, %r214;
	mov.b32 	%f1749, %r215;

$L__BB4_58:
	cvt.rn.f32.s32 	%f1656, %r522;
	sub.f32 	%f1655, %f1656, %f1777;
	add.f32 	%f1654, %f1655, 0fBF000000;
	mul.f32 	%f1653, %f70, %f1654;
	abs.f32 	%f1652, %f1653;
	setp.ltu.f32 	%p109, %f1652, 0f3F8060FE;
	mov.f32 	%f1750, %f75;
	@%p109 bra 	$L__BB4_60;

	mov.f32 	%f1690, 0f3F800000;
	ex2.approx.ftz.f32 	%f586, %f75;
	sub.f32 	%f588, %f1690, %f586;
	mov.b32 	%r216, %f588;
	or.b32  	%r217, %r52, %r216;
	mov.b32 	%f1750, %r217;

$L__BB4_60:
	sub.f32 	%f589, %f1749, %f1750;
	mul.f32 	%f101, %f589, 0f3F000000;
	cvt.rn.f32.s32 	%f102, %r523;
	sub.f32 	%f103, %f102, %f1776;
	add.f32 	%f590, %f103, 0f3F000000;
	mul.f32 	%f104, %f70, %f590;
	abs.f32 	%f591, %f104;
	setp.ltu.f32 	%p110, %f591, 0f3F8060FE;
	setp.ge.f32 	%p111, %f591, 0f3F8060FE;
	mul.f32 	%f592, %f104, %f104;
	selp.f32 	%f593, %f591, %f592, %p111;
	selp.f32 	%f594, 0f3789CA3C, 0f38B1E96A, %p111;
	selp.f32 	%f595, 0fB9F560B9, 0fBA574D20, %p111;
	fma.rn.f32 	%f596, %f594, %f593, %f595;
	selp.f32 	%f597, 0f3BAC840B, 0f3BAAD5EA, %p111;
	fma.rn.f32 	%f598, %f596, %f593, %f597;
	selp.f32 	%f599, 0fBD0C8162, 0fBCDC1BE7, %p111;
	fma.rn.f32 	%f600, %f598, %f593, %f599;
	selp.f32 	%f601, 0f3E1CF906, 0f3DE718AF, %p111;
	fma.rn.f32 	%f602, %f600, %f593, %f601;
	selp.f32 	%f603, 0f3F6A937E, 0fBEC093AC, %p111;
	fma.rn.f32 	%f604, %f602, %f593, %f603;
	selp.f32 	%f605, 0f3F20D842, 0f3E0375D3, %p111;
	fma.rn.f32 	%f606, %f604, %f593, %f605;
	neg.f32 	%f607, %f591;
	selp.f32 	%f608, %f607, %f104, %p111;
	fma.rn.f32 	%f1751, %f606, %f608, %f608;
	@%p110 bra 	$L__BB4_62;

	mov.f32 	%f1689, 0f3F800000;
	ex2.approx.ftz.f32 	%f609, %f1751;
	sub.f32 	%f611, %f1689, %f609;
	mov.b32 	%r218, %f611;
	mov.b32 	%r219, %f104;
	and.b32  	%r220, %r219, -2147483648;
	or.b32  	%r221, %r220, %r218;
	mov.b32 	%f1751, %r221;

$L__BB4_62:
	cvt.rn.f32.s32 	%f1658, %r523;
	sub.f32 	%f1657, %f1658, %f1776;
	add.f32 	%f108, %f1657, 0fBF000000;
	mul.f32 	%f109, %f70, %f108;
	abs.f32 	%f612, %f109;
	setp.ltu.f32 	%p112, %f612, 0f3F8060FE;
	setp.ge.f32 	%p113, %f612, 0f3F8060FE;
	mul.f32 	%f613, %f109, %f109;
	selp.f32 	%f614, %f612, %f613, %p113;
	selp.f32 	%f615, 0f3789CA3C, 0f38B1E96A, %p113;
	selp.f32 	%f616, 0fB9F560B9, 0fBA574D20, %p113;
	fma.rn.f32 	%f617, %f615, %f614, %f616;
	selp.f32 	%f618, 0f3BAC840B, 0f3BAAD5EA, %p113;
	fma.rn.f32 	%f619, %f617, %f614, %f618;
	selp.f32 	%f620, 0fBD0C8162, 0fBCDC1BE7, %p113;
	fma.rn.f32 	%f621, %f619, %f614, %f620;
	selp.f32 	%f622, 0f3E1CF906, 0f3DE718AF, %p113;
	fma.rn.f32 	%f623, %f621, %f614, %f622;
	selp.f32 	%f624, 0f3F6A937E, 0fBEC093AC, %p113;
	fma.rn.f32 	%f625, %f623, %f614, %f624;
	selp.f32 	%f626, 0f3F20D842, 0f3E0375D3, %p113;
	fma.rn.f32 	%f627, %f625, %f614, %f626;
	neg.f32 	%f628, %f612;
	selp.f32 	%f629, %f628, %f109, %p113;
	fma.rn.f32 	%f1752, %f627, %f629, %f629;
	@%p112 bra 	$L__BB4_64;

	mov.f32 	%f1688, 0f3F800000;
	ex2.approx.ftz.f32 	%f630, %f1752;
	sub.f32 	%f632, %f1688, %f630;
	mov.b32 	%r222, %f632;
	mov.b32 	%r223, %f109;
	and.b32  	%r224, %r223, -2147483648;
	or.b32  	%r225, %r224, %r222;
	mov.b32 	%f1752, %r225;

$L__BB4_64:
	cvt.rn.f32.s32 	%f1659, %r522;
	sub.f32 	%f634, %f1751, %f1752;
	mul.f32 	%f113, %f634, 0f3F000000;
	mul.f32 	%f635, %f101, %f1775;
	fma.rn.f32 	%f114, %f113, %f635, %f1774;
	mad.lo.s32 	%r226, %r523, %r85, %r522;
	add.s32 	%r227, %r226, %r2;
	mul.wide.s32 	%rd29, %r227, 4;
	add.s64 	%rd30, %rd1, %rd29;
	ld.global.f32 	%f115, [%rd30];
	add.f32 	%f636, %f59, %f102;
	fma.rn.f32 	%f637, %f636, %f52, %f60;
	add.f32 	%f638, %f637, %f1659;
	cvt.rzi.s32.f32 	%r228, %f638;
	mul.wide.s32 	%rd32, %r228, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.f32 	%f1773, [%rd33];
	setp.eq.f32 	%p114, %f81, 0f7F800000;
	mov.f32 	%f1753, 0f7F800000;
	@%p114 bra 	$L__BB4_66;

	fma.rn.f32 	%f1753, %f81, %f80, %f81;

$L__BB4_66:
	setp.geu.f32 	%p377, %f77, 0f00000000;
	mov.b32 	%r229, %f1753;
	xor.b32  	%r230, %r229, -2147483648;
	mov.b32 	%f639, %r230;
	selp.f32 	%f119, %f639, %f1753, %p4;
	setp.eq.f32 	%p115, %f77, 0f00000000;
	selp.f32 	%f1754, %f82, %f119, %p115;
	@%p377 bra 	$L__BB4_69;

	mov.f32 	%f1660, 0f40000000;
	cvt.rzi.f32.f32 	%f641, %f1660;
	setp.eq.f32 	%p116, %f641, 0f40000000;
	mov.f32 	%f1754, %f119;
	@%p116 bra 	$L__BB4_69;

	mov.f32 	%f1754, 0f7FFFFFFF;

$L__BB4_69:
	abs.f32 	%f1663, %f77;
	mov.f32 	%f1662, 0f3FB8AA3B;
	add.f32 	%f1661, %f1663, 0f40000000;
	mov.b32 	%r487, %f1661;
	add.f32 	%f644, %f77, 0f40000000;
	setp.gtu.f32 	%p117, %f1663, 0f7F800000;
	mov.f32 	%f1755, 0f7F800000;
	selp.f32 	%f645, %f644, %f1754, %p117;
	selp.f32 	%f646, 0fFF800000, 0f7F800000, %p4;
	setp.neu.f32 	%p118, %f1663, 0f7F800000;
	selp.f32 	%f647, %f645, %f646, %p118;
	setp.gt.s32 	%p119, %r487, 2139095039;
	selp.f32 	%f648, %f647, %f1754, %p119;
	mul.f32 	%f649, %f648, 0fBF000000;
	setp.eq.f32 	%p120, %f77, 0f3F800000;
	selp.f32 	%f650, 0fBF000000, %f649, %p120;
	mov.f32 	%f652, 0f3BBB989D;
	fma.rn.f32 	%f653, %f650, %f652, %f358;
	mov.f32 	%f655, 0f437C0000;
	cvt.sat.f32.f32 	%f656, %f653;
	mov.f32 	%f657, 0f4B400001;
	fma.rm.f32 	%f658, %f656, %f655, %f657;
	add.f32 	%f659, %f658, 0fCB40007F;
	neg.f32 	%f660, %f659;
	fma.rn.f32 	%f661, %f650, %f1662, %f660;
	mov.f32 	%f662, 0f32A57060;
	fma.rn.f32 	%f663, %f650, %f662, %f661;
	mov.b32 	%r231, %f658;
	shl.b32 	%r232, %r231, 23;
	mov.b32 	%f664, %r232;
	ex2.approx.ftz.f32 	%f665, %f663;
	mul.f32 	%f122, %f665, %f664;
	setp.eq.f32 	%p121, %f86, 0f7F800000;
	@%p121 bra 	$L__BB4_71;

	fma.rn.f32 	%f1755, %f86, %f85, %f86;

$L__BB4_71:
	setp.geu.f32 	%p378, %f83, 0f00000000;
	mov.b32 	%r233, %f1755;
	xor.b32  	%r234, %r233, -2147483648;
	mov.b32 	%f666, %r234;
	selp.f32 	%f125, %f666, %f1755, %p5;
	setp.eq.f32 	%p122, %f83, 0f00000000;
	selp.f32 	%f1756, %f87, %f125, %p122;
	@%p378 bra 	$L__BB4_74;

	mov.f32 	%f1664, 0f40000000;
	cvt.rzi.f32.f32 	%f668, %f1664;
	setp.eq.f32 	%p123, %f668, 0f40000000;
	mov.f32 	%f1756, %f125;
	@%p123 bra 	$L__BB4_74;

	mov.f32 	%f1756, 0f7FFFFFFF;

$L__BB4_74:
	abs.f32 	%f1672, %f83;
	mov.f32 	%f1671, 0f32A57060;
	mov.f32 	%f1670, 0f4B400001;
	mov.f32 	%f1669, 0f437C0000;
	mov.f32 	%f1668, 0f3BBB989D;
	add.f32 	%f1667, %f1672, 0f40000000;
	mov.b32 	%r488, %f1667;
	selp.f32 	%f1666, 0fFF800000, 0f7F800000, %p5;
	mov.f32 	%f1665, 0f3FB8AA3B;
	add.f32 	%f670, %f83, 0f40000000;
	setp.gtu.f32 	%p124, %f1672, 0f7F800000;
	selp.f32 	%f671, %f670, %f1756, %p124;
	setp.neu.f32 	%p125, %f1672, 0f7F800000;
	selp.f32 	%f672, %f671, %f1666, %p125;
	setp.gt.s32 	%p126, %r488, 2139095039;
	selp.f32 	%f673, %f672, %f1756, %p126;
	mul.f32 	%f674, %f673, 0fBF000000;
	setp.eq.f32 	%p127, %f83, 0f3F800000;
	selp.f32 	%f675, 0fBF000000, %f674, %p127;
	fma.rn.f32 	%f678, %f675, %f1668, %f358;
	cvt.sat.f32.f32 	%f681, %f678;
	fma.rm.f32 	%f683, %f681, %f1669, %f1670;
	add.f32 	%f684, %f683, 0fCB40007F;
	neg.f32 	%f685, %f684;
	fma.rn.f32 	%f686, %f675, %f1665, %f685;
	fma.rn.f32 	%f688, %f675, %f1671, %f686;
	mov.b32 	%r235, %f683;
	shl.b32 	%r236, %r235, 23;
	mov.b32 	%f689, %r236;
	ex2.approx.ftz.f32 	%f690, %f688;
	mul.f32 	%f128, %f690, %f689;
	sub.f32 	%f691, %f122, %f128;
	mul.f32 	%f692, %f58, %f691;
	mul.f32 	%f129, %f113, %f692;
	not.pred 	%p128, %p6;
	mov.f64 	%fd335, %fd36;
	@%p128 bra 	$L__BB4_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r237}, %fd36;
	}
	xor.b32  	%r238, %r237, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r239, %temp}, %fd36;
	}
	mov.b64 	%fd335, {%r239, %r238};

$L__BB4_76:
	setp.eq.f32 	%p129, %f325, 0f00000000;
	@%p129 bra 	$L__BB4_80;
	bra.uni 	$L__BB4_77;

$L__BB4_80:
	mov.u32 	%r240, 0;
	mov.b64 	%fd335, {%r240, %r56};
	bra.uni 	$L__BB4_81;

$L__BB4_77:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r489}, %fd220;
	}
	setp.gt.s32 	%p130, %r489, -1;
	@%p130 bra 	$L__BB4_81;

	cvt.rzi.f64.f64 	%fd226, %fd222;
	setp.eq.f64 	%p131, %fd226, 0d4008000000000000;
	@%p131 bra 	$L__BB4_81;

	mov.f64 	%fd335, 0dFFF8000000000000;

$L__BB4_81:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r491}, %fd34;
	}
	and.b32  	%r490, %r491, 2146435072;
	setp.ne.s32 	%p380, %r490, 2146435072;
	or.pred  	%p379, %p380, %p101;
	selp.f64 	%fd336, %fd335, %fd34, %p380;
	@%p379 bra 	$L__BB4_86;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r493}, %fd222;
	}
	and.b32  	%r492, %r493, 2147483647;
	setp.eq.s32 	%p133, %r492, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r241, %temp}, %fd222;
	}
	setp.eq.s32 	%p134, %r241, 0;
	and.pred  	%p135, %p133, %p134;
	@%p135 bra 	$L__BB4_85;
	bra.uni 	$L__BB4_83;

$L__BB4_85:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r499}, %fd222;
	}
	setp.lt.s32 	%p381, %r499, 0;
	selp.b32 	%r498, 2146435072, 0, %p102;
	xor.b32  	%r497, %r498, 2146435072;
	selp.b32 	%r496, %r497, %r498, %p381;
	selp.b32 	%r495, 1072693248, %r496, %p103;
	mov.u32 	%r245, 0;
	mov.b64 	%fd336, {%r245, %r495};
	bra.uni 	$L__BB4_86;

$L__BB4_83:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r494}, %fd220;
	}
	and.b32  	%r242, %r494, 2147483647;
	setp.ne.s32 	%p136, %r242, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r243, %temp}, %fd220;
	}
	setp.ne.s32 	%p137, %r243, 0;
	or.pred  	%p138, %p136, %p137;
	mov.f64 	%fd336, %fd335;
	@%p138 bra 	$L__BB4_86;

	mov.u32 	%r244, 0;
	mov.b64 	%fd336, {%r244, %r60};

$L__BB4_86:
	cvt.rn.f32.s32 	%f1687, %r522;
	cvt.rn.f32.s32 	%f1686, %r523;
	mov.f32 	%f1685, 0f3102E308;
	mov.f32 	%f1684, 0fBF317218;
	mov.f32 	%f1683, 0f35BFBE8E;
	mov.f32 	%f1682, 0f3F317200;
	mov.f32 	%f1681, 0f3DAAAABD;
	mov.f32 	%f1680, 0f3C4CAF63;
	mov.f32 	%f1679, 0f3B18F0FE;
	add.f32 	%f1678, %f1687, 0f3F000000;
	sub.f32 	%f1677, %f1678, %f1777;
	sub.f32 	%f1676, %f1687, %f1777;
	add.f32 	%f1675, %f1676, 0fBF000000;
	mov.f32 	%f1674, 0f3FB8AA3B;
	mov.f32 	%f1673, 0f40000000;
	setp.eq.f32 	%p139, %f325, 0f3F800000;
	selp.f64 	%fd230, 0d3FF0000000000000, %fd336, %p139;
	div.rn.f64 	%fd45, %fd35, %fd230;
	mul.f32 	%f694, %f1675, %f128;
	mul.f32 	%f695, %f1677, %f122;
	sub.f32 	%f696, %f695, %f694;
	cvt.f64.f32 	%fd231, %f696;
	mul.f64 	%fd232, %fd45, %fd231;
	cvt.f64.f32 	%fd233, %f113;
	mul.f64 	%fd234, %fd232, %fd233;
	cvt.rn.f32.f64 	%f130, %fd234;
	add.f32 	%f697, %f1686, 0f3F000000;
	sub.f32 	%f131, %f697, %f1776;
	div.rn.f32 	%f132, %f131, %f325;
	abs.f32 	%f133, %f132;
	setp.lt.f32 	%p140, %f133, 0f00800000;
	mul.f32 	%f698, %f133, 0f4B800000;
	selp.f32 	%f699, %f698, %f133, %p140;
	selp.f32 	%f700, 0fC3170000, 0fC2FE0000, %p140;
	mov.b32 	%r246, %f699;
	and.b32  	%r247, %r246, 8388607;
	or.b32  	%r248, %r247, 1065353216;
	mov.b32 	%f701, %r248;
	shr.u32 	%r249, %r246, 23;
	cvt.rn.f32.u32 	%f702, %r249;
	add.f32 	%f703, %f700, %f702;
	setp.gt.f32 	%p141, %f701, 0f3FB504F3;
	mul.f32 	%f704, %f701, 0f3F000000;
	add.f32 	%f705, %f703, 0f3F800000;
	selp.f32 	%f706, %f705, %f703, %p141;
	selp.f32 	%f707, %f704, %f701, %p141;
	add.f32 	%f708, %f707, 0fBF800000;
	add.f32 	%f709, %f707, 0f3F800000;
	rcp.approx.ftz.f32 	%f710, %f709;
	add.f32 	%f711, %f708, %f708;
	mul.f32 	%f713, %f711, %f710;
	mul.f32 	%f714, %f713, %f713;
	fma.rn.f32 	%f717, %f1679, %f714, %f1680;
	fma.rn.f32 	%f719, %f717, %f714, %f1681;
	mul.rn.f32 	%f720, %f719, %f714;
	mul.rn.f32 	%f721, %f720, %f713;
	sub.f32 	%f722, %f708, %f713;
	add.f32 	%f723, %f722, %f722;
	neg.f32 	%f724, %f713;
	fma.rn.f32 	%f725, %f724, %f708, %f723;
	mul.rn.f32 	%f726, %f710, %f725;
	add.f32 	%f727, %f721, %f713;
	sub.f32 	%f728, %f713, %f727;
	add.f32 	%f729, %f721, %f728;
	add.f32 	%f730, %f726, %f729;
	add.f32 	%f731, %f727, %f730;
	sub.f32 	%f732, %f727, %f731;
	add.f32 	%f733, %f730, %f732;
	mul.rn.f32 	%f735, %f706, %f1682;
	mul.rn.f32 	%f737, %f706, %f1683;
	add.f32 	%f738, %f735, %f731;
	sub.f32 	%f739, %f735, %f738;
	add.f32 	%f740, %f731, %f739;
	add.f32 	%f741, %f733, %f740;
	add.f32 	%f742, %f737, %f741;
	add.f32 	%f743, %f738, %f742;
	sub.f32 	%f744, %f738, %f743;
	add.f32 	%f745, %f742, %f744;
	mul.rn.f32 	%f746, %f1673, %f743;
	neg.f32 	%f747, %f746;
	fma.rn.f32 	%f748, %f1673, %f743, %f747;
	fma.rn.f32 	%f749, %f1673, %f745, %f748;
	mov.f32 	%f750, 0f00000000;
	fma.rn.f32 	%f751, %f750, %f743, %f749;
	add.rn.f32 	%f752, %f746, %f751;
	neg.f32 	%f753, %f752;
	add.rn.f32 	%f754, %f746, %f753;
	add.rn.f32 	%f755, %f754, %f751;
	mov.b32 	%r250, %f752;
	setp.eq.s32 	%p142, %r250, 1118925336;
	add.s32 	%r251, %r250, -1;
	mov.b32 	%f756, %r251;
	add.f32 	%f757, %f755, 0f37000000;
	selp.f32 	%f134, %f757, %f755, %p142;
	selp.f32 	%f758, %f756, %f752, %p142;
	mul.rn.f32 	%f760, %f758, %f1674;
	cvt.rzi.f32.f32 	%f761, %f760;
	abs.f32 	%f762, %f761;
	setp.gt.f32 	%p143, %f762, 0f42FC0000;
	mov.b32 	%r252, %f761;
	and.b32  	%r253, %r252, -2147483648;
	or.b32  	%r254, %r253, 1123811328;
	mov.b32 	%f763, %r254;
	selp.f32 	%f764, %f763, %f761, %p143;
	fma.rn.f32 	%f766, %f764, %f1684, %f758;
	fma.rn.f32 	%f768, %f764, %f1685, %f766;
	mul.f32 	%f769, %f768, 0f3FB8AA3B;
	add.f32 	%f770, %f764, 0f4B40007F;
	mov.b32 	%r255, %f770;
	shl.b32 	%r256, %r255, 23;
	mov.b32 	%f771, %r256;
	ex2.approx.ftz.f32 	%f772, %f769;
	mul.f32 	%f135, %f772, %f771;
	setp.eq.f32 	%p144, %f135, 0f7F800000;
	mov.f32 	%f1757, 0f7F800000;
	@%p144 bra 	$L__BB4_88;

	fma.rn.f32 	%f1757, %f135, %f134, %f135;

$L__BB4_88:
	setp.lt.f32 	%p145, %f132, 0f00000000;
	and.pred  	%p10, %p145, %p86;
	setp.eq.f32 	%p147, %f132, 0f00000000;
	@%p147 bra 	$L__BB4_92;
	bra.uni 	$L__BB4_89;

$L__BB4_92:
	add.f32 	%f777, %f132, %f132;
	selp.f32 	%f1759, %f777, 0f00000000, %p86;
	bra.uni 	$L__BB4_93;

$L__BB4_89:
	mov.b32 	%r257, %f1757;
	xor.b32  	%r258, %r257, -2147483648;
	mov.b32 	%f773, %r258;
	selp.f32 	%f1759, %f773, %f1757, %p10;
	setp.geu.f32 	%p148, %f132, 0f00000000;
	@%p148 bra 	$L__BB4_93;

	mov.f32 	%f1695, 0f40000000;
	cvt.rzi.f32.f32 	%f775, %f1695;
	setp.eq.f32 	%p149, %f775, 0f40000000;
	@%p149 bra 	$L__BB4_93;

	mov.f32 	%f1759, 0f7FFFFFFF;

$L__BB4_93:
	abs.f32 	%f1615, %f132;
	add.f32 	%f778, %f1615, 0f40000000;
	mov.b32 	%r259, %f778;
	setp.lt.s32 	%p151, %r259, 2139095040;
	@%p151 bra 	$L__BB4_98;

	abs.f32 	%f1693, %f132;
	setp.gtu.f32 	%p152, %f1693, 0f7F800000;
	@%p152 bra 	$L__BB4_97;
	bra.uni 	$L__BB4_95;

$L__BB4_97:
	add.f32 	%f1759, %f132, 0f40000000;
	bra.uni 	$L__BB4_98;

$L__BB4_95:
	abs.f32 	%f1694, %f132;
	setp.neu.f32 	%p153, %f1694, 0f7F800000;
	@%p153 bra 	$L__BB4_98;

	selp.f32 	%f1759, 0fFF800000, 0f7F800000, %p10;

$L__BB4_98:
	mov.f32 	%f1632, 0f00000000;
	cvt.rn.f32.s32 	%f1631, %r523;
	sub.f32 	%f1630, %f1631, %f1776;
	add.f32 	%f1629, %f1630, 0fBF000000;
	mov.f32 	%f1628, 0f3102E308;
	mov.f32 	%f1627, 0fBF317218;
	mov.f32 	%f1626, 0f35BFBE8E;
	mov.f32 	%f1625, 0f3F317200;
	mov.f32 	%f1624, 0f3DAAAABD;
	mov.f32 	%f1623, 0f3C4CAF63;
	mov.f32 	%f1622, 0f3B18F0FE;
	mov.f32 	%f1621, 0f32A57060;
	mov.f32 	%f1620, 0f4B400001;
	mov.f32 	%f1619, 0f437C0000;
	mov.f32 	%f1618, 0f3BBB989D;
	mov.f32 	%f1617, 0f3FB8AA3B;
	mov.f32 	%f1616, 0f40000000;
	mul.f32 	%f780, %f1759, 0fBF000000;
	setp.eq.f32 	%p154, %f132, 0f3F800000;
	selp.f32 	%f781, 0fBF000000, %f780, %p154;
	fma.rn.f32 	%f784, %f781, %f1618, %f358;
	cvt.sat.f32.f32 	%f787, %f784;
	fma.rm.f32 	%f789, %f787, %f1619, %f1620;
	add.f32 	%f790, %f789, 0fCB40007F;
	neg.f32 	%f791, %f790;
	fma.rn.f32 	%f792, %f781, %f1617, %f791;
	fma.rn.f32 	%f794, %f781, %f1621, %f792;
	mov.b32 	%r260, %f789;
	shl.b32 	%r261, %r260, 23;
	mov.b32 	%f795, %r261;
	ex2.approx.ftz.f32 	%f796, %f794;
	mul.f32 	%f144, %f796, %f795;
	div.rn.f32 	%f145, %f1629, %f325;
	abs.f32 	%f146, %f145;
	setp.lt.f32 	%p155, %f146, 0f00800000;
	mul.f32 	%f797, %f146, 0f4B800000;
	selp.f32 	%f798, %f797, %f146, %p155;
	selp.f32 	%f799, 0fC3170000, 0fC2FE0000, %p155;
	mov.b32 	%r262, %f798;
	and.b32  	%r263, %r262, 8388607;
	or.b32  	%r264, %r263, 1065353216;
	mov.b32 	%f800, %r264;
	shr.u32 	%r265, %r262, 23;
	cvt.rn.f32.u32 	%f801, %r265;
	add.f32 	%f802, %f799, %f801;
	setp.gt.f32 	%p156, %f800, 0f3FB504F3;
	mul.f32 	%f803, %f800, 0f3F000000;
	add.f32 	%f804, %f802, 0f3F800000;
	selp.f32 	%f805, %f804, %f802, %p156;
	selp.f32 	%f806, %f803, %f800, %p156;
	add.f32 	%f807, %f806, 0fBF800000;
	add.f32 	%f808, %f806, 0f3F800000;
	rcp.approx.ftz.f32 	%f809, %f808;
	add.f32 	%f810, %f807, %f807;
	mul.f32 	%f812, %f810, %f809;
	mul.f32 	%f813, %f812, %f812;
	fma.rn.f32 	%f816, %f1622, %f813, %f1623;
	fma.rn.f32 	%f818, %f816, %f813, %f1624;
	mul.rn.f32 	%f819, %f818, %f813;
	mul.rn.f32 	%f820, %f819, %f812;
	sub.f32 	%f821, %f807, %f812;
	add.f32 	%f822, %f821, %f821;
	neg.f32 	%f823, %f812;
	fma.rn.f32 	%f824, %f823, %f807, %f822;
	mul.rn.f32 	%f825, %f809, %f824;
	add.f32 	%f826, %f820, %f812;
	sub.f32 	%f827, %f812, %f826;
	add.f32 	%f828, %f820, %f827;
	add.f32 	%f829, %f825, %f828;
	add.f32 	%f830, %f826, %f829;
	sub.f32 	%f831, %f826, %f830;
	add.f32 	%f832, %f829, %f831;
	mul.rn.f32 	%f834, %f805, %f1625;
	mul.rn.f32 	%f836, %f805, %f1626;
	add.f32 	%f837, %f834, %f830;
	sub.f32 	%f838, %f834, %f837;
	add.f32 	%f839, %f830, %f838;
	add.f32 	%f840, %f832, %f839;
	add.f32 	%f841, %f836, %f840;
	add.f32 	%f842, %f837, %f841;
	sub.f32 	%f843, %f837, %f842;
	add.f32 	%f844, %f841, %f843;
	mul.rn.f32 	%f845, %f1616, %f842;
	neg.f32 	%f846, %f845;
	fma.rn.f32 	%f847, %f1616, %f842, %f846;
	fma.rn.f32 	%f848, %f1616, %f844, %f847;
	fma.rn.f32 	%f850, %f1632, %f842, %f848;
	add.rn.f32 	%f851, %f845, %f850;
	neg.f32 	%f852, %f851;
	add.rn.f32 	%f853, %f845, %f852;
	add.rn.f32 	%f854, %f853, %f850;
	mov.b32 	%r266, %f851;
	setp.eq.s32 	%p157, %r266, 1118925336;
	add.s32 	%r267, %r266, -1;
	mov.b32 	%f855, %r267;
	add.f32 	%f856, %f854, 0f37000000;
	selp.f32 	%f147, %f856, %f854, %p157;
	selp.f32 	%f857, %f855, %f851, %p157;
	mul.rn.f32 	%f858, %f857, %f1617;
	cvt.rzi.f32.f32 	%f859, %f858;
	abs.f32 	%f860, %f859;
	setp.gt.f32 	%p158, %f860, 0f42FC0000;
	mov.b32 	%r268, %f859;
	and.b32  	%r269, %r268, -2147483648;
	or.b32  	%r270, %r269, 1123811328;
	mov.b32 	%f861, %r270;
	selp.f32 	%f862, %f861, %f859, %p158;
	fma.rn.f32 	%f864, %f862, %f1627, %f857;
	fma.rn.f32 	%f866, %f862, %f1628, %f864;
	mul.f32 	%f867, %f866, 0f3FB8AA3B;
	add.f32 	%f868, %f862, 0f4B40007F;
	mov.b32 	%r271, %f868;
	shl.b32 	%r272, %r271, 23;
	mov.b32 	%f869, %r272;
	ex2.approx.ftz.f32 	%f870, %f867;
	mul.f32 	%f148, %f870, %f869;
	setp.eq.f32 	%p159, %f148, 0f7F800000;
	mov.f32 	%f1760, 0f7F800000;
	@%p159 bra 	$L__BB4_100;

	fma.rn.f32 	%f1760, %f148, %f147, %f148;

$L__BB4_100:
	setp.lt.f32 	%p160, %f145, 0f00000000;
	and.pred  	%p11, %p160, %p86;
	setp.eq.f32 	%p162, %f145, 0f00000000;
	@%p162 bra 	$L__BB4_104;
	bra.uni 	$L__BB4_101;

$L__BB4_104:
	add.f32 	%f875, %f145, %f145;
	selp.f32 	%f1762, %f875, 0f00000000, %p86;
	bra.uni 	$L__BB4_105;

$L__BB4_101:
	mov.b32 	%r273, %f1760;
	xor.b32  	%r274, %r273, -2147483648;
	mov.b32 	%f871, %r274;
	selp.f32 	%f1762, %f871, %f1760, %p11;
	setp.geu.f32 	%p163, %f145, 0f00000000;
	@%p163 bra 	$L__BB4_105;

	mov.f32 	%f1692, 0f40000000;
	cvt.rzi.f32.f32 	%f873, %f1692;
	setp.eq.f32 	%p164, %f873, 0f40000000;
	@%p164 bra 	$L__BB4_105;

	mov.f32 	%f1762, 0f7FFFFFFF;

$L__BB4_105:
	abs.f32 	%f1696, %f145;
	add.f32 	%f876, %f1696, 0f40000000;
	mov.b32 	%r275, %f876;
	setp.lt.s32 	%p166, %r275, 2139095040;
	@%p166 bra 	$L__BB4_110;

	abs.f32 	%f1697, %f145;
	setp.gtu.f32 	%p167, %f1697, 0f7F800000;
	@%p167 bra 	$L__BB4_109;
	bra.uni 	$L__BB4_107;

$L__BB4_109:
	add.f32 	%f1762, %f145, 0f40000000;
	bra.uni 	$L__BB4_110;

$L__BB4_107:
	abs.f32 	%f1698, %f145;
	setp.neu.f32 	%p168, %f1698, 0f7F800000;
	@%p168 bra 	$L__BB4_110;

	selp.f32 	%f1762, 0fFF800000, 0f7F800000, %p11;

$L__BB4_110:
	cvt.rn.f32.s32 	%f1643, %r523;
	add.f32 	%f1642, %f1643, 0f3F000000;
	sub.f32 	%f1641, %f1642, %f1776;
	mov.f32 	%f1763, 0f00000000;
	sub.f32 	%f1639, %f1643, %f1776;
	add.f32 	%f1638, %f1639, 0fBF000000;
	mov.f32 	%f1637, 0f32A57060;
	mov.f32 	%f1636, 0f4B400001;
	mov.f32 	%f1635, 0f437C0000;
	mov.f32 	%f1634, 0f3BBB989D;
	mov.f32 	%f1633, 0f3FB8AA3B;
	mul.f32 	%f878, %f1762, 0fBF000000;
	setp.eq.f32 	%p169, %f145, 0f3F800000;
	selp.f32 	%f879, 0fBF000000, %f878, %p169;
	fma.rn.f32 	%f882, %f879, %f1634, %f358;
	cvt.sat.f32.f32 	%f885, %f882;
	fma.rm.f32 	%f887, %f885, %f1635, %f1636;
	add.f32 	%f888, %f887, 0fCB40007F;
	neg.f32 	%f889, %f888;
	fma.rn.f32 	%f890, %f879, %f1633, %f889;
	fma.rn.f32 	%f892, %f879, %f1637, %f890;
	mov.b32 	%r276, %f887;
	shl.b32 	%r277, %r276, 23;
	mov.b32 	%f893, %r277;
	ex2.approx.ftz.f32 	%f894, %f892;
	mul.f32 	%f895, %f894, %f893;
	sub.f32 	%f896, %f144, %f895;
	mul.f32 	%f897, %f58, %f896;
	mul.f32 	%f157, %f101, %f897;
	mul.f32 	%f898, %f1638, %f895;
	mul.f32 	%f899, %f1641, %f144;
	sub.f32 	%f900, %f899, %f898;
	cvt.f64.f32 	%fd235, %f900;
	mul.f64 	%fd236, %fd45, %fd235;
	cvt.f64.f32 	%fd237, %f101;
	mul.f64 	%fd238, %fd236, %fd237;
	cvt.rn.f32.f64 	%f158, %fd238;
	mul.f32 	%f159, %f101, %f113;
	setp.leu.f32 	%p170, %f114, 0f3C23D70A;
	@%p170 bra 	$L__BB4_112;

	sub.f32 	%f901, %f115, %f114;
	add.f32 	%f902, %f114, %f1773;
	div.rn.f32 	%f1763, %f901, %f902;

$L__BB4_112:
	mov.f32 	%f1764, 0f00000000;
	@%p170 bra 	$L__BB4_127;

	mov.f64 	%fd309, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r507}, %fd309;
	}
	and.b32  	%r506, %r507, 2146435072;
	setp.eq.s32 	%p172, %r506, 1062207488;
	add.f32 	%f162, %f114, %f1773;
	cvt.f64.f32 	%fd46, %f162;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd46;
	}
	abs.f64 	%fd47, %fd46;
	{ // callseq 90, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd47;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd338, [retval0+0];
	} // callseq 90
	setp.lt.s32 	%p173, %r68, 0;
	and.pred  	%p12, %p173, %p172;
	not.pred 	%p174, %p12;
	@%p174 bra 	$L__BB4_115;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r278}, %fd338;
	}
	xor.b32  	%r279, %r278, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r280, %temp}, %fd338;
	}
	mov.b64 	%fd338, {%r280, %r279};

$L__BB4_115:
	setp.eq.f32 	%p175, %f162, 0f00000000;
	@%p175 bra 	$L__BB4_119;
	bra.uni 	$L__BB4_116;

$L__BB4_119:
	setp.lt.s32 	%p178, %r61, 0;
	mov.u32 	%r281, 0;
	selp.b32 	%r282, %r68, 0, %p172;
	or.b32  	%r283, %r282, 2146435072;
	selp.b32 	%r284, %r283, %r282, %p178;
	mov.b64 	%fd338, {%r281, %r284};
	bra.uni 	$L__BB4_120;

$L__BB4_116:
	setp.gt.s32 	%p176, %r68, -1;
	@%p176 bra 	$L__BB4_120;

	cvt.rzi.f64.f64 	%fd241, %fd224;
	setp.eq.f64 	%p177, %fd241, 0d4000000000000000;
	@%p177 bra 	$L__BB4_120;

	mov.f64 	%fd338, 0dFFF8000000000000;

$L__BB4_120:
	add.f64 	%fd53, %fd46, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r285}, %fd53;
	}
	and.b32  	%r286, %r285, 2146435072;
	setp.ne.s32 	%p180, %r286, 2146435072;
	mov.f64 	%fd339, %fd338;
	@%p180 bra 	$L__BB4_126;

	setp.gtu.f64 	%p181, %fd47, 0d7FF0000000000000;
	mov.f64 	%fd339, %fd53;
	@%p181 bra 	$L__BB4_126;

	setp.eq.s32 	%p182, %r63, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r287, %temp}, %fd224;
	}
	setp.eq.s32 	%p183, %r287, 0;
	and.pred  	%p184, %p182, %p183;
	@%p184 bra 	$L__BB4_125;
	bra.uni 	$L__BB4_123;

$L__BB4_125:
	setp.lt.s32 	%p190, %r61, 0;
	mov.u32 	%r292, 0;
	setp.gt.f64 	%p191, %fd47, 0d3FF0000000000000;
	selp.b32 	%r293, 2146435072, 0, %p191;
	xor.b32  	%r294, %r293, 2146435072;
	selp.b32 	%r295, %r294, %r293, %p190;
	setp.eq.f32 	%p192, %f162, 0fBF800000;
	selp.b32 	%r296, 1072693248, %r295, %p192;
	mov.b64 	%fd339, {%r292, %r296};
	bra.uni 	$L__BB4_126;

$L__BB4_123:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r288, %temp}, %fd46;
	}
	and.b32  	%r289, %r68, 2147483647;
	setp.ne.s32 	%p185, %r289, 2146435072;
	setp.ne.s32 	%p186, %r288, 0;
	or.pred  	%p187, %p185, %p186;
	mov.f64 	%fd339, %fd338;
	@%p187 bra 	$L__BB4_126;

	setp.ne.s32 	%p188, %r63, 1071644672;
	and.pred  	%p189, %p188, %p12;
	selp.b32 	%r290, %r65, %r64, %p189;
	mov.u32 	%r291, 0;
	mov.b64 	%fd339, {%r291, %r290};

$L__BB4_126:
	setp.eq.f32 	%p193, %f162, 0f3F800000;
	selp.f64 	%fd244, 0d3FF0000000000000, %fd339, %p193;
	add.f32 	%f904, %f115, %f1773;
	cvt.f64.f32 	%fd245, %f904;
	div.rn.f64 	%fd246, %fd245, %fd244;
	cvt.rn.f32.f64 	%f1764, %fd246;

$L__BB4_127:
	mov.f64 	%fd308, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r483}, %fd308;
	}
	and.b32  	%r482, %r483, 2146435072;
	mov.f32 	%f905, 0f47C35000;
	min.f32 	%f906, %f1764, %f905;
	cvt.f64.f32 	%fd57, %f906;
	min.f32 	%f165, %f1763, %f905;
	fma.rn.f32 	%f1744, %f165, %f129, %f1744;
	mul.f32 	%f907, %f165, %f130;
	cvt.f64.f32 	%fd58, %f907;
	cvt.f64.f32 	%fd59, %f129;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd59;
	}
	abs.f64 	%fd60, %fd59;
	{ // callseq 91, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd60;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd308;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd340, [retval0+0];
	} // callseq 91
	setp.eq.s32 	%p194, %r482, 1062207488;
	@%p194 bra 	$L__BB4_162;
	bra.uni 	$L__BB4_128;

$L__BB4_162:
	setp.gt.s32 	%p240, %r69, -1;
	@%p240 bra 	$L__BB4_164;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r333}, %fd340;
	}
	xor.b32  	%r334, %r333, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r335, %temp}, %fd340;
	}
	mov.b64 	%fd340, {%r335, %r334};

$L__BB4_164:
	setp.eq.f32 	%p241, %f129, 0f00000000;
	@%p241 bra 	$L__BB4_168;
	bra.uni 	$L__BB4_165;

$L__BB4_168:
	setp.lt.s32 	%p244, %r61, 0;
	mov.u32 	%r336, 0;
	or.b32  	%r337, %r69, 2146435072;
	selp.b32 	%r338, %r337, %r69, %p244;
	mov.b64 	%fd340, {%r336, %r338};
	bra.uni 	$L__BB4_169;

$L__BB4_128:
	setp.eq.f32 	%p195, %f129, 0f00000000;
	@%p195 bra 	$L__BB4_132;
	bra.uni 	$L__BB4_129;

$L__BB4_132:
	shr.s32 	%r505, %r61, 31;
	and.b32  	%r504, %r505, 2146435072;
	mov.u32 	%r297, 0;
	mov.b64 	%fd340, {%r297, %r504};
	bra.uni 	$L__BB4_133;

$L__BB4_165:
	@%p240 bra 	$L__BB4_169;

	cvt.rzi.f64.f64 	%fd279, %fd224;
	setp.eq.f64 	%p243, %fd279, 0d4000000000000000;
	@%p243 bra 	$L__BB4_169;

	mov.f64 	%fd340, 0dFFF8000000000000;

$L__BB4_169:
	add.f64 	%fd94, %fd59, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r339}, %fd94;
	}
	and.b32  	%r340, %r339, 2146435072;
	setp.ne.s32 	%p245, %r340, 2146435072;
	mov.f64 	%fd348, %fd340;
	@%p245 bra 	$L__BB4_175;

	setp.gtu.f64 	%p246, %fd60, 0d7FF0000000000000;
	mov.f64 	%fd348, %fd94;
	@%p246 bra 	$L__BB4_175;

	setp.eq.s32 	%p247, %r63, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r341, %temp}, %fd224;
	}
	setp.eq.s32 	%p248, %r341, 0;
	and.pred  	%p249, %p247, %p248;
	@%p249 bra 	$L__BB4_174;
	bra.uni 	$L__BB4_172;

$L__BB4_174:
	setp.lt.s32 	%p256, %r61, 0;
	mov.u32 	%r346, 0;
	setp.gt.f64 	%p257, %fd60, 0d3FF0000000000000;
	selp.b32 	%r347, 2146435072, 0, %p257;
	xor.b32  	%r348, %r347, 2146435072;
	selp.b32 	%r349, %r348, %r347, %p256;
	setp.eq.f32 	%p258, %f129, 0fBF800000;
	selp.b32 	%r350, 1072693248, %r349, %p258;
	mov.b64 	%fd348, {%r346, %r350};
	bra.uni 	$L__BB4_175;

$L__BB4_129:
	setp.gt.s32 	%p196, %r69, -1;
	@%p196 bra 	$L__BB4_133;

	cvt.rzi.f64.f64 	%fd249, %fd224;
	setp.eq.f64 	%p197, %fd249, 0d4000000000000000;
	@%p197 bra 	$L__BB4_133;

	mov.f64 	%fd340, 0dFFF8000000000000;

$L__BB4_133:
	add.f64 	%fd64, %fd59, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r298}, %fd64;
	}
	and.b32  	%r299, %r298, 2146435072;
	setp.ne.s32 	%p198, %r299, 2146435072;
	mov.f64 	%fd341, %fd340;
	@%p198 bra 	$L__BB4_139;

	setp.gtu.f64 	%p199, %fd60, 0d7FF0000000000000;
	mov.f64 	%fd341, %fd64;
	@%p199 bra 	$L__BB4_139;

	setp.eq.s32 	%p200, %r63, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r300, %temp}, %fd224;
	}
	setp.eq.s32 	%p201, %r300, 0;
	and.pred  	%p202, %p200, %p201;
	@%p202 bra 	$L__BB4_138;
	bra.uni 	$L__BB4_136;

$L__BB4_138:
	setp.lt.s32 	%p206, %r61, 0;
	mov.u32 	%r304, 0;
	setp.gt.f64 	%p207, %fd60, 0d3FF0000000000000;
	selp.b32 	%r305, 2146435072, 0, %p207;
	xor.b32  	%r306, %r305, 2146435072;
	selp.b32 	%r307, %r306, %r305, %p206;
	setp.eq.f32 	%p208, %f129, 0fBF800000;
	selp.b32 	%r308, 1072693248, %r307, %p208;
	mov.b64 	%fd341, {%r304, %r308};
	bra.uni 	$L__BB4_139;

$L__BB4_172:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r342, %temp}, %fd59;
	}
	and.b32  	%r343, %r69, 2147483647;
	setp.ne.s32 	%p250, %r343, 2146435072;
	setp.ne.s32 	%p251, %r342, 0;
	or.pred  	%p252, %p250, %p251;
	mov.f64 	%fd348, %fd340;
	@%p252 bra 	$L__BB4_175;

	setp.lt.s32 	%p253, %r69, 0;
	mov.u32 	%r344, 0;
	setp.ne.s32 	%p254, %r63, 1071644672;
	and.pred  	%p255, %p254, %p253;
	selp.b32 	%r345, %r65, %r64, %p255;
	mov.b64 	%fd348, {%r344, %r345};

$L__BB4_175:
	setp.eq.f32 	%p259, %f129, 0f3F800000;
	selp.f64 	%fd282, 0d3FF0000000000000, %fd348, %p259;
	mul.f64 	%fd283, %fd282, %fd57;
	sub.f64 	%fd284, %fd58, %fd283;
	cvt.f64.f32 	%fd285, %f1748;
	add.f64 	%fd358, %fd284, %fd285;
	cvt.f64.f32 	%fd99, %f157;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r72}, %fd99;
	}
	abs.f64 	%fd100, %fd99;
	{ // callseq 94, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd100;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd224;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd350, [retval0+0];
	} // callseq 94
	setp.gt.s32 	%p260, %r72, -1;
	@%p260 bra 	$L__BB4_177;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r351}, %fd350;
	}
	xor.b32  	%r352, %r351, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r353, %temp}, %fd350;
	}
	mov.b64 	%fd350, {%r353, %r352};

$L__BB4_177:
	setp.eq.f32 	%p261, %f157, 0f00000000;
	@%p261 bra 	$L__BB4_181;
	bra.uni 	$L__BB4_178;

$L__BB4_181:
	setp.lt.s32 	%p264, %r61, 0;
	mov.u32 	%r354, 0;
	or.b32  	%r355, %r72, 2146435072;
	selp.b32 	%r356, %r355, %r72, %p264;
	mov.b64 	%fd350, {%r354, %r356};
	bra.uni 	$L__BB4_182;

$L__BB4_178:
	@%p260 bra 	$L__BB4_182;

	cvt.rzi.f64.f64 	%fd288, %fd224;
	setp.eq.f64 	%p263, %fd288, 0d4000000000000000;
	@%p263 bra 	$L__BB4_182;

	mov.f64 	%fd350, 0dFFF8000000000000;

$L__BB4_182:
	add.f64 	%fd106, %fd99, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r357}, %fd106;
	}
	and.b32  	%r358, %r357, 2146435072;
	setp.ne.s32 	%p265, %r358, 2146435072;
	mov.f64 	%fd351, %fd350;
	@%p265 bra 	$L__BB4_188;

	setp.gtu.f64 	%p266, %fd100, 0d7FF0000000000000;
	mov.f64 	%fd351, %fd106;
	@%p266 bra 	$L__BB4_188;

	setp.eq.s32 	%p267, %r63, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r359, %temp}, %fd224;
	}
	setp.eq.s32 	%p268, %r359, 0;
	and.pred  	%p269, %p267, %p268;
	@%p269 bra 	$L__BB4_187;
	bra.uni 	$L__BB4_185;

$L__BB4_187:
	setp.lt.s32 	%p276, %r61, 0;
	mov.u32 	%r364, 0;
	setp.gt.f64 	%p277, %fd100, 0d3FF0000000000000;
	selp.b32 	%r365, 2146435072, 0, %p277;
	xor.b32  	%r366, %r365, 2146435072;
	selp.b32 	%r367, %r366, %r365, %p276;
	setp.eq.f32 	%p278, %f157, 0fBF800000;
	selp.b32 	%r368, 1072693248, %r367, %p278;
	mov.b64 	%fd351, {%r364, %r368};
	bra.uni 	$L__BB4_188;

$L__BB4_136:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r301, %temp}, %fd59;
	}
	and.b32  	%r302, %r69, 2147483647;
	setp.ne.s32 	%p203, %r302, 2146435072;
	setp.ne.s32 	%p204, %r301, 0;
	or.pred  	%p205, %p203, %p204;
	mov.f64 	%fd341, %fd340;
	@%p205 bra 	$L__BB4_139;

	mov.u32 	%r303, 0;
	mov.b64 	%fd341, {%r303, %r64};

$L__BB4_139:
	setp.eq.f32 	%p209, %f129, 0f3F800000;
	selp.f64 	%fd252, 0d3FF0000000000000, %fd341, %p209;
	mul.f64 	%fd253, %fd252, %fd57;
	sub.f64 	%fd254, %fd58, %fd253;
	cvt.f64.f32 	%fd255, %f1748;
	add.f64 	%fd358, %fd254, %fd255;
	cvt.f64.f32 	%fd69, %f157;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd69;
	}
	abs.f64 	%fd70, %fd69;
	setp.eq.f32 	%p210, %f157, 0f00000000;
	@%p210 bra 	$L__BB4_143;
	bra.uni 	$L__BB4_140;

$L__BB4_143:
	shr.s32 	%r503, %r61, 31;
	and.b32  	%r502, %r503, 2146435072;
	mov.u32 	%r309, 0;
	mov.b64 	%fd342, {%r309, %r502};
	bra.uni 	$L__BB4_144;

$L__BB4_140:
	{ // callseq 92, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd224;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd342, [retval0+0];
	} // callseq 92
	setp.gt.s32 	%p211, %r70, -1;
	@%p211 bra 	$L__BB4_144;

	cvt.rzi.f64.f64 	%fd258, %fd224;
	setp.eq.f64 	%p212, %fd258, 0d4000000000000000;
	@%p212 bra 	$L__BB4_144;

	mov.f64 	%fd342, 0dFFF8000000000000;

$L__BB4_144:
	add.f64 	%fd74, %fd69, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r310}, %fd74;
	}
	and.b32  	%r311, %r310, 2146435072;
	setp.ne.s32 	%p213, %r311, 2146435072;
	mov.f64 	%fd343, %fd342;
	@%p213 bra 	$L__BB4_150;

	setp.gtu.f64 	%p214, %fd70, 0d7FF0000000000000;
	mov.f64 	%fd343, %fd74;
	@%p214 bra 	$L__BB4_150;

	setp.eq.s32 	%p215, %r63, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r312, %temp}, %fd224;
	}
	setp.eq.s32 	%p216, %r312, 0;
	and.pred  	%p217, %p215, %p216;
	@%p217 bra 	$L__BB4_149;
	bra.uni 	$L__BB4_147;

$L__BB4_149:
	setp.lt.s32 	%p221, %r61, 0;
	mov.u32 	%r316, 0;
	setp.gt.f64 	%p222, %fd70, 0d3FF0000000000000;
	selp.b32 	%r317, 2146435072, 0, %p222;
	xor.b32  	%r318, %r317, 2146435072;
	selp.b32 	%r319, %r318, %r317, %p221;
	setp.eq.f32 	%p223, %f157, 0fBF800000;
	selp.b32 	%r320, 1072693248, %r319, %p223;
	mov.b64 	%fd343, {%r316, %r320};
	bra.uni 	$L__BB4_150;

$L__BB4_185:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r360, %temp}, %fd99;
	}
	and.b32  	%r361, %r72, 2147483647;
	setp.ne.s32 	%p270, %r361, 2146435072;
	setp.ne.s32 	%p271, %r360, 0;
	or.pred  	%p272, %p270, %p271;
	mov.f64 	%fd351, %fd350;
	@%p272 bra 	$L__BB4_188;

	setp.lt.s32 	%p273, %r72, 0;
	mov.u32 	%r362, 0;
	setp.ne.s32 	%p274, %r63, 1071644672;
	and.pred  	%p275, %p274, %p273;
	selp.b32 	%r363, %r65, %r64, %p275;
	mov.b64 	%fd351, {%r362, %r363};

$L__BB4_188:
	setp.eq.f32 	%p279, %f157, 0f3F800000;
	selp.f64 	%fd291, 0d3FF0000000000000, %fd351, %p279;
	mul.f64 	%fd292, %fd291, %fd57;
	mul.f32 	%f910, %f165, %f158;
	cvt.f64.f32 	%fd293, %f910;
	sub.f64 	%fd294, %fd293, %fd292;
	cvt.f64.f32 	%fd295, %f1747;
	add.f64 	%fd357, %fd294, %fd295;
	cvt.f64.f32 	%fd111, %f159;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd111;
	}
	abs.f64 	%fd112, %fd111;
	{ // callseq 95, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd112;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd224;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd353, [retval0+0];
	} // callseq 95
	setp.gt.s32 	%p280, %r73, -1;
	@%p280 bra 	$L__BB4_190;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r369}, %fd353;
	}
	xor.b32  	%r370, %r369, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r371, %temp}, %fd353;
	}
	mov.b64 	%fd353, {%r371, %r370};

$L__BB4_190:
	setp.eq.f32 	%p281, %f159, 0f00000000;
	@%p281 bra 	$L__BB4_194;
	bra.uni 	$L__BB4_191;

$L__BB4_194:
	setp.lt.s32 	%p284, %r61, 0;
	mov.u32 	%r372, 0;
	or.b32  	%r373, %r73, 2146435072;
	selp.b32 	%r374, %r373, %r73, %p284;
	mov.b64 	%fd353, {%r372, %r374};
	bra.uni 	$L__BB4_195;

$L__BB4_191:
	@%p280 bra 	$L__BB4_195;

	cvt.rzi.f64.f64 	%fd298, %fd224;
	setp.eq.f64 	%p283, %fd298, 0d4000000000000000;
	@%p283 bra 	$L__BB4_195;

	mov.f64 	%fd353, 0dFFF8000000000000;

$L__BB4_195:
	add.f64 	%fd118, %fd111, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r375}, %fd118;
	}
	and.b32  	%r376, %r375, 2146435072;
	setp.ne.s32 	%p285, %r376, 2146435072;
	mov.f64 	%fd354, %fd353;
	@%p285 bra 	$L__BB4_201;

	setp.gtu.f64 	%p286, %fd112, 0d7FF0000000000000;
	mov.f64 	%fd354, %fd118;
	@%p286 bra 	$L__BB4_201;

	setp.eq.s32 	%p287, %r63, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r377, %temp}, %fd224;
	}
	setp.eq.s32 	%p288, %r377, 0;
	and.pred  	%p289, %p287, %p288;
	@%p289 bra 	$L__BB4_200;
	bra.uni 	$L__BB4_198;

$L__BB4_200:
	setp.lt.s32 	%p296, %r61, 0;
	mov.u32 	%r382, 0;
	setp.gt.f64 	%p297, %fd112, 0d3FF0000000000000;
	selp.b32 	%r383, 2146435072, 0, %p297;
	xor.b32  	%r384, %r383, 2146435072;
	selp.b32 	%r385, %r384, %r383, %p296;
	setp.eq.f32 	%p298, %f159, 0fBF800000;
	selp.b32 	%r386, 1072693248, %r385, %p298;
	mov.b64 	%fd354, {%r382, %r386};
	bra.uni 	$L__BB4_201;

$L__BB4_147:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r313, %temp}, %fd69;
	}
	and.b32  	%r314, %r70, 2147483647;
	setp.ne.s32 	%p218, %r314, 2146435072;
	setp.ne.s32 	%p219, %r313, 0;
	or.pred  	%p220, %p218, %p219;
	mov.f64 	%fd343, %fd342;
	@%p220 bra 	$L__BB4_150;

	mov.u32 	%r315, 0;
	mov.b64 	%fd343, {%r315, %r64};

$L__BB4_150:
	setp.eq.f32 	%p224, %f157, 0f3F800000;
	selp.f64 	%fd261, 0d3FF0000000000000, %fd343, %p224;
	mul.f64 	%fd262, %fd261, %fd57;
	mul.f32 	%f908, %f165, %f158;
	cvt.f64.f32 	%fd263, %f908;
	sub.f64 	%fd264, %fd263, %fd262;
	cvt.f64.f32 	%fd265, %f1747;
	add.f64 	%fd357, %fd264, %fd265;
	cvt.f64.f32 	%fd79, %f159;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r71}, %fd79;
	}
	abs.f64 	%fd80, %fd79;
	setp.eq.f32 	%p225, %f159, 0f00000000;
	@%p225 bra 	$L__BB4_154;
	bra.uni 	$L__BB4_151;

$L__BB4_154:
	shr.s32 	%r501, %r61, 31;
	and.b32  	%r500, %r501, 2146435072;
	mov.u32 	%r321, 0;
	mov.b64 	%fd344, {%r321, %r500};
	bra.uni 	$L__BB4_155;

$L__BB4_151:
	{ // callseq 93, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd80;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd224;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd344, [retval0+0];
	} // callseq 93
	setp.gt.s32 	%p226, %r71, -1;
	@%p226 bra 	$L__BB4_155;

	cvt.rzi.f64.f64 	%fd268, %fd224;
	setp.eq.f64 	%p227, %fd268, 0d4000000000000000;
	@%p227 bra 	$L__BB4_155;

	mov.f64 	%fd344, 0dFFF8000000000000;

$L__BB4_155:
	add.f64 	%fd84, %fd79, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r322}, %fd84;
	}
	and.b32  	%r323, %r322, 2146435072;
	setp.ne.s32 	%p228, %r323, 2146435072;
	mov.f64 	%fd345, %fd344;
	@%p228 bra 	$L__BB4_161;

	setp.gtu.f64 	%p229, %fd80, 0d7FF0000000000000;
	mov.f64 	%fd345, %fd84;
	@%p229 bra 	$L__BB4_161;

	setp.eq.s32 	%p230, %r63, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r324, %temp}, %fd224;
	}
	setp.eq.s32 	%p231, %r324, 0;
	and.pred  	%p232, %p230, %p231;
	@%p232 bra 	$L__BB4_160;
	bra.uni 	$L__BB4_158;

$L__BB4_160:
	setp.lt.s32 	%p236, %r61, 0;
	mov.u32 	%r328, 0;
	setp.gt.f64 	%p237, %fd80, 0d3FF0000000000000;
	selp.b32 	%r329, 2146435072, 0, %p237;
	xor.b32  	%r330, %r329, 2146435072;
	selp.b32 	%r331, %r330, %r329, %p236;
	setp.eq.f32 	%p238, %f159, 0fBF800000;
	selp.b32 	%r332, 1072693248, %r331, %p238;
	mov.b64 	%fd345, {%r328, %r332};
	bra.uni 	$L__BB4_161;

$L__BB4_198:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r378, %temp}, %fd111;
	}
	and.b32  	%r379, %r73, 2147483647;
	setp.ne.s32 	%p290, %r379, 2146435072;
	setp.ne.s32 	%p291, %r378, 0;
	or.pred  	%p292, %p290, %p291;
	mov.f64 	%fd354, %fd353;
	@%p292 bra 	$L__BB4_201;

	setp.lt.s32 	%p293, %r73, 0;
	mov.u32 	%r380, 0;
	setp.ne.s32 	%p294, %r63, 1071644672;
	and.pred  	%p295, %p294, %p293;
	selp.b32 	%r381, %r65, %r64, %p295;
	mov.b64 	%fd354, {%r380, %r381};

$L__BB4_201:
	mul.f32 	%f911, %f165, 0f00000000;
	cvt.f64.f32 	%fd301, %f911;
	setp.eq.f32 	%p299, %f159, 0f3F800000;
	selp.f64 	%fd302, 0d3FF0000000000000, %fd354, %p299;
	mul.f64 	%fd303, %fd302, %fd57;
	sub.f64 	%fd304, %fd301, %fd303;
	cvt.f64.f32 	%fd305, %f1746;
	add.f64 	%fd356, %fd304, %fd305;
	cvt.f64.f32 	%fd306, %f1745;
	sub.f64 	%fd307, %fd301, %fd57;
	add.f64 	%fd355, %fd307, %fd306;
	bra.uni 	$L__BB4_202;

$L__BB4_158:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r325, %temp}, %fd79;
	}
	and.b32  	%r326, %r71, 2147483647;
	setp.ne.s32 	%p233, %r326, 2146435072;
	setp.ne.s32 	%p234, %r325, 0;
	or.pred  	%p235, %p233, %p234;
	mov.f64 	%fd345, %fd344;
	@%p235 bra 	$L__BB4_161;

	mov.u32 	%r327, 0;
	mov.b64 	%fd345, {%r327, %r64};

$L__BB4_161:
	mul.f32 	%f909, %f165, 0f00000000;
	cvt.f64.f32 	%fd271, %f909;
	setp.eq.f32 	%p239, %f159, 0f3F800000;
	selp.f64 	%fd272, 0d3FF0000000000000, %fd345, %p239;
	mul.f64 	%fd273, %fd272, %fd57;
	sub.f64 	%fd274, %fd271, %fd273;
	cvt.f64.f32 	%fd275, %f1746;
	add.f64 	%fd356, %fd274, %fd275;
	cvt.f64.f32 	%fd276, %f1745;
	sub.f64 	%fd277, %fd271, %fd57;
	add.f64 	%fd355, %fd277, %fd276;

$L__BB4_202:
	cvt.rn.f32.f64 	%f1748, %fd358;
	cvt.rn.f32.f64 	%f1747, %fd357;
	cvt.rn.f32.f64 	%f1746, %fd356;
	cvt.rn.f32.f64 	%f1745, %fd355;
	fma.rn.f32 	%f1743, %f165, %f157, %f1743;
	fma.rn.f32 	%f1742, %f165, %f159, %f1742;
	add.f32 	%f1741, %f1741, %f165;
	add.s32 	%r523, %r523, 1;
	setp.lt.s32 	%p300, %r523, %r85;
	@%p300 bra 	$L__BB4_56;

	add.s32 	%r522, %r522, 1;
	setp.lt.s32 	%p301, %r522, %r85;
	@%p301 bra 	$L__BB4_55;

$L__BB4_204:
	ld.param.u32 	%r484, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_6];
	div.rn.f32 	%f912, %f1744, %f1748;
	mov.f32 	%f913, 0fBF800000;
	max.f32 	%f914, %f912, %f913;
	mov.f32 	%f915, 0f3F800000;
	min.f32 	%f916, %f914, %f915;
	sub.f32 	%f1777, %f1777, %f916;
	div.rn.f32 	%f917, %f1743, %f1747;
	max.f32 	%f918, %f917, %f913;
	min.f32 	%f919, %f918, %f915;
	sub.f32 	%f1776, %f1776, %f919;
	neg.f32 	%f920, %f1775;
	div.rn.f32 	%f921, %f1742, %f1746;
	max.f32 	%f922, %f921, %f920;
	min.f32 	%f923, %f922, %f1775;
	sub.f32 	%f924, %f1775, %f923;
	neg.f32 	%f925, %f1774;
	div.rn.f32 	%f926, %f1741, %f1745;
	max.f32 	%f927, %f926, %f925;
	min.f32 	%f928, %f927, %f1774;
	sub.f32 	%f929, %f1774, %f928;
	max.f32 	%f1775, %f924, %f915;
	mov.f32 	%f930, 0f3C23D70A;
	max.f32 	%f1774, %f929, %f930;
	add.s32 	%r521, %r521, 1;
	setp.lt.s32 	%p302, %r521, %r484;
	@%p302 bra 	$L__BB4_53;

$L__BB4_205:
	mov.f32 	%f941, 0f00000000;
	mov.f32 	%f1790, %f941;
	mov.f32 	%f1791, %f941;
	mov.f32 	%f1792, %f941;
	mov.f32 	%f1795, %f941;
	mov.f32 	%f1793, %f941;
	mov.f32 	%f1794, %f941;
	mov.f32 	%f1796, %f941;
	mov.f32 	%f1797, %f941;
	mov.f32 	%f1798, %f941;
	mov.f32 	%f1799, %f941;
	mov.f32 	%f1817, %f941;
	@%p20 bra 	$L__BB4_260;

	div.rn.f32 	%f953, %f1775, 0fC0206C98;
	div.rn.f32 	%f192, %f953, %f325;
	sqrt.rn.f32 	%f193, %f34;
	mov.f32 	%f954, 0f3F800000;
	cvt.rzi.f32.f32 	%f955, %f954;
	add.f32 	%f956, %f955, %f955;
	mov.f32 	%f957, 0f40000000;
	sub.f32 	%f958, %f957, %f956;
	abs.f32 	%f194, %f958;
	mov.u32 	%r387, 0;
	setp.eq.f32 	%p311, %f194, 0f3F800000;
	mov.u32 	%r524, %r387;

$L__BB4_207:
	cvt.rn.f32.s32 	%f959, %r524;
	sub.f32 	%f960, %f959, %f1777;
	add.f32 	%f961, %f960, 0f3F000000;
	mul.f32 	%f962, %f193, %f961;
	abs.f32 	%f206, %f962;
	setp.ge.f32 	%p304, %f206, 0f3F8060FE;
	mul.f32 	%f963, %f962, %f962;
	selp.f32 	%f964, %f206, %f963, %p304;
	selp.f32 	%f965, 0f3789CA3C, 0f38B1E96A, %p304;
	selp.f32 	%f966, 0fB9F560B9, 0fBA574D20, %p304;
	fma.rn.f32 	%f967, %f965, %f964, %f966;
	selp.f32 	%f968, 0f3BAC840B, 0f3BAAD5EA, %p304;
	fma.rn.f32 	%f969, %f967, %f964, %f968;
	selp.f32 	%f970, 0fBD0C8162, 0fBCDC1BE7, %p304;
	fma.rn.f32 	%f971, %f969, %f964, %f970;
	selp.f32 	%f972, 0f3E1CF906, 0f3DE718AF, %p304;
	fma.rn.f32 	%f973, %f971, %f964, %f972;
	selp.f32 	%f974, 0f3F6A937E, 0fBEC093AC, %p304;
	fma.rn.f32 	%f975, %f973, %f964, %f974;
	selp.f32 	%f976, 0f3F20D842, 0f3E0375D3, %p304;
	fma.rn.f32 	%f977, %f975, %f964, %f976;
	neg.f32 	%f978, %f206;
	selp.f32 	%f979, %f978, %f962, %p304;
	fma.rn.f32 	%f207, %f977, %f979, %f979;
	mov.b32 	%r389, %f962;
	and.b32  	%r78, %r389, -2147483648;
	add.f32 	%f980, %f960, 0fBF000000;
	mul.f32 	%f981, %f193, %f980;
	abs.f32 	%f208, %f981;
	setp.ge.f32 	%p305, %f208, 0f3F8060FE;
	mul.f32 	%f982, %f981, %f981;
	selp.f32 	%f983, %f208, %f982, %p305;
	selp.f32 	%f984, 0f3789CA3C, 0f38B1E96A, %p305;
	selp.f32 	%f985, 0fB9F560B9, 0fBA574D20, %p305;
	fma.rn.f32 	%f986, %f984, %f983, %f985;
	selp.f32 	%f987, 0f3BAC840B, 0f3BAAD5EA, %p305;
	fma.rn.f32 	%f988, %f986, %f983, %f987;
	selp.f32 	%f989, 0fBD0C8162, 0fBCDC1BE7, %p305;
	fma.rn.f32 	%f990, %f988, %f983, %f989;
	selp.f32 	%f991, 0f3E1CF906, 0f3DE718AF, %p305;
	fma.rn.f32 	%f992, %f990, %f983, %f991;
	selp.f32 	%f993, 0f3F6A937E, 0fBEC093AC, %p305;
	fma.rn.f32 	%f994, %f992, %f983, %f993;
	selp.f32 	%f995, 0f3F20D842, 0f3E0375D3, %p305;
	fma.rn.f32 	%f996, %f994, %f983, %f995;
	neg.f32 	%f997, %f208;
	selp.f32 	%f998, %f997, %f981, %p305;
	fma.rn.f32 	%f209, %f996, %f998, %f998;
	mov.b32 	%r390, %f981;
	and.b32  	%r79, %r390, -2147483648;
	add.f32 	%f999, %f959, 0f3F000000;
	sub.f32 	%f1000, %f999, %f1777;
	div.rn.f32 	%f210, %f1000, %f325;
	abs.f32 	%f211, %f210;
	setp.lt.f32 	%p306, %f211, 0f00800000;
	mul.f32 	%f1001, %f211, 0f4B800000;
	selp.f32 	%f1002, %f1001, %f211, %p306;
	selp.f32 	%f1003, 0fC3170000, 0fC2FE0000, %p306;
	mov.b32 	%r391, %f1002;
	and.b32  	%r392, %r391, 8388607;
	or.b32  	%r393, %r392, 1065353216;
	mov.b32 	%f1004, %r393;
	shr.u32 	%r394, %r391, 23;
	cvt.rn.f32.u32 	%f1005, %r394;
	add.f32 	%f1006, %f1003, %f1005;
	setp.gt.f32 	%p307, %f1004, 0f3FB504F3;
	mul.f32 	%f1007, %f1004, 0f3F000000;
	add.f32 	%f1008, %f1006, 0f3F800000;
	selp.f32 	%f1009, %f1008, %f1006, %p307;
	selp.f32 	%f1010, %f1007, %f1004, %p307;
	add.f32 	%f1011, %f1010, 0fBF800000;
	add.f32 	%f1012, %f1010, 0f3F800000;
	rcp.approx.ftz.f32 	%f1013, %f1012;
	add.f32 	%f1014, %f1011, %f1011;
	mul.f32 	%f1016, %f1014, %f1013;
	mul.f32 	%f1017, %f1016, %f1016;
	mov.f32 	%f1018, 0f3C4CAF63;
	mov.f32 	%f1019, 0f3B18F0FE;
	fma.rn.f32 	%f1020, %f1019, %f1017, %f1018;
	mov.f32 	%f1021, 0f3DAAAABD;
	fma.rn.f32 	%f1022, %f1020, %f1017, %f1021;
	mul.rn.f32 	%f1023, %f1022, %f1017;
	mul.rn.f32 	%f1024, %f1023, %f1016;
	sub.f32 	%f1025, %f1011, %f1016;
	add.f32 	%f1026, %f1025, %f1025;
	neg.f32 	%f1027, %f1016;
	fma.rn.f32 	%f1028, %f1027, %f1011, %f1026;
	mul.rn.f32 	%f1029, %f1013, %f1028;
	add.f32 	%f1030, %f1024, %f1016;
	sub.f32 	%f1031, %f1016, %f1030;
	add.f32 	%f1032, %f1024, %f1031;
	add.f32 	%f1033, %f1029, %f1032;
	add.f32 	%f1034, %f1030, %f1033;
	sub.f32 	%f1035, %f1030, %f1034;
	add.f32 	%f1036, %f1033, %f1035;
	mov.f32 	%f1037, 0f3F317200;
	mul.rn.f32 	%f1038, %f1009, %f1037;
	mov.f32 	%f1039, 0f35BFBE8E;
	mul.rn.f32 	%f1040, %f1009, %f1039;
	add.f32 	%f1041, %f1038, %f1034;
	sub.f32 	%f1042, %f1038, %f1041;
	add.f32 	%f1043, %f1034, %f1042;
	add.f32 	%f1044, %f1036, %f1043;
	add.f32 	%f1045, %f1040, %f1044;
	add.f32 	%f1046, %f1041, %f1045;
	sub.f32 	%f1047, %f1041, %f1046;
	add.f32 	%f1048, %f1045, %f1047;
	mul.rn.f32 	%f1049, %f957, %f1046;
	neg.f32 	%f1050, %f1049;
	fma.rn.f32 	%f1051, %f957, %f1046, %f1050;
	fma.rn.f32 	%f1052, %f957, %f1048, %f1051;
	fma.rn.f32 	%f1054, %f941, %f1046, %f1052;
	add.rn.f32 	%f1055, %f1049, %f1054;
	neg.f32 	%f1056, %f1055;
	add.rn.f32 	%f1057, %f1049, %f1056;
	add.rn.f32 	%f1058, %f1057, %f1054;
	mov.b32 	%r395, %f1055;
	setp.eq.s32 	%p308, %r395, 1118925336;
	add.s32 	%r396, %r395, -1;
	mov.b32 	%f1059, %r396;
	add.f32 	%f1060, %f1058, 0f37000000;
	selp.f32 	%f212, %f1060, %f1058, %p308;
	selp.f32 	%f1061, %f1059, %f1055, %p308;
	mov.f32 	%f1062, 0f3FB8AA3B;
	mul.rn.f32 	%f1063, %f1061, %f1062;
	cvt.rzi.f32.f32 	%f1064, %f1063;
	abs.f32 	%f1065, %f1064;
	setp.gt.f32 	%p309, %f1065, 0f42FC0000;
	mov.b32 	%r397, %f1064;
	and.b32  	%r398, %r397, -2147483648;
	or.b32  	%r399, %r398, 1123811328;
	mov.b32 	%f1066, %r399;
	selp.f32 	%f1067, %f1066, %f1064, %p309;
	mov.f32 	%f1068, 0fBF317218;
	fma.rn.f32 	%f1069, %f1067, %f1068, %f1061;
	mov.f32 	%f1070, 0f3102E308;
	fma.rn.f32 	%f1071, %f1067, %f1070, %f1069;
	mul.f32 	%f1072, %f1071, 0f3FB8AA3B;
	add.f32 	%f1073, %f1067, 0f4B40007F;
	mov.b32 	%r400, %f1073;
	shl.b32 	%r401, %r400, 23;
	mov.b32 	%f1074, %r401;
	ex2.approx.ftz.f32 	%f1075, %f1072;
	mul.f32 	%f213, %f1075, %f1074;
	setp.lt.f32 	%p310, %f210, 0f00000000;
	and.pred  	%p13, %p310, %p311;
	add.f32 	%f1076, %f210, %f210;
	selp.f32 	%f214, %f1076, 0f00000000, %p311;
	add.f32 	%f1077, %f211, 0f40000000;
	mov.b32 	%r80, %f1077;
	div.rn.f32 	%f215, %f980, %f325;
	abs.f32 	%f216, %f215;
	setp.lt.f32 	%p312, %f216, 0f00800000;
	mul.f32 	%f1078, %f216, 0f4B800000;
	selp.f32 	%f1079, %f1078, %f216, %p312;
	selp.f32 	%f1080, 0fC3170000, 0fC2FE0000, %p312;
	mov.b32 	%r402, %f1079;
	and.b32  	%r403, %r402, 8388607;
	or.b32  	%r404, %r403, 1065353216;
	mov.b32 	%f1081, %r404;
	shr.u32 	%r405, %r402, 23;
	cvt.rn.f32.u32 	%f1082, %r405;
	add.f32 	%f1083, %f1080, %f1082;
	setp.gt.f32 	%p313, %f1081, 0f3FB504F3;
	mul.f32 	%f1084, %f1081, 0f3F000000;
	add.f32 	%f1085, %f1083, 0f3F800000;
	selp.f32 	%f1086, %f1085, %f1083, %p313;
	selp.f32 	%f1087, %f1084, %f1081, %p313;
	add.f32 	%f1088, %f1087, 0fBF800000;
	add.f32 	%f1089, %f1087, 0f3F800000;
	rcp.approx.ftz.f32 	%f1090, %f1089;
	add.f32 	%f1091, %f1088, %f1088;
	mul.f32 	%f1092, %f1091, %f1090;
	mul.f32 	%f1093, %f1092, %f1092;
	fma.rn.f32 	%f1094, %f1019, %f1093, %f1018;
	fma.rn.f32 	%f1095, %f1094, %f1093, %f1021;
	mul.rn.f32 	%f1096, %f1095, %f1093;
	mul.rn.f32 	%f1097, %f1096, %f1092;
	sub.f32 	%f1098, %f1088, %f1092;
	add.f32 	%f1099, %f1098, %f1098;
	neg.f32 	%f1100, %f1092;
	fma.rn.f32 	%f1101, %f1100, %f1088, %f1099;
	mul.rn.f32 	%f1102, %f1090, %f1101;
	add.f32 	%f1103, %f1097, %f1092;
	sub.f32 	%f1104, %f1092, %f1103;
	add.f32 	%f1105, %f1097, %f1104;
	add.f32 	%f1106, %f1102, %f1105;
	add.f32 	%f1107, %f1103, %f1106;
	sub.f32 	%f1108, %f1103, %f1107;
	add.f32 	%f1109, %f1106, %f1108;
	mul.rn.f32 	%f1110, %f1086, %f1037;
	mul.rn.f32 	%f1111, %f1086, %f1039;
	add.f32 	%f1112, %f1110, %f1107;
	sub.f32 	%f1113, %f1110, %f1112;
	add.f32 	%f1114, %f1107, %f1113;
	add.f32 	%f1115, %f1109, %f1114;
	add.f32 	%f1116, %f1111, %f1115;
	add.f32 	%f1117, %f1112, %f1116;
	sub.f32 	%f1118, %f1112, %f1117;
	add.f32 	%f1119, %f1116, %f1118;
	mul.rn.f32 	%f1120, %f957, %f1117;
	neg.f32 	%f1121, %f1120;
	fma.rn.f32 	%f1122, %f957, %f1117, %f1121;
	fma.rn.f32 	%f1123, %f957, %f1119, %f1122;
	fma.rn.f32 	%f1124, %f941, %f1117, %f1123;
	add.rn.f32 	%f1125, %f1120, %f1124;
	neg.f32 	%f1126, %f1125;
	add.rn.f32 	%f1127, %f1120, %f1126;
	add.rn.f32 	%f1128, %f1127, %f1124;
	mov.b32 	%r406, %f1125;
	setp.eq.s32 	%p314, %r406, 1118925336;
	add.s32 	%r407, %r406, -1;
	mov.b32 	%f1129, %r407;
	add.f32 	%f1130, %f1128, 0f37000000;
	selp.f32 	%f217, %f1130, %f1128, %p314;
	selp.f32 	%f1131, %f1129, %f1125, %p314;
	mul.rn.f32 	%f1132, %f1131, %f1062;
	cvt.rzi.f32.f32 	%f1133, %f1132;
	abs.f32 	%f1134, %f1133;
	setp.gt.f32 	%p315, %f1134, 0f42FC0000;
	mov.b32 	%r408, %f1133;
	and.b32  	%r409, %r408, -2147483648;
	or.b32  	%r410, %r409, 1123811328;
	mov.b32 	%f1135, %r410;
	selp.f32 	%f1136, %f1135, %f1133, %p315;
	fma.rn.f32 	%f1137, %f1136, %f1068, %f1131;
	fma.rn.f32 	%f1138, %f1136, %f1070, %f1137;
	mul.f32 	%f1139, %f1138, 0f3FB8AA3B;
	add.f32 	%f1140, %f1136, 0f4B40007F;
	mov.b32 	%r411, %f1140;
	shl.b32 	%r412, %r411, 23;
	mov.b32 	%f1141, %r412;
	ex2.approx.ftz.f32 	%f1142, %f1139;
	mul.f32 	%f218, %f1142, %f1141;
	add.f32 	%f219, %f210, 0f40000000;
	setp.lt.f32 	%p316, %f215, 0f00000000;
	and.pred  	%p14, %p316, %p311;
	selp.f32 	%f220, 0fFF800000, 0f7F800000, %p13;
	add.f32 	%f1143, %f215, %f215;
	selp.f32 	%f221, %f1143, 0f00000000, %p311;
	add.f32 	%f1144, %f216, 0f40000000;
	mov.b32 	%r81, %f1144;
	add.f32 	%f222, %f215, 0f40000000;
	selp.f32 	%f223, 0fFF800000, 0f7F800000, %p14;
	setp.geu.f32 	%p15, %f210, 0f00000000;
	setp.geu.f32 	%p16, %f215, 0f00000000;
	mov.u32 	%r525, %r387;

$L__BB4_208:
	setp.ltu.f32 	%p317, %f206, 0f3F8060FE;
	mov.f32 	%f1801, %f207;
	@%p317 bra 	$L__BB4_210;

	ex2.approx.ftz.f32 	%f1145, %f207;
	sub.f32 	%f1147, %f954, %f1145;
	mov.b32 	%r413, %f1147;
	or.b32  	%r414, %r78, %r413;
	mov.b32 	%f1801, %r414;

$L__BB4_210:
	setp.ltu.f32 	%p318, %f208, 0f3F8060FE;
	mov.f32 	%f1802, %f209;
	@%p318 bra 	$L__BB4_212;

	ex2.approx.ftz.f32 	%f1148, %f209;
	sub.f32 	%f1150, %f954, %f1148;
	mov.b32 	%r415, %f1150;
	or.b32  	%r416, %r79, %r415;
	mov.b32 	%f1802, %r416;

$L__BB4_212:
	sub.f32 	%f1151, %f1801, %f1802;
	mul.f32 	%f239, %f1151, 0f3F000000;
	cvt.rn.f32.s32 	%f240, %r525;
	sub.f32 	%f241, %f240, %f1776;
	add.f32 	%f1152, %f241, 0f3F000000;
	mul.f32 	%f242, %f193, %f1152;
	abs.f32 	%f1153, %f242;
	setp.ltu.f32 	%p319, %f1153, 0f3F8060FE;
	setp.ge.f32 	%p320, %f1153, 0f3F8060FE;
	mul.f32 	%f1154, %f242, %f242;
	selp.f32 	%f1155, %f1153, %f1154, %p320;
	selp.f32 	%f1156, 0f3789CA3C, 0f38B1E96A, %p320;
	selp.f32 	%f1157, 0fB9F560B9, 0fBA574D20, %p320;
	fma.rn.f32 	%f1158, %f1156, %f1155, %f1157;
	selp.f32 	%f1159, 0f3BAC840B, 0f3BAAD5EA, %p320;
	fma.rn.f32 	%f1160, %f1158, %f1155, %f1159;
	selp.f32 	%f1161, 0fBD0C8162, 0fBCDC1BE7, %p320;
	fma.rn.f32 	%f1162, %f1160, %f1155, %f1161;
	selp.f32 	%f1163, 0f3E1CF906, 0f3DE718AF, %p320;
	fma.rn.f32 	%f1164, %f1162, %f1155, %f1163;
	selp.f32 	%f1165, 0f3F6A937E, 0fBEC093AC, %p320;
	fma.rn.f32 	%f1166, %f1164, %f1155, %f1165;
	selp.f32 	%f1167, 0f3F20D842, 0f3E0375D3, %p320;
	fma.rn.f32 	%f1168, %f1166, %f1155, %f1167;
	neg.f32 	%f1169, %f1153;
	selp.f32 	%f1170, %f1169, %f242, %p320;
	fma.rn.f32 	%f1803, %f1168, %f1170, %f1170;
	@%p319 bra 	$L__BB4_214;

	ex2.approx.ftz.f32 	%f1171, %f1803;
	sub.f32 	%f1173, %f954, %f1171;
	mov.b32 	%r417, %f1173;
	mov.b32 	%r418, %f242;
	and.b32  	%r419, %r418, -2147483648;
	or.b32  	%r420, %r419, %r417;
	mov.b32 	%f1803, %r420;

$L__BB4_214:
	add.f32 	%f246, %f241, 0fBF000000;
	mul.f32 	%f247, %f193, %f246;
	abs.f32 	%f1174, %f247;
	setp.ltu.f32 	%p321, %f1174, 0f3F8060FE;
	setp.ge.f32 	%p322, %f1174, 0f3F8060FE;
	mul.f32 	%f1175, %f247, %f247;
	selp.f32 	%f1176, %f1174, %f1175, %p322;
	selp.f32 	%f1177, 0f3789CA3C, 0f38B1E96A, %p322;
	selp.f32 	%f1178, 0fB9F560B9, 0fBA574D20, %p322;
	fma.rn.f32 	%f1179, %f1177, %f1176, %f1178;
	selp.f32 	%f1180, 0f3BAC840B, 0f3BAAD5EA, %p322;
	fma.rn.f32 	%f1181, %f1179, %f1176, %f1180;
	selp.f32 	%f1182, 0fBD0C8162, 0fBCDC1BE7, %p322;
	fma.rn.f32 	%f1183, %f1181, %f1176, %f1182;
	selp.f32 	%f1184, 0f3E1CF906, 0f3DE718AF, %p322;
	fma.rn.f32 	%f1185, %f1183, %f1176, %f1184;
	selp.f32 	%f1186, 0f3F6A937E, 0fBEC093AC, %p322;
	fma.rn.f32 	%f1187, %f1185, %f1176, %f1186;
	selp.f32 	%f1188, 0f3F20D842, 0f3E0375D3, %p322;
	fma.rn.f32 	%f1189, %f1187, %f1176, %f1188;
	neg.f32 	%f1190, %f1174;
	selp.f32 	%f1191, %f1190, %f247, %p322;
	fma.rn.f32 	%f1804, %f1189, %f1191, %f1191;
	@%p321 bra 	$L__BB4_216;

	ex2.approx.ftz.f32 	%f1192, %f1804;
	sub.f32 	%f1194, %f954, %f1192;
	mov.b32 	%r421, %f1194;
	mov.b32 	%r422, %f247;
	and.b32  	%r423, %r422, -2147483648;
	or.b32  	%r424, %r423, %r421;
	mov.b32 	%f1804, %r424;

$L__BB4_216:
	sub.f32 	%f1196, %f1803, %f1804;
	mul.f32 	%f251, %f1196, 0f3F000000;
	mul.f32 	%f1197, %f239, %f1775;
	fma.rn.f32 	%f252, %f251, %f1197, %f1774;
	mad.lo.s32 	%r425, %r525, %r85, %r524;
	add.s32 	%r426, %r425, %r2;
	mul.wide.s32 	%rd34, %r426, 4;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.f32 	%f253, [%rd35];
	setp.eq.f32 	%p323, %f213, 0f7F800000;
	mov.f32 	%f1805, 0f7F800000;
	@%p323 bra 	$L__BB4_218;

	fma.rn.f32 	%f1805, %f213, %f212, %f213;

$L__BB4_218:
	mov.b32 	%r427, %f1805;
	xor.b32  	%r428, %r427, -2147483648;
	mov.b32 	%f1198, %r428;
	selp.f32 	%f256, %f1198, %f1805, %p13;
	setp.eq.f32 	%p324, %f210, 0f00000000;
	selp.f32 	%f1806, %f214, %f256, %p324;
	@%p15 bra 	$L__BB4_221;

	cvt.rzi.f32.f32 	%f1200, %f957;
	setp.eq.f32 	%p325, %f1200, 0f40000000;
	mov.f32 	%f1806, %f256;
	@%p325 bra 	$L__BB4_221;

	mov.f32 	%f1806, 0f7FFFFFFF;

$L__BB4_221:
	setp.eq.f32 	%p326, %f218, 0f7F800000;
	mov.f32 	%f1807, 0f7F800000;
	@%p326 bra 	$L__BB4_223;

	fma.rn.f32 	%f1807, %f218, %f217, %f218;

$L__BB4_223:
	mov.b32 	%r429, %f1807;
	xor.b32  	%r430, %r429, -2147483648;
	mov.b32 	%f1203, %r430;
	selp.f32 	%f261, %f1203, %f1807, %p14;
	setp.eq.f32 	%p327, %f215, 0f00000000;
	selp.f32 	%f1808, %f221, %f261, %p327;
	@%p16 bra 	$L__BB4_226;

	cvt.rzi.f32.f32 	%f1205, %f957;
	setp.eq.f32 	%p328, %f1205, 0f40000000;
	mov.f32 	%f1808, %f261;
	@%p328 bra 	$L__BB4_226;

	mov.f32 	%f1808, 0f7FFFFFFF;

$L__BB4_226:
	setp.gtu.f32 	%p329, %f211, 0f7F800000;
	mov.f32 	%f1809, 0f7F800000;
	selp.f32 	%f1208, %f219, %f1806, %p329;
	setp.neu.f32 	%p330, %f211, 0f7F800000;
	selp.f32 	%f1209, %f1208, %f220, %p330;
	setp.gt.s32 	%p331, %r80, 2139095039;
	selp.f32 	%f1210, %f1209, %f1806, %p331;
	mul.f32 	%f1211, %f1210, 0fBF000000;
	setp.eq.f32 	%p332, %f210, 0f3F800000;
	selp.f32 	%f1212, 0fBF000000, %f1211, %p332;
	mov.f32 	%f1214, 0f3BBB989D;
	fma.rn.f32 	%f1215, %f1212, %f1214, %f358;
	mov.f32 	%f1217, 0f437C0000;
	cvt.sat.f32.f32 	%f1218, %f1215;
	mov.f32 	%f1219, 0f4B400001;
	fma.rm.f32 	%f1220, %f1218, %f1217, %f1219;
	setp.gtu.f32 	%p333, %f216, 0f7F800000;
	selp.f32 	%f1221, %f222, %f1808, %p333;
	setp.neu.f32 	%p334, %f216, 0f7F800000;
	selp.f32 	%f1222, %f1221, %f223, %p334;
	setp.gt.s32 	%p335, %r81, 2139095039;
	selp.f32 	%f1223, %f1222, %f1808, %p335;
	mul.f32 	%f1224, %f1223, 0fBF000000;
	setp.eq.f32 	%p336, %f215, 0f3F800000;
	selp.f32 	%f1225, 0fBF000000, %f1224, %p336;
	fma.rn.f32 	%f1226, %f1225, %f1214, %f358;
	cvt.sat.f32.f32 	%f1227, %f1226;
	fma.rm.f32 	%f1228, %f1227, %f1217, %f1219;
	add.f32 	%f1229, %f1228, 0fCB40007F;
	neg.f32 	%f1230, %f1229;
	fma.rn.f32 	%f1231, %f1225, %f1062, %f1230;
	mov.f32 	%f1232, 0f32A57060;
	fma.rn.f32 	%f1233, %f1225, %f1232, %f1231;
	mov.b32 	%r431, %f1228;
	shl.b32 	%r432, %r431, 23;
	mov.b32 	%f1234, %r432;
	ex2.approx.ftz.f32 	%f1235, %f1233;
	mul.f32 	%f1236, %f1235, %f1234;
	mov.b32 	%r433, %f1220;
	shl.b32 	%r434, %r433, 23;
	mov.b32 	%f1237, %r434;
	add.f32 	%f1238, %f1220, 0fCB40007F;
	neg.f32 	%f1239, %f1238;
	fma.rn.f32 	%f1240, %f1212, %f1062, %f1239;
	fma.rn.f32 	%f1241, %f1212, %f1232, %f1240;
	ex2.approx.ftz.f32 	%f1242, %f1241;
	mul.f32 	%f1243, %f1242, %f1237;
	sub.f32 	%f1244, %f1243, %f1236;
	mul.f32 	%f1245, %f192, %f1244;
	mul.f32 	%f264, %f251, %f1245;
	add.f32 	%f1246, %f240, 0f3F000000;
	sub.f32 	%f1247, %f1246, %f1776;
	div.rn.f32 	%f265, %f1247, %f325;
	abs.f32 	%f266, %f265;
	setp.lt.f32 	%p337, %f266, 0f00800000;
	mul.f32 	%f1248, %f266, 0f4B800000;
	selp.f32 	%f1249, %f1248, %f266, %p337;
	selp.f32 	%f1250, 0fC3170000, 0fC2FE0000, %p337;
	mov.b32 	%r435, %f1249;
	and.b32  	%r436, %r435, 8388607;
	or.b32  	%r437, %r436, 1065353216;
	mov.b32 	%f1251, %r437;
	shr.u32 	%r438, %r435, 23;
	cvt.rn.f32.u32 	%f1252, %r438;
	add.f32 	%f1253, %f1250, %f1252;
	setp.gt.f32 	%p338, %f1251, 0f3FB504F3;
	mul.f32 	%f1254, %f1251, 0f3F000000;
	add.f32 	%f1255, %f1253, 0f3F800000;
	selp.f32 	%f1256, %f1255, %f1253, %p338;
	selp.f32 	%f1257, %f1254, %f1251, %p338;
	add.f32 	%f1258, %f1257, 0fBF800000;
	add.f32 	%f1259, %f1257, 0f3F800000;
	rcp.approx.ftz.f32 	%f1260, %f1259;
	add.f32 	%f1261, %f1258, %f1258;
	mul.f32 	%f1263, %f1261, %f1260;
	mul.f32 	%f1264, %f1263, %f1263;
	fma.rn.f32 	%f1267, %f1019, %f1264, %f1018;
	fma.rn.f32 	%f1269, %f1267, %f1264, %f1021;
	mul.rn.f32 	%f1270, %f1269, %f1264;
	mul.rn.f32 	%f1271, %f1270, %f1263;
	sub.f32 	%f1272, %f1258, %f1263;
	add.f32 	%f1273, %f1272, %f1272;
	neg.f32 	%f1274, %f1263;
	fma.rn.f32 	%f1275, %f1274, %f1258, %f1273;
	mul.rn.f32 	%f1276, %f1260, %f1275;
	add.f32 	%f1277, %f1271, %f1263;
	sub.f32 	%f1278, %f1263, %f1277;
	add.f32 	%f1279, %f1271, %f1278;
	add.f32 	%f1280, %f1276, %f1279;
	add.f32 	%f1281, %f1277, %f1280;
	sub.f32 	%f1282, %f1277, %f1281;
	add.f32 	%f1283, %f1280, %f1282;
	mul.rn.f32 	%f1285, %f1256, %f1037;
	mul.rn.f32 	%f1287, %f1256, %f1039;
	add.f32 	%f1288, %f1285, %f1281;
	sub.f32 	%f1289, %f1285, %f1288;
	add.f32 	%f1290, %f1281, %f1289;
	add.f32 	%f1291, %f1283, %f1290;
	add.f32 	%f1292, %f1287, %f1291;
	add.f32 	%f1293, %f1288, %f1292;
	sub.f32 	%f1294, %f1288, %f1293;
	add.f32 	%f1295, %f1292, %f1294;
	mul.rn.f32 	%f1296, %f957, %f1293;
	neg.f32 	%f1297, %f1296;
	fma.rn.f32 	%f1298, %f957, %f1293, %f1297;
	fma.rn.f32 	%f1299, %f957, %f1295, %f1298;
	mov.f32 	%f1300, 0f00000000;
	fma.rn.f32 	%f1301, %f1300, %f1293, %f1299;
	add.rn.f32 	%f1302, %f1296, %f1301;
	neg.f32 	%f1303, %f1302;
	add.rn.f32 	%f1304, %f1296, %f1303;
	add.rn.f32 	%f1305, %f1304, %f1301;
	mov.b32 	%r439, %f1302;
	setp.eq.s32 	%p339, %r439, 1118925336;
	add.s32 	%r440, %r439, -1;
	mov.b32 	%f1306, %r440;
	add.f32 	%f1307, %f1305, 0f37000000;
	selp.f32 	%f267, %f1307, %f1305, %p339;
	selp.f32 	%f1308, %f1306, %f1302, %p339;
	mul.rn.f32 	%f1309, %f1308, %f1062;
	cvt.rzi.f32.f32 	%f1310, %f1309;
	abs.f32 	%f1311, %f1310;
	setp.gt.f32 	%p340, %f1311, 0f42FC0000;
	mov.b32 	%r441, %f1310;
	and.b32  	%r442, %r441, -2147483648;
	or.b32  	%r443, %r442, 1123811328;
	mov.b32 	%f1312, %r443;
	selp.f32 	%f1313, %f1312, %f1310, %p340;
	fma.rn.f32 	%f1315, %f1313, %f1068, %f1308;
	fma.rn.f32 	%f1317, %f1313, %f1070, %f1315;
	mul.f32 	%f1318, %f1317, 0f3FB8AA3B;
	add.f32 	%f1319, %f1313, 0f4B40007F;
	mov.b32 	%r444, %f1319;
	shl.b32 	%r445, %r444, 23;
	mov.b32 	%f1320, %r445;
	ex2.approx.ftz.f32 	%f1321, %f1318;
	mul.f32 	%f268, %f1321, %f1320;
	setp.eq.f32 	%p341, %f268, 0f7F800000;
	@%p341 bra 	$L__BB4_228;

	fma.rn.f32 	%f1809, %f268, %f267, %f268;

$L__BB4_228:
	setp.lt.f32 	%p342, %f265, 0f00000000;
	and.pred  	%p17, %p342, %p311;
	setp.eq.f32 	%p344, %f265, 0f00000000;
	@%p344 bra 	$L__BB4_232;
	bra.uni 	$L__BB4_229;

$L__BB4_232:
	add.f32 	%f1326, %f265, %f265;
	selp.f32 	%f1811, %f1326, 0f00000000, %p311;
	bra.uni 	$L__BB4_233;

$L__BB4_229:
	mov.b32 	%r446, %f1809;
	xor.b32  	%r447, %r446, -2147483648;
	mov.b32 	%f1322, %r447;
	selp.f32 	%f1811, %f1322, %f1809, %p17;
	setp.geu.f32 	%p345, %f265, 0f00000000;
	@%p345 bra 	$L__BB4_233;

	cvt.rzi.f32.f32 	%f1324, %f957;
	setp.eq.f32 	%p346, %f1324, 0f40000000;
	@%p346 bra 	$L__BB4_233;

	mov.f32 	%f1811, 0f7FFFFFFF;

$L__BB4_233:
	add.f32 	%f1327, %f266, 0f40000000;
	mov.b32 	%r448, %f1327;
	setp.lt.s32 	%p348, %r448, 2139095040;
	@%p348 bra 	$L__BB4_238;

	setp.gtu.f32 	%p349, %f266, 0f7F800000;
	@%p349 bra 	$L__BB4_237;
	bra.uni 	$L__BB4_235;

$L__BB4_237:
	add.f32 	%f1811, %f265, 0f40000000;
	bra.uni 	$L__BB4_238;

$L__BB4_235:
	setp.neu.f32 	%p350, %f266, 0f7F800000;
	@%p350 bra 	$L__BB4_238;

	selp.f32 	%f1811, 0fFF800000, 0f7F800000, %p17;

$L__BB4_238:
	mul.f32 	%f1329, %f1811, 0fBF000000;
	setp.eq.f32 	%p351, %f265, 0f3F800000;
	selp.f32 	%f1330, 0fBF000000, %f1329, %p351;
	fma.rn.f32 	%f1333, %f1330, %f1214, %f358;
	cvt.sat.f32.f32 	%f1336, %f1333;
	fma.rm.f32 	%f1338, %f1336, %f1217, %f1219;
	add.f32 	%f1339, %f1338, 0fCB40007F;
	neg.f32 	%f1340, %f1339;
	fma.rn.f32 	%f1341, %f1330, %f1062, %f1340;
	fma.rn.f32 	%f1343, %f1330, %f1232, %f1341;
	mov.b32 	%r449, %f1338;
	shl.b32 	%r450, %r449, 23;
	mov.b32 	%f1344, %r450;
	ex2.approx.ftz.f32 	%f1345, %f1343;
	mul.f32 	%f277, %f1345, %f1344;
	div.rn.f32 	%f278, %f246, %f325;
	abs.f32 	%f279, %f278;
	setp.lt.f32 	%p352, %f279, 0f00800000;
	mul.f32 	%f1346, %f279, 0f4B800000;
	selp.f32 	%f1347, %f1346, %f279, %p352;
	selp.f32 	%f1348, 0fC3170000, 0fC2FE0000, %p352;
	mov.b32 	%r451, %f1347;
	and.b32  	%r452, %r451, 8388607;
	or.b32  	%r453, %r452, 1065353216;
	mov.b32 	%f1349, %r453;
	shr.u32 	%r454, %r451, 23;
	cvt.rn.f32.u32 	%f1350, %r454;
	add.f32 	%f1351, %f1348, %f1350;
	setp.gt.f32 	%p353, %f1349, 0f3FB504F3;
	mul.f32 	%f1352, %f1349, 0f3F000000;
	add.f32 	%f1353, %f1351, 0f3F800000;
	selp.f32 	%f1354, %f1353, %f1351, %p353;
	selp.f32 	%f1355, %f1352, %f1349, %p353;
	add.f32 	%f1356, %f1355, 0fBF800000;
	add.f32 	%f1357, %f1355, 0f3F800000;
	rcp.approx.ftz.f32 	%f1358, %f1357;
	add.f32 	%f1359, %f1356, %f1356;
	mul.f32 	%f1361, %f1359, %f1358;
	mul.f32 	%f1362, %f1361, %f1361;
	fma.rn.f32 	%f1365, %f1019, %f1362, %f1018;
	fma.rn.f32 	%f1367, %f1365, %f1362, %f1021;
	mul.rn.f32 	%f1368, %f1367, %f1362;
	mul.rn.f32 	%f1369, %f1368, %f1361;
	sub.f32 	%f1370, %f1356, %f1361;
	add.f32 	%f1371, %f1370, %f1370;
	neg.f32 	%f1372, %f1361;
	fma.rn.f32 	%f1373, %f1372, %f1356, %f1371;
	mul.rn.f32 	%f1374, %f1358, %f1373;
	add.f32 	%f1375, %f1369, %f1361;
	sub.f32 	%f1376, %f1361, %f1375;
	add.f32 	%f1377, %f1369, %f1376;
	add.f32 	%f1378, %f1374, %f1377;
	add.f32 	%f1379, %f1375, %f1378;
	sub.f32 	%f1380, %f1375, %f1379;
	add.f32 	%f1381, %f1378, %f1380;
	mul.rn.f32 	%f1383, %f1354, %f1037;
	mul.rn.f32 	%f1385, %f1354, %f1039;
	add.f32 	%f1386, %f1383, %f1379;
	sub.f32 	%f1387, %f1383, %f1386;
	add.f32 	%f1388, %f1379, %f1387;
	add.f32 	%f1389, %f1381, %f1388;
	add.f32 	%f1390, %f1385, %f1389;
	add.f32 	%f1391, %f1386, %f1390;
	sub.f32 	%f1392, %f1386, %f1391;
	add.f32 	%f1393, %f1390, %f1392;
	mul.rn.f32 	%f1394, %f957, %f1391;
	neg.f32 	%f1395, %f1394;
	fma.rn.f32 	%f1396, %f957, %f1391, %f1395;
	fma.rn.f32 	%f1397, %f957, %f1393, %f1396;
	fma.rn.f32 	%f1399, %f1300, %f1391, %f1397;
	add.rn.f32 	%f1400, %f1394, %f1399;
	neg.f32 	%f1401, %f1400;
	add.rn.f32 	%f1402, %f1394, %f1401;
	add.rn.f32 	%f1403, %f1402, %f1399;
	mov.b32 	%r455, %f1400;
	setp.eq.s32 	%p354, %r455, 1118925336;
	add.s32 	%r456, %r455, -1;
	mov.b32 	%f1404, %r456;
	add.f32 	%f1405, %f1403, 0f37000000;
	selp.f32 	%f280, %f1405, %f1403, %p354;
	selp.f32 	%f1406, %f1404, %f1400, %p354;
	mul.rn.f32 	%f1407, %f1406, %f1062;
	cvt.rzi.f32.f32 	%f1408, %f1407;
	abs.f32 	%f1409, %f1408;
	setp.gt.f32 	%p355, %f1409, 0f42FC0000;
	mov.b32 	%r457, %f1408;
	and.b32  	%r458, %r457, -2147483648;
	or.b32  	%r459, %r458, 1123811328;
	mov.b32 	%f1410, %r459;
	selp.f32 	%f1411, %f1410, %f1408, %p355;
	fma.rn.f32 	%f1413, %f1411, %f1068, %f1406;
	fma.rn.f32 	%f1415, %f1411, %f1070, %f1413;
	mul.f32 	%f1416, %f1415, 0f3FB8AA3B;
	add.f32 	%f1417, %f1411, 0f4B40007F;
	mov.b32 	%r460, %f1417;
	shl.b32 	%r461, %r460, 23;
	mov.b32 	%f1418, %r461;
	ex2.approx.ftz.f32 	%f1419, %f1416;
	mul.f32 	%f281, %f1419, %f1418;
	setp.eq.f32 	%p356, %f281, 0f7F800000;
	mov.f32 	%f1812, 0f7F800000;
	@%p356 bra 	$L__BB4_240;

	fma.rn.f32 	%f1812, %f281, %f280, %f281;

$L__BB4_240:
	setp.lt.f32 	%p357, %f278, 0f00000000;
	and.pred  	%p18, %p357, %p311;
	setp.eq.f32 	%p359, %f278, 0f00000000;
	@%p359 bra 	$L__BB4_244;
	bra.uni 	$L__BB4_241;

$L__BB4_244:
	add.f32 	%f1424, %f278, %f278;
	selp.f32 	%f1814, %f1424, 0f00000000, %p311;
	bra.uni 	$L__BB4_245;

$L__BB4_241:
	mov.b32 	%r462, %f1812;
	xor.b32  	%r463, %r462, -2147483648;
	mov.b32 	%f1420, %r463;
	selp.f32 	%f1814, %f1420, %f1812, %p18;
	setp.geu.f32 	%p360, %f278, 0f00000000;
	@%p360 bra 	$L__BB4_245;

	cvt.rzi.f32.f32 	%f1422, %f957;
	setp.eq.f32 	%p361, %f1422, 0f40000000;
	@%p361 bra 	$L__BB4_245;

	mov.f32 	%f1814, 0f7FFFFFFF;

$L__BB4_245:
	add.f32 	%f1425, %f279, 0f40000000;
	mov.b32 	%r464, %f1425;
	setp.lt.s32 	%p363, %r464, 2139095040;
	@%p363 bra 	$L__BB4_250;

	setp.gtu.f32 	%p364, %f279, 0f7F800000;
	@%p364 bra 	$L__BB4_249;
	bra.uni 	$L__BB4_247;

$L__BB4_249:
	add.f32 	%f1814, %f278, 0f40000000;
	bra.uni 	$L__BB4_250;

$L__BB4_247:
	setp.neu.f32 	%p365, %f279, 0f7F800000;
	@%p365 bra 	$L__BB4_250;

	selp.f32 	%f1814, 0fFF800000, 0f7F800000, %p18;

$L__BB4_250:
	mul.f32 	%f1426, %f1814, 0fBF000000;
	setp.eq.f32 	%p366, %f278, 0f3F800000;
	selp.f32 	%f1427, 0fBF000000, %f1426, %p366;
	fma.rn.f32 	%f1430, %f1427, %f1214, %f358;
	cvt.sat.f32.f32 	%f1433, %f1430;
	fma.rm.f32 	%f1435, %f1433, %f1217, %f1219;
	add.f32 	%f1436, %f1435, 0fCB40007F;
	neg.f32 	%f1437, %f1436;
	fma.rn.f32 	%f1438, %f1427, %f1062, %f1437;
	fma.rn.f32 	%f1440, %f1427, %f1232, %f1438;
	mov.b32 	%r465, %f1435;
	shl.b32 	%r466, %r465, 23;
	mov.b32 	%f1441, %r466;
	ex2.approx.ftz.f32 	%f1442, %f1440;
	mul.f32 	%f1443, %f1442, %f1441;
	sub.f32 	%f1444, %f277, %f1443;
	mul.f32 	%f1445, %f192, %f1444;
	mul.f32 	%f1446, %f239, %f1445;
	mul.f32 	%f1447, %f264, %f264;
	add.f32 	%f290, %f1773, %f252;
	div.rn.f32 	%f1448, %f1447, %f290;
	add.f32 	%f1796, %f1796, %f1448;
	mul.f32 	%f1449, %f1446, %f264;
	div.rn.f32 	%f1450, %f1449, %f290;
	add.f32 	%f1795, %f1795, %f1450;
	mul.f32 	%f1451, %f239, %f251;
	mul.f32 	%f1452, %f1451, %f264;
	div.rn.f32 	%f1453, %f1452, %f290;
	add.f32 	%f1794, %f1794, %f1453;
	div.rn.f32 	%f1454, %f264, %f290;
	add.f32 	%f1793, %f1793, %f1454;
	mul.f32 	%f1455, %f1446, %f1446;
	div.rn.f32 	%f1456, %f1455, %f290;
	add.f32 	%f1792, %f1792, %f1456;
	mul.f32 	%f1457, %f1451, %f1446;
	div.rn.f32 	%f1458, %f1457, %f290;
	add.f32 	%f1791, %f1791, %f1458;
	div.rn.f32 	%f1459, %f1446, %f290;
	add.f32 	%f1790, %f1790, %f1459;
	mul.f32 	%f1460, %f1451, %f1451;
	div.rn.f32 	%f1461, %f1460, %f290;
	add.f32 	%f1797, %f1797, %f1461;
	div.rn.f32 	%f1462, %f1451, %f290;
	add.f32 	%f1798, %f1798, %f1462;
	rcp.rn.f32 	%f1463, %f290;
	add.f32 	%f1799, %f1799, %f1463;
	setp.leu.f32 	%p367, %f290, 0f00000000;
	@%p367 bra 	$L__BB4_258;

	add.f32 	%f301, %f1773, %f253;
	setp.gt.f32 	%p368, %f301, 0f00000000;
	@%p368 bra 	$L__BB4_253;
	bra.uni 	$L__BB4_252;

$L__BB4_253:
	setp.lt.f32 	%p369, %f290, 0f00800000;
	mul.f32 	%f1466, %f290, 0f4B000000;
	selp.f32 	%f303, %f1466, %f290, %p369;
	selp.f32 	%f1467, 0fC1B80000, 0f00000000, %p369;
	mov.b32 	%r467, %f303;
	add.s32 	%r468, %r467, -1059760811;
	and.b32  	%r469, %r468, -8388608;
	sub.s32 	%r470, %r467, %r469;
	mov.b32 	%f1468, %r470;
	cvt.rn.f32.s32 	%f1469, %r469;
	mov.f32 	%f1470, 0f34000000;
	fma.rn.f32 	%f1471, %f1469, %f1470, %f1467;
	add.f32 	%f1472, %f1468, 0fBF800000;
	mov.f32 	%f1473, 0f3E1039F6;
	mov.f32 	%f1474, 0fBE055027;
	fma.rn.f32 	%f1475, %f1474, %f1472, %f1473;
	mov.f32 	%f1476, 0fBDF8CDCC;
	fma.rn.f32 	%f1477, %f1475, %f1472, %f1476;
	mov.f32 	%f1478, 0f3E0F2955;
	fma.rn.f32 	%f1479, %f1477, %f1472, %f1478;
	mov.f32 	%f1480, 0fBE2AD8B9;
	fma.rn.f32 	%f1481, %f1479, %f1472, %f1480;
	mov.f32 	%f1482, 0f3E4CED0B;
	fma.rn.f32 	%f1483, %f1481, %f1472, %f1482;
	mov.f32 	%f1484, 0fBE7FFF22;
	fma.rn.f32 	%f1485, %f1483, %f1472, %f1484;
	mov.f32 	%f1486, 0f3EAAAA78;
	fma.rn.f32 	%f1487, %f1485, %f1472, %f1486;
	mov.f32 	%f1488, 0fBF000000;
	fma.rn.f32 	%f1489, %f1487, %f1472, %f1488;
	mul.f32 	%f1490, %f1472, %f1489;
	fma.rn.f32 	%f1491, %f1490, %f1472, %f1472;
	mov.f32 	%f1492, 0f3F317218;
	fma.rn.f32 	%f1815, %f1471, %f1492, %f1491;
	setp.lt.u32 	%p370, %r467, 2139095040;
	@%p370 bra 	$L__BB4_255;

	mov.f32 	%f1493, 0f7F800000;
	fma.rn.f32 	%f1815, %f303, %f1493, %f1493;

$L__BB4_255:
	setp.eq.f32 	%p371, %f303, 0f00000000;
	selp.f32 	%f1494, 0fFF800000, %f1815, %p371;
	mul.f32 	%f1495, %f301, %f1494;
	sub.f32 	%f307, %f1495, %f252;
	mul.f32 	%f1496, %f301, 0f4B000000;
	setp.lt.f32 	%p372, %f301, 0f00800000;
	selp.f32 	%f308, %f1496, %f301, %p372;
	selp.f32 	%f1497, 0fC1B80000, 0f00000000, %p372;
	mov.b32 	%r471, %f308;
	add.s32 	%r472, %r471, -1059760811;
	and.b32  	%r473, %r472, -8388608;
	sub.s32 	%r474, %r471, %r473;
	mov.b32 	%f1498, %r474;
	cvt.rn.f32.s32 	%f1499, %r473;
	fma.rn.f32 	%f1501, %f1499, %f1470, %f1497;
	add.f32 	%f1502, %f1498, 0fBF800000;
	fma.rn.f32 	%f1505, %f1474, %f1502, %f1473;
	fma.rn.f32 	%f1507, %f1505, %f1502, %f1476;
	fma.rn.f32 	%f1509, %f1507, %f1502, %f1478;
	fma.rn.f32 	%f1511, %f1509, %f1502, %f1480;
	fma.rn.f32 	%f1513, %f1511, %f1502, %f1482;
	fma.rn.f32 	%f1515, %f1513, %f1502, %f1484;
	fma.rn.f32 	%f1517, %f1515, %f1502, %f1486;
	fma.rn.f32 	%f1519, %f1517, %f1502, %f1488;
	mul.f32 	%f1520, %f1502, %f1519;
	fma.rn.f32 	%f1521, %f1520, %f1502, %f1502;
	fma.rn.f32 	%f1816, %f1501, %f1492, %f1521;
	setp.lt.u32 	%p373, %r471, 2139095040;
	@%p373 bra 	$L__BB4_257;

	mov.f32 	%f1523, 0f7F800000;
	fma.rn.f32 	%f1816, %f308, %f1523, %f1523;

$L__BB4_257:
	setp.eq.f32 	%p374, %f308, 0f00000000;
	selp.f32 	%f1524, 0fFF800000, %f1816, %p374;
	mul.f32 	%f1525, %f301, %f1524;
	sub.f32 	%f1526, %f307, %f1525;
	add.f32 	%f1527, %f253, %f1526;
	add.f32 	%f1817, %f1817, %f1527;
	bra.uni 	$L__BB4_258;

$L__BB4_252:
	neg.f32 	%f1464, %f252;
	sub.f32 	%f1465, %f1464, %f1773;
	add.f32 	%f1817, %f1817, %f1465;

$L__BB4_258:
	add.s32 	%r525, %r525, 1;
	setp.lt.s32 	%p375, %r525, %r85;
	@%p375 bra 	$L__BB4_208;

	add.s32 	%r524, %r524, 1;
	setp.lt.s32 	%p376, %r524, %r85;
	@%p376 bra 	$L__BB4_207;

$L__BB4_260:
	ld.param.u64 	%rd54, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_9];
	ld.param.u64 	%rd53, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_8];
	ld.param.u32 	%r485, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_10];
	ld.param.u64 	%rd52, [_Z24kernel_MLEFit_SCMOSXYNB_PKfS0_S0_fiiiPfS1_S1_i_param_7];
	rcp.rn.f32 	%f1528, %f1796;
	mov.f32 	%f1529, 0f3F800000;
	mul.f32 	%f1530, %f1528, %f1795;
	mul.f32 	%f1531, %f1528, %f1794;
	mul.f32 	%f1532, %f1528, %f1793;
	fma.rn.f32 	%f1533, %f1530, %f1795, 0f00000000;
	sub.f32 	%f1535, %f1792, %f1533;
	fma.rn.f32 	%f1536, %f1531, %f1795, 0f00000000;
	rcp.rn.f32 	%f1537, %f1535;
	sub.f32 	%f1538, %f1791, %f1536;
	mul.f32 	%f1539, %f1537, %f1538;
	fma.rn.f32 	%f1540, %f1532, %f1795, 0f00000000;
	sub.f32 	%f1541, %f1790, %f1540;
	mul.f32 	%f1542, %f1537, %f1541;
	fma.rn.f32 	%f1543, %f1530, %f1794, 0f00000000;
	sub.f32 	%f1544, %f1791, %f1543;
	fma.rn.f32 	%f1545, %f1531, %f1794, 0f00000000;
	fma.rn.f32 	%f1546, %f1539, %f1544, %f1545;
	sub.f32 	%f1547, %f1797, %f1546;
	fma.rn.f32 	%f1548, %f1532, %f1794, 0f00000000;
	fma.rn.f32 	%f1549, %f1542, %f1544, %f1548;
	rcp.rn.f32 	%f1550, %f1547;
	sub.f32 	%f1551, %f1798, %f1549;
	mul.f32 	%f1552, %f1550, %f1551;
	fma.rn.f32 	%f1553, %f1530, %f1793, 0f00000000;
	sub.f32 	%f1554, %f1790, %f1553;
	fma.rn.f32 	%f1555, %f1531, %f1793, 0f00000000;
	fma.rn.f32 	%f1556, %f1539, %f1554, %f1555;
	sub.f32 	%f1557, %f1798, %f1556;
	fma.rn.f32 	%f1558, %f1532, %f1793, 0f00000000;
	fma.rn.f32 	%f1559, %f1542, %f1554, %f1558;
	fma.rn.f32 	%f1560, %f1552, %f1557, %f1559;
	sub.f32 	%f1561, %f1799, %f1560;
	add.f32 	%f1562, %f1530, 0f00000000;
	sub.f32 	%f1563, %f941, %f1562;
	add.f32 	%f1564, %f1531, 0f00000000;
	fma.rn.f32 	%f1565, %f1539, %f1563, %f1564;
	sub.f32 	%f1566, %f941, %f1565;
	add.f32 	%f1567, %f1532, 0f00000000;
	fma.rn.f32 	%f1568, %f1542, %f1563, %f1567;
	fma.rn.f32 	%f1569, %f1552, %f1566, %f1568;
	sub.f32 	%f1570, %f941, %f1569;
	div.rn.f32 	%f1571, %f1570, %f1561;
	fma.rn.f32 	%f1572, %f1557, %f1571, 0f00000000;
	sub.f32 	%f1573, %f1566, %f1572;
	mul.f32 	%f1574, %f1550, %f1573;
	fma.rn.f32 	%f1575, %f1544, %f1574, 0f00000000;
	fma.rn.f32 	%f1576, %f1554, %f1571, %f1575;
	sub.f32 	%f1577, %f1563, %f1576;
	mul.f32 	%f1578, %f1537, %f1577;
	fma.rn.f32 	%f1579, %f1795, %f1578, 0f00000000;
	fma.rn.f32 	%f1580, %f1794, %f1574, %f1579;
	fma.rn.f32 	%f1581, %f1793, %f1571, %f1580;
	sub.f32 	%f1582, %f1529, %f1581;
	mul.f32 	%f1583, %f1528, %f1582;
	fma.rn.f32 	%f1584, %f1530, 0f00000000, 0f00000000;
	sub.f32 	%f1585, %f1529, %f1584;
	fma.rn.f32 	%f1586, %f1531, 0f00000000, 0f00000000;
	fma.rn.f32 	%f1587, %f1539, %f1585, %f1586;
	sub.f32 	%f1588, %f941, %f1587;
	fma.rn.f32 	%f1589, %f1532, 0f00000000, 0f00000000;
	fma.rn.f32 	%f1590, %f1542, %f1585, %f1589;
	fma.rn.f32 	%f1591, %f1552, %f1588, %f1590;
	sub.f32 	%f1592, %f941, %f1591;
	div.rn.f32 	%f1593, %f1592, %f1561;
	fma.rn.f32 	%f1594, %f1557, %f1593, 0f00000000;
	sub.f32 	%f1595, %f1588, %f1594;
	mul.f32 	%f1596, %f1550, %f1595;
	fma.rn.f32 	%f1597, %f1544, %f1596, 0f00000000;
	fma.rn.f32 	%f1598, %f1554, %f1593, %f1597;
	sub.f32 	%f1599, %f1585, %f1598;
	mul.f32 	%f1600, %f1537, %f1599;
	sub.f32 	%f1601, %f941, %f1584;
	fma.rn.f32 	%f1602, %f1539, %f1601, %f1586;
	sub.f32 	%f1603, %f1529, %f1602;
	fma.rn.f32 	%f1604, %f1542, %f1601, %f1589;
	fma.rn.f32 	%f1605, %f1552, %f1603, %f1604;
	sub.f32 	%f1606, %f941, %f1605;
	div.rn.f32 	%f1607, %f1606, %f1561;
	fma.rn.f32 	%f1608, %f1557, %f1607, 0f00000000;
	sub.f32 	%f1609, %f1603, %f1608;
	mul.f32 	%f1610, %f1550, %f1609;
	sub.f32 	%f1611, %f941, %f1602;
	fma.rn.f32 	%f1612, %f1552, %f1611, %f1604;
	sub.f32 	%f1613, %f1529, %f1612;
	div.rn.f32 	%f1614, %f1613, %f1561;
	cvta.to.global.u64 	%rd36, %rd52;
	mul.wide.s32 	%rd37, %r1, 4;
	add.s64 	%rd38, %rd36, %rd37;
	st.global.f32 	[%rd38], %f1777;
	add.s32 	%r479, %r1, %r485;
	mul.wide.s32 	%rd39, %r485, 4;
	add.s64 	%rd40, %rd38, %rd39;
	st.global.f32 	[%rd40], %f1776;
	add.s32 	%r480, %r479, %r485;
	mul.wide.s32 	%rd41, %r480, 4;
	add.s64 	%rd42, %rd36, %rd41;
	st.global.f32 	[%rd42], %f1775;
	add.s32 	%r481, %r480, %r485;
	mul.wide.s32 	%rd43, %r481, 4;
	add.s64 	%rd44, %rd36, %rd43;
	st.global.f32 	[%rd44], %f1774;
	cvta.to.global.u64 	%rd45, %rd53;
	add.s64 	%rd46, %rd45, %rd37;
	st.global.f32 	[%rd46], %f1583;
	add.s64 	%rd47, %rd46, %rd39;
	st.global.f32 	[%rd47], %f1600;
	add.s64 	%rd48, %rd45, %rd41;
	st.global.f32 	[%rd48], %f1610;
	add.s64 	%rd49, %rd45, %rd43;
	st.global.f32 	[%rd49], %f1614;
	cvta.to.global.u64 	%rd50, %rd54;
	add.s64 	%rd51, %rd50, %rd37;
	st.global.f32 	[%rd51], %f1817;

$L__BB4_261:
	ret;

}
	// .globl	_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i
.visible .entry _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i(
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_0,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_1,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_2,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_3,
	.param .u32 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_4,
	.param .u32 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_5,
	.param .u32 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_6,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_7,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_8,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_9,
	.param .u32 _Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_10
)
{
	.reg .pred 	%p<680>;
	.reg .f32 	%f<2967>;
	.reg .b32 	%r<789>;
	.reg .f64 	%fd<558>;
	.reg .b64 	%rd<60>;


	ld.param.u64 	%rd7, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_0];
	ld.param.u64 	%rd8, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_1];
	ld.param.u64 	%rd9, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_2];
	ld.param.f32 	%f2886, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_3];
	ld.param.u32 	%r102, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_4];
	ld.param.u32 	%r105, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_10];
	cvta.to.global.u64 	%rd1, %rd7;
	mov.u32 	%r106, %ntid.x;
	mov.u32 	%r107, %ctaid.x;
	mov.u32 	%r108, %tid.x;
	mad.lo.s32 	%r1, %r107, %r106, %r108;
	setp.ge.s32 	%p39, %r1, %r105;
	@%p39 bra 	$L__BB5_427;

	mul.lo.s32 	%r109, %r102, %r102;
	mul.lo.s32 	%r2, %r109, %r1;
	setp.lt.s32 	%p40, %r102, 1;
	mov.f32 	%f2816, 0f00000000;
	mov.f32 	%f2807, %f2816;
	mov.f32 	%f2808, %f2816;
	mov.f32 	%f2809, %f2816;
	@%p40 bra 	$L__BB5_11;

	add.s32 	%r3, %r102, -1;
	and.b32  	%r4, %r102, 3;
	sub.s32 	%r5, %r102, %r4;
	shl.b32 	%r6, %r102, 2;
	mov.u32 	%r110, 0;
	setp.lt.u32 	%p41, %r3, 3;
	setp.eq.s32 	%p43, %r4, 0;
	setp.eq.s32 	%p44, %r4, 1;
	setp.eq.s32 	%p45, %r4, 2;
	cvt.s64.s32 	%rd15, %r6;
	mov.u32 	%r774, %r110;

$L__BB5_3:
	cvt.rn.f32.s32 	%f4, %r774;
	mov.u32 	%r777, %r110;
	@%p41 bra 	$L__BB5_6;

	mov.u32 	%r777, %r110;
	mov.u32 	%r776, %r5;

$L__BB5_5:
	mad.lo.s32 	%r113, %r777, %r102, %r774;
	add.s32 	%r114, %r113, %r2;
	mul.wide.s32 	%rd13, %r114, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.f32 	%f475, [%rd14];
	fma.rn.f32 	%f476, %f475, %f4, %f2807;
	cvt.rn.f32.s32 	%f477, %r777;
	fma.rn.f32 	%f478, %f475, %f477, %f2808;
	add.f32 	%f479, %f2809, %f475;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.f32 	%f480, [%rd16];
	fma.rn.f32 	%f481, %f480, %f4, %f476;
	add.s32 	%r115, %r777, 1;
	cvt.rn.f32.s32 	%f482, %r115;
	fma.rn.f32 	%f483, %f480, %f482, %f478;
	add.f32 	%f484, %f479, %f480;
	add.s64 	%rd17, %rd16, %rd15;
	ld.global.f32 	%f485, [%rd17];
	fma.rn.f32 	%f486, %f485, %f4, %f481;
	add.s32 	%r116, %r777, 2;
	cvt.rn.f32.s32 	%f487, %r116;
	fma.rn.f32 	%f488, %f485, %f487, %f483;
	add.f32 	%f489, %f484, %f485;
	add.s64 	%rd18, %rd17, %rd15;
	ld.global.f32 	%f490, [%rd18];
	fma.rn.f32 	%f2807, %f490, %f4, %f486;
	add.s32 	%r117, %r777, 3;
	cvt.rn.f32.s32 	%f491, %r117;
	fma.rn.f32 	%f2808, %f490, %f491, %f488;
	add.f32 	%f2809, %f489, %f490;
	add.s32 	%r777, %r777, 4;
	add.s32 	%r776, %r776, -4;
	setp.ne.s32 	%p42, %r776, 0;
	@%p42 bra 	$L__BB5_5;

$L__BB5_6:
	@%p43 bra 	$L__BB5_10;

	mad.lo.s32 	%r13, %r777, %r102, %r774;
	add.s32 	%r118, %r13, %r2;
	mul.wide.s32 	%rd19, %r118, 4;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.f32 	%f492, [%rd20];
	fma.rn.f32 	%f2807, %f492, %f4, %f2807;
	cvt.rn.f32.s32 	%f493, %r777;
	fma.rn.f32 	%f2808, %f492, %f493, %f2808;
	add.f32 	%f2809, %f2809, %f492;
	@%p44 bra 	$L__BB5_10;

	add.s32 	%r14, %r13, %r102;
	add.s32 	%r119, %r14, %r2;
	mul.wide.s32 	%rd21, %r119, 4;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.f32 	%f494, [%rd22];
	fma.rn.f32 	%f2807, %f494, %f4, %f2807;
	add.s32 	%r120, %r777, 1;
	cvt.rn.f32.s32 	%f495, %r120;
	fma.rn.f32 	%f2808, %f494, %f495, %f2808;
	add.f32 	%f2809, %f2809, %f494;
	@%p45 bra 	$L__BB5_10;

	add.s32 	%r121, %r777, 2;
	add.s32 	%r122, %r14, %r102;
	add.s32 	%r123, %r122, %r2;
	mul.wide.s32 	%rd23, %r123, 4;
	add.s64 	%rd24, %rd1, %rd23;
	ld.global.f32 	%f496, [%rd24];
	fma.rn.f32 	%f2807, %f496, %f4, %f2807;
	cvt.rn.f32.s32 	%f497, %r121;
	fma.rn.f32 	%f2808, %f496, %f497, %f2808;
	add.f32 	%f2809, %f2809, %f496;

$L__BB5_10:
	add.s32 	%r774, %r774, 1;
	setp.lt.s32 	%p46, %r774, %r102;
	@%p46 bra 	$L__BB5_3;

$L__BB5_11:
	div.rn.f32 	%f2890, %f2807, %f2809;
	div.rn.f32 	%f2889, %f2808, %f2809;
	mov.f32 	%f2887, 0f51BA43B7;
	@%p40 bra 	$L__BB5_51;

	mov.f32 	%f502, 0f3F000000;
	div.rn.f32 	%f503, %f502, %f2886;
	div.rn.f32 	%f504, %f503, %f2886;
	cvt.f64.f32 	%fd1, %f504;
	mov.f64 	%fd215, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd215;
	}
	and.b32  	%r17, %r16, 2146435072;
	and.b32  	%r18, %r16, 2147483647;
	setp.gt.s32 	%p48, %r16, -1;
	selp.b32 	%r19, 2146435072, 0, %p48;
	mov.u32 	%r124, 0;
	or.b32  	%r20, %r19, -2147483648;
	mul.wide.s32 	%rd25, %r2, 4;
	add.s64 	%rd2, %rd1, %rd25;
	setp.eq.s32 	%p50, %r17, 1062207488;
	setp.lt.s32 	%p51, %r16, 0;
	setp.ne.s32 	%p56, %r18, 1071644672;
	setp.eq.s32 	%p83, %r18, 2146435072;
	mov.u32 	%r778, %r124;

$L__BB5_13:
	mov.u32 	%r779, %r124;

$L__BB5_14:
	mov.u32 	%r127, 1;
	sub.s32 	%r24, %r127, %r779;
	mov.f32 	%f2819, 0f00000000;
	mov.f32 	%f2820, %f2819;
	mov.u32 	%r780, %r124;

$L__BB5_15:
	add.s32 	%r782, %r779, -1;
	sub.s32 	%r26, %r780, %r778;
	cvt.rn.f32.s32 	%f507, %r26;
	cvt.f64.f32 	%fd2, %f507;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd2;
	}
	abs.f64 	%fd216, %fd2;
	{ // callseq 96, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd216;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd215;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 96
	setp.lt.s32 	%p49, %r27, 0;
	and.pred  	%p1, %p49, %p50;
	selp.b32 	%r129, %r27, 0, %p50;
	or.b32  	%r130, %r129, 2146435072;
	selp.b32 	%r28, %r130, %r129, %p51;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r131}, %fd4;
	}
	and.b32  	%r29, %r131, 2146435072;
	setp.ne.s32 	%p52, %r29, 2146435072;
	setp.gtu.f64 	%p53, %fd216, 0d7FF0000000000000;
	setp.gt.f64 	%p54, %fd216, 0d3FF0000000000000;
	selp.b32 	%r132, 2146435072, 0, %p54;
	xor.b32  	%r133, %r132, 2146435072;
	selp.b32 	%r134, %r133, %r132, %p51;
	setp.eq.s32 	%p55, %r26, -1;
	selp.b32 	%r30, 1072693248, %r134, %p55;
	and.b32  	%r31, %r27, 2147483647;
	and.pred  	%p57, %p56, %p1;
	selp.b32 	%r32, %r20, %r19, %p57;
	or.pred  	%p2, %p52, %p53;
	mul.lo.s32 	%r135, %r102, %r780;
	mul.wide.s32 	%rd26, %r135, 4;
	add.s64 	%rd59, %rd2, %rd26;
	mov.u32 	%r781, %r24;
	mov.u32 	%r783, %r124;

$L__BB5_16:
	not.pred 	%p58, %p1;
	mov.f64 	%fd502, %fd3;
	@%p58 bra 	$L__BB5_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r136}, %fd3;
	}
	xor.b32  	%r137, %r136, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r138, %temp}, %fd3;
	}
	mov.b64 	%fd502, {%r138, %r137};

$L__BB5_18:
	setp.eq.s32 	%p59, %r26, 0;
	@%p59 bra 	$L__BB5_22;

	setp.gt.s32 	%p60, %r27, -1;
	@%p60 bra 	$L__BB5_23;

	cvt.rzi.f64.f64 	%fd219, %fd215;
	setp.eq.f64 	%p61, %fd219, 0d4000000000000000;
	@%p61 bra 	$L__BB5_23;

	mov.f64 	%fd502, 0dFFF8000000000000;
	bra.uni 	$L__BB5_23;

$L__BB5_22:
	mov.u32 	%r139, 0;
	mov.b64 	%fd502, {%r139, %r28};

$L__BB5_23:
	selp.f64 	%fd503, %fd502, %fd4, %p52;
	@%p2 bra 	$L__BB5_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd215;
	}
	setp.eq.s32 	%p64, %r140, 0;
	and.pred  	%p65, %p83, %p64;
	@%p65 bra 	$L__BB5_27;
	bra.uni 	$L__BB5_25;

$L__BB5_27:
	mov.u32 	%r143, 0;
	mov.b64 	%fd503, {%r143, %r30};
	bra.uni 	$L__BB5_28;

$L__BB5_25:
	setp.ne.s32 	%p66, %r31, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r141, %temp}, %fd2;
	}
	setp.ne.s32 	%p67, %r141, 0;
	or.pred  	%p68, %p66, %p67;
	mov.f64 	%fd503, %fd502;
	@%p68 bra 	$L__BB5_28;

	mov.u32 	%r142, 0;
	mov.b64 	%fd503, {%r142, %r32};

$L__BB5_28:
	setp.eq.s32 	%p69, %r26, 1;
	selp.f64 	%fd222, 0d3FF0000000000000, %fd503, %p69;
	mov.f64 	%fd223, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd222, %fd1;
	neg.f64 	%fd224, %fd13;
	mov.f64 	%fd225, 0d4338000000000000;
	mov.f64 	%fd226, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd227, %fd224, %fd226, %fd225;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd227;
	}
	mov.f64 	%fd228, 0dC338000000000000;
	add.rn.f64 	%fd229, %fd227, %fd228;
	mov.f64 	%fd230, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd231, %fd229, %fd230, %fd224;
	mov.f64 	%fd232, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd233, %fd229, %fd232, %fd231;
	mov.f64 	%fd234, 0d3E928AF3FCA213EA;
	mov.f64 	%fd235, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd236, %fd235, %fd233, %fd234;
	mov.f64 	%fd237, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd238, %fd236, %fd233, %fd237;
	mov.f64 	%fd239, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd240, %fd238, %fd233, %fd239;
	mov.f64 	%fd241, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd242, %fd240, %fd233, %fd241;
	mov.f64 	%fd243, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd244, %fd242, %fd233, %fd243;
	mov.f64 	%fd245, 0d3F81111111122322;
	fma.rn.f64 	%fd246, %fd244, %fd233, %fd245;
	mov.f64 	%fd247, 0d3FA55555555502A1;
	fma.rn.f64 	%fd248, %fd246, %fd233, %fd247;
	mov.f64 	%fd249, 0d3FC5555555555511;
	fma.rn.f64 	%fd250, %fd248, %fd233, %fd249;
	mov.f64 	%fd251, 0d3FE000000000000B;
	fma.rn.f64 	%fd252, %fd250, %fd233, %fd251;
	fma.rn.f64 	%fd253, %fd252, %fd233, %fd223;
	fma.rn.f64 	%fd254, %fd253, %fd233, %fd223;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd254;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd254;
	}
	shl.b32 	%r144, %r36, 20;
	add.s32 	%r145, %r38, %r144;
	mov.b64 	%fd504, {%r37, %r145};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r146}, %fd224;
	}
	mov.b32 	%f508, %r146;
	abs.f32 	%f42, %f508;
	setp.lt.f32 	%p70, %f42, 0f4086232B;
	@%p70 bra 	$L__BB5_31;

	setp.gt.f64 	%p71, %fd13, 0d8000000000000000;
	mov.f64 	%fd255, 0d7FF0000000000000;
	sub.f64 	%fd256, %fd255, %fd13;
	selp.f64 	%fd504, 0d0000000000000000, %fd256, %p71;
	setp.geu.f32 	%p72, %f42, 0f40874800;
	@%p72 bra 	$L__BB5_31;

	shr.u32 	%r147, %r36, 31;
	add.s32 	%r148, %r36, %r147;
	shr.s32 	%r149, %r148, 1;
	shl.b32 	%r150, %r149, 20;
	add.s32 	%r151, %r38, %r150;
	mov.b64 	%fd257, {%r37, %r151};
	sub.s32 	%r152, %r36, %r149;
	shl.b32 	%r153, %r152, 20;
	add.s32 	%r154, %r153, 1072693248;
	mov.u32 	%r155, 0;
	mov.b64 	%fd258, {%r155, %r154};
	mul.f64 	%fd504, %fd257, %fd258;

$L__BB5_31:
	add.s32 	%r156, %r782, 1;
	cvt.rn.f32.s32 	%f509, %r156;
	cvt.f64.f32 	%fd18, %f509;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 97, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd215;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd506, [retval0+0];
	} // callseq 97
	setp.lt.s32 	%p73, %r39, 0;
	and.pred  	%p3, %p73, %p50;
	not.pred 	%p75, %p3;
	@%p75 bra 	$L__BB5_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r157}, %fd506;
	}
	xor.b32  	%r158, %r157, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r159, %temp}, %fd506;
	}
	mov.b64 	%fd506, {%r159, %r158};

$L__BB5_33:
	setp.eq.s32 	%p76, %r781, 1;
	@%p76 bra 	$L__BB5_37;
	bra.uni 	$L__BB5_34;

$L__BB5_37:
	mov.u32 	%r160, 0;
	selp.b32 	%r161, %r39, 0, %p50;
	or.b32  	%r162, %r161, 2146435072;
	selp.b32 	%r163, %r162, %r161, %p51;
	mov.b64 	%fd506, {%r160, %r163};
	bra.uni 	$L__BB5_38;

$L__BB5_34:
	setp.gt.s32 	%p77, %r39, -1;
	@%p77 bra 	$L__BB5_38;

	cvt.rzi.f64.f64 	%fd261, %fd215;
	setp.eq.f64 	%p78, %fd261, 0d4000000000000000;
	@%p78 bra 	$L__BB5_38;

	mov.f64 	%fd506, 0dFFF8000000000000;

$L__BB5_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r164}, %fd25;
	}
	and.b32  	%r165, %r164, 2146435072;
	setp.ne.s32 	%p81, %r165, 2146435072;
	mov.f64 	%fd507, %fd506;
	@%p81 bra 	$L__BB5_44;

	setp.gtu.f64 	%p82, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd507, %fd25;
	@%p82 bra 	$L__BB5_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r166, %temp}, %fd215;
	}
	setp.eq.s32 	%p84, %r166, 0;
	and.pred  	%p85, %p83, %p84;
	@%p85 bra 	$L__BB5_43;
	bra.uni 	$L__BB5_41;

$L__BB5_43:
	mov.u32 	%r171, 0;
	setp.gt.f64 	%p92, %fd19, 0d3FF0000000000000;
	selp.b32 	%r172, 2146435072, 0, %p92;
	xor.b32  	%r173, %r172, 2146435072;
	selp.b32 	%r174, %r173, %r172, %p51;
	setp.eq.s32 	%p93, %r782, -2;
	selp.b32 	%r175, 1072693248, %r174, %p93;
	mov.b64 	%fd507, {%r171, %r175};
	bra.uni 	$L__BB5_44;

$L__BB5_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r167, %temp}, %fd18;
	}
	and.b32  	%r168, %r39, 2147483647;
	setp.ne.s32 	%p86, %r168, 2146435072;
	setp.ne.s32 	%p87, %r167, 0;
	or.pred  	%p88, %p86, %p87;
	mov.f64 	%fd507, %fd506;
	@%p88 bra 	$L__BB5_44;

	and.pred  	%p90, %p56, %p3;
	selp.b32 	%r169, %r20, %r19, %p90;
	mov.u32 	%r170, 0;
	mov.b64 	%fd507, {%r170, %r169};

$L__BB5_44:
	mov.f64 	%fd500, 0d3FF0000000000000;
	mov.f64 	%fd499, 0d3FE000000000000B;
	mov.f64 	%fd498, 0d3FC5555555555511;
	mov.f64 	%fd497, 0d3FA55555555502A1;
	mov.f64 	%fd496, 0d3F81111111122322;
	mov.f64 	%fd495, 0d3F56C16C1852B7AF;
	mov.f64 	%fd494, 0d3F2A01A014761F65;
	mov.f64 	%fd493, 0d3EFA01997C89EB71;
	mov.f64 	%fd492, 0d3EC71DEE62401315;
	mov.f64 	%fd491, 0d3E928AF3FCA213EA;
	mov.f64 	%fd490, 0d3E5ADE1569CE2BDF;
	mov.f64 	%fd489, 0dBC7ABC9E3B39803F;
	mov.f64 	%fd488, 0dBFE62E42FEFA39EF;
	mov.f64 	%fd487, 0dC338000000000000;
	mov.f64 	%fd486, 0d4338000000000000;
	mov.f64 	%fd485, 0d3FF71547652B82FE;
	setp.eq.s32 	%p94, %r782, 0;
	selp.f64 	%fd264, 0d3FF0000000000000, %fd507, %p94;
	mul.f64 	%fd29, %fd264, %fd1;
	neg.f64 	%fd266, %fd29;
	fma.rn.f64 	%fd269, %fd266, %fd485, %fd486;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd269;
	}
	add.rn.f64 	%fd271, %fd269, %fd487;
	fma.rn.f64 	%fd273, %fd271, %fd488, %fd266;
	fma.rn.f64 	%fd275, %fd271, %fd489, %fd273;
	fma.rn.f64 	%fd278, %fd490, %fd275, %fd491;
	fma.rn.f64 	%fd280, %fd278, %fd275, %fd492;
	fma.rn.f64 	%fd282, %fd280, %fd275, %fd493;
	fma.rn.f64 	%fd284, %fd282, %fd275, %fd494;
	fma.rn.f64 	%fd286, %fd284, %fd275, %fd495;
	fma.rn.f64 	%fd288, %fd286, %fd275, %fd496;
	fma.rn.f64 	%fd290, %fd288, %fd275, %fd497;
	fma.rn.f64 	%fd292, %fd290, %fd275, %fd498;
	fma.rn.f64 	%fd294, %fd292, %fd275, %fd499;
	fma.rn.f64 	%fd295, %fd294, %fd275, %fd500;
	fma.rn.f64 	%fd296, %fd295, %fd275, %fd500;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd296;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd296;
	}
	shl.b32 	%r176, %r40, 20;
	add.s32 	%r177, %r42, %r176;
	mov.b64 	%fd508, {%r41, %r177};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r178}, %fd266;
	}
	mov.b32 	%f510, %r178;
	abs.f32 	%f43, %f510;
	setp.lt.f32 	%p95, %f43, 0f4086232B;
	@%p95 bra 	$L__BB5_47;

	setp.gt.f64 	%p96, %fd29, 0d8000000000000000;
	mov.f64 	%fd297, 0d7FF0000000000000;
	sub.f64 	%fd298, %fd297, %fd29;
	selp.f64 	%fd508, 0d0000000000000000, %fd298, %p96;
	setp.geu.f32 	%p97, %f43, 0f40874800;
	@%p97 bra 	$L__BB5_47;

	shr.u32 	%r179, %r40, 31;
	add.s32 	%r180, %r40, %r179;
	shr.s32 	%r181, %r180, 1;
	shl.b32 	%r182, %r181, 20;
	add.s32 	%r183, %r42, %r182;
	mov.b64 	%fd299, {%r41, %r183};
	sub.s32 	%r184, %r40, %r181;
	shl.b32 	%r185, %r184, 20;
	add.s32 	%r186, %r185, 1072693248;
	mov.u32 	%r187, 0;
	mov.b64 	%fd300, {%r187, %r186};
	mul.f64 	%fd508, %fd299, %fd300;

$L__BB5_47:
	ld.global.f32 	%f511, [%rd59];
	cvt.f64.f32 	%fd301, %f511;
	mul.f64 	%fd302, %fd504, %fd508;
	cvt.f64.f32 	%fd303, %f2820;
	fma.rn.f64 	%fd304, %fd302, %fd301, %fd303;
	cvt.rn.f32.f64 	%f2820, %fd304;
	cvt.f64.f32 	%fd305, %f2819;
	add.f64 	%fd306, %fd302, %fd305;
	cvt.rn.f32.f64 	%f2819, %fd306;
	add.s32 	%r782, %r782, -1;
	add.s32 	%r781, %r781, 1;
	add.s64 	%rd59, %rd59, 4;
	add.s32 	%r783, %r783, 1;
	setp.lt.s32 	%p98, %r783, %r102;
	@%p98 bra 	$L__BB5_16;

	add.s32 	%r780, %r780, 1;
	setp.lt.s32 	%p99, %r780, %r102;
	@%p99 bra 	$L__BB5_15;

	div.rn.f32 	%f512, %f2820, %f2819;
	max.f32 	%f2816, %f2816, %f512;
	min.f32 	%f2887, %f2887, %f512;
	add.s32 	%r779, %r779, 1;
	setp.lt.s32 	%p100, %r779, %r102;
	@%p100 bra 	$L__BB5_14;

	add.s32 	%r778, %r778, 1;
	setp.lt.s32 	%p101, %r778, %r102;
	@%p101 bra 	$L__BB5_13;

$L__BB5_51:
	ld.param.u32 	%r771, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_6];
	mov.f32 	%f2794, 0f00000000;
	sub.f32 	%f514, %f2816, %f2887;
	add.f32 	%f515, %f514, %f514;
	fma.rn.f32 	%f516, %f514, 0f40000000, %f515;
	mul.f32 	%f517, %f516, 0f40490FD8;
	mul.f32 	%f518, %f517, %f2886;
	mul.f32 	%f519, %f518, %f2886;
	max.f32 	%f2888, %f2794, %f519;
	setp.lt.s32 	%p102, %r771, 1;
	@%p102 bra 	$L__BB5_337;

	ld.param.u32 	%r772, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_5];
	cvt.rn.f32.s32 	%f522, %r102;
	mul.f32 	%f51, %f522, 0f3F000000;
	cvt.rn.f32.s32 	%f52, %r772;
	mov.u32 	%r784, 0;
	cvta.to.global.u64 	%rd27, %rd8;
	mov.f64 	%fd309, 0d4008000000000000;
	cvta.to.global.u64 	%rd33, %rd9;

$L__BB5_53:
	mov.f32 	%f2839, 0f00000000;
	mov.f32 	%f2840, %f2839;
	mov.f32 	%f2841, %f2839;
	mov.f32 	%f2842, %f2839;
	mov.f32 	%f2843, %f2839;
	mov.f32 	%f2844, %f2839;
	mov.f32 	%f2845, %f2839;
	mov.f32 	%f2846, %f2839;
	mov.f32 	%f2847, %f2839;
	mov.f32 	%f2848, %f2839;
	@%p40 bra 	$L__BB5_336;

	mov.f32 	%f2839, 0f00000000;
	mov.f32 	%f543, 0f3F000000;
	div.rn.f32 	%f544, %f543, %f2886;
	div.rn.f32 	%f59, %f544, %f2886;
	div.rn.f32 	%f545, %f2888, 0fC0206C98;
	div.rn.f32 	%f60, %f545, %f2886;
	cvt.f64.f32 	%fd34, %f545;
	cvt.f64.f32 	%fd307, %f2886;
	add.f64 	%fd35, %fd307, 0d4008000000000000;
	div.rn.f32 	%f61, %f60, %f2886;
	mov.f32 	%f546, 0fC0000000;
	div.rn.f32 	%f62, %f546, %f2886;
	div.rn.f32 	%f547, %f2888, 0f40206C98;
	cvt.f64.f32 	%fd36, %f547;
	shl.b32 	%r194, %r1, 1;
	mul.wide.s32 	%rd28, %r194, 4;
	add.s64 	%rd29, %rd27, %rd28;
	ld.global.f32 	%f63, [%rd29+4];
	ld.global.f32 	%f64, [%rd29];
	mov.u32 	%r785, 0;

$L__BB5_55:
	cvt.f64.f32 	%fd477, %f2886;
	mov.u32 	%r786, 0;
	mov.f32 	%f2667, 0f00000000;
	cvt.rn.f32.s32 	%f75, %r785;
	sub.f32 	%f76, %f75, %f2890;
	add.f32 	%f77, %f76, 0f3F000000;
	sqrt.rn.f32 	%f78, %f59;
	mul.f32 	%f548, %f77, %f78;
	abs.f32 	%f79, %f548;
	setp.ge.f32 	%p104, %f79, 0f3F8060FE;
	mul.f32 	%f549, %f548, %f548;
	selp.f32 	%f550, %f79, %f549, %p104;
	selp.f32 	%f551, 0f3789CA3C, 0f38B1E96A, %p104;
	selp.f32 	%f552, 0fB9F560B9, 0fBA574D20, %p104;
	fma.rn.f32 	%f553, %f551, %f550, %f552;
	selp.f32 	%f554, 0f3BAC840B, 0f3BAAD5EA, %p104;
	fma.rn.f32 	%f555, %f553, %f550, %f554;
	selp.f32 	%f556, 0fBD0C8162, 0fBCDC1BE7, %p104;
	fma.rn.f32 	%f557, %f555, %f550, %f556;
	selp.f32 	%f558, 0f3E1CF906, 0f3DE718AF, %p104;
	fma.rn.f32 	%f559, %f557, %f550, %f558;
	selp.f32 	%f560, 0f3F6A937E, 0fBEC093AC, %p104;
	fma.rn.f32 	%f561, %f559, %f550, %f560;
	selp.f32 	%f562, 0f3F20D842, 0f3E0375D3, %p104;
	fma.rn.f32 	%f563, %f561, %f550, %f562;
	neg.f32 	%f564, %f79;
	selp.f32 	%f565, %f564, %f548, %p104;
	fma.rn.f32 	%f80, %f563, %f565, %f565;
	mov.b32 	%r196, %f548;
	and.b32  	%r51, %r196, -2147483648;
	add.f32 	%f81, %f76, 0fBF000000;
	mul.f32 	%f566, %f81, %f78;
	abs.f32 	%f82, %f566;
	setp.ge.f32 	%p105, %f82, 0f3F8060FE;
	mul.f32 	%f567, %f566, %f566;
	selp.f32 	%f568, %f82, %f567, %p105;
	selp.f32 	%f569, 0f3789CA3C, 0f38B1E96A, %p105;
	selp.f32 	%f570, 0fB9F560B9, 0fBA574D20, %p105;
	fma.rn.f32 	%f571, %f569, %f568, %f570;
	selp.f32 	%f572, 0f3BAC840B, 0f3BAAD5EA, %p105;
	fma.rn.f32 	%f573, %f571, %f568, %f572;
	selp.f32 	%f574, 0fBD0C8162, 0fBCDC1BE7, %p105;
	fma.rn.f32 	%f575, %f573, %f568, %f574;
	selp.f32 	%f576, 0f3E1CF906, 0f3DE718AF, %p105;
	fma.rn.f32 	%f577, %f575, %f568, %f576;
	selp.f32 	%f578, 0f3F6A937E, 0fBEC093AC, %p105;
	fma.rn.f32 	%f579, %f577, %f568, %f578;
	selp.f32 	%f580, 0f3F20D842, 0f3E0375D3, %p105;
	fma.rn.f32 	%f581, %f579, %f568, %f580;
	neg.f32 	%f582, %f82;
	selp.f32 	%f583, %f582, %f566, %p105;
	fma.rn.f32 	%f83, %f581, %f583, %f583;
	mov.b32 	%r197, %f566;
	and.b32  	%r52, %r197, -2147483648;
	add.f32 	%f584, %f75, 0f3F000000;
	sub.f32 	%f84, %f584, %f2890;
	div.rn.f32 	%f85, %f84, %f2886;
	mov.f32 	%f585, 0f3F800000;
	cvt.rzi.f32.f32 	%f586, %f585;
	add.f32 	%f587, %f586, %f586;
	mov.f32 	%f588, 0f40000000;
	sub.f32 	%f589, %f588, %f587;
	abs.f32 	%f86, %f589;
	setp.eq.f32 	%p106, %f86, 0f3F800000;
	abs.f32 	%f87, %f85;
	setp.lt.f32 	%p107, %f87, 0f00800000;
	mul.f32 	%f590, %f87, 0f4B800000;
	selp.f32 	%f591, %f590, %f87, %p107;
	selp.f32 	%f592, 0fC3170000, 0fC2FE0000, %p107;
	mov.b32 	%r198, %f591;
	and.b32  	%r199, %r198, 8388607;
	or.b32  	%r200, %r199, 1065353216;
	mov.b32 	%f593, %r200;
	shr.u32 	%r201, %r198, 23;
	cvt.rn.f32.u32 	%f594, %r201;
	add.f32 	%f595, %f592, %f594;
	setp.gt.f32 	%p108, %f593, 0f3FB504F3;
	mul.f32 	%f596, %f593, 0f3F000000;
	add.f32 	%f597, %f595, 0f3F800000;
	selp.f32 	%f598, %f597, %f595, %p108;
	selp.f32 	%f599, %f596, %f593, %p108;
	add.f32 	%f600, %f599, 0fBF800000;
	add.f32 	%f601, %f599, 0f3F800000;
	rcp.approx.ftz.f32 	%f602, %f601;
	add.f32 	%f603, %f600, %f600;
	mul.f32 	%f604, %f603, %f602;
	mul.f32 	%f605, %f604, %f604;
	mov.f32 	%f606, 0f3C4CAF63;
	mov.f32 	%f607, 0f3B18F0FE;
	fma.rn.f32 	%f608, %f607, %f605, %f606;
	mov.f32 	%f609, 0f3DAAAABD;
	fma.rn.f32 	%f610, %f608, %f605, %f609;
	mul.rn.f32 	%f611, %f610, %f605;
	mul.rn.f32 	%f612, %f611, %f604;
	sub.f32 	%f613, %f600, %f604;
	add.f32 	%f614, %f613, %f613;
	neg.f32 	%f615, %f604;
	fma.rn.f32 	%f616, %f615, %f600, %f614;
	mul.rn.f32 	%f617, %f602, %f616;
	add.f32 	%f618, %f612, %f604;
	sub.f32 	%f619, %f604, %f618;
	add.f32 	%f620, %f612, %f619;
	add.f32 	%f621, %f617, %f620;
	add.f32 	%f622, %f618, %f621;
	sub.f32 	%f623, %f618, %f622;
	add.f32 	%f624, %f621, %f623;
	mov.f32 	%f625, 0f3F317200;
	mul.rn.f32 	%f626, %f598, %f625;
	mov.f32 	%f627, 0f35BFBE8E;
	mul.rn.f32 	%f628, %f598, %f627;
	add.f32 	%f629, %f626, %f622;
	sub.f32 	%f630, %f626, %f629;
	add.f32 	%f631, %f622, %f630;
	add.f32 	%f632, %f624, %f631;
	add.f32 	%f633, %f628, %f632;
	add.f32 	%f634, %f629, %f633;
	sub.f32 	%f635, %f629, %f634;
	add.f32 	%f636, %f633, %f635;
	mul.rn.f32 	%f637, %f588, %f634;
	neg.f32 	%f638, %f637;
	fma.rn.f32 	%f639, %f588, %f634, %f638;
	fma.rn.f32 	%f640, %f588, %f636, %f639;
	fma.rn.f32 	%f642, %f2667, %f634, %f640;
	add.rn.f32 	%f643, %f637, %f642;
	neg.f32 	%f644, %f643;
	add.rn.f32 	%f645, %f637, %f644;
	add.rn.f32 	%f646, %f645, %f642;
	mov.b32 	%r202, %f643;
	setp.eq.s32 	%p109, %r202, 1118925336;
	add.s32 	%r203, %r202, -1;
	mov.b32 	%f647, %r203;
	add.f32 	%f648, %f646, 0f37000000;
	selp.f32 	%f88, %f648, %f646, %p109;
	selp.f32 	%f649, %f647, %f643, %p109;
	mov.f32 	%f650, 0f3FB8AA3B;
	mul.rn.f32 	%f651, %f649, %f650;
	cvt.rzi.f32.f32 	%f652, %f651;
	abs.f32 	%f653, %f652;
	setp.gt.f32 	%p110, %f653, 0f42FC0000;
	mov.b32 	%r204, %f652;
	and.b32  	%r205, %r204, -2147483648;
	or.b32  	%r206, %r205, 1123811328;
	mov.b32 	%f654, %r206;
	selp.f32 	%f655, %f654, %f652, %p110;
	mov.f32 	%f656, 0fBF317218;
	fma.rn.f32 	%f657, %f655, %f656, %f649;
	mov.f32 	%f658, 0f3102E308;
	fma.rn.f32 	%f659, %f655, %f658, %f657;
	mul.f32 	%f660, %f659, 0f3FB8AA3B;
	add.f32 	%f661, %f655, 0f4B40007F;
	mov.b32 	%r207, %f661;
	shl.b32 	%r208, %r207, 23;
	mov.b32 	%f662, %r208;
	ex2.approx.ftz.f32 	%f663, %f660;
	mul.f32 	%f89, %f663, %f662;
	setp.lt.f32 	%p111, %f85, 0f00000000;
	and.pred  	%p4, %p111, %p106;
	div.rn.f32 	%f90, %f81, %f2886;
	abs.f32 	%f91, %f90;
	setp.lt.f32 	%p112, %f91, 0f00800000;
	mul.f32 	%f664, %f91, 0f4B800000;
	selp.f32 	%f665, %f664, %f91, %p112;
	selp.f32 	%f666, 0fC3170000, 0fC2FE0000, %p112;
	mov.b32 	%r209, %f665;
	and.b32  	%r210, %r209, 8388607;
	or.b32  	%r211, %r210, 1065353216;
	mov.b32 	%f667, %r211;
	shr.u32 	%r212, %r209, 23;
	cvt.rn.f32.u32 	%f668, %r212;
	add.f32 	%f669, %f666, %f668;
	setp.gt.f32 	%p113, %f667, 0f3FB504F3;
	mul.f32 	%f670, %f667, 0f3F000000;
	add.f32 	%f671, %f669, 0f3F800000;
	selp.f32 	%f672, %f671, %f669, %p113;
	selp.f32 	%f673, %f670, %f667, %p113;
	add.f32 	%f674, %f673, 0fBF800000;
	add.f32 	%f675, %f673, 0f3F800000;
	rcp.approx.ftz.f32 	%f676, %f675;
	add.f32 	%f677, %f674, %f674;
	mul.f32 	%f678, %f677, %f676;
	mul.f32 	%f679, %f678, %f678;
	fma.rn.f32 	%f680, %f607, %f679, %f606;
	fma.rn.f32 	%f681, %f680, %f679, %f609;
	mul.rn.f32 	%f682, %f681, %f679;
	mul.rn.f32 	%f683, %f682, %f678;
	sub.f32 	%f684, %f674, %f678;
	add.f32 	%f685, %f684, %f684;
	neg.f32 	%f686, %f678;
	fma.rn.f32 	%f687, %f686, %f674, %f685;
	mul.rn.f32 	%f688, %f676, %f687;
	add.f32 	%f689, %f683, %f678;
	sub.f32 	%f690, %f678, %f689;
	add.f32 	%f691, %f683, %f690;
	add.f32 	%f692, %f688, %f691;
	add.f32 	%f693, %f689, %f692;
	sub.f32 	%f694, %f689, %f693;
	add.f32 	%f695, %f692, %f694;
	mul.rn.f32 	%f696, %f672, %f625;
	mul.rn.f32 	%f697, %f672, %f627;
	add.f32 	%f698, %f696, %f693;
	sub.f32 	%f699, %f696, %f698;
	add.f32 	%f700, %f693, %f699;
	add.f32 	%f701, %f695, %f700;
	add.f32 	%f702, %f697, %f701;
	add.f32 	%f703, %f698, %f702;
	sub.f32 	%f704, %f698, %f703;
	add.f32 	%f705, %f702, %f704;
	mul.rn.f32 	%f706, %f588, %f703;
	neg.f32 	%f707, %f706;
	fma.rn.f32 	%f708, %f588, %f703, %f707;
	fma.rn.f32 	%f709, %f588, %f705, %f708;
	fma.rn.f32 	%f710, %f2667, %f703, %f709;
	add.rn.f32 	%f711, %f706, %f710;
	neg.f32 	%f712, %f711;
	add.rn.f32 	%f713, %f706, %f712;
	add.rn.f32 	%f714, %f713, %f710;
	mov.b32 	%r213, %f711;
	setp.eq.s32 	%p114, %r213, 1118925336;
	add.s32 	%r214, %r213, -1;
	mov.b32 	%f715, %r214;
	add.f32 	%f716, %f714, 0f37000000;
	selp.f32 	%f92, %f716, %f714, %p114;
	selp.f32 	%f717, %f715, %f711, %p114;
	mul.rn.f32 	%f718, %f717, %f650;
	cvt.rzi.f32.f32 	%f719, %f718;
	abs.f32 	%f720, %f719;
	setp.gt.f32 	%p115, %f720, 0f42FC0000;
	mov.b32 	%r215, %f719;
	and.b32  	%r216, %r215, -2147483648;
	or.b32  	%r217, %r216, 1123811328;
	mov.b32 	%f721, %r217;
	selp.f32 	%f722, %f721, %f719, %p115;
	fma.rn.f32 	%f723, %f722, %f656, %f717;
	fma.rn.f32 	%f724, %f722, %f658, %f723;
	mul.f32 	%f725, %f724, 0f3FB8AA3B;
	add.f32 	%f726, %f722, 0f4B40007F;
	mov.b32 	%r218, %f726;
	shl.b32 	%r219, %r218, 23;
	mov.b32 	%f727, %r219;
	ex2.approx.ftz.f32 	%f728, %f725;
	mul.f32 	%f93, %f728, %f727;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd477;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd309;
	}
	and.b32  	%r55, %r54, 2146435072;
	setp.eq.s32 	%p117, %r55, 1073741824;
	abs.f64 	%fd310, %fd477;
	{ // callseq 98, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd310;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd37, [retval0+0];
	} // callseq 98
	setp.lt.s32 	%p118, %r53, 0;
	and.pred  	%p6, %p118, %p117;
	selp.b32 	%r220, %r53, 0, %p117;
	setp.lt.s32 	%p119, %r54, 0;
	or.b32  	%r221, %r220, 2146435072;
	selp.b32 	%r56, %r221, %r220, %p119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r222}, %fd35;
	}
	and.b32  	%r57, %r222, 2146435072;
	setp.ne.s32 	%p120, %r57, 2146435072;
	setp.gtu.f64 	%p121, %fd310, 0d7FF0000000000000;
	and.b32  	%r58, %r54, 2147483647;
	setp.gt.f64 	%p122, %fd310, 0d3FF0000000000000;
	selp.b32 	%r223, 2146435072, 0, %p122;
	xor.b32  	%r224, %r223, 2146435072;
	selp.b32 	%r225, %r224, %r223, %p119;
	setp.eq.f32 	%p123, %f2886, 0fBF800000;
	selp.b32 	%r59, 1072693248, %r225, %p123;
	setp.gt.s32 	%p124, %r54, -1;
	selp.b32 	%r60, 2146435072, 0, %p124;
	setp.ne.s32 	%p125, %r58, 1071644672;
	and.pred  	%p126, %p125, %p6;
	or.b32  	%r61, %r60, -2147483648;
	selp.b32 	%r62, %r61, %r60, %p126;
	add.f32 	%f729, %f75, 0f3F800000;
	sub.f32 	%f730, %f729, %f2890;
	div.rn.f32 	%f94, %f730, %f2886;
	abs.f32 	%f95, %f94;
	setp.lt.f32 	%p127, %f95, 0f00800000;
	mul.f32 	%f731, %f95, 0f4B800000;
	selp.f32 	%f732, %f731, %f95, %p127;
	selp.f32 	%f733, 0fC3170000, 0fC2FE0000, %p127;
	mov.b32 	%r226, %f732;
	and.b32  	%r227, %r226, 8388607;
	or.b32  	%r228, %r227, 1065353216;
	mov.b32 	%f734, %r228;
	shr.u32 	%r229, %r226, 23;
	cvt.rn.f32.u32 	%f735, %r229;
	add.f32 	%f736, %f733, %f735;
	setp.gt.f32 	%p128, %f734, 0f3FB504F3;
	mul.f32 	%f737, %f734, 0f3F000000;
	add.f32 	%f738, %f736, 0f3F800000;
	selp.f32 	%f739, %f738, %f736, %p128;
	selp.f32 	%f740, %f737, %f734, %p128;
	add.f32 	%f741, %f740, 0fBF800000;
	add.f32 	%f742, %f740, 0f3F800000;
	rcp.approx.ftz.f32 	%f743, %f742;
	add.f32 	%f744, %f741, %f741;
	mul.f32 	%f745, %f744, %f743;
	mul.f32 	%f746, %f745, %f745;
	fma.rn.f32 	%f747, %f607, %f746, %f606;
	fma.rn.f32 	%f748, %f747, %f746, %f609;
	mul.rn.f32 	%f749, %f748, %f746;
	mul.rn.f32 	%f750, %f749, %f745;
	sub.f32 	%f751, %f741, %f745;
	add.f32 	%f752, %f751, %f751;
	neg.f32 	%f753, %f745;
	fma.rn.f32 	%f754, %f753, %f741, %f752;
	mul.rn.f32 	%f755, %f743, %f754;
	add.f32 	%f756, %f750, %f745;
	sub.f32 	%f757, %f745, %f756;
	add.f32 	%f758, %f750, %f757;
	add.f32 	%f759, %f755, %f758;
	add.f32 	%f760, %f756, %f759;
	sub.f32 	%f761, %f756, %f760;
	add.f32 	%f762, %f759, %f761;
	mul.rn.f32 	%f763, %f739, %f625;
	mul.rn.f32 	%f764, %f739, %f627;
	add.f32 	%f765, %f763, %f760;
	sub.f32 	%f766, %f763, %f765;
	add.f32 	%f767, %f760, %f766;
	add.f32 	%f768, %f762, %f767;
	add.f32 	%f769, %f764, %f768;
	add.f32 	%f770, %f765, %f769;
	sub.f32 	%f771, %f765, %f770;
	add.f32 	%f772, %f769, %f771;
	mul.rn.f32 	%f773, %f588, %f770;
	neg.f32 	%f774, %f773;
	fma.rn.f32 	%f775, %f588, %f770, %f774;
	fma.rn.f32 	%f776, %f588, %f772, %f775;
	fma.rn.f32 	%f777, %f2667, %f770, %f776;
	add.rn.f32 	%f778, %f773, %f777;
	neg.f32 	%f779, %f778;
	add.rn.f32 	%f780, %f773, %f779;
	add.rn.f32 	%f781, %f780, %f777;
	mov.b32 	%r230, %f778;
	setp.eq.s32 	%p129, %r230, 1118925336;
	add.s32 	%r231, %r230, -1;
	mov.b32 	%f782, %r231;
	add.f32 	%f783, %f781, 0f37000000;
	selp.f32 	%f96, %f783, %f781, %p129;
	selp.f32 	%f784, %f782, %f778, %p129;
	mul.rn.f32 	%f785, %f784, %f650;
	cvt.rzi.f32.f32 	%f786, %f785;
	abs.f32 	%f787, %f786;
	setp.gt.f32 	%p130, %f787, 0f42FC0000;
	mov.b32 	%r232, %f786;
	and.b32  	%r233, %r232, -2147483648;
	or.b32  	%r234, %r233, 1123811328;
	mov.b32 	%f788, %r234;
	selp.f32 	%f789, %f788, %f786, %p130;
	fma.rn.f32 	%f790, %f789, %f656, %f784;
	fma.rn.f32 	%f791, %f789, %f658, %f790;
	mul.f32 	%f792, %f791, 0f3FB8AA3B;
	add.f32 	%f793, %f789, 0f4B40007F;
	mov.b32 	%r235, %f793;
	shl.b32 	%r236, %r235, 23;
	mov.b32 	%f794, %r236;
	ex2.approx.ftz.f32 	%f795, %f792;
	mul.f32 	%f97, %f795, %f794;
	div.rn.f32 	%f98, %f76, %f2886;
	abs.f32 	%f99, %f98;
	setp.lt.f32 	%p132, %f99, 0f00800000;
	mul.f32 	%f796, %f99, 0f4B800000;
	selp.f32 	%f797, %f796, %f99, %p132;
	selp.f32 	%f798, 0fC3170000, 0fC2FE0000, %p132;
	mov.b32 	%r237, %f797;
	and.b32  	%r238, %r237, 8388607;
	or.b32  	%r239, %r238, 1065353216;
	mov.b32 	%f799, %r239;
	shr.u32 	%r240, %r237, 23;
	cvt.rn.f32.u32 	%f800, %r240;
	add.f32 	%f801, %f798, %f800;
	setp.gt.f32 	%p133, %f799, 0f3FB504F3;
	mul.f32 	%f802, %f799, 0f3F000000;
	add.f32 	%f803, %f801, 0f3F800000;
	selp.f32 	%f804, %f803, %f801, %p133;
	selp.f32 	%f805, %f802, %f799, %p133;
	add.f32 	%f806, %f805, 0fBF800000;
	add.f32 	%f807, %f805, 0f3F800000;
	rcp.approx.ftz.f32 	%f808, %f807;
	add.f32 	%f809, %f806, %f806;
	mul.f32 	%f810, %f809, %f808;
	mul.f32 	%f811, %f810, %f810;
	fma.rn.f32 	%f812, %f607, %f811, %f606;
	fma.rn.f32 	%f813, %f812, %f811, %f609;
	mul.rn.f32 	%f814, %f813, %f811;
	mul.rn.f32 	%f815, %f814, %f810;
	sub.f32 	%f816, %f806, %f810;
	add.f32 	%f817, %f816, %f816;
	neg.f32 	%f818, %f810;
	fma.rn.f32 	%f819, %f818, %f806, %f817;
	mul.rn.f32 	%f820, %f808, %f819;
	add.f32 	%f821, %f815, %f810;
	sub.f32 	%f822, %f810, %f821;
	add.f32 	%f823, %f815, %f822;
	add.f32 	%f824, %f820, %f823;
	add.f32 	%f825, %f821, %f824;
	sub.f32 	%f826, %f821, %f825;
	add.f32 	%f827, %f824, %f826;
	mul.rn.f32 	%f828, %f804, %f625;
	mul.rn.f32 	%f829, %f804, %f627;
	add.f32 	%f830, %f828, %f825;
	sub.f32 	%f831, %f828, %f830;
	add.f32 	%f832, %f825, %f831;
	add.f32 	%f833, %f827, %f832;
	add.f32 	%f834, %f829, %f833;
	add.f32 	%f835, %f830, %f834;
	sub.f32 	%f836, %f830, %f835;
	add.f32 	%f837, %f834, %f836;
	mul.rn.f32 	%f838, %f588, %f835;
	neg.f32 	%f839, %f838;
	fma.rn.f32 	%f840, %f588, %f835, %f839;
	fma.rn.f32 	%f841, %f588, %f837, %f840;
	fma.rn.f32 	%f842, %f2667, %f835, %f841;
	add.rn.f32 	%f843, %f838, %f842;
	neg.f32 	%f844, %f843;
	add.rn.f32 	%f845, %f838, %f844;
	add.rn.f32 	%f846, %f845, %f842;
	mov.b32 	%r241, %f843;
	setp.eq.s32 	%p134, %r241, 1118925336;
	add.s32 	%r242, %r241, -1;
	mov.b32 	%f847, %r242;
	add.f32 	%f848, %f846, 0f37000000;
	selp.f32 	%f100, %f848, %f846, %p134;
	selp.f32 	%f849, %f847, %f843, %p134;
	mul.rn.f32 	%f850, %f849, %f650;
	cvt.rzi.f32.f32 	%f851, %f850;
	abs.f32 	%f852, %f851;
	setp.gt.f32 	%p135, %f852, 0f42FC0000;
	mov.b32 	%r243, %f851;
	and.b32  	%r244, %r243, -2147483648;
	or.b32  	%r245, %r244, 1123811328;
	mov.b32 	%f853, %r245;
	selp.f32 	%f854, %f853, %f851, %p135;
	fma.rn.f32 	%f855, %f854, %f656, %f849;
	fma.rn.f32 	%f856, %f854, %f658, %f855;
	mul.f32 	%f857, %f856, 0f3FB8AA3B;
	add.f32 	%f858, %f854, 0f4B40007F;
	mov.b32 	%r246, %f858;
	shl.b32 	%r247, %r246, 23;
	mov.b32 	%f859, %r247;
	ex2.approx.ftz.f32 	%f860, %f857;
	mul.f32 	%f101, %f860, %f859;
	mov.f64 	%fd311, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r248}, %fd311;
	}
	and.b32  	%r249, %r248, 2146435072;
	setp.eq.s32 	%p137, %r249, 1074790400;
	{ // callseq 99, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd310;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd311;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd38, [retval0+0];
	} // callseq 99
	and.pred  	%p9, %p118, %p137;
	selp.b32 	%r250, %r53, 0, %p137;
	setp.lt.s32 	%p138, %r248, 0;
	or.b32  	%r251, %r250, 2146435072;
	selp.b32 	%r63, %r251, %r250, %p138;
	add.f64 	%fd312, %fd477, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r252}, %fd312;
	}
	and.b32  	%r64, %r252, 2146435072;
	setp.ne.s32 	%p139, %r64, 2146435072;
	cvt.f64.f32 	%fd39, %f77;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd39;
	}
	abs.f64 	%fd313, %fd39;
	{ // callseq 100, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd313;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd40, [retval0+0];
	} // callseq 100
	setp.lt.s32 	%p140, %r65, 0;
	and.pred  	%p10, %p140, %p117;
	and.b32  	%r66, %r248, 2147483647;
	selp.b32 	%r253, %r224, %r223, %p138;
	selp.b32 	%r67, 1072693248, %r253, %p123;
	add.f64 	%fd41, %fd39, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r254}, %fd41;
	}
	and.b32  	%r68, %r254, 2146435072;
	setp.ne.s32 	%p141, %r68, 2146435072;
	setp.gt.s32 	%p142, %r248, -1;
	selp.b32 	%r255, 2146435072, 0, %p142;
	setp.ne.s32 	%p143, %r66, 1071644672;
	and.pred  	%p144, %p143, %p9;
	or.b32  	%r256, %r255, -2147483648;
	selp.b32 	%r69, %r256, %r255, %p144;
	setp.gtu.f64 	%p145, %fd313, 0d7FF0000000000000;
	cvt.f64.f32 	%fd42, %f81;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd42;
	}
	abs.f64 	%fd314, %fd42;
	{ // callseq 101, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd314;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd43, [retval0+0];
	} // callseq 101
	setp.lt.s32 	%p146, %r70, 0;
	and.pred  	%p11, %p146, %p117;
	setp.gt.f64 	%p147, %fd313, 0d3FF0000000000000;
	selp.b32 	%r257, 2146435072, 0, %p147;
	xor.b32  	%r258, %r257, 2146435072;
	selp.b32 	%r259, %r258, %r257, %p119;
	setp.eq.f32 	%p148, %f77, 0fBF800000;
	selp.b32 	%r71, 1072693248, %r259, %p148;
	add.f64 	%fd44, %fd42, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd44;
	}
	and.b32  	%r72, %r260, 2146435072;
	setp.ne.s32 	%p149, %r72, 2146435072;
	setp.gtu.f64 	%p150, %fd314, 0d7FF0000000000000;
	setp.gt.f64 	%p151, %fd314, 0d3FF0000000000000;
	selp.b32 	%r261, 2146435072, 0, %p151;
	xor.b32  	%r262, %r261, 2146435072;
	selp.b32 	%r263, %r262, %r261, %p119;
	setp.eq.f32 	%p152, %f81, 0fBF800000;
	selp.b32 	%r73, 1072693248, %r263, %p152;
	mov.f64 	%fd315, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd315;
	}
	and.b32  	%r75, %r74, 2147483647;
	setp.gt.s32 	%p153, %r74, -1;
	selp.b32 	%r76, 2146435072, 0, %p153;
	or.pred  	%p14, %p120, %p121;
	or.pred  	%p17, %p139, %p121;
	or.pred  	%p18, %p141, %p145;
	or.pred  	%p19, %p149, %p150;
	shr.s32 	%r264, %r74, 31;
	and.b32  	%r77, %r264, 2146435072;

$L__BB5_56:
	cvt.rn.f32.s32 	%f2672, %r785;
	sub.f32 	%f2671, %f2672, %f2890;
	add.f32 	%f2670, %f2671, 0f3F000000;
	mul.f32 	%f2669, %f2670, %f78;
	abs.f32 	%f2668, %f2669;
	setp.ltu.f32 	%p154, %f2668, 0f3F8060FE;
	mov.f32 	%f2849, %f80;
	@%p154 bra 	$L__BB5_58;

	mov.f32 	%f2778, 0f3F800000;
	ex2.approx.ftz.f32 	%f861, %f80;
	sub.f32 	%f863, %f2778, %f861;
	mov.b32 	%r265, %f863;
	or.b32  	%r266, %r51, %r265;
	mov.b32 	%f2849, %r266;

$L__BB5_58:
	cvt.rn.f32.s32 	%f2677, %r785;
	sub.f32 	%f2676, %f2677, %f2890;
	add.f32 	%f2675, %f2676, 0fBF000000;
	mul.f32 	%f2674, %f2675, %f78;
	abs.f32 	%f2673, %f2674;
	setp.ltu.f32 	%p155, %f2673, 0f3F8060FE;
	mov.f32 	%f2850, %f83;
	@%p155 bra 	$L__BB5_60;

	mov.f32 	%f2777, 0f3F800000;
	ex2.approx.ftz.f32 	%f864, %f83;
	sub.f32 	%f866, %f2777, %f864;
	mov.b32 	%r267, %f866;
	or.b32  	%r268, %r52, %r267;
	mov.b32 	%f2850, %r268;

$L__BB5_60:
	sub.f32 	%f867, %f2849, %f2850;
	mul.f32 	%f116, %f867, 0f3F000000;
	cvt.rn.f32.s32 	%f117, %r786;
	sub.f32 	%f118, %f117, %f2889;
	add.f32 	%f119, %f118, 0f3F000000;
	mul.f32 	%f120, %f78, %f119;
	abs.f32 	%f868, %f120;
	setp.ltu.f32 	%p156, %f868, 0f3F8060FE;
	setp.ge.f32 	%p157, %f868, 0f3F8060FE;
	mul.f32 	%f869, %f120, %f120;
	selp.f32 	%f870, %f868, %f869, %p157;
	selp.f32 	%f871, 0f3789CA3C, 0f38B1E96A, %p157;
	selp.f32 	%f872, 0fB9F560B9, 0fBA574D20, %p157;
	fma.rn.f32 	%f873, %f871, %f870, %f872;
	selp.f32 	%f874, 0f3BAC840B, 0f3BAAD5EA, %p157;
	fma.rn.f32 	%f875, %f873, %f870, %f874;
	selp.f32 	%f876, 0fBD0C8162, 0fBCDC1BE7, %p157;
	fma.rn.f32 	%f877, %f875, %f870, %f876;
	selp.f32 	%f878, 0f3E1CF906, 0f3DE718AF, %p157;
	fma.rn.f32 	%f879, %f877, %f870, %f878;
	selp.f32 	%f880, 0f3F6A937E, 0fBEC093AC, %p157;
	fma.rn.f32 	%f881, %f879, %f870, %f880;
	selp.f32 	%f882, 0f3F20D842, 0f3E0375D3, %p157;
	fma.rn.f32 	%f883, %f881, %f870, %f882;
	neg.f32 	%f884, %f868;
	selp.f32 	%f885, %f884, %f120, %p157;
	fma.rn.f32 	%f2851, %f883, %f885, %f885;
	@%p156 bra 	$L__BB5_62;

	mov.f32 	%f2776, 0f3F800000;
	ex2.approx.ftz.f32 	%f886, %f2851;
	sub.f32 	%f888, %f2776, %f886;
	mov.b32 	%r269, %f888;
	mov.b32 	%r270, %f120;
	and.b32  	%r271, %r270, -2147483648;
	or.b32  	%r272, %r271, %r269;
	mov.b32 	%f2851, %r272;

$L__BB5_62:
	cvt.rn.f32.s32 	%f2679, %r786;
	sub.f32 	%f2678, %f2679, %f2889;
	add.f32 	%f124, %f2678, 0fBF000000;
	mul.f32 	%f125, %f78, %f124;
	abs.f32 	%f889, %f125;
	setp.ltu.f32 	%p158, %f889, 0f3F8060FE;
	setp.ge.f32 	%p159, %f889, 0f3F8060FE;
	mul.f32 	%f890, %f125, %f125;
	selp.f32 	%f891, %f889, %f890, %p159;
	selp.f32 	%f892, 0f3789CA3C, 0f38B1E96A, %p159;
	selp.f32 	%f893, 0fB9F560B9, 0fBA574D20, %p159;
	fma.rn.f32 	%f894, %f892, %f891, %f893;
	selp.f32 	%f895, 0f3BAC840B, 0f3BAAD5EA, %p159;
	fma.rn.f32 	%f896, %f894, %f891, %f895;
	selp.f32 	%f897, 0fBD0C8162, 0fBCDC1BE7, %p159;
	fma.rn.f32 	%f898, %f896, %f891, %f897;
	selp.f32 	%f899, 0f3E1CF906, 0f3DE718AF, %p159;
	fma.rn.f32 	%f900, %f898, %f891, %f899;
	selp.f32 	%f901, 0f3F6A937E, 0fBEC093AC, %p159;
	fma.rn.f32 	%f902, %f900, %f891, %f901;
	selp.f32 	%f903, 0f3F20D842, 0f3E0375D3, %p159;
	fma.rn.f32 	%f904, %f902, %f891, %f903;
	neg.f32 	%f905, %f889;
	selp.f32 	%f906, %f905, %f125, %p159;
	fma.rn.f32 	%f2852, %f904, %f906, %f906;
	@%p158 bra 	$L__BB5_64;

	mov.f32 	%f2775, 0f3F800000;
	ex2.approx.ftz.f32 	%f907, %f2852;
	sub.f32 	%f909, %f2775, %f907;
	mov.b32 	%r273, %f909;
	mov.b32 	%r274, %f125;
	and.b32  	%r275, %r274, -2147483648;
	or.b32  	%r276, %r275, %r273;
	mov.b32 	%f2852, %r276;

$L__BB5_64:
	cvt.rn.f32.s32 	%f2680, %r785;
	sub.f32 	%f911, %f2851, %f2852;
	mul.f32 	%f129, %f911, 0f3F000000;
	mul.f32 	%f912, %f116, %f2888;
	fma.rn.f32 	%f130, %f129, %f912, %f2887;
	mad.lo.s32 	%r277, %r786, %r102, %r785;
	add.s32 	%r278, %r277, %r2;
	mul.wide.s32 	%rd31, %r278, 4;
	add.s64 	%rd32, %rd1, %rd31;
	ld.global.f32 	%f131, [%rd32];
	add.f32 	%f913, %f63, %f117;
	fma.rn.f32 	%f914, %f913, %f52, %f64;
	add.f32 	%f915, %f914, %f2680;
	cvt.rzi.s32.f32 	%r279, %f915;
	mul.wide.s32 	%rd34, %r279, 4;
	add.s64 	%rd35, %rd33, %rd34;
	ld.global.f32 	%f2885, [%rd35];
	setp.eq.f32 	%p160, %f89, 0f7F800000;
	mov.f32 	%f2853, 0f7F800000;
	@%p160 bra 	$L__BB5_66;

	fma.rn.f32 	%f2853, %f89, %f88, %f89;

$L__BB5_66:
	setp.geu.f32 	%p660, %f85, 0f00000000;
	mov.b32 	%r280, %f2853;
	xor.b32  	%r281, %r280, -2147483648;
	mov.b32 	%f916, %r281;
	selp.f32 	%f135, %f916, %f2853, %p4;
	add.f32 	%f917, %f85, %f85;
	selp.f32 	%f918, %f917, 0f00000000, %p106;
	setp.eq.f32 	%p162, %f85, 0f00000000;
	selp.f32 	%f2854, %f918, %f135, %p162;
	@%p660 bra 	$L__BB5_69;

	cvt.rzi.f32.f32 	%f920, %f588;
	setp.eq.f32 	%p163, %f920, 0f40000000;
	mov.f32 	%f2854, %f135;
	@%p163 bra 	$L__BB5_69;

	mov.f32 	%f2854, 0f7FFFFFFF;

$L__BB5_69:
	mov.f32 	%f2683, 0f3FB8AA3B;
	mov.f32 	%f2682, 0f3F000000;
	abs.f32 	%f2681, %f85;
	add.f32 	%f923, %f2681, 0f40000000;
	mov.b32 	%r282, %f923;
	setp.gt.s32 	%p164, %r282, 2139095039;
	add.f32 	%f924, %f85, 0f40000000;
	setp.gtu.f32 	%p165, %f2681, 0f7F800000;
	mov.f32 	%f2855, 0f7F800000;
	selp.f32 	%f925, %f924, %f2854, %p165;
	selp.f32 	%f926, 0fFF800000, 0f7F800000, %p4;
	setp.neu.f32 	%p166, %f2681, 0f7F800000;
	selp.f32 	%f927, %f925, %f926, %p166;
	selp.f32 	%f928, %f927, %f2854, %p164;
	mul.f32 	%f929, %f928, 0fBF000000;
	setp.eq.f32 	%p167, %f85, 0f3F800000;
	selp.f32 	%f930, 0fBF000000, %f929, %p167;
	mov.f32 	%f932, 0f3BBB989D;
	fma.rn.f32 	%f933, %f930, %f932, %f2682;
	mov.f32 	%f935, 0f437C0000;
	cvt.sat.f32.f32 	%f936, %f933;
	mov.f32 	%f937, 0f4B400001;
	fma.rm.f32 	%f938, %f936, %f935, %f937;
	add.f32 	%f939, %f938, 0fCB40007F;
	neg.f32 	%f940, %f939;
	fma.rn.f32 	%f941, %f930, %f2683, %f940;
	mov.f32 	%f942, 0f32A57060;
	fma.rn.f32 	%f943, %f930, %f942, %f941;
	mov.b32 	%r283, %f938;
	shl.b32 	%r284, %r283, 23;
	mov.b32 	%f944, %r284;
	ex2.approx.ftz.f32 	%f945, %f943;
	mul.f32 	%f138, %f945, %f944;
	setp.eq.f32 	%p168, %f93, 0f7F800000;
	@%p168 bra 	$L__BB5_71;

	fma.rn.f32 	%f2855, %f93, %f92, %f93;

$L__BB5_71:
	setp.geu.f32 	%p663, %f90, 0f00000000;
	setp.lt.f32 	%p662, %f90, 0f00000000;
	and.pred  	%p661, %p662, %p106;
	mov.b32 	%r285, %f2855;
	xor.b32  	%r286, %r285, -2147483648;
	mov.b32 	%f946, %r286;
	selp.f32 	%f141, %f946, %f2855, %p661;
	add.f32 	%f947, %f90, %f90;
	selp.f32 	%f948, %f947, 0f00000000, %p106;
	setp.eq.f32 	%p170, %f90, 0f00000000;
	selp.f32 	%f2856, %f948, %f141, %p170;
	@%p663 bra 	$L__BB5_74;

	cvt.rzi.f32.f32 	%f950, %f588;
	setp.eq.f32 	%p171, %f950, 0f40000000;
	mov.f32 	%f2856, %f141;
	@%p171 bra 	$L__BB5_74;

	mov.f32 	%f2856, 0f7FFFFFFF;

$L__BB5_74:
	mov.f32 	%f2690, 0f32A57060;
	mov.f32 	%f2689, 0f4B400001;
	mov.f32 	%f2688, 0f437C0000;
	mov.f32 	%f2687, 0f3BBB989D;
	abs.f32 	%f2686, %f90;
	setp.lt.f32 	%p665, %f90, 0f00000000;
	and.pred  	%p664, %p665, %p106;
	mov.f32 	%f2685, 0f3FB8AA3B;
	mov.f32 	%f2684, 0f3F000000;
	add.f32 	%f952, %f2686, 0f40000000;
	mov.b32 	%r287, %f952;
	setp.gt.s32 	%p172, %r287, 2139095039;
	add.f32 	%f953, %f90, 0f40000000;
	setp.gtu.f32 	%p173, %f2686, 0f7F800000;
	selp.f32 	%f954, %f953, %f2856, %p173;
	selp.f32 	%f955, 0fFF800000, 0f7F800000, %p664;
	setp.neu.f32 	%p174, %f2686, 0f7F800000;
	selp.f32 	%f956, %f954, %f955, %p174;
	selp.f32 	%f957, %f956, %f2856, %p172;
	mul.f32 	%f958, %f957, 0fBF000000;
	setp.eq.f32 	%p175, %f90, 0f3F800000;
	selp.f32 	%f959, 0fBF000000, %f958, %p175;
	fma.rn.f32 	%f962, %f959, %f2687, %f2684;
	cvt.sat.f32.f32 	%f965, %f962;
	fma.rm.f32 	%f967, %f965, %f2688, %f2689;
	add.f32 	%f968, %f967, 0fCB40007F;
	neg.f32 	%f969, %f968;
	fma.rn.f32 	%f970, %f959, %f2685, %f969;
	fma.rn.f32 	%f972, %f959, %f2690, %f970;
	mov.b32 	%r288, %f967;
	shl.b32 	%r289, %r288, 23;
	mov.b32 	%f973, %r289;
	ex2.approx.ftz.f32 	%f974, %f972;
	mul.f32 	%f144, %f974, %f973;
	sub.f32 	%f975, %f138, %f144;
	mul.f32 	%f976, %f60, %f975;
	mul.f32 	%f145, %f129, %f976;
	not.pred 	%p176, %p6;
	mov.f64 	%fd510, %fd37;
	@%p176 bra 	$L__BB5_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r290}, %fd37;
	}
	xor.b32  	%r291, %r290, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r292, %temp}, %fd37;
	}
	mov.b64 	%fd510, {%r292, %r291};

$L__BB5_76:
	setp.eq.f32 	%p177, %f2886, 0f00000000;
	@%p177 bra 	$L__BB5_80;
	bra.uni 	$L__BB5_77;

$L__BB5_80:
	mov.u32 	%r293, 0;
	mov.b64 	%fd510, {%r293, %r56};
	bra.uni 	$L__BB5_81;

$L__BB5_77:
	setp.gt.s32 	%p178, %r53, -1;
	@%p178 bra 	$L__BB5_81;

	cvt.rzi.f64.f64 	%fd317, %fd309;
	setp.eq.f64 	%p179, %fd317, 0d4008000000000000;
	@%p179 bra 	$L__BB5_81;

	mov.f64 	%fd510, 0dFFF8000000000000;

$L__BB5_81:
	selp.f64 	%fd511, %fd510, %fd35, %p120;
	@%p14 bra 	$L__BB5_86;

	setp.eq.s32 	%p181, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r294, %temp}, %fd309;
	}
	setp.eq.s32 	%p182, %r294, 0;
	and.pred  	%p183, %p181, %p182;
	@%p183 bra 	$L__BB5_85;
	bra.uni 	$L__BB5_83;

$L__BB5_85:
	mov.u32 	%r298, 0;
	mov.b64 	%fd511, {%r298, %r59};
	bra.uni 	$L__BB5_86;

$L__BB5_83:
	and.b32  	%r295, %r53, 2147483647;
	setp.ne.s32 	%p184, %r295, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r296, %temp}, %fd307;
	}
	setp.ne.s32 	%p185, %r296, 0;
	or.pred  	%p186, %p184, %p185;
	mov.f64 	%fd511, %fd510;
	@%p186 bra 	$L__BB5_86;

	mov.u32 	%r297, 0;
	mov.b64 	%fd511, {%r297, %r62};

$L__BB5_86:
	mov.f32 	%f2701, 0f3102E308;
	mov.f32 	%f2700, 0fBF317218;
	mov.f32 	%f2699, 0f35BFBE8E;
	mov.f32 	%f2698, 0f3F317200;
	mov.f32 	%f2697, 0f3DAAAABD;
	mov.f32 	%f2696, 0f3C4CAF63;
	mov.f32 	%f2695, 0f3B18F0FE;
	cvt.rn.f32.s32 	%f2694, %r785;
	add.f32 	%f2693, %f2694, 0f3F000000;
	sub.f32 	%f2692, %f2693, %f2890;
	mov.f32 	%f2691, 0f3FB8AA3B;
	setp.eq.f32 	%p187, %f2886, 0f3F800000;
	selp.f64 	%fd321, 0d3FF0000000000000, %fd511, %p187;
	div.rn.f64 	%fd322, %fd34, %fd321;
	mul.f32 	%f978, %f81, %f144;
	mul.f32 	%f979, %f2692, %f138;
	sub.f32 	%f980, %f979, %f978;
	cvt.f64.f32 	%fd323, %f980;
	mul.f64 	%fd324, %fd322, %fd323;
	cvt.f64.f32 	%fd53, %f129;
	mul.f64 	%fd325, %fd324, %fd53;
	cvt.rn.f32.f64 	%f146, %fd325;
	add.f32 	%f981, %f117, 0f3F000000;
	sub.f32 	%f147, %f981, %f2889;
	div.rn.f32 	%f148, %f147, %f2886;
	abs.f32 	%f149, %f148;
	setp.lt.f32 	%p188, %f149, 0f00800000;
	mul.f32 	%f982, %f149, 0f4B800000;
	selp.f32 	%f983, %f982, %f149, %p188;
	selp.f32 	%f984, 0fC3170000, 0fC2FE0000, %p188;
	mov.b32 	%r299, %f983;
	and.b32  	%r300, %r299, 8388607;
	or.b32  	%r301, %r300, 1065353216;
	mov.b32 	%f985, %r301;
	shr.u32 	%r302, %r299, 23;
	cvt.rn.f32.u32 	%f986, %r302;
	add.f32 	%f987, %f984, %f986;
	setp.gt.f32 	%p189, %f985, 0f3FB504F3;
	mul.f32 	%f988, %f985, 0f3F000000;
	add.f32 	%f989, %f987, 0f3F800000;
	selp.f32 	%f990, %f989, %f987, %p189;
	selp.f32 	%f991, %f988, %f985, %p189;
	add.f32 	%f992, %f991, 0fBF800000;
	add.f32 	%f993, %f991, 0f3F800000;
	rcp.approx.ftz.f32 	%f994, %f993;
	add.f32 	%f995, %f992, %f992;
	mul.f32 	%f997, %f995, %f994;
	mul.f32 	%f998, %f997, %f997;
	fma.rn.f32 	%f1001, %f2695, %f998, %f2696;
	fma.rn.f32 	%f1003, %f1001, %f998, %f2697;
	mul.rn.f32 	%f1004, %f1003, %f998;
	mul.rn.f32 	%f1005, %f1004, %f997;
	sub.f32 	%f1006, %f992, %f997;
	add.f32 	%f1007, %f1006, %f1006;
	neg.f32 	%f1008, %f997;
	fma.rn.f32 	%f1009, %f1008, %f992, %f1007;
	mul.rn.f32 	%f1010, %f994, %f1009;
	add.f32 	%f1011, %f1005, %f997;
	sub.f32 	%f1012, %f997, %f1011;
	add.f32 	%f1013, %f1005, %f1012;
	add.f32 	%f1014, %f1010, %f1013;
	add.f32 	%f1015, %f1011, %f1014;
	sub.f32 	%f1016, %f1011, %f1015;
	add.f32 	%f1017, %f1014, %f1016;
	mul.rn.f32 	%f1019, %f990, %f2698;
	mul.rn.f32 	%f1021, %f990, %f2699;
	add.f32 	%f1022, %f1019, %f1015;
	sub.f32 	%f1023, %f1019, %f1022;
	add.f32 	%f1024, %f1015, %f1023;
	add.f32 	%f1025, %f1017, %f1024;
	add.f32 	%f1026, %f1021, %f1025;
	add.f32 	%f1027, %f1022, %f1026;
	sub.f32 	%f1028, %f1022, %f1027;
	add.f32 	%f1029, %f1026, %f1028;
	mul.rn.f32 	%f1030, %f588, %f1027;
	neg.f32 	%f1031, %f1030;
	fma.rn.f32 	%f1032, %f588, %f1027, %f1031;
	fma.rn.f32 	%f1033, %f588, %f1029, %f1032;
	mov.f32 	%f1034, 0f00000000;
	fma.rn.f32 	%f1035, %f1034, %f1027, %f1033;
	add.rn.f32 	%f1036, %f1030, %f1035;
	neg.f32 	%f1037, %f1036;
	add.rn.f32 	%f1038, %f1030, %f1037;
	add.rn.f32 	%f1039, %f1038, %f1035;
	mov.b32 	%r303, %f1036;
	setp.eq.s32 	%p190, %r303, 1118925336;
	add.s32 	%r304, %r303, -1;
	mov.b32 	%f1040, %r304;
	add.f32 	%f1041, %f1039, 0f37000000;
	selp.f32 	%f150, %f1041, %f1039, %p190;
	selp.f32 	%f1042, %f1040, %f1036, %p190;
	mul.rn.f32 	%f1044, %f1042, %f2691;
	cvt.rzi.f32.f32 	%f1045, %f1044;
	abs.f32 	%f1046, %f1045;
	setp.gt.f32 	%p191, %f1046, 0f42FC0000;
	mov.b32 	%r305, %f1045;
	and.b32  	%r306, %r305, -2147483648;
	or.b32  	%r307, %r306, 1123811328;
	mov.b32 	%f1047, %r307;
	selp.f32 	%f1048, %f1047, %f1045, %p191;
	fma.rn.f32 	%f1050, %f1048, %f2700, %f1042;
	fma.rn.f32 	%f1052, %f1048, %f2701, %f1050;
	mul.f32 	%f1053, %f1052, 0f3FB8AA3B;
	add.f32 	%f1054, %f1048, 0f4B40007F;
	mov.b32 	%r308, %f1054;
	shl.b32 	%r309, %r308, 23;
	mov.b32 	%f1055, %r309;
	ex2.approx.ftz.f32 	%f1056, %f1053;
	mul.f32 	%f151, %f1056, %f1055;
	setp.eq.f32 	%p192, %f151, 0f7F800000;
	mov.f32 	%f2857, 0f7F800000;
	@%p192 bra 	$L__BB5_88;

	fma.rn.f32 	%f2857, %f151, %f150, %f151;

$L__BB5_88:
	setp.lt.f32 	%p193, %f148, 0f00000000;
	and.pred  	%p20, %p193, %p106;
	setp.eq.f32 	%p195, %f148, 0f00000000;
	@%p195 bra 	$L__BB5_92;
	bra.uni 	$L__BB5_89;

$L__BB5_92:
	add.f32 	%f1061, %f148, %f148;
	selp.f32 	%f2859, %f1061, 0f00000000, %p106;
	bra.uni 	$L__BB5_93;

$L__BB5_89:
	mov.b32 	%r310, %f2857;
	xor.b32  	%r311, %r310, -2147483648;
	mov.b32 	%f1057, %r311;
	selp.f32 	%f2859, %f1057, %f2857, %p20;
	setp.geu.f32 	%p196, %f148, 0f00000000;
	@%p196 bra 	$L__BB5_93;

	cvt.rzi.f32.f32 	%f1059, %f588;
	setp.eq.f32 	%p197, %f1059, 0f40000000;
	@%p197 bra 	$L__BB5_93;

	mov.f32 	%f2859, 0f7FFFFFFF;

$L__BB5_93:
	abs.f32 	%f2781, %f148;
	add.f32 	%f1062, %f2781, 0f40000000;
	mov.b32 	%r312, %f1062;
	setp.lt.s32 	%p199, %r312, 2139095040;
	@%p199 bra 	$L__BB5_98;

	abs.f32 	%f2786, %f148;
	setp.gtu.f32 	%p200, %f2786, 0f7F800000;
	@%p200 bra 	$L__BB5_97;
	bra.uni 	$L__BB5_95;

$L__BB5_97:
	add.f32 	%f2859, %f148, 0f40000000;
	bra.uni 	$L__BB5_98;

$L__BB5_95:
	abs.f32 	%f2787, %f148;
	setp.neu.f32 	%p201, %f2787, 0f7F800000;
	@%p201 bra 	$L__BB5_98;

	selp.f32 	%f2859, 0fFF800000, 0f7F800000, %p20;

$L__BB5_98:
	mov.f32 	%f2715, 0f00000000;
	mov.f32 	%f2714, 0f3102E308;
	mov.f32 	%f2713, 0fBF317218;
	mov.f32 	%f2712, 0f35BFBE8E;
	mov.f32 	%f2711, 0f3F317200;
	mov.f32 	%f2710, 0f3DAAAABD;
	mov.f32 	%f2709, 0f3C4CAF63;
	mov.f32 	%f2708, 0f3B18F0FE;
	mov.f32 	%f2707, 0f32A57060;
	mov.f32 	%f2706, 0f4B400001;
	mov.f32 	%f2705, 0f437C0000;
	mov.f32 	%f2704, 0f3BBB989D;
	mov.f32 	%f2703, 0f3FB8AA3B;
	mov.f32 	%f2702, 0f3F000000;
	mul.f32 	%f1064, %f2859, 0fBF000000;
	setp.eq.f32 	%p202, %f148, 0f3F800000;
	selp.f32 	%f1065, 0fBF000000, %f1064, %p202;
	fma.rn.f32 	%f1068, %f1065, %f2704, %f2702;
	cvt.sat.f32.f32 	%f1071, %f1068;
	fma.rm.f32 	%f1073, %f1071, %f2705, %f2706;
	add.f32 	%f1074, %f1073, 0fCB40007F;
	neg.f32 	%f1075, %f1074;
	fma.rn.f32 	%f1076, %f1065, %f2703, %f1075;
	fma.rn.f32 	%f1078, %f1065, %f2707, %f1076;
	mov.b32 	%r313, %f1073;
	shl.b32 	%r314, %r313, 23;
	mov.b32 	%f1079, %r314;
	ex2.approx.ftz.f32 	%f1080, %f1078;
	mul.f32 	%f160, %f1080, %f1079;
	div.rn.f32 	%f161, %f124, %f2886;
	abs.f32 	%f162, %f161;
	setp.lt.f32 	%p203, %f162, 0f00800000;
	mul.f32 	%f1081, %f162, 0f4B800000;
	selp.f32 	%f1082, %f1081, %f162, %p203;
	selp.f32 	%f1083, 0fC3170000, 0fC2FE0000, %p203;
	mov.b32 	%r315, %f1082;
	and.b32  	%r316, %r315, 8388607;
	or.b32  	%r317, %r316, 1065353216;
	mov.b32 	%f1084, %r317;
	shr.u32 	%r318, %r315, 23;
	cvt.rn.f32.u32 	%f1085, %r318;
	add.f32 	%f1086, %f1083, %f1085;
	setp.gt.f32 	%p204, %f1084, 0f3FB504F3;
	mul.f32 	%f1087, %f1084, 0f3F000000;
	add.f32 	%f1088, %f1086, 0f3F800000;
	selp.f32 	%f1089, %f1088, %f1086, %p204;
	selp.f32 	%f1090, %f1087, %f1084, %p204;
	add.f32 	%f1091, %f1090, 0fBF800000;
	add.f32 	%f1092, %f1090, 0f3F800000;
	rcp.approx.ftz.f32 	%f1093, %f1092;
	add.f32 	%f1094, %f1091, %f1091;
	mul.f32 	%f1096, %f1094, %f1093;
	mul.f32 	%f1097, %f1096, %f1096;
	fma.rn.f32 	%f1100, %f2708, %f1097, %f2709;
	fma.rn.f32 	%f1102, %f1100, %f1097, %f2710;
	mul.rn.f32 	%f1103, %f1102, %f1097;
	mul.rn.f32 	%f1104, %f1103, %f1096;
	sub.f32 	%f1105, %f1091, %f1096;
	add.f32 	%f1106, %f1105, %f1105;
	neg.f32 	%f1107, %f1096;
	fma.rn.f32 	%f1108, %f1107, %f1091, %f1106;
	mul.rn.f32 	%f1109, %f1093, %f1108;
	add.f32 	%f1110, %f1104, %f1096;
	sub.f32 	%f1111, %f1096, %f1110;
	add.f32 	%f1112, %f1104, %f1111;
	add.f32 	%f1113, %f1109, %f1112;
	add.f32 	%f1114, %f1110, %f1113;
	sub.f32 	%f1115, %f1110, %f1114;
	add.f32 	%f1116, %f1113, %f1115;
	mul.rn.f32 	%f1118, %f1089, %f2711;
	mul.rn.f32 	%f1120, %f1089, %f2712;
	add.f32 	%f1121, %f1118, %f1114;
	sub.f32 	%f1122, %f1118, %f1121;
	add.f32 	%f1123, %f1114, %f1122;
	add.f32 	%f1124, %f1116, %f1123;
	add.f32 	%f1125, %f1120, %f1124;
	add.f32 	%f1126, %f1121, %f1125;
	sub.f32 	%f1127, %f1121, %f1126;
	add.f32 	%f1128, %f1125, %f1127;
	mul.rn.f32 	%f1129, %f588, %f1126;
	neg.f32 	%f1130, %f1129;
	fma.rn.f32 	%f1131, %f588, %f1126, %f1130;
	fma.rn.f32 	%f1132, %f588, %f1128, %f1131;
	fma.rn.f32 	%f1134, %f2715, %f1126, %f1132;
	add.rn.f32 	%f1135, %f1129, %f1134;
	neg.f32 	%f1136, %f1135;
	add.rn.f32 	%f1137, %f1129, %f1136;
	add.rn.f32 	%f1138, %f1137, %f1134;
	mov.b32 	%r319, %f1135;
	setp.eq.s32 	%p205, %r319, 1118925336;
	add.s32 	%r320, %r319, -1;
	mov.b32 	%f1139, %r320;
	add.f32 	%f1140, %f1138, 0f37000000;
	selp.f32 	%f163, %f1140, %f1138, %p205;
	selp.f32 	%f1141, %f1139, %f1135, %p205;
	mul.rn.f32 	%f1142, %f1141, %f2703;
	cvt.rzi.f32.f32 	%f1143, %f1142;
	abs.f32 	%f1144, %f1143;
	setp.gt.f32 	%p206, %f1144, 0f42FC0000;
	mov.b32 	%r321, %f1143;
	and.b32  	%r322, %r321, -2147483648;
	or.b32  	%r323, %r322, 1123811328;
	mov.b32 	%f1145, %r323;
	selp.f32 	%f1146, %f1145, %f1143, %p206;
	fma.rn.f32 	%f1148, %f1146, %f2713, %f1141;
	fma.rn.f32 	%f1150, %f1146, %f2714, %f1148;
	mul.f32 	%f1151, %f1150, 0f3FB8AA3B;
	add.f32 	%f1152, %f1146, 0f4B40007F;
	mov.b32 	%r324, %f1152;
	shl.b32 	%r325, %r324, 23;
	mov.b32 	%f1153, %r325;
	ex2.approx.ftz.f32 	%f1154, %f1151;
	mul.f32 	%f164, %f1154, %f1153;
	setp.eq.f32 	%p207, %f164, 0f7F800000;
	mov.f32 	%f2860, 0f7F800000;
	@%p207 bra 	$L__BB5_100;

	fma.rn.f32 	%f2860, %f164, %f163, %f164;

$L__BB5_100:
	setp.lt.f32 	%p208, %f161, 0f00000000;
	and.pred  	%p21, %p208, %p106;
	setp.eq.f32 	%p210, %f161, 0f00000000;
	@%p210 bra 	$L__BB5_104;
	bra.uni 	$L__BB5_101;

$L__BB5_104:
	add.f32 	%f1159, %f161, %f161;
	selp.f32 	%f2862, %f1159, 0f00000000, %p106;
	bra.uni 	$L__BB5_105;

$L__BB5_101:
	mov.b32 	%r326, %f2860;
	xor.b32  	%r327, %r326, -2147483648;
	mov.b32 	%f1155, %r327;
	selp.f32 	%f2862, %f1155, %f2860, %p21;
	setp.geu.f32 	%p211, %f161, 0f00000000;
	@%p211 bra 	$L__BB5_105;

	cvt.rzi.f32.f32 	%f1157, %f588;
	setp.eq.f32 	%p212, %f1157, 0f40000000;
	@%p212 bra 	$L__BB5_105;

	mov.f32 	%f2862, 0f7FFFFFFF;

$L__BB5_105:
	abs.f32 	%f2788, %f161;
	add.f32 	%f1160, %f2788, 0f40000000;
	mov.b32 	%r328, %f1160;
	setp.lt.s32 	%p214, %r328, 2139095040;
	@%p214 bra 	$L__BB5_110;

	abs.f32 	%f2789, %f161;
	setp.gtu.f32 	%p215, %f2789, 0f7F800000;
	@%p215 bra 	$L__BB5_109;
	bra.uni 	$L__BB5_107;

$L__BB5_109:
	add.f32 	%f2862, %f161, 0f40000000;
	bra.uni 	$L__BB5_110;

$L__BB5_107:
	abs.f32 	%f2790, %f161;
	setp.neu.f32 	%p216, %f2790, 0f7F800000;
	@%p216 bra 	$L__BB5_110;

	selp.f32 	%f2862, 0fFF800000, 0f7F800000, %p21;

$L__BB5_110:
	mov.f32 	%f2721, 0f32A57060;
	mov.f32 	%f2720, 0f4B400001;
	mov.f32 	%f2719, 0f437C0000;
	mov.f32 	%f2718, 0f3BBB989D;
	mov.f32 	%f2717, 0f3FB8AA3B;
	mov.f32 	%f2716, 0f3F000000;
	mul.f32 	%f1161, %f2862, 0fBF000000;
	setp.eq.f32 	%p217, %f161, 0f3F800000;
	selp.f32 	%f1162, 0fBF000000, %f1161, %p217;
	fma.rn.f32 	%f1165, %f1162, %f2718, %f2716;
	cvt.sat.f32.f32 	%f1168, %f1165;
	fma.rm.f32 	%f1170, %f1168, %f2719, %f2720;
	add.f32 	%f1171, %f1170, 0fCB40007F;
	neg.f32 	%f1172, %f1171;
	fma.rn.f32 	%f1173, %f1162, %f2717, %f1172;
	fma.rn.f32 	%f1175, %f1162, %f2721, %f1173;
	mov.b32 	%r329, %f1170;
	shl.b32 	%r330, %r329, 23;
	mov.b32 	%f1176, %r330;
	ex2.approx.ftz.f32 	%f1177, %f1175;
	mul.f32 	%f173, %f1177, %f1176;
	sub.f32 	%f1178, %f160, %f173;
	mul.f32 	%f1179, %f60, %f1178;
	mul.f32 	%f174, %f116, %f1179;
	mov.f64 	%fd513, %fd37;
	@%p176 bra 	$L__BB5_112;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r331}, %fd37;
	}
	xor.b32  	%r332, %r331, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r333, %temp}, %fd37;
	}
	mov.b64 	%fd513, {%r333, %r332};

$L__BB5_112:
	setp.eq.f32 	%p676, %f2886, 0f00000000;
	@%p676 bra 	$L__BB5_116;
	bra.uni 	$L__BB5_113;

$L__BB5_116:
	mov.u32 	%r334, 0;
	mov.b64 	%fd513, {%r334, %r56};
	bra.uni 	$L__BB5_117;

$L__BB5_113:
	setp.gt.s32 	%p220, %r53, -1;
	@%p220 bra 	$L__BB5_117;

	cvt.rzi.f64.f64 	%fd327, %fd309;
	setp.eq.f64 	%p221, %fd327, 0d4008000000000000;
	@%p221 bra 	$L__BB5_117;

	mov.f64 	%fd513, 0dFFF8000000000000;

$L__BB5_117:
	selp.f64 	%fd514, %fd513, %fd35, %p120;
	@%p14 bra 	$L__BB5_122;

	setp.eq.s32 	%p223, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r335, %temp}, %fd309;
	}
	setp.eq.s32 	%p224, %r335, 0;
	and.pred  	%p225, %p223, %p224;
	@%p225 bra 	$L__BB5_121;
	bra.uni 	$L__BB5_119;

$L__BB5_121:
	mov.u32 	%r339, 0;
	mov.b64 	%fd514, {%r339, %r59};
	bra.uni 	$L__BB5_122;

$L__BB5_119:
	and.b32  	%r336, %r53, 2147483647;
	setp.ne.s32 	%p226, %r336, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r337, %temp}, %fd307;
	}
	setp.ne.s32 	%p227, %r337, 0;
	or.pred  	%p228, %p226, %p227;
	mov.f64 	%fd514, %fd513;
	@%p228 bra 	$L__BB5_122;

	mov.u32 	%r338, 0;
	mov.b64 	%fd514, {%r338, %r62};

$L__BB5_122:
	cvt.rn.f32.s32 	%f2784, %r786;
	add.f32 	%f2783, %f2784, 0f3F000000;
	sub.f32 	%f2782, %f2783, %f2889;
	setp.eq.f32 	%p677, %f2886, 0f3F800000;
	selp.f64 	%fd331, 0d3FF0000000000000, %fd514, %p677;
	div.rn.f64 	%fd332, %fd34, %fd331;
	mul.f32 	%f1181, %f124, %f173;
	mul.f32 	%f1182, %f2782, %f160;
	sub.f32 	%f1183, %f1182, %f1181;
	cvt.f64.f32 	%fd333, %f1183;
	mul.f64 	%fd334, %fd332, %fd333;
	cvt.f64.f32 	%fd335, %f116;
	mul.f64 	%fd336, %fd334, %fd335;
	cvt.rn.f32.f64 	%f175, %fd336;
	setp.eq.f32 	%p230, %f97, 0f7F800000;
	mov.f32 	%f2863, 0f7F800000;
	@%p230 bra 	$L__BB5_124;

	fma.rn.f32 	%f2863, %f97, %f96, %f97;

$L__BB5_124:
	setp.geu.f32 	%p668, %f94, 0f00000000;
	setp.lt.f32 	%p667, %f94, 0f00000000;
	and.pred  	%p666, %p667, %p106;
	mov.b32 	%r340, %f2863;
	xor.b32  	%r341, %r340, -2147483648;
	mov.b32 	%f1184, %r341;
	selp.f32 	%f178, %f1184, %f2863, %p666;
	add.f32 	%f1185, %f94, %f94;
	selp.f32 	%f1186, %f1185, 0f00000000, %p106;
	setp.eq.f32 	%p232, %f94, 0f00000000;
	selp.f32 	%f2864, %f1186, %f178, %p232;
	@%p668 bra 	$L__BB5_127;

	cvt.rzi.f32.f32 	%f1188, %f588;
	setp.eq.f32 	%p233, %f1188, 0f40000000;
	mov.f32 	%f2864, %f178;
	@%p233 bra 	$L__BB5_127;

	mov.f32 	%f2864, 0f7FFFFFFF;

$L__BB5_127:
	abs.f32 	%f2728, %f94;
	setp.lt.f32 	%p670, %f94, 0f00000000;
	and.pred  	%p669, %p670, %p106;
	mov.f32 	%f2727, 0f32A57060;
	mov.f32 	%f2726, 0f4B400001;
	mov.f32 	%f2725, 0f437C0000;
	mov.f32 	%f2724, 0f3BBB989D;
	mov.f32 	%f2723, 0f3FB8AA3B;
	mov.f32 	%f2722, 0f3F000000;
	add.f32 	%f1191, %f2728, 0f40000000;
	mov.b32 	%r342, %f1191;
	setp.gt.s32 	%p234, %r342, 2139095039;
	add.f32 	%f1192, %f94, 0f40000000;
	setp.gtu.f32 	%p235, %f2728, 0f7F800000;
	mov.f32 	%f2865, 0f7F800000;
	selp.f32 	%f1193, %f1192, %f2864, %p235;
	selp.f32 	%f1194, 0fFF800000, 0f7F800000, %p669;
	setp.neu.f32 	%p236, %f2728, 0f7F800000;
	selp.f32 	%f1195, %f1193, %f1194, %p236;
	selp.f32 	%f1196, %f1195, %f2864, %p234;
	mul.f32 	%f1197, %f1196, 0fBF000000;
	setp.eq.f32 	%p237, %f94, 0f3F800000;
	selp.f32 	%f1198, 0fBF000000, %f1197, %p237;
	fma.rn.f32 	%f1201, %f1198, %f2724, %f2722;
	cvt.sat.f32.f32 	%f1204, %f1201;
	fma.rm.f32 	%f1206, %f1204, %f2725, %f2726;
	add.f32 	%f1207, %f1206, 0fCB40007F;
	neg.f32 	%f1208, %f1207;
	fma.rn.f32 	%f1209, %f1198, %f2723, %f1208;
	fma.rn.f32 	%f1211, %f1198, %f2727, %f1209;
	mov.b32 	%r343, %f1206;
	shl.b32 	%r344, %r343, 23;
	mov.b32 	%f1212, %r344;
	ex2.approx.ftz.f32 	%f1213, %f1211;
	mul.f32 	%f181, %f1213, %f1212;
	setp.eq.f32 	%p238, %f101, 0f7F800000;
	@%p238 bra 	$L__BB5_129;

	fma.rn.f32 	%f2865, %f101, %f100, %f101;

$L__BB5_129:
	setp.geu.f32 	%p673, %f98, 0f00000000;
	setp.lt.f32 	%p672, %f98, 0f00000000;
	and.pred  	%p671, %p672, %p106;
	mov.b32 	%r345, %f2865;
	xor.b32  	%r346, %r345, -2147483648;
	mov.b32 	%f1214, %r346;
	selp.f32 	%f184, %f1214, %f2865, %p671;
	add.f32 	%f1215, %f98, %f98;
	selp.f32 	%f1216, %f1215, 0f00000000, %p106;
	setp.eq.f32 	%p240, %f98, 0f00000000;
	selp.f32 	%f2866, %f1216, %f184, %p240;
	@%p673 bra 	$L__BB5_132;

	cvt.rzi.f32.f32 	%f1218, %f588;
	setp.eq.f32 	%p241, %f1218, 0f40000000;
	mov.f32 	%f2866, %f184;
	@%p241 bra 	$L__BB5_132;

	mov.f32 	%f2866, 0f7FFFFFFF;

$L__BB5_132:
	cvt.rn.f32.s32 	%f2737, %r785;
	sub.f32 	%f2736, %f2737, %f2890;
	abs.f32 	%f2735, %f98;
	setp.lt.f32 	%p675, %f98, 0f00000000;
	and.pred  	%p674, %p675, %p106;
	mov.f32 	%f2734, 0f32A57060;
	mov.f32 	%f2733, 0f4B400001;
	mov.f32 	%f2732, 0f437C0000;
	mov.f32 	%f2731, 0f3BBB989D;
	mov.f32 	%f2730, 0f3FB8AA3B;
	mov.f32 	%f2729, 0f3F000000;
	add.f32 	%f1220, %f2735, 0f40000000;
	mov.b32 	%r347, %f1220;
	setp.gt.s32 	%p242, %r347, 2139095039;
	add.f32 	%f1221, %f98, 0f40000000;
	setp.gtu.f32 	%p243, %f2735, 0f7F800000;
	selp.f32 	%f1222, %f1221, %f2866, %p243;
	selp.f32 	%f1223, 0fFF800000, 0f7F800000, %p674;
	setp.neu.f32 	%p244, %f2735, 0f7F800000;
	selp.f32 	%f1224, %f1222, %f1223, %p244;
	selp.f32 	%f1225, %f1224, %f2866, %p242;
	mul.f32 	%f1226, %f1225, 0fBF000000;
	setp.eq.f32 	%p245, %f98, 0f3F800000;
	selp.f32 	%f1227, 0fBF000000, %f1226, %p245;
	fma.rn.f32 	%f1230, %f1227, %f2731, %f2729;
	cvt.sat.f32.f32 	%f1233, %f1230;
	fma.rm.f32 	%f1235, %f1233, %f2732, %f2733;
	add.f32 	%f1236, %f1235, 0fCB40007F;
	neg.f32 	%f1237, %f1236;
	fma.rn.f32 	%f1238, %f1227, %f2730, %f1237;
	fma.rn.f32 	%f1240, %f1227, %f2734, %f1238;
	mov.b32 	%r348, %f1235;
	shl.b32 	%r349, %r348, 23;
	mov.b32 	%f1241, %r349;
	ex2.approx.ftz.f32 	%f1242, %f1240;
	mul.f32 	%f187, %f1242, %f1241;
	add.f32 	%f1243, %f2736, 0f3F800000;
	mul.f32 	%f1244, %f1243, %f181;
	mul.f32 	%f1245, %f2736, %f187;
	sub.f32 	%f1246, %f1244, %f1245;
	mul.f32 	%f1247, %f61, %f1246;
	mul.f32 	%f188, %f129, %f1247;
	not.pred 	%p246, %p9;
	mov.f64 	%fd516, %fd38;
	@%p246 bra 	$L__BB5_134;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r350}, %fd38;
	}
	xor.b32  	%r351, %r350, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r352, %temp}, %fd38;
	}
	mov.b64 	%fd516, {%r352, %r351};

$L__BB5_134:
	setp.eq.f32 	%p678, %f2886, 0f00000000;
	@%p678 bra 	$L__BB5_138;
	bra.uni 	$L__BB5_135;

$L__BB5_138:
	mov.u32 	%r353, 0;
	mov.b64 	%fd516, {%r353, %r63};
	bra.uni 	$L__BB5_139;

$L__BB5_135:
	setp.gt.s32 	%p248, %r53, -1;
	@%p248 bra 	$L__BB5_139;

	mov.f64 	%fd483, 0d4014000000000000;
	cvt.rzi.f64.f64 	%fd338, %fd483;
	setp.eq.f64 	%p249, %fd338, 0d4014000000000000;
	@%p249 bra 	$L__BB5_139;

	mov.f64 	%fd516, 0dFFF8000000000000;

$L__BB5_139:
	cvt.f64.f32 	%fd479, %f2886;
	add.f64 	%fd478, %fd477, 0d4014000000000000;
	selp.f64 	%fd517, %fd516, %fd478, %p139;
	@%p17 bra 	$L__BB5_144;

	mov.f64 	%fd480, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r770}, %fd480;
	}
	and.b32  	%r769, %r770, 2147483647;
	setp.eq.s32 	%p251, %r769, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r354, %temp}, %fd480;
	}
	setp.eq.s32 	%p252, %r354, 0;
	and.pred  	%p253, %p251, %p252;
	@%p253 bra 	$L__BB5_143;
	bra.uni 	$L__BB5_141;

$L__BB5_143:
	mov.u32 	%r358, 0;
	mov.b64 	%fd517, {%r358, %r67};
	bra.uni 	$L__BB5_144;

$L__BB5_141:
	and.b32  	%r355, %r53, 2147483647;
	setp.ne.s32 	%p254, %r355, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r356, %temp}, %fd307;
	}
	setp.ne.s32 	%p255, %r356, 0;
	or.pred  	%p256, %p254, %p255;
	mov.f64 	%fd517, %fd516;
	@%p256 bra 	$L__BB5_144;

	mov.u32 	%r357, 0;
	mov.b64 	%fd517, {%r357, %r69};

$L__BB5_144:
	setp.eq.f32 	%p679, %f2886, 0f3F800000;
	selp.f64 	%fd344, 0d3FF0000000000000, %fd517, %p679;
	div.rn.f64 	%fd70, %fd36, %fd344;
	not.pred 	%p258, %p10;
	mov.f64 	%fd519, %fd40;
	@%p258 bra 	$L__BB5_146;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r359}, %fd40;
	}
	xor.b32  	%r360, %r359, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r361, %temp}, %fd40;
	}
	mov.b64 	%fd519, {%r361, %r360};

$L__BB5_146:
	cvt.rn.f32.s32 	%f2740, %r785;
	sub.f32 	%f2739, %f2740, %f2890;
	add.f32 	%f2738, %f2739, 0f3F000000;
	setp.eq.f32 	%p259, %f2738, 0f00000000;
	@%p259 bra 	$L__BB5_150;
	bra.uni 	$L__BB5_147;

$L__BB5_150:
	mov.u32 	%r362, 0;
	selp.b32 	%r364, %r65, 0, %p117;
	or.b32  	%r365, %r364, 2146435072;
	selp.b32 	%r366, %r365, %r364, %p119;
	mov.b64 	%fd519, {%r362, %r366};
	bra.uni 	$L__BB5_151;

$L__BB5_147:
	setp.gt.s32 	%p260, %r65, -1;
	@%p260 bra 	$L__BB5_151;

	cvt.rzi.f64.f64 	%fd346, %fd309;
	setp.eq.f64 	%p261, %fd346, 0d4008000000000000;
	@%p261 bra 	$L__BB5_151;

	mov.f64 	%fd519, 0dFFF8000000000000;

$L__BB5_151:
	selp.f64 	%fd520, %fd519, %fd41, %p141;
	@%p18 bra 	$L__BB5_156;

	setp.eq.s32 	%p265, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r367, %temp}, %fd309;
	}
	setp.eq.s32 	%p266, %r367, 0;
	and.pred  	%p267, %p265, %p266;
	@%p267 bra 	$L__BB5_155;
	bra.uni 	$L__BB5_153;

$L__BB5_155:
	mov.u32 	%r374, 0;
	mov.b64 	%fd520, {%r374, %r71};
	bra.uni 	$L__BB5_156;

$L__BB5_153:
	cvt.rn.f32.s32 	%f2743, %r785;
	sub.f32 	%f2742, %f2743, %f2890;
	add.f32 	%f2741, %f2742, 0f3F000000;
	cvt.f64.f32 	%fd481, %f2741;
	and.b32  	%r368, %r65, 2147483647;
	setp.ne.s32 	%p268, %r368, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r369, %temp}, %fd481;
	}
	setp.ne.s32 	%p269, %r369, 0;
	or.pred  	%p270, %p268, %p269;
	mov.f64 	%fd520, %fd519;
	@%p270 bra 	$L__BB5_156;

	and.pred  	%p272, %p125, %p10;
	selp.b32 	%r372, %r61, %r60, %p272;
	mov.u32 	%r373, 0;
	mov.b64 	%fd520, {%r373, %r372};

$L__BB5_156:
	cvt.rn.f32.s32 	%f2746, %r785;
	sub.f32 	%f2745, %f2746, %f2890;
	add.f32 	%f2744, %f2745, 0f3F000000;
	setp.eq.f32 	%p273, %f2744, 0f3F800000;
	selp.f64 	%fd349, 0d3FF0000000000000, %fd520, %p273;
	cvt.f64.f32 	%fd350, %f181;
	mul.f64 	%fd79, %fd349, %fd350;
	not.pred 	%p274, %p11;
	mov.f64 	%fd522, %fd43;
	@%p274 bra 	$L__BB5_158;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r375}, %fd43;
	}
	xor.b32  	%r376, %r375, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r377, %temp}, %fd43;
	}
	mov.b64 	%fd522, {%r377, %r376};

$L__BB5_158:
	setp.eq.f32 	%p275, %f81, 0f00000000;
	@%p275 bra 	$L__BB5_162;
	bra.uni 	$L__BB5_159;

$L__BB5_162:
	mov.u32 	%r378, 0;
	selp.b32 	%r380, %r70, 0, %p117;
	or.b32  	%r381, %r380, 2146435072;
	selp.b32 	%r382, %r381, %r380, %p119;
	mov.b64 	%fd522, {%r378, %r382};
	bra.uni 	$L__BB5_163;

$L__BB5_159:
	setp.gt.s32 	%p276, %r70, -1;
	@%p276 bra 	$L__BB5_163;

	cvt.rzi.f64.f64 	%fd352, %fd309;
	setp.eq.f64 	%p277, %fd352, 0d4008000000000000;
	@%p277 bra 	$L__BB5_163;

	mov.f64 	%fd522, 0dFFF8000000000000;

$L__BB5_163:
	selp.f64 	%fd523, %fd522, %fd44, %p149;
	@%p19 bra 	$L__BB5_168;

	setp.eq.s32 	%p281, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r383, %temp}, %fd309;
	}
	setp.eq.s32 	%p282, %r383, 0;
	and.pred  	%p283, %p281, %p282;
	@%p283 bra 	$L__BB5_167;
	bra.uni 	$L__BB5_165;

$L__BB5_167:
	mov.u32 	%r390, 0;
	mov.b64 	%fd523, {%r390, %r73};
	bra.uni 	$L__BB5_168;

$L__BB5_165:
	cvt.rn.f32.s32 	%f2749, %r785;
	sub.f32 	%f2748, %f2749, %f2890;
	add.f32 	%f2747, %f2748, 0fBF000000;
	cvt.f64.f32 	%fd482, %f2747;
	and.b32  	%r384, %r70, 2147483647;
	setp.ne.s32 	%p284, %r384, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r385, %temp}, %fd482;
	}
	setp.ne.s32 	%p285, %r385, 0;
	or.pred  	%p286, %p284, %p285;
	mov.f64 	%fd523, %fd522;
	@%p286 bra 	$L__BB5_168;

	and.pred  	%p288, %p125, %p11;
	selp.b32 	%r388, %r61, %r60, %p288;
	mov.u32 	%r389, 0;
	mov.b64 	%fd523, {%r389, %r388};

$L__BB5_168:
	cvt.f64.f32 	%fd484, %f129;
	cvt.rn.f32.s32 	%f2785, %r786;
	mov.f32 	%f2758, 0f00000000;
	mov.f32 	%f2757, 0f3102E308;
	mov.f32 	%f2756, 0fBF317218;
	mov.f32 	%f2755, 0f35BFBE8E;
	mov.f32 	%f2754, 0f3F317200;
	mov.f32 	%f2753, 0f3DAAAABD;
	mov.f32 	%f2752, 0f3C4CAF63;
	mov.f32 	%f2751, 0f3B18F0FE;
	mov.f32 	%f2750, 0f3FB8AA3B;
	setp.eq.f32 	%p289, %f81, 0f3F800000;
	selp.f64 	%fd355, 0d3FF0000000000000, %fd523, %p289;
	cvt.f64.f32 	%fd356, %f187;
	mul.f64 	%fd357, %fd355, %fd356;
	sub.f64 	%fd358, %fd79, %fd357;
	mul.f64 	%fd359, %fd70, %fd358;
	mul.f64 	%fd360, %fd359, %fd484;
	mul.f32 	%f1249, %f62, %f188;
	cvt.f64.f32 	%fd361, %f1249;
	sub.f64 	%fd362, %fd361, %fd360;
	cvt.rn.f32.f64 	%f189, %fd362;
	add.f32 	%f1250, %f2785, 0f3F800000;
	sub.f32 	%f1251, %f1250, %f2889;
	div.rn.f32 	%f190, %f1251, %f2886;
	abs.f32 	%f191, %f190;
	setp.lt.f32 	%p290, %f191, 0f00800000;
	mul.f32 	%f1252, %f191, 0f4B800000;
	selp.f32 	%f1253, %f1252, %f191, %p290;
	selp.f32 	%f1254, 0fC3170000, 0fC2FE0000, %p290;
	mov.b32 	%r391, %f1253;
	and.b32  	%r392, %r391, 8388607;
	or.b32  	%r393, %r392, 1065353216;
	mov.b32 	%f1255, %r393;
	shr.u32 	%r394, %r391, 23;
	cvt.rn.f32.u32 	%f1256, %r394;
	add.f32 	%f1257, %f1254, %f1256;
	setp.gt.f32 	%p291, %f1255, 0f3FB504F3;
	mul.f32 	%f1258, %f1255, 0f3F000000;
	add.f32 	%f1259, %f1257, 0f3F800000;
	selp.f32 	%f1260, %f1259, %f1257, %p291;
	selp.f32 	%f1261, %f1258, %f1255, %p291;
	add.f32 	%f1262, %f1261, 0fBF800000;
	add.f32 	%f1263, %f1261, 0f3F800000;
	rcp.approx.ftz.f32 	%f1264, %f1263;
	add.f32 	%f1265, %f1262, %f1262;
	mul.f32 	%f1267, %f1265, %f1264;
	mul.f32 	%f1268, %f1267, %f1267;
	fma.rn.f32 	%f1271, %f2751, %f1268, %f2752;
	fma.rn.f32 	%f1273, %f1271, %f1268, %f2753;
	mul.rn.f32 	%f1274, %f1273, %f1268;
	mul.rn.f32 	%f1275, %f1274, %f1267;
	sub.f32 	%f1276, %f1262, %f1267;
	add.f32 	%f1277, %f1276, %f1276;
	neg.f32 	%f1278, %f1267;
	fma.rn.f32 	%f1279, %f1278, %f1262, %f1277;
	mul.rn.f32 	%f1280, %f1264, %f1279;
	add.f32 	%f1281, %f1275, %f1267;
	sub.f32 	%f1282, %f1267, %f1281;
	add.f32 	%f1283, %f1275, %f1282;
	add.f32 	%f1284, %f1280, %f1283;
	add.f32 	%f1285, %f1281, %f1284;
	sub.f32 	%f1286, %f1281, %f1285;
	add.f32 	%f1287, %f1284, %f1286;
	mul.rn.f32 	%f1289, %f1260, %f2754;
	mul.rn.f32 	%f1291, %f1260, %f2755;
	add.f32 	%f1292, %f1289, %f1285;
	sub.f32 	%f1293, %f1289, %f1292;
	add.f32 	%f1294, %f1285, %f1293;
	add.f32 	%f1295, %f1287, %f1294;
	add.f32 	%f1296, %f1291, %f1295;
	add.f32 	%f1297, %f1292, %f1296;
	sub.f32 	%f1298, %f1292, %f1297;
	add.f32 	%f1299, %f1296, %f1298;
	mul.rn.f32 	%f1300, %f588, %f1297;
	neg.f32 	%f1301, %f1300;
	fma.rn.f32 	%f1302, %f588, %f1297, %f1301;
	fma.rn.f32 	%f1303, %f588, %f1299, %f1302;
	fma.rn.f32 	%f1305, %f2758, %f1297, %f1303;
	add.rn.f32 	%f1306, %f1300, %f1305;
	neg.f32 	%f1307, %f1306;
	add.rn.f32 	%f1308, %f1300, %f1307;
	add.rn.f32 	%f1309, %f1308, %f1305;
	mov.b32 	%r395, %f1306;
	setp.eq.s32 	%p292, %r395, 1118925336;
	add.s32 	%r396, %r395, -1;
	mov.b32 	%f1310, %r396;
	add.f32 	%f1311, %f1309, 0f37000000;
	selp.f32 	%f192, %f1311, %f1309, %p292;
	selp.f32 	%f1312, %f1310, %f1306, %p292;
	mul.rn.f32 	%f1314, %f1312, %f2750;
	cvt.rzi.f32.f32 	%f1315, %f1314;
	abs.f32 	%f1316, %f1315;
	setp.gt.f32 	%p293, %f1316, 0f42FC0000;
	mov.b32 	%r397, %f1315;
	and.b32  	%r398, %r397, -2147483648;
	or.b32  	%r399, %r398, 1123811328;
	mov.b32 	%f1317, %r399;
	selp.f32 	%f1318, %f1317, %f1315, %p293;
	fma.rn.f32 	%f1320, %f1318, %f2756, %f1312;
	fma.rn.f32 	%f1322, %f1318, %f2757, %f1320;
	mul.f32 	%f1323, %f1322, 0f3FB8AA3B;
	add.f32 	%f1324, %f1318, 0f4B40007F;
	mov.b32 	%r400, %f1324;
	shl.b32 	%r401, %r400, 23;
	mov.b32 	%f1325, %r401;
	ex2.approx.ftz.f32 	%f1326, %f1323;
	mul.f32 	%f193, %f1326, %f1325;
	setp.eq.f32 	%p294, %f193, 0f7F800000;
	mov.f32 	%f2867, 0f7F800000;
	@%p294 bra 	$L__BB5_170;

	fma.rn.f32 	%f2867, %f193, %f192, %f193;

$L__BB5_170:
	setp.lt.f32 	%p295, %f190, 0f00000000;
	and.pred  	%p22, %p295, %p106;
	setp.eq.f32 	%p297, %f190, 0f00000000;
	@%p297 bra 	$L__BB5_174;
	bra.uni 	$L__BB5_171;

$L__BB5_174:
	add.f32 	%f1331, %f190, %f190;
	selp.f32 	%f2869, %f1331, 0f00000000, %p106;
	bra.uni 	$L__BB5_175;

$L__BB5_171:
	mov.b32 	%r402, %f2867;
	xor.b32  	%r403, %r402, -2147483648;
	mov.b32 	%f1327, %r403;
	selp.f32 	%f2869, %f1327, %f2867, %p22;
	setp.geu.f32 	%p298, %f190, 0f00000000;
	@%p298 bra 	$L__BB5_175;

	cvt.rzi.f32.f32 	%f1329, %f588;
	setp.eq.f32 	%p299, %f1329, 0f40000000;
	@%p299 bra 	$L__BB5_175;

	mov.f32 	%f2869, 0f7FFFFFFF;

$L__BB5_175:
	abs.f32 	%f2791, %f190;
	add.f32 	%f1332, %f2791, 0f40000000;
	mov.b32 	%r404, %f1332;
	setp.lt.s32 	%p301, %r404, 2139095040;
	@%p301 bra 	$L__BB5_180;

	abs.f32 	%f2792, %f190;
	setp.gtu.f32 	%p302, %f2792, 0f7F800000;
	@%p302 bra 	$L__BB5_179;
	bra.uni 	$L__BB5_177;

$L__BB5_179:
	add.f32 	%f2869, %f190, 0f40000000;
	bra.uni 	$L__BB5_180;

$L__BB5_177:
	abs.f32 	%f2793, %f190;
	setp.neu.f32 	%p303, %f2793, 0f7F800000;
	@%p303 bra 	$L__BB5_180;

	selp.f32 	%f2869, 0fFF800000, 0f7F800000, %p22;

$L__BB5_180:
	mov.f32 	%f2774, 0f00000000;
	mov.f32 	%f2773, 0f3102E308;
	mov.f32 	%f2772, 0fBF317218;
	mov.f32 	%f2771, 0f35BFBE8E;
	mov.f32 	%f2770, 0f3F317200;
	mov.f32 	%f2769, 0f3DAAAABD;
	mov.f32 	%f2768, 0f3C4CAF63;
	mov.f32 	%f2767, 0f3B18F0FE;
	mov.f32 	%f2766, 0f32A57060;
	mov.f32 	%f2765, 0f4B400001;
	mov.f32 	%f2764, 0f437C0000;
	mov.f32 	%f2763, 0f3BBB989D;
	mov.f32 	%f2762, 0f3FB8AA3B;
	mov.f32 	%f2761, 0f3F000000;
	cvt.rn.f32.s32 	%f2760, %r786;
	sub.f32 	%f2759, %f2760, %f2889;
	mul.f32 	%f1334, %f2869, 0fBF000000;
	setp.eq.f32 	%p304, %f190, 0f3F800000;
	selp.f32 	%f1335, 0fBF000000, %f1334, %p304;
	fma.rn.f32 	%f1338, %f1335, %f2763, %f2761;
	cvt.sat.f32.f32 	%f1341, %f1338;
	fma.rm.f32 	%f1343, %f1341, %f2764, %f2765;
	add.f32 	%f1344, %f1343, 0fCB40007F;
	neg.f32 	%f1345, %f1344;
	fma.rn.f32 	%f1346, %f1335, %f2762, %f1345;
	fma.rn.f32 	%f1348, %f1335, %f2766, %f1346;
	mov.b32 	%r405, %f1343;
	shl.b32 	%r406, %r405, 23;
	mov.b32 	%f1349, %r406;
	ex2.approx.ftz.f32 	%f1350, %f1348;
	mul.f32 	%f202, %f1350, %f1349;
	div.rn.f32 	%f203, %f2759, %f2886;
	abs.f32 	%f204, %f203;
	setp.lt.f32 	%p305, %f204, 0f00800000;
	mul.f32 	%f1351, %f204, 0f4B800000;
	selp.f32 	%f1352, %f1351, %f204, %p305;
	selp.f32 	%f1353, 0fC3170000, 0fC2FE0000, %p305;
	mov.b32 	%r407, %f1352;
	and.b32  	%r408, %r407, 8388607;
	or.b32  	%r409, %r408, 1065353216;
	mov.b32 	%f1354, %r409;
	shr.u32 	%r410, %r407, 23;
	cvt.rn.f32.u32 	%f1355, %r410;
	add.f32 	%f1356, %f1353, %f1355;
	setp.gt.f32 	%p306, %f1354, 0f3FB504F3;
	mul.f32 	%f1357, %f1354, 0f3F000000;
	add.f32 	%f1358, %f1356, 0f3F800000;
	selp.f32 	%f1359, %f1358, %f1356, %p306;
	selp.f32 	%f1360, %f1357, %f1354, %p306;
	add.f32 	%f1361, %f1360, 0fBF800000;
	add.f32 	%f1362, %f1360, 0f3F800000;
	rcp.approx.ftz.f32 	%f1363, %f1362;
	add.f32 	%f1364, %f1361, %f1361;
	mul.f32 	%f1366, %f1364, %f1363;
	mul.f32 	%f1367, %f1366, %f1366;
	fma.rn.f32 	%f1370, %f2767, %f1367, %f2768;
	fma.rn.f32 	%f1372, %f1370, %f1367, %f2769;
	mul.rn.f32 	%f1373, %f1372, %f1367;
	mul.rn.f32 	%f1374, %f1373, %f1366;
	sub.f32 	%f1375, %f1361, %f1366;
	add.f32 	%f1376, %f1375, %f1375;
	neg.f32 	%f1377, %f1366;
	fma.rn.f32 	%f1378, %f1377, %f1361, %f1376;
	mul.rn.f32 	%f1379, %f1363, %f1378;
	add.f32 	%f1380, %f1374, %f1366;
	sub.f32 	%f1381, %f1366, %f1380;
	add.f32 	%f1382, %f1374, %f1381;
	add.f32 	%f1383, %f1379, %f1382;
	add.f32 	%f1384, %f1380, %f1383;
	sub.f32 	%f1385, %f1380, %f1384;
	add.f32 	%f1386, %f1383, %f1385;
	mul.rn.f32 	%f1388, %f1359, %f2770;
	mul.rn.f32 	%f1390, %f1359, %f2771;
	add.f32 	%f1391, %f1388, %f1384;
	sub.f32 	%f1392, %f1388, %f1391;
	add.f32 	%f1393, %f1384, %f1392;
	add.f32 	%f1394, %f1386, %f1393;
	add.f32 	%f1395, %f1390, %f1394;
	add.f32 	%f1396, %f1391, %f1395;
	sub.f32 	%f1397, %f1391, %f1396;
	add.f32 	%f1398, %f1395, %f1397;
	mul.rn.f32 	%f1399, %f588, %f1396;
	neg.f32 	%f1400, %f1399;
	fma.rn.f32 	%f1401, %f588, %f1396, %f1400;
	fma.rn.f32 	%f1402, %f588, %f1398, %f1401;
	fma.rn.f32 	%f1404, %f2774, %f1396, %f1402;
	add.rn.f32 	%f1405, %f1399, %f1404;
	neg.f32 	%f1406, %f1405;
	add.rn.f32 	%f1407, %f1399, %f1406;
	add.rn.f32 	%f1408, %f1407, %f1404;
	mov.b32 	%r411, %f1405;
	setp.eq.s32 	%p307, %r411, 1118925336;
	add.s32 	%r412, %r411, -1;
	mov.b32 	%f1409, %r412;
	add.f32 	%f1410, %f1408, 0f37000000;
	selp.f32 	%f205, %f1410, %f1408, %p307;
	selp.f32 	%f1411, %f1409, %f1405, %p307;
	mul.rn.f32 	%f1412, %f1411, %f2762;
	cvt.rzi.f32.f32 	%f1413, %f1412;
	abs.f32 	%f1414, %f1413;
	setp.gt.f32 	%p308, %f1414, 0f42FC0000;
	mov.b32 	%r413, %f1413;
	and.b32  	%r414, %r413, -2147483648;
	or.b32  	%r415, %r414, 1123811328;
	mov.b32 	%f1415, %r415;
	selp.f32 	%f1416, %f1415, %f1413, %p308;
	fma.rn.f32 	%f1418, %f1416, %f2772, %f1411;
	fma.rn.f32 	%f1420, %f1416, %f2773, %f1418;
	mul.f32 	%f1421, %f1420, 0f3FB8AA3B;
	add.f32 	%f1422, %f1416, 0f4B40007F;
	mov.b32 	%r416, %f1422;
	shl.b32 	%r417, %r416, 23;
	mov.b32 	%f1423, %r417;
	ex2.approx.ftz.f32 	%f1424, %f1421;
	mul.f32 	%f206, %f1424, %f1423;
	setp.eq.f32 	%p309, %f206, 0f7F800000;
	mov.f32 	%f2870, 0f7F800000;
	@%p309 bra 	$L__BB5_182;

	fma.rn.f32 	%f2870, %f206, %f205, %f206;

$L__BB5_182:
	setp.lt.f32 	%p310, %f203, 0f00000000;
	and.pred  	%p23, %p310, %p106;
	setp.eq.f32 	%p312, %f203, 0f00000000;
	@%p312 bra 	$L__BB5_186;
	bra.uni 	$L__BB5_183;

$L__BB5_186:
	add.f32 	%f1429, %f203, %f203;
	selp.f32 	%f2872, %f1429, 0f00000000, %p106;
	bra.uni 	$L__BB5_187;

$L__BB5_183:
	mov.b32 	%r418, %f2870;
	xor.b32  	%r419, %r418, -2147483648;
	mov.b32 	%f1425, %r419;
	selp.f32 	%f2872, %f1425, %f2870, %p23;
	setp.geu.f32 	%p313, %f203, 0f00000000;
	@%p313 bra 	$L__BB5_187;

	cvt.rzi.f32.f32 	%f1427, %f588;
	setp.eq.f32 	%p314, %f1427, 0f40000000;
	@%p314 bra 	$L__BB5_187;

	mov.f32 	%f2872, 0f7FFFFFFF;

$L__BB5_187:
	abs.f32 	%f2655, %f203;
	add.f32 	%f1430, %f2655, 0f40000000;
	mov.b32 	%r420, %f1430;
	setp.lt.s32 	%p316, %r420, 2139095040;
	@%p316 bra 	$L__BB5_192;

	abs.f32 	%f2779, %f203;
	setp.gtu.f32 	%p317, %f2779, 0f7F800000;
	@%p317 bra 	$L__BB5_191;
	bra.uni 	$L__BB5_189;

$L__BB5_191:
	add.f32 	%f2872, %f203, 0f40000000;
	bra.uni 	$L__BB5_192;

$L__BB5_189:
	abs.f32 	%f2780, %f203;
	setp.neu.f32 	%p318, %f2780, 0f7F800000;
	@%p318 bra 	$L__BB5_192;

	selp.f32 	%f2872, 0fFF800000, 0f7F800000, %p23;

$L__BB5_192:
	mov.f32 	%f2663, 0f32A57060;
	mov.f32 	%f2662, 0f4B400001;
	mov.f32 	%f2661, 0f437C0000;
	mov.f32 	%f2660, 0f3BBB989D;
	mov.f32 	%f2659, 0f3FB8AA3B;
	mov.f32 	%f2658, 0f3F000000;
	cvt.rn.f32.s32 	%f2657, %r786;
	sub.f32 	%f2656, %f2657, %f2889;
	mul.f32 	%f1431, %f2872, 0fBF000000;
	setp.eq.f32 	%p319, %f203, 0f3F800000;
	selp.f32 	%f1432, 0fBF000000, %f1431, %p319;
	fma.rn.f32 	%f1435, %f1432, %f2660, %f2658;
	cvt.sat.f32.f32 	%f1438, %f1435;
	fma.rm.f32 	%f1440, %f1438, %f2661, %f2662;
	add.f32 	%f1441, %f1440, 0fCB40007F;
	neg.f32 	%f1442, %f1441;
	fma.rn.f32 	%f1443, %f1432, %f2659, %f1442;
	fma.rn.f32 	%f1445, %f1432, %f2663, %f1443;
	mov.b32 	%r421, %f1440;
	shl.b32 	%r422, %r421, 23;
	mov.b32 	%f1446, %r422;
	ex2.approx.ftz.f32 	%f1447, %f1445;
	mul.f32 	%f215, %f1447, %f1446;
	add.f32 	%f1448, %f2656, 0f3F800000;
	mul.f32 	%f1449, %f1448, %f202;
	mul.f32 	%f1450, %f2656, %f215;
	sub.f32 	%f216, %f1449, %f1450;
	cvt.f64.f32 	%fd363, %f119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd363;
	}
	abs.f64 	%fd88, %fd363;
	{ // callseq 102, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd88;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd525, [retval0+0];
	} // callseq 102
	setp.lt.s32 	%p320, %r79, 0;
	and.pred  	%p24, %p320, %p117;
	not.pred 	%p322, %p24;
	@%p322 bra 	$L__BB5_194;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r423}, %fd525;
	}
	xor.b32  	%r424, %r423, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r425, %temp}, %fd525;
	}
	mov.b64 	%fd525, {%r425, %r424};

$L__BB5_194:
	setp.eq.f32 	%p323, %f119, 0f00000000;
	@%p323 bra 	$L__BB5_198;
	bra.uni 	$L__BB5_195;

$L__BB5_198:
	mov.u32 	%r426, 0;
	selp.b32 	%r427, %r79, 0, %p117;
	or.b32  	%r428, %r427, 2146435072;
	selp.b32 	%r429, %r428, %r427, %p119;
	mov.b64 	%fd525, {%r426, %r429};
	bra.uni 	$L__BB5_199;

$L__BB5_195:
	setp.gt.s32 	%p324, %r79, -1;
	@%p324 bra 	$L__BB5_199;

	cvt.rzi.f64.f64 	%fd366, %fd309;
	setp.eq.f64 	%p325, %fd366, 0d4008000000000000;
	@%p325 bra 	$L__BB5_199;

	mov.f64 	%fd525, 0dFFF8000000000000;

$L__BB5_199:
	add.f64 	%fd94, %fd363, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r430}, %fd94;
	}
	and.b32  	%r431, %r430, 2146435072;
	setp.ne.s32 	%p328, %r431, 2146435072;
	mov.f64 	%fd526, %fd525;
	@%p328 bra 	$L__BB5_205;

	setp.gtu.f64 	%p329, %fd88, 0d7FF0000000000000;
	mov.f64 	%fd526, %fd94;
	@%p329 bra 	$L__BB5_205;

	setp.eq.s32 	%p330, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r432, %temp}, %fd309;
	}
	setp.eq.s32 	%p331, %r432, 0;
	and.pred  	%p332, %p330, %p331;
	@%p332 bra 	$L__BB5_204;
	bra.uni 	$L__BB5_202;

$L__BB5_204:
	mov.u32 	%r437, 0;
	setp.gt.f64 	%p339, %fd88, 0d3FF0000000000000;
	selp.b32 	%r438, 2146435072, 0, %p339;
	xor.b32  	%r439, %r438, 2146435072;
	selp.b32 	%r440, %r439, %r438, %p119;
	setp.eq.f32 	%p340, %f119, 0fBF800000;
	selp.b32 	%r441, 1072693248, %r440, %p340;
	mov.b64 	%fd526, {%r437, %r441};
	bra.uni 	$L__BB5_205;

$L__BB5_202:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r433, %temp}, %fd363;
	}
	and.b32  	%r434, %r79, 2147483647;
	setp.ne.s32 	%p333, %r434, 2146435072;
	setp.ne.s32 	%p334, %r433, 0;
	or.pred  	%p335, %p333, %p334;
	mov.f64 	%fd526, %fd525;
	@%p335 bra 	$L__BB5_205;

	and.pred  	%p337, %p125, %p24;
	selp.b32 	%r435, %r61, %r60, %p337;
	mov.u32 	%r436, 0;
	mov.b64 	%fd526, {%r436, %r435};

$L__BB5_205:
	mul.f32 	%f1451, %f61, %f216;
	mul.f32 	%f217, %f116, %f1451;
	setp.eq.f32 	%p341, %f119, 0f3F800000;
	selp.f64 	%fd371, 0d3FF0000000000000, %fd526, %p341;
	cvt.f64.f32 	%fd372, %f202;
	mul.f64 	%fd98, %fd371, %fd372;
	cvt.f64.f32 	%fd99, %f124;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd99;
	}
	abs.f64 	%fd100, %fd99;
	{ // callseq 103, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd100;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd309;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd528, [retval0+0];
	} // callseq 103
	setp.lt.s32 	%p342, %r80, 0;
	and.pred  	%p25, %p342, %p117;
	not.pred 	%p344, %p25;
	@%p344 bra 	$L__BB5_207;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r442}, %fd528;
	}
	xor.b32  	%r443, %r442, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r444, %temp}, %fd528;
	}
	mov.b64 	%fd528, {%r444, %r443};

$L__BB5_207:
	setp.eq.f32 	%p345, %f124, 0f00000000;
	@%p345 bra 	$L__BB5_211;
	bra.uni 	$L__BB5_208;

$L__BB5_211:
	mov.u32 	%r445, 0;
	selp.b32 	%r446, %r80, 0, %p117;
	or.b32  	%r447, %r446, 2146435072;
	selp.b32 	%r448, %r447, %r446, %p119;
	mov.b64 	%fd528, {%r445, %r448};
	bra.uni 	$L__BB5_212;

$L__BB5_208:
	setp.gt.s32 	%p346, %r80, -1;
	@%p346 bra 	$L__BB5_212;

	cvt.rzi.f64.f64 	%fd375, %fd309;
	setp.eq.f64 	%p347, %fd375, 0d4008000000000000;
	@%p347 bra 	$L__BB5_212;

	mov.f64 	%fd528, 0dFFF8000000000000;

$L__BB5_212:
	add.f64 	%fd106, %fd99, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r449}, %fd106;
	}
	and.b32  	%r450, %r449, 2146435072;
	setp.ne.s32 	%p350, %r450, 2146435072;
	mov.f64 	%fd529, %fd528;
	@%p350 bra 	$L__BB5_218;

	setp.gtu.f64 	%p351, %fd100, 0d7FF0000000000000;
	mov.f64 	%fd529, %fd106;
	@%p351 bra 	$L__BB5_218;

	setp.eq.s32 	%p352, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r451, %temp}, %fd309;
	}
	setp.eq.s32 	%p353, %r451, 0;
	and.pred  	%p354, %p352, %p353;
	@%p354 bra 	$L__BB5_217;
	bra.uni 	$L__BB5_215;

$L__BB5_217:
	mov.u32 	%r456, 0;
	setp.gt.f64 	%p361, %fd100, 0d3FF0000000000000;
	selp.b32 	%r457, 2146435072, 0, %p361;
	xor.b32  	%r458, %r457, 2146435072;
	selp.b32 	%r459, %r458, %r457, %p119;
	setp.eq.f32 	%p362, %f124, 0fBF800000;
	selp.b32 	%r460, 1072693248, %r459, %p362;
	mov.b64 	%fd529, {%r456, %r460};
	bra.uni 	$L__BB5_218;

$L__BB5_215:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r452, %temp}, %fd99;
	}
	and.b32  	%r453, %r80, 2147483647;
	setp.ne.s32 	%p355, %r453, 2146435072;
	setp.ne.s32 	%p356, %r452, 0;
	or.pred  	%p357, %p355, %p356;
	mov.f64 	%fd529, %fd528;
	@%p357 bra 	$L__BB5_218;

	and.pred  	%p359, %p125, %p25;
	selp.b32 	%r454, %r61, %r60, %p359;
	mov.u32 	%r455, 0;
	mov.b64 	%fd529, {%r455, %r454};

$L__BB5_218:
	cvt.f64.f32 	%fd476, %f116;
	mov.f32 	%f2873, 0f00000000;
	setp.eq.f32 	%p363, %f124, 0f3F800000;
	selp.f64 	%fd378, 0d3FF0000000000000, %fd529, %p363;
	cvt.f64.f32 	%fd379, %f215;
	mul.f64 	%fd380, %fd378, %fd379;
	sub.f64 	%fd381, %fd98, %fd380;
	mul.f64 	%fd382, %fd70, %fd381;
	mul.f64 	%fd384, %fd382, %fd476;
	mul.f32 	%f1453, %f62, %f217;
	cvt.f64.f32 	%fd385, %f1453;
	sub.f64 	%fd386, %fd385, %fd384;
	cvt.rn.f32.f64 	%f1454, %fd386;
	add.f32 	%f218, %f188, %f217;
	add.f32 	%f219, %f189, %f1454;
	mul.f32 	%f220, %f116, %f129;
	setp.leu.f32 	%p364, %f130, 0f3C23D70A;
	@%p364 bra 	$L__BB5_220;

	sub.f32 	%f1455, %f131, %f130;
	add.f32 	%f1456, %f130, %f2885;
	div.rn.f32 	%f2873, %f1455, %f1456;

$L__BB5_220:
	mov.f32 	%f2874, 0f00000000;
	@%p364 bra 	$L__BB5_235;

	and.b32  	%r461, %r74, 2146435072;
	setp.eq.s32 	%p366, %r461, 1062207488;
	add.f32 	%f223, %f130, %f2885;
	cvt.f64.f32 	%fd110, %f223;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r81}, %fd110;
	}
	abs.f64 	%fd111, %fd110;
	{ // callseq 104, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd531, [retval0+0];
	} // callseq 104
	setp.lt.s32 	%p367, %r81, 0;
	and.pred  	%p26, %p367, %p366;
	not.pred 	%p368, %p26;
	@%p368 bra 	$L__BB5_223;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r462}, %fd531;
	}
	xor.b32  	%r463, %r462, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r464, %temp}, %fd531;
	}
	mov.b64 	%fd531, {%r464, %r463};

$L__BB5_223:
	setp.eq.f32 	%p369, %f223, 0f00000000;
	@%p369 bra 	$L__BB5_227;
	bra.uni 	$L__BB5_224;

$L__BB5_227:
	setp.lt.s32 	%p372, %r74, 0;
	mov.u32 	%r465, 0;
	selp.b32 	%r467, %r81, 0, %p366;
	or.b32  	%r468, %r467, 2146435072;
	selp.b32 	%r469, %r468, %r467, %p372;
	mov.b64 	%fd531, {%r465, %r469};
	bra.uni 	$L__BB5_228;

$L__BB5_224:
	setp.gt.s32 	%p370, %r81, -1;
	@%p370 bra 	$L__BB5_228;

	cvt.rzi.f64.f64 	%fd389, %fd315;
	setp.eq.f64 	%p371, %fd389, 0d4000000000000000;
	@%p371 bra 	$L__BB5_228;

	mov.f64 	%fd531, 0dFFF8000000000000;

$L__BB5_228:
	add.f64 	%fd117, %fd110, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r470}, %fd117;
	}
	and.b32  	%r471, %r470, 2146435072;
	setp.ne.s32 	%p374, %r471, 2146435072;
	mov.f64 	%fd532, %fd531;
	@%p374 bra 	$L__BB5_234;

	setp.gtu.f64 	%p375, %fd111, 0d7FF0000000000000;
	mov.f64 	%fd532, %fd117;
	@%p375 bra 	$L__BB5_234;

	setp.eq.s32 	%p376, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r472, %temp}, %fd315;
	}
	setp.eq.s32 	%p377, %r472, 0;
	and.pred  	%p378, %p376, %p377;
	@%p378 bra 	$L__BB5_233;
	bra.uni 	$L__BB5_231;

$L__BB5_233:
	setp.lt.s32 	%p384, %r74, 0;
	mov.u32 	%r478, 0;
	setp.gt.f64 	%p385, %fd111, 0d3FF0000000000000;
	selp.b32 	%r479, 2146435072, 0, %p385;
	xor.b32  	%r480, %r479, 2146435072;
	selp.b32 	%r481, %r480, %r479, %p384;
	setp.eq.f32 	%p386, %f223, 0fBF800000;
	selp.b32 	%r482, 1072693248, %r481, %p386;
	mov.b64 	%fd532, {%r478, %r482};
	bra.uni 	$L__BB5_234;

$L__BB5_231:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r473, %temp}, %fd110;
	}
	and.b32  	%r474, %r81, 2147483647;
	setp.ne.s32 	%p379, %r474, 2146435072;
	setp.ne.s32 	%p380, %r473, 0;
	or.pred  	%p381, %p379, %p380;
	mov.f64 	%fd532, %fd531;
	@%p381 bra 	$L__BB5_234;

	setp.ne.s32 	%p382, %r75, 1071644672;
	and.pred  	%p383, %p382, %p26;
	or.b32  	%r475, %r76, -2147483648;
	selp.b32 	%r476, %r475, %r76, %p383;
	mov.u32 	%r477, 0;
	mov.b64 	%fd532, {%r477, %r476};

$L__BB5_234:
	setp.eq.f32 	%p387, %f223, 0f3F800000;
	selp.f64 	%fd392, 0d3FF0000000000000, %fd532, %p387;
	add.f32 	%f1458, %f131, %f2885;
	cvt.f64.f32 	%fd393, %f1458;
	div.rn.f64 	%fd394, %fd393, %fd392;
	cvt.rn.f32.f64 	%f2874, %fd394;

$L__BB5_235:
	and.b32  	%r483, %r74, 2146435072;
	setp.eq.s32 	%p388, %r483, 1062207488;
	mov.f32 	%f1459, 0f47C35000;
	min.f32 	%f1460, %f2874, %f1459;
	cvt.f64.f32 	%fd121, %f1460;
	min.f32 	%f226, %f2873, %f1459;
	fma.rn.f32 	%f2843, %f226, %f145, %f2843;
	mul.f32 	%f1461, %f226, %f146;
	cvt.f64.f32 	%fd122, %f1461;
	cvt.f64.f32 	%fd123, %f145;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd123;
	}
	abs.f64 	%fd124, %fd123;
	{ // callseq 105, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd124;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd533, [retval0+0];
	} // callseq 105
	@%p388 bra 	$L__BB5_281;
	bra.uni 	$L__BB5_236;

$L__BB5_281:
	setp.gt.s32 	%p449, %r82, -1;
	@%p449 bra 	$L__BB5_283;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r532}, %fd533;
	}
	xor.b32  	%r533, %r532, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r534, %temp}, %fd533;
	}
	mov.b64 	%fd533, {%r534, %r533};

$L__BB5_283:
	setp.eq.f32 	%p450, %f145, 0f00000000;
	@%p450 bra 	$L__BB5_287;
	bra.uni 	$L__BB5_284;

$L__BB5_287:
	setp.lt.s32 	%p453, %r74, 0;
	mov.u32 	%r535, 0;
	or.b32  	%r536, %r82, 2146435072;
	selp.b32 	%r537, %r536, %r82, %p453;
	mov.b64 	%fd533, {%r535, %r537};
	bra.uni 	$L__BB5_288;

$L__BB5_236:
	setp.eq.f32 	%p389, %f145, 0f00000000;
	@%p389 bra 	$L__BB5_240;
	bra.uni 	$L__BB5_237;

$L__BB5_240:
	mov.u32 	%r484, 0;
	mov.b64 	%fd533, {%r484, %r77};
	bra.uni 	$L__BB5_241;

$L__BB5_284:
	@%p449 bra 	$L__BB5_288;

	cvt.rzi.f64.f64 	%fd437, %fd315;
	setp.eq.f64 	%p452, %fd437, 0d4000000000000000;
	@%p452 bra 	$L__BB5_288;

	mov.f64 	%fd533, 0dFFF8000000000000;

$L__BB5_288:
	add.f64 	%fd168, %fd123, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r538}, %fd168;
	}
	and.b32  	%r539, %r538, 2146435072;
	setp.ne.s32 	%p454, %r539, 2146435072;
	mov.f64 	%fd543, %fd533;
	@%p454 bra 	$L__BB5_294;

	setp.gtu.f64 	%p455, %fd124, 0d7FF0000000000000;
	mov.f64 	%fd543, %fd168;
	@%p455 bra 	$L__BB5_294;

	setp.eq.s32 	%p456, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r540, %temp}, %fd315;
	}
	setp.eq.s32 	%p457, %r540, 0;
	and.pred  	%p458, %p456, %p457;
	@%p458 bra 	$L__BB5_293;
	bra.uni 	$L__BB5_291;

$L__BB5_293:
	setp.lt.s32 	%p465, %r74, 0;
	mov.u32 	%r546, 0;
	setp.gt.f64 	%p466, %fd124, 0d3FF0000000000000;
	selp.b32 	%r547, 2146435072, 0, %p466;
	xor.b32  	%r548, %r547, 2146435072;
	selp.b32 	%r549, %r548, %r547, %p465;
	setp.eq.f32 	%p467, %f145, 0fBF800000;
	selp.b32 	%r550, 1072693248, %r549, %p467;
	mov.b64 	%fd543, {%r546, %r550};
	bra.uni 	$L__BB5_294;

$L__BB5_237:
	setp.gt.s32 	%p390, %r82, -1;
	@%p390 bra 	$L__BB5_241;

	cvt.rzi.f64.f64 	%fd397, %fd315;
	setp.eq.f64 	%p391, %fd397, 0d4000000000000000;
	@%p391 bra 	$L__BB5_241;

	mov.f64 	%fd533, 0dFFF8000000000000;

$L__BB5_241:
	add.f64 	%fd128, %fd123, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r485}, %fd128;
	}
	and.b32  	%r486, %r485, 2146435072;
	setp.ne.s32 	%p392, %r486, 2146435072;
	mov.f64 	%fd534, %fd533;
	@%p392 bra 	$L__BB5_247;

	setp.gtu.f64 	%p393, %fd124, 0d7FF0000000000000;
	mov.f64 	%fd534, %fd128;
	@%p393 bra 	$L__BB5_247;

	setp.eq.s32 	%p394, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r487, %temp}, %fd315;
	}
	setp.eq.s32 	%p395, %r487, 0;
	and.pred  	%p396, %p394, %p395;
	@%p396 bra 	$L__BB5_246;
	bra.uni 	$L__BB5_244;

$L__BB5_246:
	setp.lt.s32 	%p400, %r74, 0;
	mov.u32 	%r491, 0;
	setp.gt.f64 	%p401, %fd124, 0d3FF0000000000000;
	selp.b32 	%r492, 2146435072, 0, %p401;
	xor.b32  	%r493, %r492, 2146435072;
	selp.b32 	%r494, %r493, %r492, %p400;
	setp.eq.f32 	%p402, %f145, 0fBF800000;
	selp.b32 	%r495, 1072693248, %r494, %p402;
	mov.b64 	%fd534, {%r491, %r495};
	bra.uni 	$L__BB5_247;

$L__BB5_291:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r541, %temp}, %fd123;
	}
	and.b32  	%r542, %r82, 2147483647;
	setp.ne.s32 	%p459, %r542, 2146435072;
	setp.ne.s32 	%p460, %r541, 0;
	or.pred  	%p461, %p459, %p460;
	mov.f64 	%fd543, %fd533;
	@%p461 bra 	$L__BB5_294;

	setp.lt.s32 	%p462, %r82, 0;
	mov.u32 	%r543, 0;
	setp.ne.s32 	%p463, %r75, 1071644672;
	and.pred  	%p464, %p463, %p462;
	or.b32  	%r544, %r76, -2147483648;
	selp.b32 	%r545, %r544, %r76, %p464;
	mov.b64 	%fd543, {%r543, %r545};

$L__BB5_294:
	setp.eq.f32 	%p468, %f145, 0f3F800000;
	selp.f64 	%fd440, 0d3FF0000000000000, %fd543, %p468;
	mul.f64 	%fd441, %fd440, %fd121;
	sub.f64 	%fd442, %fd122, %fd441;
	cvt.f64.f32 	%fd443, %f2848;
	add.f64 	%fd557, %fd442, %fd443;
	cvt.f64.f32 	%fd173, %f174;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd173;
	}
	abs.f64 	%fd174, %fd173;
	{ // callseq 109, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd174;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd545, [retval0+0];
	} // callseq 109
	setp.gt.s32 	%p469, %r86, -1;
	@%p469 bra 	$L__BB5_296;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r551}, %fd545;
	}
	xor.b32  	%r552, %r551, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r553, %temp}, %fd545;
	}
	mov.b64 	%fd545, {%r553, %r552};

$L__BB5_296:
	setp.eq.f32 	%p470, %f174, 0f00000000;
	@%p470 bra 	$L__BB5_300;
	bra.uni 	$L__BB5_297;

$L__BB5_300:
	setp.lt.s32 	%p473, %r74, 0;
	mov.u32 	%r554, 0;
	or.b32  	%r555, %r86, 2146435072;
	selp.b32 	%r556, %r555, %r86, %p473;
	mov.b64 	%fd545, {%r554, %r556};
	bra.uni 	$L__BB5_301;

$L__BB5_297:
	@%p469 bra 	$L__BB5_301;

	cvt.rzi.f64.f64 	%fd446, %fd315;
	setp.eq.f64 	%p472, %fd446, 0d4000000000000000;
	@%p472 bra 	$L__BB5_301;

	mov.f64 	%fd545, 0dFFF8000000000000;

$L__BB5_301:
	add.f64 	%fd180, %fd173, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r557}, %fd180;
	}
	and.b32  	%r558, %r557, 2146435072;
	setp.ne.s32 	%p474, %r558, 2146435072;
	mov.f64 	%fd546, %fd545;
	@%p474 bra 	$L__BB5_307;

	setp.gtu.f64 	%p475, %fd174, 0d7FF0000000000000;
	mov.f64 	%fd546, %fd180;
	@%p475 bra 	$L__BB5_307;

	setp.eq.s32 	%p476, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r559, %temp}, %fd315;
	}
	setp.eq.s32 	%p477, %r559, 0;
	and.pred  	%p478, %p476, %p477;
	@%p478 bra 	$L__BB5_306;
	bra.uni 	$L__BB5_304;

$L__BB5_306:
	setp.lt.s32 	%p485, %r74, 0;
	mov.u32 	%r565, 0;
	setp.gt.f64 	%p486, %fd174, 0d3FF0000000000000;
	selp.b32 	%r566, 2146435072, 0, %p486;
	xor.b32  	%r567, %r566, 2146435072;
	selp.b32 	%r568, %r567, %r566, %p485;
	setp.eq.f32 	%p487, %f174, 0fBF800000;
	selp.b32 	%r569, 1072693248, %r568, %p487;
	mov.b64 	%fd546, {%r565, %r569};
	bra.uni 	$L__BB5_307;

$L__BB5_244:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r488, %temp}, %fd123;
	}
	and.b32  	%r489, %r82, 2147483647;
	setp.ne.s32 	%p397, %r489, 2146435072;
	setp.ne.s32 	%p398, %r488, 0;
	or.pred  	%p399, %p397, %p398;
	mov.f64 	%fd534, %fd533;
	@%p399 bra 	$L__BB5_247;

	mov.u32 	%r490, 0;
	mov.b64 	%fd534, {%r490, %r76};

$L__BB5_247:
	setp.eq.f32 	%p403, %f145, 0f3F800000;
	selp.f64 	%fd400, 0d3FF0000000000000, %fd534, %p403;
	mul.f64 	%fd401, %fd400, %fd121;
	sub.f64 	%fd402, %fd122, %fd401;
	cvt.f64.f32 	%fd403, %f2848;
	add.f64 	%fd557, %fd402, %fd403;
	cvt.f64.f32 	%fd133, %f174;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd133;
	}
	abs.f64 	%fd134, %fd133;
	setp.eq.f32 	%p404, %f174, 0f00000000;
	@%p404 bra 	$L__BB5_251;
	bra.uni 	$L__BB5_248;

$L__BB5_251:
	mov.u32 	%r496, 0;
	mov.b64 	%fd535, {%r496, %r77};
	bra.uni 	$L__BB5_252;

$L__BB5_248:
	{ // callseq 106, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd134;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd535, [retval0+0];
	} // callseq 106
	setp.gt.s32 	%p405, %r83, -1;
	@%p405 bra 	$L__BB5_252;

	cvt.rzi.f64.f64 	%fd406, %fd315;
	setp.eq.f64 	%p406, %fd406, 0d4000000000000000;
	@%p406 bra 	$L__BB5_252;

	mov.f64 	%fd535, 0dFFF8000000000000;

$L__BB5_252:
	add.f64 	%fd138, %fd133, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r497}, %fd138;
	}
	and.b32  	%r498, %r497, 2146435072;
	setp.ne.s32 	%p407, %r498, 2146435072;
	mov.f64 	%fd536, %fd535;
	@%p407 bra 	$L__BB5_258;

	setp.gtu.f64 	%p408, %fd134, 0d7FF0000000000000;
	mov.f64 	%fd536, %fd138;
	@%p408 bra 	$L__BB5_258;

	setp.eq.s32 	%p409, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r499, %temp}, %fd315;
	}
	setp.eq.s32 	%p410, %r499, 0;
	and.pred  	%p411, %p409, %p410;
	@%p411 bra 	$L__BB5_257;
	bra.uni 	$L__BB5_255;

$L__BB5_257:
	setp.lt.s32 	%p415, %r74, 0;
	mov.u32 	%r503, 0;
	setp.gt.f64 	%p416, %fd134, 0d3FF0000000000000;
	selp.b32 	%r504, 2146435072, 0, %p416;
	xor.b32  	%r505, %r504, 2146435072;
	selp.b32 	%r506, %r505, %r504, %p415;
	setp.eq.f32 	%p417, %f174, 0fBF800000;
	selp.b32 	%r507, 1072693248, %r506, %p417;
	mov.b64 	%fd536, {%r503, %r507};
	bra.uni 	$L__BB5_258;

$L__BB5_304:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r560, %temp}, %fd173;
	}
	and.b32  	%r561, %r86, 2147483647;
	setp.ne.s32 	%p479, %r561, 2146435072;
	setp.ne.s32 	%p480, %r560, 0;
	or.pred  	%p481, %p479, %p480;
	mov.f64 	%fd546, %fd545;
	@%p481 bra 	$L__BB5_307;

	setp.lt.s32 	%p482, %r86, 0;
	mov.u32 	%r562, 0;
	setp.ne.s32 	%p483, %r75, 1071644672;
	and.pred  	%p484, %p483, %p482;
	or.b32  	%r563, %r76, -2147483648;
	selp.b32 	%r564, %r563, %r76, %p484;
	mov.b64 	%fd546, {%r562, %r564};

$L__BB5_307:
	setp.eq.f32 	%p488, %f174, 0f3F800000;
	selp.f64 	%fd449, 0d3FF0000000000000, %fd546, %p488;
	mul.f64 	%fd450, %fd449, %fd121;
	mul.f32 	%f1465, %f226, %f175;
	cvt.f64.f32 	%fd451, %f1465;
	sub.f64 	%fd452, %fd451, %fd450;
	cvt.f64.f32 	%fd453, %f2847;
	add.f64 	%fd556, %fd452, %fd453;
	cvt.f64.f32 	%fd185, %f220;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd185;
	}
	abs.f64 	%fd186, %fd185;
	{ // callseq 110, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd186;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd548, [retval0+0];
	} // callseq 110
	setp.gt.s32 	%p489, %r87, -1;
	@%p489 bra 	$L__BB5_309;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r570}, %fd548;
	}
	xor.b32  	%r571, %r570, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r572, %temp}, %fd548;
	}
	mov.b64 	%fd548, {%r572, %r571};

$L__BB5_309:
	setp.eq.f32 	%p490, %f220, 0f00000000;
	@%p490 bra 	$L__BB5_313;
	bra.uni 	$L__BB5_310;

$L__BB5_313:
	setp.lt.s32 	%p493, %r74, 0;
	mov.u32 	%r573, 0;
	or.b32  	%r574, %r87, 2146435072;
	selp.b32 	%r575, %r574, %r87, %p493;
	mov.b64 	%fd548, {%r573, %r575};
	bra.uni 	$L__BB5_314;

$L__BB5_310:
	@%p489 bra 	$L__BB5_314;

	cvt.rzi.f64.f64 	%fd456, %fd315;
	setp.eq.f64 	%p492, %fd456, 0d4000000000000000;
	@%p492 bra 	$L__BB5_314;

	mov.f64 	%fd548, 0dFFF8000000000000;

$L__BB5_314:
	add.f64 	%fd192, %fd185, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r576}, %fd192;
	}
	and.b32  	%r577, %r576, 2146435072;
	setp.ne.s32 	%p494, %r577, 2146435072;
	mov.f64 	%fd549, %fd548;
	@%p494 bra 	$L__BB5_320;

	setp.gtu.f64 	%p495, %fd186, 0d7FF0000000000000;
	mov.f64 	%fd549, %fd192;
	@%p495 bra 	$L__BB5_320;

	setp.eq.s32 	%p496, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r578, %temp}, %fd315;
	}
	setp.eq.s32 	%p497, %r578, 0;
	and.pred  	%p498, %p496, %p497;
	@%p498 bra 	$L__BB5_319;
	bra.uni 	$L__BB5_317;

$L__BB5_319:
	setp.lt.s32 	%p505, %r74, 0;
	mov.u32 	%r584, 0;
	setp.gt.f64 	%p506, %fd186, 0d3FF0000000000000;
	selp.b32 	%r585, 2146435072, 0, %p506;
	xor.b32  	%r586, %r585, 2146435072;
	selp.b32 	%r587, %r586, %r585, %p505;
	setp.eq.f32 	%p507, %f220, 0fBF800000;
	selp.b32 	%r588, 1072693248, %r587, %p507;
	mov.b64 	%fd549, {%r584, %r588};
	bra.uni 	$L__BB5_320;

$L__BB5_255:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r500, %temp}, %fd133;
	}
	and.b32  	%r501, %r83, 2147483647;
	setp.ne.s32 	%p412, %r501, 2146435072;
	setp.ne.s32 	%p413, %r500, 0;
	or.pred  	%p414, %p412, %p413;
	mov.f64 	%fd536, %fd535;
	@%p414 bra 	$L__BB5_258;

	mov.u32 	%r502, 0;
	mov.b64 	%fd536, {%r502, %r76};

$L__BB5_258:
	setp.eq.f32 	%p418, %f174, 0f3F800000;
	selp.f64 	%fd409, 0d3FF0000000000000, %fd536, %p418;
	mul.f64 	%fd410, %fd409, %fd121;
	mul.f32 	%f1462, %f226, %f175;
	cvt.f64.f32 	%fd411, %f1462;
	sub.f64 	%fd412, %fd411, %fd410;
	cvt.f64.f32 	%fd413, %f2847;
	add.f64 	%fd556, %fd412, %fd413;
	cvt.f64.f32 	%fd143, %f220;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd143;
	}
	abs.f64 	%fd144, %fd143;
	setp.eq.f32 	%p419, %f220, 0f00000000;
	@%p419 bra 	$L__BB5_262;
	bra.uni 	$L__BB5_259;

$L__BB5_262:
	mov.u32 	%r508, 0;
	mov.b64 	%fd537, {%r508, %r77};
	bra.uni 	$L__BB5_263;

$L__BB5_259:
	{ // callseq 107, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd144;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd537, [retval0+0];
	} // callseq 107
	setp.gt.s32 	%p420, %r84, -1;
	@%p420 bra 	$L__BB5_263;

	cvt.rzi.f64.f64 	%fd416, %fd315;
	setp.eq.f64 	%p421, %fd416, 0d4000000000000000;
	@%p421 bra 	$L__BB5_263;

	mov.f64 	%fd537, 0dFFF8000000000000;

$L__BB5_263:
	add.f64 	%fd148, %fd143, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r509}, %fd148;
	}
	and.b32  	%r510, %r509, 2146435072;
	setp.ne.s32 	%p422, %r510, 2146435072;
	mov.f64 	%fd538, %fd537;
	@%p422 bra 	$L__BB5_269;

	setp.gtu.f64 	%p423, %fd144, 0d7FF0000000000000;
	mov.f64 	%fd538, %fd148;
	@%p423 bra 	$L__BB5_269;

	setp.eq.s32 	%p424, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r511, %temp}, %fd315;
	}
	setp.eq.s32 	%p425, %r511, 0;
	and.pred  	%p426, %p424, %p425;
	@%p426 bra 	$L__BB5_268;
	bra.uni 	$L__BB5_266;

$L__BB5_268:
	setp.lt.s32 	%p430, %r74, 0;
	mov.u32 	%r515, 0;
	setp.gt.f64 	%p431, %fd144, 0d3FF0000000000000;
	selp.b32 	%r516, 2146435072, 0, %p431;
	xor.b32  	%r517, %r516, 2146435072;
	selp.b32 	%r518, %r517, %r516, %p430;
	setp.eq.f32 	%p432, %f220, 0fBF800000;
	selp.b32 	%r519, 1072693248, %r518, %p432;
	mov.b64 	%fd538, {%r515, %r519};
	bra.uni 	$L__BB5_269;

$L__BB5_317:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r579, %temp}, %fd185;
	}
	and.b32  	%r580, %r87, 2147483647;
	setp.ne.s32 	%p499, %r580, 2146435072;
	setp.ne.s32 	%p500, %r579, 0;
	or.pred  	%p501, %p499, %p500;
	mov.f64 	%fd549, %fd548;
	@%p501 bra 	$L__BB5_320;

	setp.lt.s32 	%p502, %r87, 0;
	mov.u32 	%r581, 0;
	setp.ne.s32 	%p503, %r75, 1071644672;
	and.pred  	%p504, %p503, %p502;
	or.b32  	%r582, %r76, -2147483648;
	selp.b32 	%r583, %r582, %r76, %p504;
	mov.b64 	%fd549, {%r581, %r583};

$L__BB5_320:
	mul.f32 	%f1466, %f226, 0f00000000;
	cvt.f64.f32 	%fd459, %f1466;
	setp.eq.f32 	%p508, %f220, 0f3F800000;
	selp.f64 	%fd460, 0d3FF0000000000000, %fd549, %p508;
	mul.f64 	%fd461, %fd460, %fd121;
	sub.f64 	%fd462, %fd459, %fd461;
	cvt.f64.f32 	%fd463, %f2846;
	add.f64 	%fd555, %fd462, %fd463;
	cvt.f64.f32 	%fd464, %f2845;
	sub.f64 	%fd465, %fd459, %fd121;
	add.f64 	%fd554, %fd465, %fd464;
	cvt.f64.f32 	%fd198, %f218;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd198;
	}
	abs.f64 	%fd199, %fd198;
	{ // callseq 111, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd199;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd551, [retval0+0];
	} // callseq 111
	setp.gt.s32 	%p509, %r88, -1;
	@%p509 bra 	$L__BB5_322;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r589}, %fd551;
	}
	xor.b32  	%r590, %r589, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r591, %temp}, %fd551;
	}
	mov.b64 	%fd551, {%r591, %r590};

$L__BB5_322:
	setp.eq.f32 	%p510, %f218, 0f00000000;
	@%p510 bra 	$L__BB5_326;
	bra.uni 	$L__BB5_323;

$L__BB5_326:
	setp.lt.s32 	%p513, %r74, 0;
	mov.u32 	%r592, 0;
	or.b32  	%r593, %r88, 2146435072;
	selp.b32 	%r594, %r593, %r88, %p513;
	mov.b64 	%fd551, {%r592, %r594};
	bra.uni 	$L__BB5_327;

$L__BB5_323:
	@%p509 bra 	$L__BB5_327;

	cvt.rzi.f64.f64 	%fd468, %fd315;
	setp.eq.f64 	%p512, %fd468, 0d4000000000000000;
	@%p512 bra 	$L__BB5_327;

	mov.f64 	%fd551, 0dFFF8000000000000;

$L__BB5_327:
	add.f64 	%fd205, %fd198, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r595}, %fd205;
	}
	and.b32  	%r596, %r595, 2146435072;
	setp.ne.s32 	%p514, %r596, 2146435072;
	mov.f64 	%fd552, %fd551;
	@%p514 bra 	$L__BB5_333;

	setp.gtu.f64 	%p515, %fd199, 0d7FF0000000000000;
	mov.f64 	%fd552, %fd205;
	@%p515 bra 	$L__BB5_333;

	setp.eq.s32 	%p516, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r597, %temp}, %fd315;
	}
	setp.eq.s32 	%p517, %r597, 0;
	and.pred  	%p518, %p516, %p517;
	@%p518 bra 	$L__BB5_332;
	bra.uni 	$L__BB5_330;

$L__BB5_332:
	setp.lt.s32 	%p525, %r74, 0;
	mov.u32 	%r603, 0;
	setp.gt.f64 	%p526, %fd199, 0d3FF0000000000000;
	selp.b32 	%r604, 2146435072, 0, %p526;
	xor.b32  	%r605, %r604, 2146435072;
	selp.b32 	%r606, %r605, %r604, %p525;
	setp.eq.f32 	%p527, %f218, 0fBF800000;
	selp.b32 	%r607, 1072693248, %r606, %p527;
	mov.b64 	%fd552, {%r603, %r607};
	bra.uni 	$L__BB5_333;

$L__BB5_266:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r512, %temp}, %fd143;
	}
	and.b32  	%r513, %r84, 2147483647;
	setp.ne.s32 	%p427, %r513, 2146435072;
	setp.ne.s32 	%p428, %r512, 0;
	or.pred  	%p429, %p427, %p428;
	mov.f64 	%fd538, %fd537;
	@%p429 bra 	$L__BB5_269;

	mov.u32 	%r514, 0;
	mov.b64 	%fd538, {%r514, %r76};

$L__BB5_269:
	mul.f32 	%f1463, %f226, 0f00000000;
	cvt.f64.f32 	%fd419, %f1463;
	setp.eq.f32 	%p433, %f220, 0f3F800000;
	selp.f64 	%fd420, 0d3FF0000000000000, %fd538, %p433;
	mul.f64 	%fd421, %fd420, %fd121;
	sub.f64 	%fd422, %fd419, %fd421;
	cvt.f64.f32 	%fd423, %f2846;
	add.f64 	%fd555, %fd422, %fd423;
	cvt.f64.f32 	%fd424, %f2845;
	sub.f64 	%fd425, %fd419, %fd121;
	add.f64 	%fd554, %fd425, %fd424;
	cvt.f64.f32 	%fd154, %f218;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd154;
	}
	abs.f64 	%fd155, %fd154;
	setp.eq.f32 	%p434, %f218, 0f00000000;
	@%p434 bra 	$L__BB5_273;
	bra.uni 	$L__BB5_270;

$L__BB5_273:
	mov.u32 	%r520, 0;
	mov.b64 	%fd539, {%r520, %r77};
	bra.uni 	$L__BB5_274;

$L__BB5_270:
	{ // callseq 108, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd155;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd315;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd539, [retval0+0];
	} // callseq 108
	setp.gt.s32 	%p435, %r85, -1;
	@%p435 bra 	$L__BB5_274;

	cvt.rzi.f64.f64 	%fd428, %fd315;
	setp.eq.f64 	%p436, %fd428, 0d4000000000000000;
	@%p436 bra 	$L__BB5_274;

	mov.f64 	%fd539, 0dFFF8000000000000;

$L__BB5_274:
	add.f64 	%fd159, %fd154, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r521}, %fd159;
	}
	and.b32  	%r522, %r521, 2146435072;
	setp.ne.s32 	%p437, %r522, 2146435072;
	mov.f64 	%fd540, %fd539;
	@%p437 bra 	$L__BB5_280;

	setp.gtu.f64 	%p438, %fd155, 0d7FF0000000000000;
	mov.f64 	%fd540, %fd159;
	@%p438 bra 	$L__BB5_280;

	setp.eq.s32 	%p439, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r523, %temp}, %fd315;
	}
	setp.eq.s32 	%p440, %r523, 0;
	and.pred  	%p441, %p439, %p440;
	@%p441 bra 	$L__BB5_279;
	bra.uni 	$L__BB5_277;

$L__BB5_279:
	setp.lt.s32 	%p445, %r74, 0;
	mov.u32 	%r527, 0;
	setp.gt.f64 	%p446, %fd155, 0d3FF0000000000000;
	selp.b32 	%r528, 2146435072, 0, %p446;
	xor.b32  	%r529, %r528, 2146435072;
	selp.b32 	%r530, %r529, %r528, %p445;
	setp.eq.f32 	%p447, %f218, 0fBF800000;
	selp.b32 	%r531, 1072693248, %r530, %p447;
	mov.b64 	%fd540, {%r527, %r531};
	bra.uni 	$L__BB5_280;

$L__BB5_330:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r598, %temp}, %fd198;
	}
	and.b32  	%r599, %r88, 2147483647;
	setp.ne.s32 	%p519, %r599, 2146435072;
	setp.ne.s32 	%p520, %r598, 0;
	or.pred  	%p521, %p519, %p520;
	mov.f64 	%fd552, %fd551;
	@%p521 bra 	$L__BB5_333;

	setp.lt.s32 	%p522, %r88, 0;
	mov.u32 	%r600, 0;
	setp.ne.s32 	%p523, %r75, 1071644672;
	and.pred  	%p524, %p523, %p522;
	or.b32  	%r601, %r76, -2147483648;
	selp.b32 	%r602, %r601, %r76, %p524;
	mov.b64 	%fd552, {%r600, %r602};

$L__BB5_333:
	setp.eq.f32 	%p528, %f218, 0f3F800000;
	selp.f64 	%fd471, 0d3FF0000000000000, %fd552, %p528;
	mul.f64 	%fd472, %fd471, %fd121;
	mul.f32 	%f1467, %f226, %f219;
	cvt.f64.f32 	%fd473, %f1467;
	sub.f64 	%fd474, %fd473, %fd472;
	cvt.f64.f32 	%fd475, %f2844;
	add.f64 	%fd553, %fd474, %fd475;
	bra.uni 	$L__BB5_334;

$L__BB5_277:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r524, %temp}, %fd154;
	}
	and.b32  	%r525, %r85, 2147483647;
	setp.ne.s32 	%p442, %r525, 2146435072;
	setp.ne.s32 	%p443, %r524, 0;
	or.pred  	%p444, %p442, %p443;
	mov.f64 	%fd540, %fd539;
	@%p444 bra 	$L__BB5_280;

	mov.u32 	%r526, 0;
	mov.b64 	%fd540, {%r526, %r76};

$L__BB5_280:
	setp.eq.f32 	%p448, %f218, 0f3F800000;
	selp.f64 	%fd431, 0d3FF0000000000000, %fd540, %p448;
	mul.f64 	%fd432, %fd431, %fd121;
	mul.f32 	%f1464, %f226, %f219;
	cvt.f64.f32 	%fd433, %f1464;
	sub.f64 	%fd434, %fd433, %fd432;
	cvt.f64.f32 	%fd435, %f2844;
	add.f64 	%fd553, %fd434, %fd435;

$L__BB5_334:
	cvt.rn.f32.f64 	%f2848, %fd557;
	cvt.rn.f32.f64 	%f2847, %fd556;
	cvt.rn.f32.f64 	%f2846, %fd555;
	cvt.rn.f32.f64 	%f2845, %fd554;
	cvt.rn.f32.f64 	%f2844, %fd553;
	fma.rn.f32 	%f2842, %f226, %f174, %f2842;
	fma.rn.f32 	%f2841, %f226, %f220, %f2841;
	add.f32 	%f2840, %f2840, %f226;
	fma.rn.f32 	%f2839, %f226, %f218, %f2839;
	add.s32 	%r786, %r786, 1;
	setp.lt.s32 	%p529, %r786, %r102;
	@%p529 bra 	$L__BB5_56;

	add.s32 	%r785, %r785, 1;
	setp.lt.s32 	%p530, %r785, %r102;
	@%p530 bra 	$L__BB5_55;

$L__BB5_336:
	ld.param.u32 	%r766, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_6];
	div.rn.f32 	%f1468, %f2843, %f2848;
	mov.f32 	%f1469, 0fBF800000;
	max.f32 	%f1470, %f1468, %f1469;
	mov.f32 	%f1471, 0f3F800000;
	min.f32 	%f1472, %f1470, %f1471;
	sub.f32 	%f2890, %f2890, %f1472;
	div.rn.f32 	%f1473, %f2842, %f2847;
	max.f32 	%f1474, %f1473, %f1469;
	min.f32 	%f1475, %f1474, %f1471;
	sub.f32 	%f2889, %f2889, %f1475;
	neg.f32 	%f1476, %f2888;
	div.rn.f32 	%f1477, %f2841, %f2846;
	max.f32 	%f1478, %f1477, %f1476;
	min.f32 	%f1479, %f1478, %f2888;
	sub.f32 	%f1480, %f2888, %f1479;
	neg.f32 	%f1481, %f2887;
	div.rn.f32 	%f1482, %f2840, %f2845;
	max.f32 	%f1483, %f1482, %f1481;
	min.f32 	%f1484, %f1483, %f2887;
	sub.f32 	%f1485, %f2887, %f1484;
	neg.f32 	%f1486, %f2886;
	div.rn.f32 	%f1487, %f2839, %f2844;
	max.f32 	%f1488, %f1487, %f1486;
	min.f32 	%f1489, %f1488, %f2886;
	sub.f32 	%f1490, %f2886, %f1489;
	max.f32 	%f2888, %f1480, %f1471;
	mov.f32 	%f1491, 0f3C23D70A;
	max.f32 	%f2887, %f1485, %f1491;
	mov.f32 	%f1492, 0f3F000000;
	max.f32 	%f1493, %f1490, %f1492;
	min.f32 	%f2886, %f1493, %f51;
	add.s32 	%r784, %r784, 1;
	setp.lt.s32 	%p531, %r784, %r766;
	@%p531 bra 	$L__BB5_53;

$L__BB5_337:
	mov.f32 	%f1509, 0f00000000;
	mov.f32 	%f2908, %f1509;
	mov.f32 	%f2909, %f1509;
	mov.f32 	%f2910, %f1509;
	mov.f32 	%f2913, %f1509;
	mov.f32 	%f2917, %f1509;
	mov.f32 	%f2911, %f1509;
	mov.f32 	%f2912, %f1509;
	mov.f32 	%f2914, %f1509;
	mov.f32 	%f2918, %f1509;
	mov.f32 	%f2915, %f1509;
	mov.f32 	%f2916, %f1509;
	mov.f32 	%f2919, %f1509;
	mov.f32 	%f2920, %f1509;
	mov.f32 	%f2921, %f1509;
	mov.f32 	%f2922, %f1509;
	mov.f32 	%f2950, %f1509;
	@%p40 bra 	$L__BB5_426;

	mov.f32 	%f1526, 0f3F000000;
	div.rn.f32 	%f1527, %f1526, %f2886;
	div.rn.f32 	%f1528, %f1527, %f2886;
	div.rn.f32 	%f1529, %f2888, 0fC0206C98;
	div.rn.f32 	%f259, %f1529, %f2886;
	div.rn.f32 	%f260, %f259, %f2886;
	sqrt.rn.f32 	%f261, %f1528;
	mov.f32 	%f1530, 0f3F800000;
	cvt.rzi.f32.f32 	%f1531, %f1530;
	add.f32 	%f1532, %f1531, %f1531;
	mov.f32 	%f1533, 0f40000000;
	sub.f32 	%f1534, %f1533, %f1532;
	abs.f32 	%f262, %f1534;
	mov.u32 	%r608, 0;
	setp.eq.f32 	%p540, %f262, 0f3F800000;
	mov.u32 	%r787, %r608;

$L__BB5_339:
	cvt.rn.f32.s32 	%f1535, %r787;
	sub.f32 	%f279, %f1535, %f2890;
	add.f32 	%f1536, %f279, 0f3F000000;
	mul.f32 	%f1537, %f1536, %f261;
	abs.f32 	%f280, %f1537;
	setp.ge.f32 	%p533, %f280, 0f3F8060FE;
	mul.f32 	%f1538, %f1537, %f1537;
	selp.f32 	%f1539, %f280, %f1538, %p533;
	selp.f32 	%f1540, 0f3789CA3C, 0f38B1E96A, %p533;
	selp.f32 	%f1541, 0fB9F560B9, 0fBA574D20, %p533;
	fma.rn.f32 	%f1542, %f1540, %f1539, %f1541;
	selp.f32 	%f1543, 0f3BAC840B, 0f3BAAD5EA, %p533;
	fma.rn.f32 	%f1544, %f1542, %f1539, %f1543;
	selp.f32 	%f1545, 0fBD0C8162, 0fBCDC1BE7, %p533;
	fma.rn.f32 	%f1546, %f1544, %f1539, %f1545;
	selp.f32 	%f1547, 0f3E1CF906, 0f3DE718AF, %p533;
	fma.rn.f32 	%f1548, %f1546, %f1539, %f1547;
	selp.f32 	%f1549, 0f3F6A937E, 0fBEC093AC, %p533;
	fma.rn.f32 	%f1550, %f1548, %f1539, %f1549;
	selp.f32 	%f1551, 0f3F20D842, 0f3E0375D3, %p533;
	fma.rn.f32 	%f1552, %f1550, %f1539, %f1551;
	neg.f32 	%f1553, %f280;
	selp.f32 	%f1554, %f1553, %f1537, %p533;
	fma.rn.f32 	%f281, %f1552, %f1554, %f1554;
	mov.b32 	%r610, %f1537;
	and.b32  	%r93, %r610, -2147483648;
	add.f32 	%f1555, %f279, 0fBF000000;
	mul.f32 	%f1556, %f1555, %f261;
	abs.f32 	%f282, %f1556;
	setp.ge.f32 	%p534, %f282, 0f3F8060FE;
	mul.f32 	%f1557, %f1556, %f1556;
	selp.f32 	%f1558, %f282, %f1557, %p534;
	selp.f32 	%f1559, 0f3789CA3C, 0f38B1E96A, %p534;
	selp.f32 	%f1560, 0fB9F560B9, 0fBA574D20, %p534;
	fma.rn.f32 	%f1561, %f1559, %f1558, %f1560;
	selp.f32 	%f1562, 0f3BAC840B, 0f3BAAD5EA, %p534;
	fma.rn.f32 	%f1563, %f1561, %f1558, %f1562;
	selp.f32 	%f1564, 0fBD0C8162, 0fBCDC1BE7, %p534;
	fma.rn.f32 	%f1565, %f1563, %f1558, %f1564;
	selp.f32 	%f1566, 0f3E1CF906, 0f3DE718AF, %p534;
	fma.rn.f32 	%f1567, %f1565, %f1558, %f1566;
	selp.f32 	%f1568, 0f3F6A937E, 0fBEC093AC, %p534;
	fma.rn.f32 	%f1569, %f1567, %f1558, %f1568;
	selp.f32 	%f1570, 0f3F20D842, 0f3E0375D3, %p534;
	fma.rn.f32 	%f1571, %f1569, %f1558, %f1570;
	neg.f32 	%f1572, %f282;
	selp.f32 	%f1573, %f1572, %f1556, %p534;
	fma.rn.f32 	%f283, %f1571, %f1573, %f1573;
	mov.b32 	%r611, %f1556;
	and.b32  	%r94, %r611, -2147483648;
	add.f32 	%f1574, %f1535, 0f3F000000;
	sub.f32 	%f1575, %f1574, %f2890;
	div.rn.f32 	%f284, %f1575, %f2886;
	abs.f32 	%f285, %f284;
	setp.lt.f32 	%p535, %f285, 0f00800000;
	mul.f32 	%f1576, %f285, 0f4B800000;
	selp.f32 	%f1577, %f1576, %f285, %p535;
	selp.f32 	%f1578, 0fC3170000, 0fC2FE0000, %p535;
	mov.b32 	%r612, %f1577;
	and.b32  	%r613, %r612, 8388607;
	or.b32  	%r614, %r613, 1065353216;
	mov.b32 	%f1579, %r614;
	shr.u32 	%r615, %r612, 23;
	cvt.rn.f32.u32 	%f1580, %r615;
	add.f32 	%f1581, %f1578, %f1580;
	setp.gt.f32 	%p536, %f1579, 0f3FB504F3;
	mul.f32 	%f1582, %f1579, 0f3F000000;
	add.f32 	%f1583, %f1581, 0f3F800000;
	selp.f32 	%f1584, %f1583, %f1581, %p536;
	selp.f32 	%f1585, %f1582, %f1579, %p536;
	add.f32 	%f1586, %f1585, 0fBF800000;
	add.f32 	%f1587, %f1585, 0f3F800000;
	rcp.approx.ftz.f32 	%f1588, %f1587;
	add.f32 	%f1589, %f1586, %f1586;
	mul.f32 	%f1591, %f1589, %f1588;
	mul.f32 	%f1592, %f1591, %f1591;
	mov.f32 	%f1593, 0f3C4CAF63;
	mov.f32 	%f1594, 0f3B18F0FE;
	fma.rn.f32 	%f1595, %f1594, %f1592, %f1593;
	mov.f32 	%f1596, 0f3DAAAABD;
	fma.rn.f32 	%f1597, %f1595, %f1592, %f1596;
	mul.rn.f32 	%f1598, %f1597, %f1592;
	mul.rn.f32 	%f1599, %f1598, %f1591;
	sub.f32 	%f1600, %f1586, %f1591;
	add.f32 	%f1601, %f1600, %f1600;
	neg.f32 	%f1602, %f1591;
	fma.rn.f32 	%f1603, %f1602, %f1586, %f1601;
	mul.rn.f32 	%f1604, %f1588, %f1603;
	add.f32 	%f1605, %f1599, %f1591;
	sub.f32 	%f1606, %f1591, %f1605;
	add.f32 	%f1607, %f1599, %f1606;
	add.f32 	%f1608, %f1604, %f1607;
	add.f32 	%f1609, %f1605, %f1608;
	sub.f32 	%f1610, %f1605, %f1609;
	add.f32 	%f1611, %f1608, %f1610;
	mov.f32 	%f1612, 0f3F317200;
	mul.rn.f32 	%f1613, %f1584, %f1612;
	mov.f32 	%f1614, 0f35BFBE8E;
	mul.rn.f32 	%f1615, %f1584, %f1614;
	add.f32 	%f1616, %f1613, %f1609;
	sub.f32 	%f1617, %f1613, %f1616;
	add.f32 	%f1618, %f1609, %f1617;
	add.f32 	%f1619, %f1611, %f1618;
	add.f32 	%f1620, %f1615, %f1619;
	add.f32 	%f1621, %f1616, %f1620;
	sub.f32 	%f1622, %f1616, %f1621;
	add.f32 	%f1623, %f1620, %f1622;
	mul.rn.f32 	%f1624, %f1533, %f1621;
	neg.f32 	%f1625, %f1624;
	fma.rn.f32 	%f1626, %f1533, %f1621, %f1625;
	fma.rn.f32 	%f1627, %f1533, %f1623, %f1626;
	fma.rn.f32 	%f1629, %f1509, %f1621, %f1627;
	add.rn.f32 	%f1630, %f1624, %f1629;
	neg.f32 	%f1631, %f1630;
	add.rn.f32 	%f1632, %f1624, %f1631;
	add.rn.f32 	%f1633, %f1632, %f1629;
	mov.b32 	%r616, %f1630;
	setp.eq.s32 	%p537, %r616, 1118925336;
	add.s32 	%r617, %r616, -1;
	mov.b32 	%f1634, %r617;
	add.f32 	%f1635, %f1633, 0f37000000;
	selp.f32 	%f286, %f1635, %f1633, %p537;
	selp.f32 	%f1636, %f1634, %f1630, %p537;
	mov.f32 	%f1637, 0f3FB8AA3B;
	mul.rn.f32 	%f1638, %f1636, %f1637;
	cvt.rzi.f32.f32 	%f1639, %f1638;
	abs.f32 	%f1640, %f1639;
	setp.gt.f32 	%p538, %f1640, 0f42FC0000;
	mov.b32 	%r618, %f1639;
	and.b32  	%r619, %r618, -2147483648;
	or.b32  	%r620, %r619, 1123811328;
	mov.b32 	%f1641, %r620;
	selp.f32 	%f1642, %f1641, %f1639, %p538;
	mov.f32 	%f1643, 0fBF317218;
	fma.rn.f32 	%f1644, %f1642, %f1643, %f1636;
	mov.f32 	%f1645, 0f3102E308;
	fma.rn.f32 	%f1646, %f1642, %f1645, %f1644;
	mul.f32 	%f1647, %f1646, 0f3FB8AA3B;
	add.f32 	%f1648, %f1642, 0f4B40007F;
	mov.b32 	%r621, %f1648;
	shl.b32 	%r622, %r621, 23;
	mov.b32 	%f1649, %r622;
	ex2.approx.ftz.f32 	%f1650, %f1647;
	mul.f32 	%f287, %f1650, %f1649;
	setp.lt.f32 	%p539, %f284, 0f00000000;
	and.pred  	%p27, %p539, %p540;
	add.f32 	%f1651, %f284, %f284;
	selp.f32 	%f288, %f1651, 0f00000000, %p540;
	add.f32 	%f1652, %f285, 0f40000000;
	mov.b32 	%r95, %f1652;
	div.rn.f32 	%f289, %f1555, %f2886;
	abs.f32 	%f290, %f289;
	setp.lt.f32 	%p541, %f290, 0f00800000;
	mul.f32 	%f1653, %f290, 0f4B800000;
	selp.f32 	%f1654, %f1653, %f290, %p541;
	selp.f32 	%f1655, 0fC3170000, 0fC2FE0000, %p541;
	mov.b32 	%r623, %f1654;
	and.b32  	%r624, %r623, 8388607;
	or.b32  	%r625, %r624, 1065353216;
	mov.b32 	%f1656, %r625;
	shr.u32 	%r626, %r623, 23;
	cvt.rn.f32.u32 	%f1657, %r626;
	add.f32 	%f1658, %f1655, %f1657;
	setp.gt.f32 	%p542, %f1656, 0f3FB504F3;
	mul.f32 	%f1659, %f1656, 0f3F000000;
	add.f32 	%f1660, %f1658, 0f3F800000;
	selp.f32 	%f1661, %f1660, %f1658, %p542;
	selp.f32 	%f1662, %f1659, %f1656, %p542;
	add.f32 	%f1663, %f1662, 0fBF800000;
	add.f32 	%f1664, %f1662, 0f3F800000;
	rcp.approx.ftz.f32 	%f1665, %f1664;
	add.f32 	%f1666, %f1663, %f1663;
	mul.f32 	%f1667, %f1666, %f1665;
	mul.f32 	%f1668, %f1667, %f1667;
	fma.rn.f32 	%f1669, %f1594, %f1668, %f1593;
	fma.rn.f32 	%f1670, %f1669, %f1668, %f1596;
	mul.rn.f32 	%f1671, %f1670, %f1668;
	mul.rn.f32 	%f1672, %f1671, %f1667;
	sub.f32 	%f1673, %f1663, %f1667;
	add.f32 	%f1674, %f1673, %f1673;
	neg.f32 	%f1675, %f1667;
	fma.rn.f32 	%f1676, %f1675, %f1663, %f1674;
	mul.rn.f32 	%f1677, %f1665, %f1676;
	add.f32 	%f1678, %f1672, %f1667;
	sub.f32 	%f1679, %f1667, %f1678;
	add.f32 	%f1680, %f1672, %f1679;
	add.f32 	%f1681, %f1677, %f1680;
	add.f32 	%f1682, %f1678, %f1681;
	sub.f32 	%f1683, %f1678, %f1682;
	add.f32 	%f1684, %f1681, %f1683;
	mul.rn.f32 	%f1685, %f1661, %f1612;
	mul.rn.f32 	%f1686, %f1661, %f1614;
	add.f32 	%f1687, %f1685, %f1682;
	sub.f32 	%f1688, %f1685, %f1687;
	add.f32 	%f1689, %f1682, %f1688;
	add.f32 	%f1690, %f1684, %f1689;
	add.f32 	%f1691, %f1686, %f1690;
	add.f32 	%f1692, %f1687, %f1691;
	sub.f32 	%f1693, %f1687, %f1692;
	add.f32 	%f1694, %f1691, %f1693;
	mul.rn.f32 	%f1695, %f1533, %f1692;
	neg.f32 	%f1696, %f1695;
	fma.rn.f32 	%f1697, %f1533, %f1692, %f1696;
	fma.rn.f32 	%f1698, %f1533, %f1694, %f1697;
	fma.rn.f32 	%f1699, %f1509, %f1692, %f1698;
	add.rn.f32 	%f1700, %f1695, %f1699;
	neg.f32 	%f1701, %f1700;
	add.rn.f32 	%f1702, %f1695, %f1701;
	add.rn.f32 	%f1703, %f1702, %f1699;
	mov.b32 	%r627, %f1700;
	setp.eq.s32 	%p543, %r627, 1118925336;
	add.s32 	%r628, %r627, -1;
	mov.b32 	%f1704, %r628;
	add.f32 	%f1705, %f1703, 0f37000000;
	selp.f32 	%f291, %f1705, %f1703, %p543;
	selp.f32 	%f1706, %f1704, %f1700, %p543;
	mul.rn.f32 	%f1707, %f1706, %f1637;
	cvt.rzi.f32.f32 	%f1708, %f1707;
	abs.f32 	%f1709, %f1708;
	setp.gt.f32 	%p544, %f1709, 0f42FC0000;
	mov.b32 	%r629, %f1708;
	and.b32  	%r630, %r629, -2147483648;
	or.b32  	%r631, %r630, 1123811328;
	mov.b32 	%f1710, %r631;
	selp.f32 	%f1711, %f1710, %f1708, %p544;
	fma.rn.f32 	%f1712, %f1711, %f1643, %f1706;
	fma.rn.f32 	%f1713, %f1711, %f1645, %f1712;
	mul.f32 	%f1714, %f1713, 0f3FB8AA3B;
	add.f32 	%f1715, %f1711, 0f4B40007F;
	mov.b32 	%r632, %f1715;
	shl.b32 	%r633, %r632, 23;
	mov.b32 	%f1716, %r633;
	ex2.approx.ftz.f32 	%f1717, %f1714;
	mul.f32 	%f292, %f1717, %f1716;
	add.f32 	%f293, %f284, 0f40000000;
	setp.lt.f32 	%p545, %f289, 0f00000000;
	and.pred  	%p28, %p545, %p540;
	selp.f32 	%f294, 0fFF800000, 0f7F800000, %p27;
	add.f32 	%f1718, %f289, %f289;
	selp.f32 	%f295, %f1718, 0f00000000, %p540;
	add.f32 	%f1719, %f290, 0f40000000;
	mov.b32 	%r96, %f1719;
	add.f32 	%f296, %f289, 0f40000000;
	selp.f32 	%f297, 0fFF800000, 0f7F800000, %p28;
	add.f32 	%f1720, %f1535, 0f3F800000;
	sub.f32 	%f1721, %f1720, %f2890;
	div.rn.f32 	%f298, %f1721, %f2886;
	abs.f32 	%f299, %f298;
	setp.lt.f32 	%p546, %f299, 0f00800000;
	mul.f32 	%f1722, %f299, 0f4B800000;
	selp.f32 	%f1723, %f1722, %f299, %p546;
	selp.f32 	%f1724, 0fC3170000, 0fC2FE0000, %p546;
	mov.b32 	%r634, %f1723;
	and.b32  	%r635, %r634, 8388607;
	or.b32  	%r636, %r635, 1065353216;
	mov.b32 	%f1725, %r636;
	shr.u32 	%r637, %r634, 23;
	cvt.rn.f32.u32 	%f1726, %r637;
	add.f32 	%f1727, %f1724, %f1726;
	setp.gt.f32 	%p547, %f1725, 0f3FB504F3;
	mul.f32 	%f1728, %f1725, 0f3F000000;
	add.f32 	%f1729, %f1727, 0f3F800000;
	selp.f32 	%f1730, %f1729, %f1727, %p547;
	selp.f32 	%f1731, %f1728, %f1725, %p547;
	add.f32 	%f1732, %f1731, 0fBF800000;
	add.f32 	%f1733, %f1731, 0f3F800000;
	rcp.approx.ftz.f32 	%f1734, %f1733;
	add.f32 	%f1735, %f1732, %f1732;
	mul.f32 	%f1736, %f1735, %f1734;
	mul.f32 	%f1737, %f1736, %f1736;
	fma.rn.f32 	%f1738, %f1594, %f1737, %f1593;
	fma.rn.f32 	%f1739, %f1738, %f1737, %f1596;
	mul.rn.f32 	%f1740, %f1739, %f1737;
	mul.rn.f32 	%f1741, %f1740, %f1736;
	sub.f32 	%f1742, %f1732, %f1736;
	add.f32 	%f1743, %f1742, %f1742;
	neg.f32 	%f1744, %f1736;
	fma.rn.f32 	%f1745, %f1744, %f1732, %f1743;
	mul.rn.f32 	%f1746, %f1734, %f1745;
	add.f32 	%f1747, %f1741, %f1736;
	sub.f32 	%f1748, %f1736, %f1747;
	add.f32 	%f1749, %f1741, %f1748;
	add.f32 	%f1750, %f1746, %f1749;
	add.f32 	%f1751, %f1747, %f1750;
	sub.f32 	%f1752, %f1747, %f1751;
	add.f32 	%f1753, %f1750, %f1752;
	mul.rn.f32 	%f1754, %f1730, %f1612;
	mul.rn.f32 	%f1755, %f1730, %f1614;
	add.f32 	%f1756, %f1754, %f1751;
	sub.f32 	%f1757, %f1754, %f1756;
	add.f32 	%f1758, %f1751, %f1757;
	add.f32 	%f1759, %f1753, %f1758;
	add.f32 	%f1760, %f1755, %f1759;
	add.f32 	%f1761, %f1756, %f1760;
	sub.f32 	%f1762, %f1756, %f1761;
	add.f32 	%f1763, %f1760, %f1762;
	mul.rn.f32 	%f1764, %f1533, %f1761;
	neg.f32 	%f1765, %f1764;
	fma.rn.f32 	%f1766, %f1533, %f1761, %f1765;
	fma.rn.f32 	%f1767, %f1533, %f1763, %f1766;
	fma.rn.f32 	%f1768, %f1509, %f1761, %f1767;
	add.rn.f32 	%f1769, %f1764, %f1768;
	neg.f32 	%f1770, %f1769;
	add.rn.f32 	%f1771, %f1764, %f1770;
	add.rn.f32 	%f1772, %f1771, %f1768;
	mov.b32 	%r638, %f1769;
	setp.eq.s32 	%p548, %r638, 1118925336;
	add.s32 	%r639, %r638, -1;
	mov.b32 	%f1773, %r639;
	add.f32 	%f1774, %f1772, 0f37000000;
	selp.f32 	%f300, %f1774, %f1772, %p548;
	selp.f32 	%f1775, %f1773, %f1769, %p548;
	mul.rn.f32 	%f1776, %f1775, %f1637;
	cvt.rzi.f32.f32 	%f1777, %f1776;
	abs.f32 	%f1778, %f1777;
	setp.gt.f32 	%p549, %f1778, 0f42FC0000;
	mov.b32 	%r640, %f1777;
	and.b32  	%r641, %r640, -2147483648;
	or.b32  	%r642, %r641, 1123811328;
	mov.b32 	%f1779, %r642;
	selp.f32 	%f1780, %f1779, %f1777, %p549;
	fma.rn.f32 	%f1781, %f1780, %f1643, %f1775;
	fma.rn.f32 	%f1782, %f1780, %f1645, %f1781;
	mul.f32 	%f1783, %f1782, 0f3FB8AA3B;
	add.f32 	%f1784, %f1780, 0f4B40007F;
	mov.b32 	%r643, %f1784;
	shl.b32 	%r644, %r643, 23;
	mov.b32 	%f1785, %r644;
	ex2.approx.ftz.f32 	%f1786, %f1783;
	mul.f32 	%f301, %f1786, %f1785;
	setp.lt.f32 	%p550, %f298, 0f00000000;
	and.pred  	%p29, %p550, %p540;
	add.f32 	%f1787, %f298, %f298;
	selp.f32 	%f302, %f1787, 0f00000000, %p540;
	add.f32 	%f1788, %f299, 0f40000000;
	mov.b32 	%r97, %f1788;
	div.rn.f32 	%f303, %f279, %f2886;
	abs.f32 	%f304, %f303;
	setp.lt.f32 	%p551, %f304, 0f00800000;
	mul.f32 	%f1789, %f304, 0f4B800000;
	selp.f32 	%f1790, %f1789, %f304, %p551;
	selp.f32 	%f1791, 0fC3170000, 0fC2FE0000, %p551;
	mov.b32 	%r645, %f1790;
	and.b32  	%r646, %r645, 8388607;
	or.b32  	%r647, %r646, 1065353216;
	mov.b32 	%f1792, %r647;
	shr.u32 	%r648, %r645, 23;
	cvt.rn.f32.u32 	%f1793, %r648;
	add.f32 	%f1794, %f1791, %f1793;
	setp.gt.f32 	%p552, %f1792, 0f3FB504F3;
	mul.f32 	%f1795, %f1792, 0f3F000000;
	add.f32 	%f1796, %f1794, 0f3F800000;
	selp.f32 	%f1797, %f1796, %f1794, %p552;
	selp.f32 	%f1798, %f1795, %f1792, %p552;
	add.f32 	%f1799, %f1798, 0fBF800000;
	add.f32 	%f1800, %f1798, 0f3F800000;
	rcp.approx.ftz.f32 	%f1801, %f1800;
	add.f32 	%f1802, %f1799, %f1799;
	mul.f32 	%f1803, %f1802, %f1801;
	mul.f32 	%f1804, %f1803, %f1803;
	fma.rn.f32 	%f1805, %f1594, %f1804, %f1593;
	fma.rn.f32 	%f1806, %f1805, %f1804, %f1596;
	mul.rn.f32 	%f1807, %f1806, %f1804;
	mul.rn.f32 	%f1808, %f1807, %f1803;
	sub.f32 	%f1809, %f1799, %f1803;
	add.f32 	%f1810, %f1809, %f1809;
	neg.f32 	%f1811, %f1803;
	fma.rn.f32 	%f1812, %f1811, %f1799, %f1810;
	mul.rn.f32 	%f1813, %f1801, %f1812;
	add.f32 	%f1814, %f1808, %f1803;
	sub.f32 	%f1815, %f1803, %f1814;
	add.f32 	%f1816, %f1808, %f1815;
	add.f32 	%f1817, %f1813, %f1816;
	add.f32 	%f1818, %f1814, %f1817;
	sub.f32 	%f1819, %f1814, %f1818;
	add.f32 	%f1820, %f1817, %f1819;
	mul.rn.f32 	%f1821, %f1797, %f1612;
	mul.rn.f32 	%f1822, %f1797, %f1614;
	add.f32 	%f1823, %f1821, %f1818;
	sub.f32 	%f1824, %f1821, %f1823;
	add.f32 	%f1825, %f1818, %f1824;
	add.f32 	%f1826, %f1820, %f1825;
	add.f32 	%f1827, %f1822, %f1826;
	add.f32 	%f1828, %f1823, %f1827;
	sub.f32 	%f1829, %f1823, %f1828;
	add.f32 	%f1830, %f1827, %f1829;
	mul.rn.f32 	%f1831, %f1533, %f1828;
	neg.f32 	%f1832, %f1831;
	fma.rn.f32 	%f1833, %f1533, %f1828, %f1832;
	fma.rn.f32 	%f1834, %f1533, %f1830, %f1833;
	fma.rn.f32 	%f1835, %f1509, %f1828, %f1834;
	add.rn.f32 	%f1836, %f1831, %f1835;
	neg.f32 	%f1837, %f1836;
	add.rn.f32 	%f1838, %f1831, %f1837;
	add.rn.f32 	%f1839, %f1838, %f1835;
	mov.b32 	%r649, %f1836;
	setp.eq.s32 	%p553, %r649, 1118925336;
	add.s32 	%r650, %r649, -1;
	mov.b32 	%f1840, %r650;
	add.f32 	%f1841, %f1839, 0f37000000;
	selp.f32 	%f305, %f1841, %f1839, %p553;
	selp.f32 	%f1842, %f1840, %f1836, %p553;
	mul.rn.f32 	%f1843, %f1842, %f1637;
	cvt.rzi.f32.f32 	%f1844, %f1843;
	abs.f32 	%f1845, %f1844;
	setp.gt.f32 	%p554, %f1845, 0f42FC0000;
	mov.b32 	%r651, %f1844;
	and.b32  	%r652, %r651, -2147483648;
	or.b32  	%r653, %r652, 1123811328;
	mov.b32 	%f1846, %r653;
	selp.f32 	%f1847, %f1846, %f1844, %p554;
	fma.rn.f32 	%f1848, %f1847, %f1643, %f1842;
	fma.rn.f32 	%f1849, %f1847, %f1645, %f1848;
	mul.f32 	%f1850, %f1849, 0f3FB8AA3B;
	add.f32 	%f1851, %f1847, 0f4B40007F;
	mov.b32 	%r654, %f1851;
	shl.b32 	%r655, %r654, 23;
	mov.b32 	%f1852, %r655;
	ex2.approx.ftz.f32 	%f1853, %f1850;
	mul.f32 	%f306, %f1853, %f1852;
	add.f32 	%f307, %f298, 0f40000000;
	setp.lt.f32 	%p555, %f303, 0f00000000;
	and.pred  	%p30, %p555, %p540;
	selp.f32 	%f308, 0fFF800000, 0f7F800000, %p29;
	add.f32 	%f1854, %f303, %f303;
	selp.f32 	%f309, %f1854, 0f00000000, %p540;
	add.f32 	%f1855, %f304, 0f40000000;
	mov.b32 	%r98, %f1855;
	add.f32 	%f310, %f279, 0f3F800000;
	add.f32 	%f311, %f303, 0f40000000;
	selp.f32 	%f312, 0fFF800000, 0f7F800000, %p30;
	setp.geu.f32 	%p31, %f284, 0f00000000;
	setp.geu.f32 	%p32, %f289, 0f00000000;
	setp.geu.f32 	%p33, %f298, 0f00000000;
	setp.geu.f32 	%p34, %f303, 0f00000000;
	mov.u32 	%r788, %r608;

$L__BB5_340:
	setp.ltu.f32 	%p556, %f280, 0f3F8060FE;
	mov.f32 	%f2924, %f281;
	@%p556 bra 	$L__BB5_342;

	ex2.approx.ftz.f32 	%f1856, %f281;
	sub.f32 	%f1858, %f1530, %f1856;
	mov.b32 	%r656, %f1858;
	or.b32  	%r657, %r93, %r656;
	mov.b32 	%f2924, %r657;

$L__BB5_342:
	setp.ltu.f32 	%p557, %f282, 0f3F8060FE;
	mov.f32 	%f2925, %f283;
	@%p557 bra 	$L__BB5_344;

	ex2.approx.ftz.f32 	%f1859, %f283;
	sub.f32 	%f1861, %f1530, %f1859;
	mov.b32 	%r658, %f1861;
	or.b32  	%r659, %r94, %r658;
	mov.b32 	%f2925, %r659;

$L__BB5_344:
	sub.f32 	%f1862, %f2924, %f2925;
	mul.f32 	%f333, %f1862, 0f3F000000;
	cvt.rn.f32.s32 	%f334, %r788;
	sub.f32 	%f335, %f334, %f2889;
	add.f32 	%f1863, %f335, 0f3F000000;
	mul.f32 	%f336, %f261, %f1863;
	abs.f32 	%f1864, %f336;
	setp.ltu.f32 	%p558, %f1864, 0f3F8060FE;
	setp.ge.f32 	%p559, %f1864, 0f3F8060FE;
	mul.f32 	%f1865, %f336, %f336;
	selp.f32 	%f1866, %f1864, %f1865, %p559;
	selp.f32 	%f1867, 0f3789CA3C, 0f38B1E96A, %p559;
	selp.f32 	%f1868, 0fB9F560B9, 0fBA574D20, %p559;
	fma.rn.f32 	%f1869, %f1867, %f1866, %f1868;
	selp.f32 	%f1870, 0f3BAC840B, 0f3BAAD5EA, %p559;
	fma.rn.f32 	%f1871, %f1869, %f1866, %f1870;
	selp.f32 	%f1872, 0fBD0C8162, 0fBCDC1BE7, %p559;
	fma.rn.f32 	%f1873, %f1871, %f1866, %f1872;
	selp.f32 	%f1874, 0f3E1CF906, 0f3DE718AF, %p559;
	fma.rn.f32 	%f1875, %f1873, %f1866, %f1874;
	selp.f32 	%f1876, 0f3F6A937E, 0fBEC093AC, %p559;
	fma.rn.f32 	%f1877, %f1875, %f1866, %f1876;
	selp.f32 	%f1878, 0f3F20D842, 0f3E0375D3, %p559;
	fma.rn.f32 	%f1879, %f1877, %f1866, %f1878;
	neg.f32 	%f1880, %f1864;
	selp.f32 	%f1881, %f1880, %f336, %p559;
	fma.rn.f32 	%f2926, %f1879, %f1881, %f1881;
	@%p558 bra 	$L__BB5_346;

	ex2.approx.ftz.f32 	%f1882, %f2926;
	sub.f32 	%f1884, %f1530, %f1882;
	mov.b32 	%r660, %f1884;
	mov.b32 	%r661, %f336;
	and.b32  	%r662, %r661, -2147483648;
	or.b32  	%r663, %r662, %r660;
	mov.b32 	%f2926, %r663;

$L__BB5_346:
	add.f32 	%f340, %f335, 0fBF000000;
	mul.f32 	%f341, %f261, %f340;
	abs.f32 	%f1885, %f341;
	setp.ltu.f32 	%p560, %f1885, 0f3F8060FE;
	setp.ge.f32 	%p561, %f1885, 0f3F8060FE;
	mul.f32 	%f1886, %f341, %f341;
	selp.f32 	%f1887, %f1885, %f1886, %p561;
	selp.f32 	%f1888, 0f3789CA3C, 0f38B1E96A, %p561;
	selp.f32 	%f1889, 0fB9F560B9, 0fBA574D20, %p561;
	fma.rn.f32 	%f1890, %f1888, %f1887, %f1889;
	selp.f32 	%f1891, 0f3BAC840B, 0f3BAAD5EA, %p561;
	fma.rn.f32 	%f1892, %f1890, %f1887, %f1891;
	selp.f32 	%f1893, 0fBD0C8162, 0fBCDC1BE7, %p561;
	fma.rn.f32 	%f1894, %f1892, %f1887, %f1893;
	selp.f32 	%f1895, 0f3E1CF906, 0f3DE718AF, %p561;
	fma.rn.f32 	%f1896, %f1894, %f1887, %f1895;
	selp.f32 	%f1897, 0f3F6A937E, 0fBEC093AC, %p561;
	fma.rn.f32 	%f1898, %f1896, %f1887, %f1897;
	selp.f32 	%f1899, 0f3F20D842, 0f3E0375D3, %p561;
	fma.rn.f32 	%f1900, %f1898, %f1887, %f1899;
	neg.f32 	%f1901, %f1885;
	selp.f32 	%f1902, %f1901, %f341, %p561;
	fma.rn.f32 	%f2927, %f1900, %f1902, %f1902;
	@%p560 bra 	$L__BB5_348;

	ex2.approx.ftz.f32 	%f1903, %f2927;
	sub.f32 	%f1905, %f1530, %f1903;
	mov.b32 	%r664, %f1905;
	mov.b32 	%r665, %f341;
	and.b32  	%r666, %r665, -2147483648;
	or.b32  	%r667, %r666, %r664;
	mov.b32 	%f2927, %r667;

$L__BB5_348:
	sub.f32 	%f1907, %f2926, %f2927;
	mul.f32 	%f345, %f1907, 0f3F000000;
	mul.f32 	%f1908, %f333, %f2888;
	fma.rn.f32 	%f346, %f345, %f1908, %f2887;
	mad.lo.s32 	%r668, %r788, %r102, %r787;
	add.s32 	%r669, %r668, %r2;
	mul.wide.s32 	%rd36, %r669, 4;
	add.s64 	%rd37, %rd1, %rd36;
	ld.global.f32 	%f347, [%rd37];
	setp.eq.f32 	%p562, %f287, 0f7F800000;
	mov.f32 	%f2928, 0f7F800000;
	@%p562 bra 	$L__BB5_350;

	fma.rn.f32 	%f2928, %f287, %f286, %f287;

$L__BB5_350:
	mov.b32 	%r670, %f2928;
	xor.b32  	%r671, %r670, -2147483648;
	mov.b32 	%f1909, %r671;
	selp.f32 	%f350, %f1909, %f2928, %p27;
	setp.eq.f32 	%p563, %f284, 0f00000000;
	selp.f32 	%f2929, %f288, %f350, %p563;
	@%p31 bra 	$L__BB5_353;

	cvt.rzi.f32.f32 	%f1911, %f1533;
	setp.eq.f32 	%p564, %f1911, 0f40000000;
	mov.f32 	%f2929, %f350;
	@%p564 bra 	$L__BB5_353;

	mov.f32 	%f2929, 0f7FFFFFFF;

$L__BB5_353:
	setp.eq.f32 	%p565, %f292, 0f7F800000;
	mov.f32 	%f2930, 0f7F800000;
	@%p565 bra 	$L__BB5_355;

	fma.rn.f32 	%f2930, %f292, %f291, %f292;

$L__BB5_355:
	mov.b32 	%r672, %f2930;
	xor.b32  	%r673, %r672, -2147483648;
	mov.b32 	%f1914, %r673;
	selp.f32 	%f355, %f1914, %f2930, %p28;
	setp.eq.f32 	%p566, %f289, 0f00000000;
	selp.f32 	%f2931, %f295, %f355, %p566;
	@%p32 bra 	$L__BB5_358;

	cvt.rzi.f32.f32 	%f1916, %f1533;
	setp.eq.f32 	%p567, %f1916, 0f40000000;
	mov.f32 	%f2931, %f355;
	@%p567 bra 	$L__BB5_358;

	mov.f32 	%f2931, 0f7FFFFFFF;

$L__BB5_358:
	setp.gtu.f32 	%p568, %f285, 0f7F800000;
	mov.f32 	%f2932, 0f7F800000;
	selp.f32 	%f1919, %f293, %f2929, %p568;
	setp.neu.f32 	%p569, %f285, 0f7F800000;
	selp.f32 	%f1920, %f1919, %f294, %p569;
	setp.gt.s32 	%p570, %r95, 2139095039;
	selp.f32 	%f1921, %f1920, %f2929, %p570;
	mul.f32 	%f1922, %f1921, 0fBF000000;
	setp.eq.f32 	%p571, %f284, 0f3F800000;
	selp.f32 	%f1923, 0fBF000000, %f1922, %p571;
	mov.f32 	%f1925, 0f3BBB989D;
	fma.rn.f32 	%f1926, %f1923, %f1925, %f1526;
	mov.f32 	%f1928, 0f437C0000;
	cvt.sat.f32.f32 	%f1929, %f1926;
	mov.f32 	%f1930, 0f4B400001;
	fma.rm.f32 	%f1931, %f1929, %f1928, %f1930;
	setp.gtu.f32 	%p572, %f290, 0f7F800000;
	selp.f32 	%f1932, %f296, %f2931, %p572;
	setp.neu.f32 	%p573, %f290, 0f7F800000;
	selp.f32 	%f1933, %f1932, %f297, %p573;
	setp.gt.s32 	%p574, %r96, 2139095039;
	selp.f32 	%f1934, %f1933, %f2931, %p574;
	mul.f32 	%f1935, %f1934, 0fBF000000;
	setp.eq.f32 	%p575, %f289, 0f3F800000;
	selp.f32 	%f1936, 0fBF000000, %f1935, %p575;
	fma.rn.f32 	%f1937, %f1936, %f1925, %f1526;
	cvt.sat.f32.f32 	%f1938, %f1937;
	fma.rm.f32 	%f1939, %f1938, %f1928, %f1930;
	add.f32 	%f1940, %f1939, 0fCB40007F;
	neg.f32 	%f1941, %f1940;
	fma.rn.f32 	%f1942, %f1936, %f1637, %f1941;
	mov.f32 	%f1943, 0f32A57060;
	fma.rn.f32 	%f1944, %f1936, %f1943, %f1942;
	mov.b32 	%r674, %f1939;
	shl.b32 	%r675, %r674, 23;
	mov.b32 	%f1945, %r675;
	ex2.approx.ftz.f32 	%f1946, %f1944;
	mul.f32 	%f1947, %f1946, %f1945;
	mov.b32 	%r676, %f1931;
	shl.b32 	%r677, %r676, 23;
	mov.b32 	%f1948, %r677;
	add.f32 	%f1949, %f1931, 0fCB40007F;
	neg.f32 	%f1950, %f1949;
	fma.rn.f32 	%f1951, %f1923, %f1637, %f1950;
	fma.rn.f32 	%f1952, %f1923, %f1943, %f1951;
	ex2.approx.ftz.f32 	%f1953, %f1952;
	mul.f32 	%f1954, %f1953, %f1948;
	sub.f32 	%f1955, %f1954, %f1947;
	mul.f32 	%f1956, %f259, %f1955;
	mul.f32 	%f358, %f345, %f1956;
	add.f32 	%f1957, %f334, 0f3F000000;
	sub.f32 	%f1958, %f1957, %f2889;
	div.rn.f32 	%f359, %f1958, %f2886;
	abs.f32 	%f360, %f359;
	setp.lt.f32 	%p576, %f360, 0f00800000;
	mul.f32 	%f1959, %f360, 0f4B800000;
	selp.f32 	%f1960, %f1959, %f360, %p576;
	selp.f32 	%f1961, 0fC3170000, 0fC2FE0000, %p576;
	mov.b32 	%r678, %f1960;
	and.b32  	%r679, %r678, 8388607;
	or.b32  	%r680, %r679, 1065353216;
	mov.b32 	%f1962, %r680;
	shr.u32 	%r681, %r678, 23;
	cvt.rn.f32.u32 	%f1963, %r681;
	add.f32 	%f1964, %f1961, %f1963;
	setp.gt.f32 	%p577, %f1962, 0f3FB504F3;
	mul.f32 	%f1965, %f1962, 0f3F000000;
	add.f32 	%f1966, %f1964, 0f3F800000;
	selp.f32 	%f1967, %f1966, %f1964, %p577;
	selp.f32 	%f1968, %f1965, %f1962, %p577;
	add.f32 	%f1969, %f1968, 0fBF800000;
	add.f32 	%f1970, %f1968, 0f3F800000;
	rcp.approx.ftz.f32 	%f1971, %f1970;
	add.f32 	%f1972, %f1969, %f1969;
	mul.f32 	%f1974, %f1972, %f1971;
	mul.f32 	%f1975, %f1974, %f1974;
	fma.rn.f32 	%f1978, %f1594, %f1975, %f1593;
	fma.rn.f32 	%f1980, %f1978, %f1975, %f1596;
	mul.rn.f32 	%f1981, %f1980, %f1975;
	mul.rn.f32 	%f1982, %f1981, %f1974;
	sub.f32 	%f1983, %f1969, %f1974;
	add.f32 	%f1984, %f1983, %f1983;
	neg.f32 	%f1985, %f1974;
	fma.rn.f32 	%f1986, %f1985, %f1969, %f1984;
	mul.rn.f32 	%f1987, %f1971, %f1986;
	add.f32 	%f1988, %f1982, %f1974;
	sub.f32 	%f1989, %f1974, %f1988;
	add.f32 	%f1990, %f1982, %f1989;
	add.f32 	%f1991, %f1987, %f1990;
	add.f32 	%f1992, %f1988, %f1991;
	sub.f32 	%f1993, %f1988, %f1992;
	add.f32 	%f1994, %f1991, %f1993;
	mul.rn.f32 	%f1996, %f1967, %f1612;
	mul.rn.f32 	%f1998, %f1967, %f1614;
	add.f32 	%f1999, %f1996, %f1992;
	sub.f32 	%f2000, %f1996, %f1999;
	add.f32 	%f2001, %f1992, %f2000;
	add.f32 	%f2002, %f1994, %f2001;
	add.f32 	%f2003, %f1998, %f2002;
	add.f32 	%f2004, %f1999, %f2003;
	sub.f32 	%f2005, %f1999, %f2004;
	add.f32 	%f2006, %f2003, %f2005;
	mul.rn.f32 	%f2007, %f1533, %f2004;
	neg.f32 	%f2008, %f2007;
	fma.rn.f32 	%f2009, %f1533, %f2004, %f2008;
	fma.rn.f32 	%f2010, %f1533, %f2006, %f2009;
	mov.f32 	%f2011, 0f00000000;
	fma.rn.f32 	%f2012, %f2011, %f2004, %f2010;
	add.rn.f32 	%f2013, %f2007, %f2012;
	neg.f32 	%f2014, %f2013;
	add.rn.f32 	%f2015, %f2007, %f2014;
	add.rn.f32 	%f2016, %f2015, %f2012;
	mov.b32 	%r682, %f2013;
	setp.eq.s32 	%p578, %r682, 1118925336;
	add.s32 	%r683, %r682, -1;
	mov.b32 	%f2017, %r683;
	add.f32 	%f2018, %f2016, 0f37000000;
	selp.f32 	%f361, %f2018, %f2016, %p578;
	selp.f32 	%f2019, %f2017, %f2013, %p578;
	mul.rn.f32 	%f2020, %f2019, %f1637;
	cvt.rzi.f32.f32 	%f2021, %f2020;
	abs.f32 	%f2022, %f2021;
	setp.gt.f32 	%p579, %f2022, 0f42FC0000;
	mov.b32 	%r684, %f2021;
	and.b32  	%r685, %r684, -2147483648;
	or.b32  	%r686, %r685, 1123811328;
	mov.b32 	%f2023, %r686;
	selp.f32 	%f2024, %f2023, %f2021, %p579;
	fma.rn.f32 	%f2026, %f2024, %f1643, %f2019;
	fma.rn.f32 	%f2028, %f2024, %f1645, %f2026;
	mul.f32 	%f2029, %f2028, 0f3FB8AA3B;
	add.f32 	%f2030, %f2024, 0f4B40007F;
	mov.b32 	%r687, %f2030;
	shl.b32 	%r688, %r687, 23;
	mov.b32 	%f2031, %r688;
	ex2.approx.ftz.f32 	%f2032, %f2029;
	mul.f32 	%f362, %f2032, %f2031;
	setp.eq.f32 	%p580, %f362, 0f7F800000;
	@%p580 bra 	$L__BB5_360;

	fma.rn.f32 	%f2932, %f362, %f361, %f362;

$L__BB5_360:
	setp.lt.f32 	%p581, %f359, 0f00000000;
	and.pred  	%p35, %p581, %p540;
	setp.eq.f32 	%p583, %f359, 0f00000000;
	@%p583 bra 	$L__BB5_364;
	bra.uni 	$L__BB5_361;

$L__BB5_364:
	add.f32 	%f2037, %f359, %f359;
	selp.f32 	%f2934, %f2037, 0f00000000, %p540;
	bra.uni 	$L__BB5_365;

$L__BB5_361:
	mov.b32 	%r689, %f2932;
	xor.b32  	%r690, %r689, -2147483648;
	mov.b32 	%f2033, %r690;
	selp.f32 	%f2934, %f2033, %f2932, %p35;
	setp.geu.f32 	%p584, %f359, 0f00000000;
	@%p584 bra 	$L__BB5_365;

	cvt.rzi.f32.f32 	%f2035, %f1533;
	setp.eq.f32 	%p585, %f2035, 0f40000000;
	@%p585 bra 	$L__BB5_365;

	mov.f32 	%f2934, 0f7FFFFFFF;

$L__BB5_365:
	add.f32 	%f2038, %f360, 0f40000000;
	mov.b32 	%r691, %f2038;
	setp.lt.s32 	%p587, %r691, 2139095040;
	@%p587 bra 	$L__BB5_370;

	setp.gtu.f32 	%p588, %f360, 0f7F800000;
	@%p588 bra 	$L__BB5_369;
	bra.uni 	$L__BB5_367;

$L__BB5_369:
	add.f32 	%f2934, %f359, 0f40000000;
	bra.uni 	$L__BB5_370;

$L__BB5_367:
	setp.neu.f32 	%p589, %f360, 0f7F800000;
	@%p589 bra 	$L__BB5_370;

	selp.f32 	%f2934, 0fFF800000, 0f7F800000, %p35;

$L__BB5_370:
	mul.f32 	%f2040, %f2934, 0fBF000000;
	setp.eq.f32 	%p590, %f359, 0f3F800000;
	selp.f32 	%f2041, 0fBF000000, %f2040, %p590;
	fma.rn.f32 	%f2044, %f2041, %f1925, %f1526;
	cvt.sat.f32.f32 	%f2047, %f2044;
	fma.rm.f32 	%f2049, %f2047, %f1928, %f1930;
	add.f32 	%f2050, %f2049, 0fCB40007F;
	neg.f32 	%f2051, %f2050;
	fma.rn.f32 	%f2052, %f2041, %f1637, %f2051;
	fma.rn.f32 	%f2054, %f2041, %f1943, %f2052;
	mov.b32 	%r692, %f2049;
	shl.b32 	%r693, %r692, 23;
	mov.b32 	%f2055, %r693;
	ex2.approx.ftz.f32 	%f2056, %f2054;
	mul.f32 	%f371, %f2056, %f2055;
	div.rn.f32 	%f372, %f340, %f2886;
	abs.f32 	%f373, %f372;
	setp.lt.f32 	%p591, %f373, 0f00800000;
	mul.f32 	%f2057, %f373, 0f4B800000;
	selp.f32 	%f2058, %f2057, %f373, %p591;
	selp.f32 	%f2059, 0fC3170000, 0fC2FE0000, %p591;
	mov.b32 	%r694, %f2058;
	and.b32  	%r695, %r694, 8388607;
	or.b32  	%r696, %r695, 1065353216;
	mov.b32 	%f2060, %r696;
	shr.u32 	%r697, %r694, 23;
	cvt.rn.f32.u32 	%f2061, %r697;
	add.f32 	%f2062, %f2059, %f2061;
	setp.gt.f32 	%p592, %f2060, 0f3FB504F3;
	mul.f32 	%f2063, %f2060, 0f3F000000;
	add.f32 	%f2064, %f2062, 0f3F800000;
	selp.f32 	%f2065, %f2064, %f2062, %p592;
	selp.f32 	%f2066, %f2063, %f2060, %p592;
	add.f32 	%f2067, %f2066, 0fBF800000;
	add.f32 	%f2068, %f2066, 0f3F800000;
	rcp.approx.ftz.f32 	%f2069, %f2068;
	add.f32 	%f2070, %f2067, %f2067;
	mul.f32 	%f2072, %f2070, %f2069;
	mul.f32 	%f2073, %f2072, %f2072;
	fma.rn.f32 	%f2076, %f1594, %f2073, %f1593;
	fma.rn.f32 	%f2078, %f2076, %f2073, %f1596;
	mul.rn.f32 	%f2079, %f2078, %f2073;
	mul.rn.f32 	%f2080, %f2079, %f2072;
	sub.f32 	%f2081, %f2067, %f2072;
	add.f32 	%f2082, %f2081, %f2081;
	neg.f32 	%f2083, %f2072;
	fma.rn.f32 	%f2084, %f2083, %f2067, %f2082;
	mul.rn.f32 	%f2085, %f2069, %f2084;
	add.f32 	%f2086, %f2080, %f2072;
	sub.f32 	%f2087, %f2072, %f2086;
	add.f32 	%f2088, %f2080, %f2087;
	add.f32 	%f2089, %f2085, %f2088;
	add.f32 	%f2090, %f2086, %f2089;
	sub.f32 	%f2091, %f2086, %f2090;
	add.f32 	%f2092, %f2089, %f2091;
	mul.rn.f32 	%f2094, %f2065, %f1612;
	mul.rn.f32 	%f2096, %f2065, %f1614;
	add.f32 	%f2097, %f2094, %f2090;
	sub.f32 	%f2098, %f2094, %f2097;
	add.f32 	%f2099, %f2090, %f2098;
	add.f32 	%f2100, %f2092, %f2099;
	add.f32 	%f2101, %f2096, %f2100;
	add.f32 	%f2102, %f2097, %f2101;
	sub.f32 	%f2103, %f2097, %f2102;
	add.f32 	%f2104, %f2101, %f2103;
	mul.rn.f32 	%f2105, %f1533, %f2102;
	neg.f32 	%f2106, %f2105;
	fma.rn.f32 	%f2107, %f1533, %f2102, %f2106;
	fma.rn.f32 	%f2108, %f1533, %f2104, %f2107;
	fma.rn.f32 	%f2110, %f2011, %f2102, %f2108;
	add.rn.f32 	%f2111, %f2105, %f2110;
	neg.f32 	%f2112, %f2111;
	add.rn.f32 	%f2113, %f2105, %f2112;
	add.rn.f32 	%f2114, %f2113, %f2110;
	mov.b32 	%r698, %f2111;
	setp.eq.s32 	%p593, %r698, 1118925336;
	add.s32 	%r699, %r698, -1;
	mov.b32 	%f2115, %r699;
	add.f32 	%f2116, %f2114, 0f37000000;
	selp.f32 	%f374, %f2116, %f2114, %p593;
	selp.f32 	%f2117, %f2115, %f2111, %p593;
	mul.rn.f32 	%f2118, %f2117, %f1637;
	cvt.rzi.f32.f32 	%f2119, %f2118;
	abs.f32 	%f2120, %f2119;
	setp.gt.f32 	%p594, %f2120, 0f42FC0000;
	mov.b32 	%r700, %f2119;
	and.b32  	%r701, %r700, -2147483648;
	or.b32  	%r702, %r701, 1123811328;
	mov.b32 	%f2121, %r702;
	selp.f32 	%f2122, %f2121, %f2119, %p594;
	fma.rn.f32 	%f2124, %f2122, %f1643, %f2117;
	fma.rn.f32 	%f2126, %f2122, %f1645, %f2124;
	mul.f32 	%f2127, %f2126, 0f3FB8AA3B;
	add.f32 	%f2128, %f2122, 0f4B40007F;
	mov.b32 	%r703, %f2128;
	shl.b32 	%r704, %r703, 23;
	mov.b32 	%f2129, %r704;
	ex2.approx.ftz.f32 	%f2130, %f2127;
	mul.f32 	%f375, %f2130, %f2129;
	setp.eq.f32 	%p595, %f375, 0f7F800000;
	mov.f32 	%f2935, 0f7F800000;
	@%p595 bra 	$L__BB5_372;

	fma.rn.f32 	%f2935, %f375, %f374, %f375;

$L__BB5_372:
	setp.lt.f32 	%p596, %f372, 0f00000000;
	and.pred  	%p36, %p596, %p540;
	setp.eq.f32 	%p598, %f372, 0f00000000;
	@%p598 bra 	$L__BB5_376;
	bra.uni 	$L__BB5_373;

$L__BB5_376:
	add.f32 	%f2135, %f372, %f372;
	selp.f32 	%f2937, %f2135, 0f00000000, %p540;
	bra.uni 	$L__BB5_377;

$L__BB5_373:
	mov.b32 	%r705, %f2935;
	xor.b32  	%r706, %r705, -2147483648;
	mov.b32 	%f2131, %r706;
	selp.f32 	%f2937, %f2131, %f2935, %p36;
	setp.geu.f32 	%p599, %f372, 0f00000000;
	@%p599 bra 	$L__BB5_377;

	cvt.rzi.f32.f32 	%f2133, %f1533;
	setp.eq.f32 	%p600, %f2133, 0f40000000;
	@%p600 bra 	$L__BB5_377;

	mov.f32 	%f2937, 0f7FFFFFFF;

$L__BB5_377:
	add.f32 	%f2136, %f373, 0f40000000;
	mov.b32 	%r707, %f2136;
	setp.lt.s32 	%p602, %r707, 2139095040;
	@%p602 bra 	$L__BB5_382;

	setp.gtu.f32 	%p603, %f373, 0f7F800000;
	@%p603 bra 	$L__BB5_381;
	bra.uni 	$L__BB5_379;

$L__BB5_381:
	add.f32 	%f2937, %f372, 0f40000000;
	bra.uni 	$L__BB5_382;

$L__BB5_379:
	setp.neu.f32 	%p604, %f373, 0f7F800000;
	@%p604 bra 	$L__BB5_382;

	selp.f32 	%f2937, 0fFF800000, 0f7F800000, %p36;

$L__BB5_382:
	mul.f32 	%f2138, %f2937, 0fBF000000;
	setp.eq.f32 	%p605, %f372, 0f3F800000;
	selp.f32 	%f2139, 0fBF000000, %f2138, %p605;
	fma.rn.f32 	%f2142, %f2139, %f1925, %f1526;
	cvt.sat.f32.f32 	%f2145, %f2142;
	fma.rm.f32 	%f2147, %f2145, %f1928, %f1930;
	add.f32 	%f2148, %f2147, 0fCB40007F;
	neg.f32 	%f2149, %f2148;
	fma.rn.f32 	%f2150, %f2139, %f1637, %f2149;
	fma.rn.f32 	%f2152, %f2139, %f1943, %f2150;
	mov.b32 	%r708, %f2147;
	shl.b32 	%r709, %r708, 23;
	mov.b32 	%f2153, %r709;
	ex2.approx.ftz.f32 	%f2154, %f2152;
	mul.f32 	%f2155, %f2154, %f2153;
	sub.f32 	%f384, %f371, %f2155;
	setp.eq.f32 	%p606, %f301, 0f7F800000;
	mov.f32 	%f2938, 0f7F800000;
	@%p606 bra 	$L__BB5_384;

	fma.rn.f32 	%f2938, %f301, %f300, %f301;

$L__BB5_384:
	mov.b32 	%r710, %f2938;
	xor.b32  	%r711, %r710, -2147483648;
	mov.b32 	%f2156, %r711;
	selp.f32 	%f387, %f2156, %f2938, %p29;
	setp.eq.f32 	%p607, %f298, 0f00000000;
	selp.f32 	%f2939, %f302, %f387, %p607;
	@%p33 bra 	$L__BB5_387;

	cvt.rzi.f32.f32 	%f2158, %f1533;
	setp.eq.f32 	%p608, %f2158, 0f40000000;
	mov.f32 	%f2939, %f387;
	@%p608 bra 	$L__BB5_387;

	mov.f32 	%f2939, 0f7FFFFFFF;

$L__BB5_387:
	setp.eq.f32 	%p609, %f306, 0f7F800000;
	mov.f32 	%f2940, 0f7F800000;
	@%p609 bra 	$L__BB5_389;

	fma.rn.f32 	%f2940, %f306, %f305, %f306;

$L__BB5_389:
	mov.b32 	%r712, %f2940;
	xor.b32  	%r713, %r712, -2147483648;
	mov.b32 	%f2161, %r713;
	selp.f32 	%f392, %f2161, %f2940, %p30;
	setp.eq.f32 	%p610, %f303, 0f00000000;
	selp.f32 	%f2941, %f309, %f392, %p610;
	@%p34 bra 	$L__BB5_392;

	cvt.rzi.f32.f32 	%f2163, %f1533;
	setp.eq.f32 	%p611, %f2163, 0f40000000;
	mov.f32 	%f2941, %f392;
	@%p611 bra 	$L__BB5_392;

	mov.f32 	%f2941, 0f7FFFFFFF;

$L__BB5_392:
	mul.f32 	%f2166, %f259, %f384;
	mul.f32 	%f395, %f333, %f2166;
	setp.gtu.f32 	%p612, %f299, 0f7F800000;
	mov.f32 	%f2942, 0f7F800000;
	selp.f32 	%f2167, %f307, %f2939, %p612;
	setp.neu.f32 	%p613, %f299, 0f7F800000;
	selp.f32 	%f2168, %f2167, %f308, %p613;
	setp.gt.s32 	%p614, %r97, 2139095039;
	selp.f32 	%f2169, %f2168, %f2939, %p614;
	mul.f32 	%f2170, %f2169, 0fBF000000;
	setp.eq.f32 	%p615, %f298, 0f3F800000;
	selp.f32 	%f2171, 0fBF000000, %f2170, %p615;
	fma.rn.f32 	%f2174, %f2171, %f1925, %f1526;
	cvt.sat.f32.f32 	%f2177, %f2174;
	fma.rm.f32 	%f2179, %f2177, %f1928, %f1930;
	setp.gtu.f32 	%p616, %f304, 0f7F800000;
	selp.f32 	%f2180, %f311, %f2941, %p616;
	setp.neu.f32 	%p617, %f304, 0f7F800000;
	selp.f32 	%f2181, %f2180, %f312, %p617;
	setp.gt.s32 	%p618, %r98, 2139095039;
	selp.f32 	%f2182, %f2181, %f2941, %p618;
	mul.f32 	%f2183, %f2182, 0fBF000000;
	setp.eq.f32 	%p619, %f303, 0f3F800000;
	selp.f32 	%f2184, 0fBF000000, %f2183, %p619;
	fma.rn.f32 	%f2185, %f2184, %f1925, %f1526;
	cvt.sat.f32.f32 	%f2186, %f2185;
	fma.rm.f32 	%f2187, %f2186, %f1928, %f1930;
	add.f32 	%f2188, %f2187, 0fCB40007F;
	neg.f32 	%f2189, %f2188;
	fma.rn.f32 	%f2190, %f2184, %f1637, %f2189;
	fma.rn.f32 	%f2192, %f2184, %f1943, %f2190;
	mov.b32 	%r714, %f2187;
	shl.b32 	%r715, %r714, 23;
	mov.b32 	%f2193, %r715;
	ex2.approx.ftz.f32 	%f2194, %f2192;
	mul.f32 	%f2195, %f2194, %f2193;
	mul.f32 	%f2196, %f279, %f2195;
	mov.b32 	%r716, %f2179;
	shl.b32 	%r717, %r716, 23;
	mov.b32 	%f2197, %r717;
	add.f32 	%f2198, %f2179, 0fCB40007F;
	neg.f32 	%f2199, %f2198;
	fma.rn.f32 	%f2200, %f2171, %f1637, %f2199;
	fma.rn.f32 	%f2201, %f2171, %f1943, %f2200;
	ex2.approx.ftz.f32 	%f2202, %f2201;
	mul.f32 	%f2203, %f2202, %f2197;
	mul.f32 	%f2204, %f310, %f2203;
	sub.f32 	%f2205, %f2204, %f2196;
	mul.f32 	%f2206, %f260, %f2205;
	mul.f32 	%f396, %f345, %f2206;
	add.f32 	%f2207, %f334, 0f3F800000;
	sub.f32 	%f2208, %f2207, %f2889;
	div.rn.f32 	%f397, %f2208, %f2886;
	abs.f32 	%f398, %f397;
	setp.lt.f32 	%p620, %f398, 0f00800000;
	mul.f32 	%f2209, %f398, 0f4B800000;
	selp.f32 	%f2210, %f2209, %f398, %p620;
	selp.f32 	%f2211, 0fC3170000, 0fC2FE0000, %p620;
	mov.b32 	%r718, %f2210;
	and.b32  	%r719, %r718, 8388607;
	or.b32  	%r720, %r719, 1065353216;
	mov.b32 	%f2212, %r720;
	shr.u32 	%r721, %r718, 23;
	cvt.rn.f32.u32 	%f2213, %r721;
	add.f32 	%f2214, %f2211, %f2213;
	setp.gt.f32 	%p621, %f2212, 0f3FB504F3;
	mul.f32 	%f2215, %f2212, 0f3F000000;
	add.f32 	%f2216, %f2214, 0f3F800000;
	selp.f32 	%f2217, %f2216, %f2214, %p621;
	selp.f32 	%f2218, %f2215, %f2212, %p621;
	add.f32 	%f2219, %f2218, 0fBF800000;
	add.f32 	%f2220, %f2218, 0f3F800000;
	rcp.approx.ftz.f32 	%f2221, %f2220;
	add.f32 	%f2222, %f2219, %f2219;
	mul.f32 	%f2224, %f2222, %f2221;
	mul.f32 	%f2225, %f2224, %f2224;
	fma.rn.f32 	%f2228, %f1594, %f2225, %f1593;
	fma.rn.f32 	%f2230, %f2228, %f2225, %f1596;
	mul.rn.f32 	%f2231, %f2230, %f2225;
	mul.rn.f32 	%f2232, %f2231, %f2224;
	sub.f32 	%f2233, %f2219, %f2224;
	add.f32 	%f2234, %f2233, %f2233;
	neg.f32 	%f2235, %f2224;
	fma.rn.f32 	%f2236, %f2235, %f2219, %f2234;
	mul.rn.f32 	%f2237, %f2221, %f2236;
	add.f32 	%f2238, %f2232, %f2224;
	sub.f32 	%f2239, %f2224, %f2238;
	add.f32 	%f2240, %f2232, %f2239;
	add.f32 	%f2241, %f2237, %f2240;
	add.f32 	%f2242, %f2238, %f2241;
	sub.f32 	%f2243, %f2238, %f2242;
	add.f32 	%f2244, %f2241, %f2243;
	mul.rn.f32 	%f2246, %f2217, %f1612;
	mul.rn.f32 	%f2248, %f2217, %f1614;
	add.f32 	%f2249, %f2246, %f2242;
	sub.f32 	%f2250, %f2246, %f2249;
	add.f32 	%f2251, %f2242, %f2250;
	add.f32 	%f2252, %f2244, %f2251;
	add.f32 	%f2253, %f2248, %f2252;
	add.f32 	%f2254, %f2249, %f2253;
	sub.f32 	%f2255, %f2249, %f2254;
	add.f32 	%f2256, %f2253, %f2255;
	mul.rn.f32 	%f2257, %f1533, %f2254;
	neg.f32 	%f2258, %f2257;
	fma.rn.f32 	%f2259, %f1533, %f2254, %f2258;
	fma.rn.f32 	%f2260, %f1533, %f2256, %f2259;
	fma.rn.f32 	%f2262, %f2011, %f2254, %f2260;
	add.rn.f32 	%f2263, %f2257, %f2262;
	neg.f32 	%f2264, %f2263;
	add.rn.f32 	%f2265, %f2257, %f2264;
	add.rn.f32 	%f2266, %f2265, %f2262;
	mov.b32 	%r722, %f2263;
	setp.eq.s32 	%p622, %r722, 1118925336;
	add.s32 	%r723, %r722, -1;
	mov.b32 	%f2267, %r723;
	add.f32 	%f2268, %f2266, 0f37000000;
	selp.f32 	%f399, %f2268, %f2266, %p622;
	selp.f32 	%f2269, %f2267, %f2263, %p622;
	mul.rn.f32 	%f2270, %f2269, %f1637;
	cvt.rzi.f32.f32 	%f2271, %f2270;
	abs.f32 	%f2272, %f2271;
	setp.gt.f32 	%p623, %f2272, 0f42FC0000;
	mov.b32 	%r724, %f2271;
	and.b32  	%r725, %r724, -2147483648;
	or.b32  	%r726, %r725, 1123811328;
	mov.b32 	%f2273, %r726;
	selp.f32 	%f2274, %f2273, %f2271, %p623;
	fma.rn.f32 	%f2276, %f2274, %f1643, %f2269;
	fma.rn.f32 	%f2278, %f2274, %f1645, %f2276;
	mul.f32 	%f2279, %f2278, 0f3FB8AA3B;
	add.f32 	%f2280, %f2274, 0f4B40007F;
	mov.b32 	%r727, %f2280;
	shl.b32 	%r728, %r727, 23;
	mov.b32 	%f2281, %r728;
	ex2.approx.ftz.f32 	%f2282, %f2279;
	mul.f32 	%f400, %f2282, %f2281;
	setp.eq.f32 	%p624, %f400, 0f7F800000;
	@%p624 bra 	$L__BB5_394;

	fma.rn.f32 	%f2942, %f400, %f399, %f400;

$L__BB5_394:
	setp.lt.f32 	%p625, %f397, 0f00000000;
	and.pred  	%p37, %p625, %p540;
	setp.eq.f32 	%p627, %f397, 0f00000000;
	@%p627 bra 	$L__BB5_398;
	bra.uni 	$L__BB5_395;

$L__BB5_398:
	add.f32 	%f2287, %f397, %f397;
	selp.f32 	%f2944, %f2287, 0f00000000, %p540;
	bra.uni 	$L__BB5_399;

$L__BB5_395:
	mov.b32 	%r729, %f2942;
	xor.b32  	%r730, %r729, -2147483648;
	mov.b32 	%f2283, %r730;
	selp.f32 	%f2944, %f2283, %f2942, %p37;
	setp.geu.f32 	%p628, %f397, 0f00000000;
	@%p628 bra 	$L__BB5_399;

	cvt.rzi.f32.f32 	%f2285, %f1533;
	setp.eq.f32 	%p629, %f2285, 0f40000000;
	@%p629 bra 	$L__BB5_399;

	mov.f32 	%f2944, 0f7FFFFFFF;

$L__BB5_399:
	add.f32 	%f2288, %f398, 0f40000000;
	mov.b32 	%r731, %f2288;
	setp.lt.s32 	%p631, %r731, 2139095040;
	@%p631 bra 	$L__BB5_404;

	setp.gtu.f32 	%p632, %f398, 0f7F800000;
	@%p632 bra 	$L__BB5_403;
	bra.uni 	$L__BB5_401;

$L__BB5_403:
	add.f32 	%f2944, %f397, 0f40000000;
	bra.uni 	$L__BB5_404;

$L__BB5_401:
	setp.neu.f32 	%p633, %f398, 0f7F800000;
	@%p633 bra 	$L__BB5_404;

	selp.f32 	%f2944, 0fFF800000, 0f7F800000, %p37;

$L__BB5_404:
	mul.f32 	%f2290, %f2944, 0fBF000000;
	setp.eq.f32 	%p634, %f397, 0f3F800000;
	selp.f32 	%f2291, 0fBF000000, %f2290, %p634;
	fma.rn.f32 	%f2294, %f2291, %f1925, %f1526;
	cvt.sat.f32.f32 	%f2297, %f2294;
	fma.rm.f32 	%f2299, %f2297, %f1928, %f1930;
	add.f32 	%f2300, %f2299, 0fCB40007F;
	neg.f32 	%f2301, %f2300;
	fma.rn.f32 	%f2302, %f2291, %f1637, %f2301;
	fma.rn.f32 	%f2304, %f2291, %f1943, %f2302;
	mov.b32 	%r732, %f2299;
	shl.b32 	%r733, %r732, 23;
	mov.b32 	%f2305, %r733;
	ex2.approx.ftz.f32 	%f2306, %f2304;
	mul.f32 	%f409, %f2306, %f2305;
	div.rn.f32 	%f410, %f335, %f2886;
	abs.f32 	%f411, %f410;
	setp.lt.f32 	%p635, %f411, 0f00800000;
	mul.f32 	%f2307, %f411, 0f4B800000;
	selp.f32 	%f2308, %f2307, %f411, %p635;
	selp.f32 	%f2309, 0fC3170000, 0fC2FE0000, %p635;
	mov.b32 	%r734, %f2308;
	and.b32  	%r735, %r734, 8388607;
	or.b32  	%r736, %r735, 1065353216;
	mov.b32 	%f2310, %r736;
	shr.u32 	%r737, %r734, 23;
	cvt.rn.f32.u32 	%f2311, %r737;
	add.f32 	%f2312, %f2309, %f2311;
	setp.gt.f32 	%p636, %f2310, 0f3FB504F3;
	mul.f32 	%f2313, %f2310, 0f3F000000;
	add.f32 	%f2314, %f2312, 0f3F800000;
	selp.f32 	%f2315, %f2314, %f2312, %p636;
	selp.f32 	%f2316, %f2313, %f2310, %p636;
	add.f32 	%f2317, %f2316, 0fBF800000;
	add.f32 	%f2318, %f2316, 0f3F800000;
	rcp.approx.ftz.f32 	%f2319, %f2318;
	add.f32 	%f2320, %f2317, %f2317;
	mul.f32 	%f2322, %f2320, %f2319;
	mul.f32 	%f2323, %f2322, %f2322;
	fma.rn.f32 	%f2326, %f1594, %f2323, %f1593;
	fma.rn.f32 	%f2328, %f2326, %f2323, %f1596;
	mul.rn.f32 	%f2329, %f2328, %f2323;
	mul.rn.f32 	%f2330, %f2329, %f2322;
	sub.f32 	%f2331, %f2317, %f2322;
	add.f32 	%f2332, %f2331, %f2331;
	neg.f32 	%f2333, %f2322;
	fma.rn.f32 	%f2334, %f2333, %f2317, %f2332;
	mul.rn.f32 	%f2335, %f2319, %f2334;
	add.f32 	%f2336, %f2330, %f2322;
	sub.f32 	%f2337, %f2322, %f2336;
	add.f32 	%f2338, %f2330, %f2337;
	add.f32 	%f2339, %f2335, %f2338;
	add.f32 	%f2340, %f2336, %f2339;
	sub.f32 	%f2341, %f2336, %f2340;
	add.f32 	%f2342, %f2339, %f2341;
	mul.rn.f32 	%f2344, %f2315, %f1612;
	mul.rn.f32 	%f2346, %f2315, %f1614;
	add.f32 	%f2347, %f2344, %f2340;
	sub.f32 	%f2348, %f2344, %f2347;
	add.f32 	%f2349, %f2340, %f2348;
	add.f32 	%f2350, %f2342, %f2349;
	add.f32 	%f2351, %f2346, %f2350;
	add.f32 	%f2352, %f2347, %f2351;
	sub.f32 	%f2353, %f2347, %f2352;
	add.f32 	%f2354, %f2351, %f2353;
	mul.rn.f32 	%f2355, %f1533, %f2352;
	neg.f32 	%f2356, %f2355;
	fma.rn.f32 	%f2357, %f1533, %f2352, %f2356;
	fma.rn.f32 	%f2358, %f1533, %f2354, %f2357;
	fma.rn.f32 	%f2360, %f2011, %f2352, %f2358;
	add.rn.f32 	%f2361, %f2355, %f2360;
	neg.f32 	%f2362, %f2361;
	add.rn.f32 	%f2363, %f2355, %f2362;
	add.rn.f32 	%f2364, %f2363, %f2360;
	mov.b32 	%r738, %f2361;
	setp.eq.s32 	%p637, %r738, 1118925336;
	add.s32 	%r739, %r738, -1;
	mov.b32 	%f2365, %r739;
	add.f32 	%f2366, %f2364, 0f37000000;
	selp.f32 	%f412, %f2366, %f2364, %p637;
	selp.f32 	%f2367, %f2365, %f2361, %p637;
	mul.rn.f32 	%f2368, %f2367, %f1637;
	cvt.rzi.f32.f32 	%f2369, %f2368;
	abs.f32 	%f2370, %f2369;
	setp.gt.f32 	%p638, %f2370, 0f42FC0000;
	mov.b32 	%r740, %f2369;
	and.b32  	%r741, %r740, -2147483648;
	or.b32  	%r742, %r741, 1123811328;
	mov.b32 	%f2371, %r742;
	selp.f32 	%f2372, %f2371, %f2369, %p638;
	fma.rn.f32 	%f2374, %f2372, %f1643, %f2367;
	fma.rn.f32 	%f2376, %f2372, %f1645, %f2374;
	mul.f32 	%f2377, %f2376, 0f3FB8AA3B;
	add.f32 	%f2378, %f2372, 0f4B40007F;
	mov.b32 	%r743, %f2378;
	shl.b32 	%r744, %r743, 23;
	mov.b32 	%f2379, %r744;
	ex2.approx.ftz.f32 	%f2380, %f2377;
	mul.f32 	%f413, %f2380, %f2379;
	setp.eq.f32 	%p639, %f413, 0f7F800000;
	mov.f32 	%f2945, 0f7F800000;
	@%p639 bra 	$L__BB5_406;

	fma.rn.f32 	%f2945, %f413, %f412, %f413;

$L__BB5_406:
	setp.lt.f32 	%p640, %f410, 0f00000000;
	and.pred  	%p38, %p640, %p540;
	setp.eq.f32 	%p642, %f410, 0f00000000;
	@%p642 bra 	$L__BB5_410;
	bra.uni 	$L__BB5_407;

$L__BB5_410:
	add.f32 	%f2385, %f410, %f410;
	selp.f32 	%f2947, %f2385, 0f00000000, %p540;
	bra.uni 	$L__BB5_411;

$L__BB5_407:
	mov.b32 	%r745, %f2945;
	xor.b32  	%r746, %r745, -2147483648;
	mov.b32 	%f2381, %r746;
	selp.f32 	%f2947, %f2381, %f2945, %p38;
	setp.geu.f32 	%p643, %f410, 0f00000000;
	@%p643 bra 	$L__BB5_411;

	cvt.rzi.f32.f32 	%f2383, %f1533;
	setp.eq.f32 	%p644, %f2383, 0f40000000;
	@%p644 bra 	$L__BB5_411;

	mov.f32 	%f2947, 0f7FFFFFFF;

$L__BB5_411:
	add.f32 	%f2386, %f411, 0f40000000;
	mov.b32 	%r747, %f2386;
	setp.lt.s32 	%p646, %r747, 2139095040;
	@%p646 bra 	$L__BB5_416;

	setp.gtu.f32 	%p647, %f411, 0f7F800000;
	@%p647 bra 	$L__BB5_415;
	bra.uni 	$L__BB5_413;

$L__BB5_415:
	add.f32 	%f2947, %f410, 0f40000000;
	bra.uni 	$L__BB5_416;

$L__BB5_413:
	setp.neu.f32 	%p648, %f411, 0f7F800000;
	@%p648 bra 	$L__BB5_416;

	selp.f32 	%f2947, 0fFF800000, 0f7F800000, %p38;

$L__BB5_416:
	mul.f32 	%f2387, %f2947, 0fBF000000;
	setp.eq.f32 	%p649, %f410, 0f3F800000;
	selp.f32 	%f2388, 0fBF000000, %f2387, %p649;
	fma.rn.f32 	%f2391, %f2388, %f1925, %f1526;
	cvt.sat.f32.f32 	%f2394, %f2391;
	fma.rm.f32 	%f2396, %f2394, %f1928, %f1930;
	add.f32 	%f2397, %f2396, 0fCB40007F;
	neg.f32 	%f2398, %f2397;
	fma.rn.f32 	%f2399, %f2388, %f1637, %f2398;
	fma.rn.f32 	%f2401, %f2388, %f1943, %f2399;
	mov.b32 	%r748, %f2396;
	shl.b32 	%r749, %r748, 23;
	mov.b32 	%f2402, %r749;
	ex2.approx.ftz.f32 	%f2403, %f2401;
	mul.f32 	%f2404, %f2403, %f2402;
	add.f32 	%f2405, %f335, 0f3F800000;
	mul.f32 	%f2406, %f2405, %f409;
	mul.f32 	%f2407, %f335, %f2404;
	sub.f32 	%f2408, %f2406, %f2407;
	mul.f32 	%f2409, %f260, %f2408;
	fma.rn.f32 	%f2410, %f333, %f2409, %f396;
	mul.f32 	%f2411, %f358, %f358;
	add.f32 	%f422, %f2885, %f346;
	div.rn.f32 	%f2412, %f2411, %f422;
	add.f32 	%f2919, %f2919, %f2412;
	mul.f32 	%f2413, %f395, %f358;
	div.rn.f32 	%f2414, %f2413, %f422;
	add.f32 	%f2918, %f2918, %f2414;
	mul.f32 	%f2415, %f333, %f345;
	mul.f32 	%f2416, %f2415, %f358;
	div.rn.f32 	%f2417, %f2416, %f422;
	add.f32 	%f2917, %f2917, %f2417;
	div.rn.f32 	%f2418, %f358, %f422;
	add.f32 	%f2916, %f2916, %f2418;
	mul.f32 	%f2419, %f2410, %f358;
	div.rn.f32 	%f2420, %f2419, %f422;
	add.f32 	%f2915, %f2915, %f2420;
	mul.f32 	%f2421, %f395, %f395;
	div.rn.f32 	%f2422, %f2421, %f422;
	add.f32 	%f2914, %f2914, %f2422;
	mul.f32 	%f2423, %f2415, %f395;
	div.rn.f32 	%f2424, %f2423, %f422;
	add.f32 	%f2913, %f2913, %f2424;
	div.rn.f32 	%f2425, %f395, %f422;
	add.f32 	%f2912, %f2912, %f2425;
	mul.f32 	%f2426, %f2410, %f395;
	div.rn.f32 	%f2427, %f2426, %f422;
	add.f32 	%f2911, %f2911, %f2427;
	mul.f32 	%f2428, %f2415, %f2415;
	div.rn.f32 	%f2429, %f2428, %f422;
	add.f32 	%f2910, %f2910, %f2429;
	div.rn.f32 	%f2430, %f2415, %f422;
	add.f32 	%f2909, %f2909, %f2430;
	mul.f32 	%f2431, %f2410, %f2415;
	div.rn.f32 	%f2432, %f2431, %f422;
	add.f32 	%f2908, %f2908, %f2432;
	rcp.rn.f32 	%f2433, %f422;
	add.f32 	%f2920, %f2920, %f2433;
	div.rn.f32 	%f2434, %f2410, %f422;
	add.f32 	%f2921, %f2921, %f2434;
	mul.f32 	%f2435, %f2410, %f2410;
	div.rn.f32 	%f2436, %f2435, %f422;
	add.f32 	%f2922, %f2922, %f2436;
	setp.leu.f32 	%p650, %f422, 0f00000000;
	@%p650 bra 	$L__BB5_424;

	add.f32 	%f438, %f2885, %f347;
	setp.gt.f32 	%p651, %f438, 0f00000000;
	@%p651 bra 	$L__BB5_419;
	bra.uni 	$L__BB5_418;

$L__BB5_419:
	setp.lt.f32 	%p652, %f422, 0f00800000;
	mul.f32 	%f2439, %f422, 0f4B000000;
	selp.f32 	%f440, %f2439, %f422, %p652;
	selp.f32 	%f2440, 0fC1B80000, 0f00000000, %p652;
	mov.b32 	%r750, %f440;
	add.s32 	%r751, %r750, -1059760811;
	and.b32  	%r752, %r751, -8388608;
	sub.s32 	%r753, %r750, %r752;
	mov.b32 	%f2441, %r753;
	cvt.rn.f32.s32 	%f2442, %r752;
	mov.f32 	%f2443, 0f34000000;
	fma.rn.f32 	%f2444, %f2442, %f2443, %f2440;
	add.f32 	%f2445, %f2441, 0fBF800000;
	mov.f32 	%f2446, 0f3E1039F6;
	mov.f32 	%f2447, 0fBE055027;
	fma.rn.f32 	%f2448, %f2447, %f2445, %f2446;
	mov.f32 	%f2449, 0fBDF8CDCC;
	fma.rn.f32 	%f2450, %f2448, %f2445, %f2449;
	mov.f32 	%f2451, 0f3E0F2955;
	fma.rn.f32 	%f2452, %f2450, %f2445, %f2451;
	mov.f32 	%f2453, 0fBE2AD8B9;
	fma.rn.f32 	%f2454, %f2452, %f2445, %f2453;
	mov.f32 	%f2455, 0f3E4CED0B;
	fma.rn.f32 	%f2456, %f2454, %f2445, %f2455;
	mov.f32 	%f2457, 0fBE7FFF22;
	fma.rn.f32 	%f2458, %f2456, %f2445, %f2457;
	mov.f32 	%f2459, 0f3EAAAA78;
	fma.rn.f32 	%f2460, %f2458, %f2445, %f2459;
	mov.f32 	%f2461, 0fBF000000;
	fma.rn.f32 	%f2462, %f2460, %f2445, %f2461;
	mul.f32 	%f2463, %f2445, %f2462;
	fma.rn.f32 	%f2464, %f2463, %f2445, %f2445;
	mov.f32 	%f2465, 0f3F317218;
	fma.rn.f32 	%f2948, %f2444, %f2465, %f2464;
	setp.lt.u32 	%p653, %r750, 2139095040;
	@%p653 bra 	$L__BB5_421;

	mov.f32 	%f2466, 0f7F800000;
	fma.rn.f32 	%f2948, %f440, %f2466, %f2466;

$L__BB5_421:
	setp.eq.f32 	%p654, %f440, 0f00000000;
	selp.f32 	%f2467, 0fFF800000, %f2948, %p654;
	mul.f32 	%f2468, %f438, %f2467;
	sub.f32 	%f444, %f2468, %f346;
	mul.f32 	%f2469, %f438, 0f4B000000;
	setp.lt.f32 	%p655, %f438, 0f00800000;
	selp.f32 	%f445, %f2469, %f438, %p655;
	selp.f32 	%f2470, 0fC1B80000, 0f00000000, %p655;
	mov.b32 	%r754, %f445;
	add.s32 	%r755, %r754, -1059760811;
	and.b32  	%r756, %r755, -8388608;
	sub.s32 	%r757, %r754, %r756;
	mov.b32 	%f2471, %r757;
	cvt.rn.f32.s32 	%f2472, %r756;
	fma.rn.f32 	%f2474, %f2472, %f2443, %f2470;
	add.f32 	%f2475, %f2471, 0fBF800000;
	fma.rn.f32 	%f2478, %f2447, %f2475, %f2446;
	fma.rn.f32 	%f2480, %f2478, %f2475, %f2449;
	fma.rn.f32 	%f2482, %f2480, %f2475, %f2451;
	fma.rn.f32 	%f2484, %f2482, %f2475, %f2453;
	fma.rn.f32 	%f2486, %f2484, %f2475, %f2455;
	fma.rn.f32 	%f2488, %f2486, %f2475, %f2457;
	fma.rn.f32 	%f2490, %f2488, %f2475, %f2459;
	fma.rn.f32 	%f2492, %f2490, %f2475, %f2461;
	mul.f32 	%f2493, %f2475, %f2492;
	fma.rn.f32 	%f2494, %f2493, %f2475, %f2475;
	fma.rn.f32 	%f2949, %f2474, %f2465, %f2494;
	setp.lt.u32 	%p656, %r754, 2139095040;
	@%p656 bra 	$L__BB5_423;

	mov.f32 	%f2496, 0f7F800000;
	fma.rn.f32 	%f2949, %f445, %f2496, %f2496;

$L__BB5_423:
	setp.eq.f32 	%p657, %f445, 0f00000000;
	selp.f32 	%f2497, 0fFF800000, %f2949, %p657;
	mul.f32 	%f2498, %f438, %f2497;
	sub.f32 	%f2499, %f444, %f2498;
	add.f32 	%f2500, %f347, %f2499;
	add.f32 	%f2950, %f2950, %f2500;
	bra.uni 	$L__BB5_424;

$L__BB5_418:
	neg.f32 	%f2437, %f346;
	sub.f32 	%f2438, %f2437, %f2885;
	add.f32 	%f2950, %f2950, %f2438;

$L__BB5_424:
	add.s32 	%r788, %r788, 1;
	setp.lt.s32 	%p658, %r788, %r102;
	@%p658 bra 	$L__BB5_340;

	add.s32 	%r787, %r787, 1;
	setp.lt.s32 	%p659, %r787, %r102;
	@%p659 bra 	$L__BB5_339;

$L__BB5_426:
	ld.param.u64 	%rd58, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_9];
	ld.param.u64 	%rd57, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_8];
	ld.param.u32 	%r767, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_10];
	ld.param.u64 	%rd56, [_Z25kernel_MLEFit_SCMOSXYNBS_PKfS0_S0_fiiiPfS1_S1_i_param_7];
	rcp.rn.f32 	%f2501, %f2919;
	mov.f32 	%f2502, 0f3F800000;
	mul.f32 	%f2503, %f2501, %f2918;
	mul.f32 	%f2504, %f2501, %f2917;
	mul.f32 	%f2505, %f2501, %f2916;
	mul.f32 	%f2506, %f2501, %f2915;
	fma.rn.f32 	%f2507, %f2503, %f2918, 0f00000000;
	sub.f32 	%f2509, %f2914, %f2507;
	fma.rn.f32 	%f2510, %f2504, %f2918, 0f00000000;
	rcp.rn.f32 	%f2511, %f2509;
	sub.f32 	%f2512, %f2913, %f2510;
	mul.f32 	%f2513, %f2511, %f2512;
	fma.rn.f32 	%f2514, %f2505, %f2918, 0f00000000;
	sub.f32 	%f2515, %f2912, %f2514;
	mul.f32 	%f2516, %f2511, %f2515;
	fma.rn.f32 	%f2517, %f2506, %f2918, 0f00000000;
	sub.f32 	%f2518, %f2911, %f2517;
	mul.f32 	%f2519, %f2511, %f2518;
	fma.rn.f32 	%f2520, %f2503, %f2917, 0f00000000;
	sub.f32 	%f2521, %f2913, %f2520;
	fma.rn.f32 	%f2522, %f2504, %f2917, 0f00000000;
	fma.rn.f32 	%f2523, %f2513, %f2521, %f2522;
	sub.f32 	%f2524, %f2910, %f2523;
	fma.rn.f32 	%f2525, %f2505, %f2917, 0f00000000;
	fma.rn.f32 	%f2526, %f2516, %f2521, %f2525;
	rcp.rn.f32 	%f2527, %f2524;
	sub.f32 	%f2528, %f2909, %f2526;
	mul.f32 	%f2529, %f2527, %f2528;
	fma.rn.f32 	%f2530, %f2506, %f2917, 0f00000000;
	fma.rn.f32 	%f2531, %f2519, %f2521, %f2530;
	sub.f32 	%f2532, %f2908, %f2531;
	mul.f32 	%f2533, %f2527, %f2532;
	fma.rn.f32 	%f2534, %f2503, %f2916, 0f00000000;
	sub.f32 	%f2535, %f2912, %f2534;
	fma.rn.f32 	%f2536, %f2504, %f2916, 0f00000000;
	fma.rn.f32 	%f2537, %f2513, %f2535, %f2536;
	sub.f32 	%f2538, %f2909, %f2537;
	fma.rn.f32 	%f2539, %f2505, %f2916, 0f00000000;
	fma.rn.f32 	%f2540, %f2516, %f2535, %f2539;
	fma.rn.f32 	%f2541, %f2529, %f2538, %f2540;
	sub.f32 	%f2542, %f2920, %f2541;
	fma.rn.f32 	%f2543, %f2506, %f2916, 0f00000000;
	fma.rn.f32 	%f2544, %f2519, %f2535, %f2543;
	fma.rn.f32 	%f2545, %f2533, %f2538, %f2544;
	rcp.rn.f32 	%f2546, %f2542;
	sub.f32 	%f2547, %f2921, %f2545;
	mul.f32 	%f2548, %f2546, %f2547;
	fma.rn.f32 	%f2549, %f2503, %f2915, 0f00000000;
	sub.f32 	%f2550, %f2911, %f2549;
	fma.rn.f32 	%f2551, %f2504, %f2915, 0f00000000;
	fma.rn.f32 	%f2552, %f2513, %f2550, %f2551;
	sub.f32 	%f2553, %f2908, %f2552;
	fma.rn.f32 	%f2554, %f2505, %f2915, 0f00000000;
	fma.rn.f32 	%f2555, %f2516, %f2550, %f2554;
	fma.rn.f32 	%f2556, %f2529, %f2553, %f2555;
	sub.f32 	%f2557, %f2921, %f2556;
	fma.rn.f32 	%f2558, %f2506, %f2915, 0f00000000;
	fma.rn.f32 	%f2559, %f2519, %f2550, %f2558;
	fma.rn.f32 	%f2560, %f2533, %f2553, %f2559;
	fma.rn.f32 	%f2561, %f2548, %f2557, %f2560;
	sub.f32 	%f2562, %f2922, %f2561;
	add.f32 	%f2563, %f2503, 0f00000000;
	sub.f32 	%f2564, %f1509, %f2563;
	add.f32 	%f2565, %f2504, 0f00000000;
	fma.rn.f32 	%f2566, %f2513, %f2564, %f2565;
	sub.f32 	%f2567, %f1509, %f2566;
	add.f32 	%f2568, %f2505, 0f00000000;
	fma.rn.f32 	%f2569, %f2516, %f2564, %f2568;
	fma.rn.f32 	%f2570, %f2529, %f2567, %f2569;
	sub.f32 	%f2571, %f1509, %f2570;
	add.f32 	%f2572, %f2506, 0f00000000;
	fma.rn.f32 	%f2573, %f2519, %f2564, %f2572;
	fma.rn.f32 	%f2574, %f2533, %f2567, %f2573;
	fma.rn.f32 	%f2575, %f2548, %f2571, %f2574;
	sub.f32 	%f2576, %f1509, %f2575;
	div.rn.f32 	%f2577, %f2576, %f2562;
	fma.rn.f32 	%f2578, %f2557, %f2577, 0f00000000;
	sub.f32 	%f2579, %f2571, %f2578;
	mul.f32 	%f2580, %f2546, %f2579;
	fma.rn.f32 	%f2581, %f2538, %f2580, 0f00000000;
	fma.rn.f32 	%f2582, %f2553, %f2577, %f2581;
	sub.f32 	%f2583, %f2567, %f2582;
	mul.f32 	%f2584, %f2527, %f2583;
	fma.rn.f32 	%f2585, %f2521, %f2584, 0f00000000;
	fma.rn.f32 	%f2586, %f2535, %f2580, %f2585;
	fma.rn.f32 	%f2587, %f2550, %f2577, %f2586;
	sub.f32 	%f2588, %f2564, %f2587;
	mul.f32 	%f2589, %f2511, %f2588;
	fma.rn.f32 	%f2590, %f2918, %f2589, 0f00000000;
	fma.rn.f32 	%f2591, %f2917, %f2584, %f2590;
	fma.rn.f32 	%f2592, %f2916, %f2580, %f2591;
	fma.rn.f32 	%f2593, %f2915, %f2577, %f2592;
	sub.f32 	%f2594, %f2502, %f2593;
	mul.f32 	%f2595, %f2501, %f2594;
	fma.rn.f32 	%f2596, %f2503, 0f00000000, 0f00000000;
	sub.f32 	%f2597, %f2502, %f2596;
	fma.rn.f32 	%f2598, %f2504, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2599, %f2513, %f2597, %f2598;
	sub.f32 	%f2600, %f1509, %f2599;
	fma.rn.f32 	%f2601, %f2505, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2602, %f2516, %f2597, %f2601;
	fma.rn.f32 	%f2603, %f2529, %f2600, %f2602;
	sub.f32 	%f2604, %f1509, %f2603;
	fma.rn.f32 	%f2605, %f2506, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2606, %f2519, %f2597, %f2605;
	fma.rn.f32 	%f2607, %f2533, %f2600, %f2606;
	fma.rn.f32 	%f2608, %f2548, %f2604, %f2607;
	sub.f32 	%f2609, %f1509, %f2608;
	div.rn.f32 	%f2610, %f2609, %f2562;
	fma.rn.f32 	%f2611, %f2557, %f2610, 0f00000000;
	sub.f32 	%f2612, %f2604, %f2611;
	mul.f32 	%f2613, %f2546, %f2612;
	fma.rn.f32 	%f2614, %f2538, %f2613, 0f00000000;
	fma.rn.f32 	%f2615, %f2553, %f2610, %f2614;
	sub.f32 	%f2616, %f2600, %f2615;
	mul.f32 	%f2617, %f2527, %f2616;
	fma.rn.f32 	%f2618, %f2521, %f2617, 0f00000000;
	fma.rn.f32 	%f2619, %f2535, %f2613, %f2618;
	fma.rn.f32 	%f2620, %f2550, %f2610, %f2619;
	sub.f32 	%f2621, %f2597, %f2620;
	mul.f32 	%f2622, %f2511, %f2621;
	sub.f32 	%f2623, %f1509, %f2596;
	fma.rn.f32 	%f2624, %f2513, %f2623, %f2598;
	sub.f32 	%f2625, %f2502, %f2624;
	fma.rn.f32 	%f2626, %f2516, %f2623, %f2601;
	fma.rn.f32 	%f2627, %f2529, %f2625, %f2626;
	sub.f32 	%f2628, %f1509, %f2627;
	fma.rn.f32 	%f2629, %f2519, %f2623, %f2605;
	fma.rn.f32 	%f2630, %f2533, %f2625, %f2629;
	fma.rn.f32 	%f2631, %f2548, %f2628, %f2630;
	sub.f32 	%f2632, %f1509, %f2631;
	div.rn.f32 	%f2633, %f2632, %f2562;
	fma.rn.f32 	%f2634, %f2557, %f2633, 0f00000000;
	sub.f32 	%f2635, %f2628, %f2634;
	mul.f32 	%f2636, %f2546, %f2635;
	fma.rn.f32 	%f2637, %f2538, %f2636, 0f00000000;
	fma.rn.f32 	%f2638, %f2553, %f2633, %f2637;
	sub.f32 	%f2639, %f2625, %f2638;
	mul.f32 	%f2640, %f2527, %f2639;
	sub.f32 	%f2641, %f1509, %f2624;
	fma.rn.f32 	%f2642, %f2529, %f2641, %f2626;
	sub.f32 	%f2643, %f2502, %f2642;
	fma.rn.f32 	%f2644, %f2533, %f2641, %f2629;
	fma.rn.f32 	%f2645, %f2548, %f2643, %f2644;
	sub.f32 	%f2646, %f1509, %f2645;
	div.rn.f32 	%f2647, %f2646, %f2562;
	fma.rn.f32 	%f2648, %f2557, %f2647, 0f00000000;
	sub.f32 	%f2649, %f2643, %f2648;
	mul.f32 	%f2650, %f2546, %f2649;
	sub.f32 	%f2651, %f1509, %f2642;
	fma.rn.f32 	%f2652, %f2548, %f2651, %f2644;
	sub.f32 	%f2653, %f2502, %f2652;
	div.rn.f32 	%f2654, %f2653, %f2562;
	cvta.to.global.u64 	%rd38, %rd56;
	mul.wide.s32 	%rd39, %r1, 4;
	add.s64 	%rd40, %rd38, %rd39;
	st.global.f32 	[%rd40], %f2890;
	add.s32 	%r762, %r1, %r767;
	mul.wide.s32 	%rd41, %r767, 4;
	add.s64 	%rd42, %rd40, %rd41;
	st.global.f32 	[%rd42], %f2889;
	add.s32 	%r763, %r762, %r767;
	shl.b32 	%r764, %r767, 3;
	cvt.s64.s32 	%rd43, %r764;
	add.s64 	%rd44, %rd40, %rd43;
	st.global.f32 	[%rd44], %f2888;
	add.s32 	%r765, %r763, %r767;
	mul.wide.s32 	%rd45, %r765, 4;
	add.s64 	%rd46, %rd38, %rd45;
	st.global.f32 	[%rd46], %f2887;
	add.s64 	%rd47, %rd44, %rd43;
	st.global.f32 	[%rd47], %f2886;
	cvta.to.global.u64 	%rd48, %rd57;
	add.s64 	%rd49, %rd48, %rd39;
	st.global.f32 	[%rd49], %f2595;
	add.s64 	%rd50, %rd49, %rd41;
	st.global.f32 	[%rd50], %f2622;
	add.s64 	%rd51, %rd49, %rd43;
	st.global.f32 	[%rd51], %f2640;
	add.s64 	%rd52, %rd48, %rd45;
	st.global.f32 	[%rd52], %f2650;
	add.s64 	%rd53, %rd51, %rd43;
	st.global.f32 	[%rd53], %f2654;
	cvta.to.global.u64 	%rd54, %rd58;
	add.s64 	%rd55, %rd54, %rd39;
	st.global.f32 	[%rd55], %f2950;

$L__BB5_427:
	ret;

}
	// .globl	_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i
.visible .entry _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i(
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_0,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_1,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_2,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_3,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_4,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_5,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_6,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_7,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_8,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_9,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_10,
	.param .f32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_11,
	.param .u32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_12,
	.param .u32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_13,
	.param .u32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_14,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_15,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_16,
	.param .u64 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_17,
	.param .u32 _Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_18
)
{
	.reg .pred 	%p<1292>;
	.reg .f32 	%f<3376>;
	.reg .b32 	%r<1378>;
	.reg .f64 	%fd<1220>;
	.reg .b64 	%rd<60>;


	ld.param.u64 	%rd4, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_0];
	ld.param.u64 	%rd5, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_1];
	ld.param.u64 	%rd6, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_2];
	ld.param.u64 	%rd7, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_3];
	ld.param.f32 	%f547, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_4];
	ld.param.f32 	%f548, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_5];
	ld.param.f32 	%f549, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_6];
	ld.param.f32 	%f550, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_7];
	ld.param.f32 	%f551, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_8];
	ld.param.f32 	%f552, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_9];
	ld.param.f32 	%f553, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_10];
	ld.param.f32 	%f554, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_11];
	ld.param.u32 	%r182, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_12];
	ld.param.u32 	%r183, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_13];
	ld.param.u32 	%r184, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_14];
	ld.param.u32 	%r185, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_18];
	cvta.to.global.u64 	%rd1, %rd4;
	mov.u32 	%r186, %ntid.x;
	mov.u32 	%r187, %ctaid.x;
	mov.u32 	%r188, %tid.x;
	mad.lo.s32 	%r1, %r187, %r186, %r188;
	setp.ge.s32 	%p79, %r1, %r185;
	@%p79 bra 	$L__BB6_885;

	cvta.to.global.u64 	%rd11, %rd7;
	mul.lo.s32 	%r189, %r182, %r182;
	mul.lo.s32 	%r2, %r189, %r1;
	mul.wide.s32 	%rd12, %r1, 4;
	add.s64 	%rd2, %rd11, %rd12;
	setp.lt.s32 	%p80, %r182, 1;
	mov.f32 	%f557, 0f00000000;
	mov.f32 	%f3202, %f557;
	mov.f32 	%f3203, %f557;
	mov.f32 	%f3204, %f557;
	@%p80 bra 	$L__BB6_11;

	add.s32 	%r3, %r182, -1;
	and.b32  	%r4, %r182, 3;
	sub.s32 	%r5, %r182, %r4;
	shl.b32 	%r6, %r182, 2;
	mov.u32 	%r190, 0;
	setp.lt.u32 	%p81, %r3, 3;
	setp.eq.s32 	%p83, %r4, 0;
	setp.eq.s32 	%p84, %r4, 1;
	setp.eq.s32 	%p85, %r4, 2;
	cvt.s64.s32 	%rd15, %r6;
	mov.u32 	%r1365, %r190;

$L__BB6_3:
	cvt.rn.f32.s32 	%f4, %r1365;
	mov.u32 	%r1368, %r190;
	@%p81 bra 	$L__BB6_6;

	mov.u32 	%r1368, %r190;
	mov.u32 	%r1367, %r5;

$L__BB6_5:
	mad.lo.s32 	%r193, %r1368, %r182, %r1365;
	add.s32 	%r194, %r193, %r2;
	mul.wide.s32 	%rd13, %r194, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.f32 	%f562, [%rd14];
	fma.rn.f32 	%f563, %f562, %f4, %f3202;
	cvt.rn.f32.s32 	%f564, %r1368;
	fma.rn.f32 	%f565, %f562, %f564, %f3203;
	add.f32 	%f566, %f3204, %f562;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.f32 	%f567, [%rd16];
	fma.rn.f32 	%f568, %f567, %f4, %f563;
	add.s32 	%r195, %r1368, 1;
	cvt.rn.f32.s32 	%f569, %r195;
	fma.rn.f32 	%f570, %f567, %f569, %f565;
	add.f32 	%f571, %f566, %f567;
	add.s64 	%rd17, %rd16, %rd15;
	ld.global.f32 	%f572, [%rd17];
	fma.rn.f32 	%f573, %f572, %f4, %f568;
	add.s32 	%r196, %r1368, 2;
	cvt.rn.f32.s32 	%f574, %r196;
	fma.rn.f32 	%f575, %f572, %f574, %f570;
	add.f32 	%f576, %f571, %f572;
	add.s64 	%rd18, %rd17, %rd15;
	ld.global.f32 	%f577, [%rd18];
	fma.rn.f32 	%f3202, %f577, %f4, %f573;
	add.s32 	%r197, %r1368, 3;
	cvt.rn.f32.s32 	%f578, %r197;
	fma.rn.f32 	%f3203, %f577, %f578, %f575;
	add.f32 	%f3204, %f576, %f577;
	add.s32 	%r1368, %r1368, 4;
	add.s32 	%r1367, %r1367, -4;
	setp.ne.s32 	%p82, %r1367, 0;
	@%p82 bra 	$L__BB6_5;

$L__BB6_6:
	@%p83 bra 	$L__BB6_10;

	mad.lo.s32 	%r13, %r1368, %r182, %r1365;
	add.s32 	%r198, %r13, %r2;
	mul.wide.s32 	%rd19, %r198, 4;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.f32 	%f579, [%rd20];
	fma.rn.f32 	%f3202, %f579, %f4, %f3202;
	cvt.rn.f32.s32 	%f580, %r1368;
	fma.rn.f32 	%f3203, %f579, %f580, %f3203;
	add.f32 	%f3204, %f3204, %f579;
	@%p84 bra 	$L__BB6_10;

	add.s32 	%r14, %r13, %r182;
	add.s32 	%r199, %r14, %r2;
	mul.wide.s32 	%rd21, %r199, 4;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.f32 	%f581, [%rd22];
	fma.rn.f32 	%f3202, %f581, %f4, %f3202;
	add.s32 	%r200, %r1368, 1;
	cvt.rn.f32.s32 	%f582, %r200;
	fma.rn.f32 	%f3203, %f581, %f582, %f3203;
	add.f32 	%f3204, %f3204, %f581;
	@%p85 bra 	$L__BB6_10;

	add.s32 	%r201, %r1368, 2;
	add.s32 	%r202, %r14, %r182;
	add.s32 	%r203, %r202, %r2;
	mul.wide.s32 	%rd23, %r203, 4;
	add.s64 	%rd24, %rd1, %rd23;
	ld.global.f32 	%f583, [%rd24];
	fma.rn.f32 	%f3202, %f583, %f4, %f3202;
	cvt.rn.f32.s32 	%f584, %r201;
	fma.rn.f32 	%f3203, %f583, %f584, %f3203;
	add.f32 	%f3204, %f3204, %f583;

$L__BB6_10:
	add.s32 	%r1365, %r1365, 1;
	setp.lt.s32 	%p86, %r1365, %r182;
	@%p86 bra 	$L__BB6_3;

$L__BB6_11:
	div.rn.f32 	%f3295, %f3202, %f3204;
	div.rn.f32 	%f3294, %f3203, %f3204;
	mov.f32 	%f3292, 0f51BA43B7;
	mov.f32 	%f3211, %f557;
	@%p80 bra 	$L__BB6_51;

	mov.f32 	%f589, 0f3F000000;
	div.rn.f32 	%f590, %f589, %f547;
	div.rn.f32 	%f591, %f590, %f547;
	cvt.f64.f32 	%fd1, %f591;
	mov.f64 	%fd553, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd553;
	}
	and.b32  	%r17, %r16, 2146435072;
	and.b32  	%r18, %r16, 2147483647;
	setp.gt.s32 	%p88, %r16, -1;
	selp.b32 	%r19, 2146435072, 0, %p88;
	mov.u32 	%r204, 0;
	or.b32  	%r20, %r19, -2147483648;
	setp.eq.s32 	%p90, %r17, 1062207488;
	setp.lt.s32 	%p91, %r16, 0;
	setp.ne.s32 	%p96, %r18, 1071644672;
	setp.eq.s32 	%p123, %r18, 2146435072;
	mov.u32 	%r1369, %r204;
	mov.f32 	%f3211, %f557;

$L__BB6_13:
	mov.u32 	%r1370, %r204;

$L__BB6_14:
	mov.f32 	%f3214, 0f00000000;
	mov.f32 	%f3215, %f3214;
	mov.u32 	%r1371, %r204;

$L__BB6_15:
	sub.s32 	%r24, %r1371, %r1369;
	cvt.rn.f32.s32 	%f594, %r24;
	cvt.f64.f32 	%fd2, %f594;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd2;
	}
	abs.f64 	%fd554, %fd2;
	{ // callseq 112, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd554;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd553;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 112
	setp.lt.s32 	%p89, %r25, 0;
	and.pred  	%p1, %p89, %p90;
	selp.b32 	%r208, %r25, 0, %p90;
	or.b32  	%r209, %r208, 2146435072;
	selp.b32 	%r26, %r209, %r208, %p91;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r210}, %fd4;
	}
	and.b32  	%r27, %r210, 2146435072;
	setp.ne.s32 	%p92, %r27, 2146435072;
	setp.gtu.f64 	%p93, %fd554, 0d7FF0000000000000;
	setp.gt.f64 	%p94, %fd554, 0d3FF0000000000000;
	selp.b32 	%r211, 2146435072, 0, %p94;
	xor.b32  	%r212, %r211, 2146435072;
	selp.b32 	%r213, %r212, %r211, %p91;
	setp.eq.s32 	%p95, %r24, -1;
	selp.b32 	%r28, 1072693248, %r213, %p95;
	and.b32  	%r29, %r25, 2147483647;
	and.pred  	%p97, %p96, %p1;
	selp.b32 	%r30, %r20, %r19, %p97;
	mul.lo.s32 	%r31, %r1371, %r182;
	or.pred  	%p2, %p92, %p93;
	mov.u32 	%r1372, %r204;

$L__BB6_16:
	not.pred 	%p98, %p1;
	mov.f64 	%fd1071, %fd3;
	@%p98 bra 	$L__BB6_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd3;
	}
	xor.b32  	%r215, %r214, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r216, %temp}, %fd3;
	}
	mov.b64 	%fd1071, {%r216, %r215};

$L__BB6_18:
	setp.eq.s32 	%p99, %r24, 0;
	@%p99 bra 	$L__BB6_22;

	setp.gt.s32 	%p100, %r25, -1;
	@%p100 bra 	$L__BB6_23;

	cvt.rzi.f64.f64 	%fd557, %fd553;
	setp.eq.f64 	%p101, %fd557, 0d4000000000000000;
	@%p101 bra 	$L__BB6_23;

	mov.f64 	%fd1071, 0dFFF8000000000000;
	bra.uni 	$L__BB6_23;

$L__BB6_22:
	mov.u32 	%r217, 0;
	mov.b64 	%fd1071, {%r217, %r26};

$L__BB6_23:
	selp.f64 	%fd1072, %fd1071, %fd4, %p92;
	@%p2 bra 	$L__BB6_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r218, %temp}, %fd553;
	}
	setp.eq.s32 	%p104, %r218, 0;
	and.pred  	%p105, %p123, %p104;
	@%p105 bra 	$L__BB6_27;
	bra.uni 	$L__BB6_25;

$L__BB6_27:
	mov.u32 	%r221, 0;
	mov.b64 	%fd1072, {%r221, %r28};
	bra.uni 	$L__BB6_28;

$L__BB6_25:
	setp.ne.s32 	%p106, %r29, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r219, %temp}, %fd2;
	}
	setp.ne.s32 	%p107, %r219, 0;
	or.pred  	%p108, %p106, %p107;
	mov.f64 	%fd1072, %fd1071;
	@%p108 bra 	$L__BB6_28;

	mov.u32 	%r220, 0;
	mov.b64 	%fd1072, {%r220, %r30};

$L__BB6_28:
	setp.eq.s32 	%p109, %r24, 1;
	selp.f64 	%fd560, 0d3FF0000000000000, %fd1072, %p109;
	mov.f64 	%fd561, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd560, %fd1;
	neg.f64 	%fd562, %fd13;
	mov.f64 	%fd563, 0d4338000000000000;
	mov.f64 	%fd564, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd565, %fd562, %fd564, %fd563;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd565;
	}
	mov.f64 	%fd566, 0dC338000000000000;
	add.rn.f64 	%fd567, %fd565, %fd566;
	mov.f64 	%fd568, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd569, %fd567, %fd568, %fd562;
	mov.f64 	%fd570, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd571, %fd567, %fd570, %fd569;
	mov.f64 	%fd572, 0d3E928AF3FCA213EA;
	mov.f64 	%fd573, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd574, %fd573, %fd571, %fd572;
	mov.f64 	%fd575, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd576, %fd574, %fd571, %fd575;
	mov.f64 	%fd577, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd578, %fd576, %fd571, %fd577;
	mov.f64 	%fd579, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd580, %fd578, %fd571, %fd579;
	mov.f64 	%fd581, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd582, %fd580, %fd571, %fd581;
	mov.f64 	%fd583, 0d3F81111111122322;
	fma.rn.f64 	%fd584, %fd582, %fd571, %fd583;
	mov.f64 	%fd585, 0d3FA55555555502A1;
	fma.rn.f64 	%fd586, %fd584, %fd571, %fd585;
	mov.f64 	%fd587, 0d3FC5555555555511;
	fma.rn.f64 	%fd588, %fd586, %fd571, %fd587;
	mov.f64 	%fd589, 0d3FE000000000000B;
	fma.rn.f64 	%fd590, %fd588, %fd571, %fd589;
	fma.rn.f64 	%fd591, %fd590, %fd571, %fd561;
	fma.rn.f64 	%fd592, %fd591, %fd571, %fd561;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd592;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd592;
	}
	shl.b32 	%r222, %r33, 20;
	add.s32 	%r223, %r35, %r222;
	mov.b64 	%fd1073, {%r34, %r223};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r224}, %fd562;
	}
	mov.b32 	%f595, %r224;
	abs.f32 	%f42, %f595;
	setp.lt.f32 	%p110, %f42, 0f4086232B;
	@%p110 bra 	$L__BB6_31;

	setp.gt.f64 	%p111, %fd13, 0d8000000000000000;
	mov.f64 	%fd593, 0d7FF0000000000000;
	sub.f64 	%fd594, %fd593, %fd13;
	selp.f64 	%fd1073, 0d0000000000000000, %fd594, %p111;
	setp.geu.f32 	%p112, %f42, 0f40874800;
	@%p112 bra 	$L__BB6_31;

	shr.u32 	%r225, %r33, 31;
	add.s32 	%r226, %r33, %r225;
	shr.s32 	%r227, %r226, 1;
	shl.b32 	%r228, %r227, 20;
	add.s32 	%r229, %r35, %r228;
	mov.b64 	%fd595, {%r34, %r229};
	sub.s32 	%r230, %r33, %r227;
	shl.b32 	%r231, %r230, 20;
	add.s32 	%r232, %r231, 1072693248;
	mov.u32 	%r233, 0;
	mov.b64 	%fd596, {%r233, %r232};
	mul.f64 	%fd1073, %fd595, %fd596;

$L__BB6_31:
	sub.s32 	%r36, %r1370, %r1372;
	cvt.rn.f32.s32 	%f596, %r36;
	cvt.f64.f32 	%fd18, %f596;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 113, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd553;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1075, [retval0+0];
	} // callseq 113
	setp.lt.s32 	%p113, %r37, 0;
	and.pred  	%p3, %p113, %p90;
	not.pred 	%p115, %p3;
	@%p115 bra 	$L__BB6_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r234}, %fd1075;
	}
	xor.b32  	%r235, %r234, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r236, %temp}, %fd1075;
	}
	mov.b64 	%fd1075, {%r236, %r235};

$L__BB6_33:
	setp.eq.s32 	%p116, %r36, 0;
	@%p116 bra 	$L__BB6_37;

	setp.gt.s32 	%p117, %r37, -1;
	@%p117 bra 	$L__BB6_38;

	cvt.rzi.f64.f64 	%fd599, %fd553;
	setp.eq.f64 	%p118, %fd599, 0d4000000000000000;
	@%p118 bra 	$L__BB6_38;

	mov.f64 	%fd1075, 0dFFF8000000000000;
	bra.uni 	$L__BB6_38;

$L__BB6_37:
	mov.u32 	%r237, 0;
	selp.b32 	%r238, %r37, 0, %p90;
	or.b32  	%r239, %r238, 2146435072;
	selp.b32 	%r240, %r239, %r238, %p91;
	mov.b64 	%fd1075, {%r237, %r240};

$L__BB6_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r241}, %fd25;
	}
	and.b32  	%r242, %r241, 2146435072;
	setp.ne.s32 	%p121, %r242, 2146435072;
	mov.f64 	%fd1076, %fd1075;
	@%p121 bra 	$L__BB6_44;

	setp.gtu.f64 	%p122, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd1076, %fd25;
	@%p122 bra 	$L__BB6_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r243, %temp}, %fd553;
	}
	setp.eq.s32 	%p124, %r243, 0;
	and.pred  	%p125, %p123, %p124;
	@%p125 bra 	$L__BB6_43;
	bra.uni 	$L__BB6_41;

$L__BB6_43:
	mov.u32 	%r248, 0;
	setp.gt.f64 	%p132, %fd19, 0d3FF0000000000000;
	selp.b32 	%r249, 2146435072, 0, %p132;
	xor.b32  	%r250, %r249, 2146435072;
	selp.b32 	%r251, %r250, %r249, %p91;
	setp.eq.s32 	%p133, %r36, -1;
	selp.b32 	%r252, 1072693248, %r251, %p133;
	mov.b64 	%fd1076, {%r248, %r252};
	bra.uni 	$L__BB6_44;

$L__BB6_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r244, %temp}, %fd18;
	}
	and.b32  	%r245, %r37, 2147483647;
	setp.ne.s32 	%p126, %r245, 2146435072;
	setp.ne.s32 	%p127, %r244, 0;
	or.pred  	%p128, %p126, %p127;
	mov.f64 	%fd1076, %fd1075;
	@%p128 bra 	$L__BB6_44;

	and.pred  	%p130, %p96, %p3;
	selp.b32 	%r246, %r20, %r19, %p130;
	mov.u32 	%r247, 0;
	mov.b64 	%fd1076, {%r247, %r246};

$L__BB6_44:
	setp.eq.s32 	%p134, %r36, 1;
	selp.f64 	%fd602, 0d3FF0000000000000, %fd1076, %p134;
	mul.f64 	%fd29, %fd602, %fd1;
	neg.f64 	%fd604, %fd29;
	fma.rn.f64 	%fd607, %fd604, %fd564, %fd563;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd607;
	}
	add.rn.f64 	%fd609, %fd607, %fd566;
	fma.rn.f64 	%fd611, %fd609, %fd568, %fd604;
	fma.rn.f64 	%fd613, %fd609, %fd570, %fd611;
	fma.rn.f64 	%fd616, %fd573, %fd613, %fd572;
	fma.rn.f64 	%fd618, %fd616, %fd613, %fd575;
	fma.rn.f64 	%fd620, %fd618, %fd613, %fd577;
	fma.rn.f64 	%fd622, %fd620, %fd613, %fd579;
	fma.rn.f64 	%fd624, %fd622, %fd613, %fd581;
	fma.rn.f64 	%fd626, %fd624, %fd613, %fd583;
	fma.rn.f64 	%fd628, %fd626, %fd613, %fd585;
	fma.rn.f64 	%fd630, %fd628, %fd613, %fd587;
	fma.rn.f64 	%fd632, %fd630, %fd613, %fd589;
	fma.rn.f64 	%fd633, %fd632, %fd613, %fd561;
	fma.rn.f64 	%fd634, %fd633, %fd613, %fd561;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd634;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd634;
	}
	shl.b32 	%r253, %r38, 20;
	add.s32 	%r254, %r40, %r253;
	mov.b64 	%fd1077, {%r39, %r254};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r255}, %fd604;
	}
	mov.b32 	%f597, %r255;
	abs.f32 	%f43, %f597;
	setp.lt.f32 	%p135, %f43, 0f4086232B;
	@%p135 bra 	$L__BB6_47;

	setp.gt.f64 	%p136, %fd29, 0d8000000000000000;
	mov.f64 	%fd635, 0d7FF0000000000000;
	sub.f64 	%fd636, %fd635, %fd29;
	selp.f64 	%fd1077, 0d0000000000000000, %fd636, %p136;
	setp.geu.f32 	%p137, %f43, 0f40874800;
	@%p137 bra 	$L__BB6_47;

	shr.u32 	%r256, %r38, 31;
	add.s32 	%r257, %r38, %r256;
	shr.s32 	%r258, %r257, 1;
	shl.b32 	%r259, %r258, 20;
	add.s32 	%r260, %r40, %r259;
	mov.b64 	%fd637, {%r39, %r260};
	sub.s32 	%r261, %r38, %r258;
	shl.b32 	%r262, %r261, 20;
	add.s32 	%r263, %r262, 1072693248;
	mov.u32 	%r264, 0;
	mov.b64 	%fd638, {%r264, %r263};
	mul.f64 	%fd1077, %fd637, %fd638;

$L__BB6_47:
	add.s32 	%r265, %r1372, %r31;
	add.s32 	%r266, %r265, %r2;
	mul.wide.s32 	%rd25, %r266, 4;
	add.s64 	%rd26, %rd1, %rd25;
	ld.global.f32 	%f598, [%rd26];
	cvt.f64.f32 	%fd639, %f598;
	mul.f64 	%fd640, %fd1073, %fd1077;
	cvt.f64.f32 	%fd641, %f3215;
	fma.rn.f64 	%fd642, %fd640, %fd639, %fd641;
	cvt.rn.f32.f64 	%f3215, %fd642;
	cvt.f64.f32 	%fd643, %f3214;
	add.f64 	%fd644, %fd640, %fd643;
	cvt.rn.f32.f64 	%f3214, %fd644;
	add.s32 	%r1372, %r1372, 1;
	setp.lt.s32 	%p138, %r1372, %r182;
	@%p138 bra 	$L__BB6_16;

	add.s32 	%r1371, %r1371, 1;
	setp.lt.s32 	%p139, %r1371, %r182;
	@%p139 bra 	$L__BB6_15;

	div.rn.f32 	%f599, %f3215, %f3214;
	max.f32 	%f3211, %f3211, %f599;
	min.f32 	%f3292, %f3292, %f599;
	add.s32 	%r1370, %r1370, 1;
	setp.lt.s32 	%p140, %r1370, %r182;
	@%p140 bra 	$L__BB6_14;

	add.s32 	%r1369, %r1369, 1;
	setp.lt.s32 	%p141, %r1369, %r182;
	@%p141 bra 	$L__BB6_13;

$L__BB6_51:
	sub.f32 	%f601, %f3211, %f3292;
	add.f32 	%f602, %f601, %f601;
	mul.f32 	%f603, %f602, 0f40490FD8;
	mul.f32 	%f604, %f603, %f547;
	mul.f32 	%f605, %f604, %f554;
	mul.f32 	%f606, %f605, 0f3FB504F3;
	max.f32 	%f3293, %f557, %f606;
	ld.global.f32 	%f3291, [%rd2];
	setp.lt.s32 	%p142, %r184, 1;
	@%p142 bra 	$L__BB6_623;

	mul.f32 	%f52, %f547, 0f3F000000;
	mul.f32 	%f53, %f554, 0f3F000000;
	mul.f32 	%f609, %f548, 0f40400000;
	cvt.f64.f32 	%fd34, %f609;
	mul.f32 	%f54, %f553, %f553;
	mul.f32 	%f55, %f54, %f553;
	mul.f32 	%f610, %f550, 0f40800000;
	cvt.f64.f32 	%fd35, %f610;
	cvt.f64.f32 	%fd645, %f553;
	add.f64 	%fd36, %fd645, 0d4010000000000000;
	mul.f32 	%f611, %f549, 0f40400000;
	cvt.f64.f32 	%fd37, %f611;
	mul.f32 	%f612, %f551, 0f40800000;
	cvt.f64.f32 	%fd38, %f612;
	mul.f32 	%f56, %f547, 0fBE800000;
	mul.f32 	%f57, %f554, 0fBE800000;
	mov.f32 	%f613, 0f40000000;
	div.rn.f32 	%f58, %f613, %f54;
	mul.f32 	%f59, %f548, 0f40C00000;
	mul.f32 	%f614, %f550, 0f41400000;
	cvt.f64.f32 	%fd39, %f614;
	mul.f32 	%f60, %f549, 0f40C00000;
	mul.f32 	%f615, %f551, 0f41400000;
	cvt.f64.f32 	%fd40, %f615;
	cvt.rn.f32.s32 	%f61, %r183;
	mov.u32 	%r1373, 0;
	cvta.to.global.u64 	%rd27, %rd5;
	setp.eq.f32 	%p193, %f553, 0fBF800000;
	cvta.to.global.u64 	%rd33, %rd6;

$L__BB6_53:
	mov.f32 	%f3234, 0f00000000;
	mov.f32 	%f3235, %f3234;
	mov.f32 	%f3236, %f3234;
	mov.f32 	%f3237, %f3234;
	mov.f32 	%f3238, %f3234;
	mov.f32 	%f3239, %f3234;
	mov.f32 	%f3240, %f3234;
	mov.f32 	%f3241, %f3234;
	mov.f32 	%f3242, %f3234;
	mov.f32 	%f3243, %f3234;
	@%p80 bra 	$L__BB6_622;

	sub.f32 	%f68, %f3291, %f552;
	div.rn.f32 	%f69, %f68, %f553;
	cvt.f64.f32 	%fd41, %f69;
	add.f32 	%f70, %f3291, %f552;
	div.rn.f32 	%f71, %f70, %f553;
	cvt.f64.f32 	%fd42, %f71;
	div.rn.f32 	%f72, %f3293, 0fC0206C98;
	div.rn.f32 	%f636, %f3293, 0f40206C98;
	cvt.f64.f32 	%fd43, %f636;
	add.f32 	%f637, %f68, %f68;
	div.rn.f32 	%f638, %f637, %f54;
	cvt.f64.f32 	%fd44, %f638;
	cvt.f64.f32 	%fd45, %f68;
	add.f64 	%fd46, %fd45, 0d4000000000000000;
	add.f64 	%fd47, %fd45, 0d4008000000000000;
	add.f32 	%f639, %f70, %f70;
	div.rn.f32 	%f640, %f639, %f54;
	cvt.f64.f32 	%fd48, %f640;
	cvt.f64.f32 	%fd49, %f70;
	add.f64 	%fd50, %fd49, 0d4000000000000000;
	add.f64 	%fd51, %fd49, 0d4008000000000000;
	mul.f32 	%f641, %f59, %f68;
	div.rn.f32 	%f642, %f641, %f55;
	add.f32 	%f643, %f58, %f642;
	cvt.f64.f32 	%fd52, %f643;
	mul.f32 	%f644, %f60, %f70;
	div.rn.f32 	%f645, %f644, %f55;
	add.f32 	%f646, %f58, %f645;
	cvt.f64.f32 	%fd53, %f646;
	shl.b32 	%r273, %r1, 1;
	mul.wide.s32 	%rd28, %r273, 4;
	add.s64 	%rd29, %rd27, %rd28;
	ld.global.f32 	%f73, [%rd29+4];
	ld.global.f32 	%f74, [%rd29];
	mov.u32 	%r1374, 0;

$L__BB6_55:
	cvt.f64.f32 	%fd1052, %f69;
	cvt.f64.f32 	%fd1051, %f71;
	mov.u32 	%r1375, 0;
	add.f32 	%f3069, %f3291, %f552;
	sub.f32 	%f3068, %f3291, %f552;
	mov.f64 	%fd646, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd646;
	}
	and.b32  	%r48, %r47, 2146435072;
	setp.eq.s32 	%p144, %r48, 1062207488;
	abs.f64 	%fd647, %fd1052;
	{ // callseq 114, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd647;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd54, [retval0+0];
	} // callseq 114
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd1052;
	}
	setp.lt.s32 	%p145, %r49, 0;
	and.pred  	%p4, %p145, %p144;
	setp.lt.s32 	%p146, %r47, 0;
	add.f64 	%fd648, %fd1052, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r275}, %fd648;
	}
	and.b32  	%r50, %r275, 2146435072;
	setp.ne.s32 	%p147, %r50, 2146435072;
	setp.gtu.f64 	%p148, %fd647, 0d7FF0000000000000;
	mov.f64 	%fd649, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd649;
	}
	and.b32  	%r52, %r51, 2146435072;
	setp.eq.s32 	%p149, %r52, 1073741824;
	{ // callseq 115, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd647;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd55, [retval0+0];
	} // callseq 115
	and.pred  	%p5, %p145, %p149;
	and.b32  	%r53, %r47, 2147483647;
	setp.gt.f64 	%p150, %fd647, 0d3FF0000000000000;
	selp.b32 	%r276, 2146435072, 0, %p150;
	xor.b32  	%r277, %r276, 2146435072;
	selp.b32 	%r278, %r277, %r276, %p146;
	setp.eq.f32 	%p151, %f69, 0fBF800000;
	selp.b32 	%r54, 1072693248, %r278, %p151;
	setp.lt.s32 	%p152, %r51, 0;
	add.f64 	%fd650, %fd1052, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r279}, %fd650;
	}
	and.b32  	%r55, %r279, 2146435072;
	setp.ne.s32 	%p153, %r55, 2146435072;
	setp.gt.s32 	%p154, %r47, -1;
	selp.b32 	%r56, 2146435072, 0, %p154;
	setp.ne.s32 	%p155, %r53, 1071644672;
	or.b32  	%r57, %r56, -2147483648;
	mov.f64 	%fd651, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r280}, %fd651;
	}
	and.b32  	%r281, %r280, 2146435072;
	setp.eq.s32 	%p156, %r281, 1072693248;
	{ // callseq 116, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd647;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd651;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd56, [retval0+0];
	} // callseq 116
	and.pred  	%p6, %p145, %p156;
	and.b32  	%r58, %r51, 2147483647;
	selp.b32 	%r282, %r277, %r276, %p152;
	selp.b32 	%r59, 1072693248, %r282, %p151;
	selp.b32 	%r283, %r49, 0, %p156;
	setp.lt.s32 	%p157, %r280, 0;
	or.b32  	%r284, %r283, 2146435072;
	selp.b32 	%r60, %r284, %r283, %p157;
	add.f64 	%fd652, %fd1052, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r285}, %fd652;
	}
	and.b32  	%r61, %r285, 2146435072;
	setp.ne.s32 	%p158, %r61, 2146435072;
	setp.gt.s32 	%p159, %r51, -1;
	selp.b32 	%r62, 2146435072, 0, %p159;
	or.b32  	%r63, %r62, -2147483648;
	abs.f64 	%fd653, %fd1051;
	{ // callseq 117, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd653;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd57, [retval0+0];
	} // callseq 117
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd1051;
	}
	setp.lt.s32 	%p160, %r64, 0;
	and.pred  	%p7, %p160, %p144;
	and.b32  	%r65, %r280, 2147483647;
	selp.b32 	%r286, %r277, %r276, %p157;
	selp.b32 	%r66, 1072693248, %r286, %p151;
	add.f64 	%fd654, %fd1051, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r287}, %fd654;
	}
	and.b32  	%r67, %r287, 2146435072;
	setp.ne.s32 	%p161, %r67, 2146435072;
	setp.gt.s32 	%p162, %r280, -1;
	selp.b32 	%r288, 2146435072, 0, %p162;
	setp.ne.s32 	%p163, %r65, 1071644672;
	and.pred  	%p164, %p163, %p6;
	or.b32  	%r289, %r288, -2147483648;
	selp.b32 	%r68, %r289, %r288, %p164;
	setp.gtu.f64 	%p165, %fd653, 0d7FF0000000000000;
	{ // callseq 118, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd653;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd58, [retval0+0];
	} // callseq 118
	and.pred  	%p8, %p160, %p149;
	setp.gt.f64 	%p166, %fd653, 0d3FF0000000000000;
	selp.b32 	%r290, 2146435072, 0, %p166;
	xor.b32  	%r291, %r290, 2146435072;
	selp.b32 	%r292, %r291, %r290, %p146;
	setp.eq.f32 	%p167, %f71, 0fBF800000;
	selp.b32 	%r69, 1072693248, %r292, %p167;
	add.f64 	%fd655, %fd1051, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r293}, %fd655;
	}
	and.b32  	%r70, %r293, 2146435072;
	setp.ne.s32 	%p168, %r70, 2146435072;
	{ // callseq 119, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd653;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd651;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd59, [retval0+0];
	} // callseq 119
	and.pred  	%p9, %p160, %p156;
	selp.b32 	%r294, %r291, %r290, %p152;
	selp.b32 	%r71, 1072693248, %r294, %p167;
	selp.b32 	%r295, %r64, 0, %p156;
	or.b32  	%r296, %r295, 2146435072;
	selp.b32 	%r72, %r296, %r295, %p157;
	add.f64 	%fd656, %fd1051, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r297}, %fd656;
	}
	and.b32  	%r73, %r297, 2146435072;
	setp.ne.s32 	%p169, %r73, 2146435072;
	cvt.rn.f32.s32 	%f85, %r1374;
	sub.f32 	%f86, %f85, %f3295;
	add.f32 	%f87, %f86, 0f3F000000;
	add.f32 	%f88, %f86, 0fBF000000;
	selp.b32 	%r298, %r291, %r290, %p157;
	selp.b32 	%r74, 1072693248, %r298, %p167;
	and.pred  	%p170, %p163, %p9;
	selp.b32 	%r75, %r289, %r288, %p170;
	cvt.f64.f32 	%fd60, %f87;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd60;
	}
	abs.f64 	%fd657, %fd60;
	{ // callseq 120, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd657;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd61, [retval0+0];
	} // callseq 120
	setp.lt.s32 	%p171, %r76, 0;
	and.pred  	%p10, %p171, %p149;
	add.f64 	%fd62, %fd60, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r299}, %fd62;
	}
	and.b32  	%r77, %r299, 2146435072;
	setp.ne.s32 	%p172, %r77, 2146435072;
	mov.f64 	%fd658, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd658;
	}
	setp.gtu.f64 	%p173, %fd657, 0d7FF0000000000000;
	cvt.f64.f32 	%fd63, %f88;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd63;
	}
	abs.f64 	%fd659, %fd63;
	{ // callseq 121, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd659;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd64, [retval0+0];
	} // callseq 121
	setp.lt.s32 	%p174, %r79, 0;
	and.pred  	%p11, %p174, %p149;
	setp.gt.f64 	%p175, %fd657, 0d3FF0000000000000;
	selp.b32 	%r300, 2146435072, 0, %p175;
	xor.b32  	%r301, %r300, 2146435072;
	selp.b32 	%r302, %r301, %r300, %p152;
	setp.eq.f32 	%p176, %f87, 0fBF800000;
	selp.b32 	%r80, 1072693248, %r302, %p176;
	add.f64 	%fd65, %fd63, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r303}, %fd65;
	}
	and.b32  	%r81, %r303, 2146435072;
	setp.ne.s32 	%p177, %r81, 2146435072;
	setp.gtu.f64 	%p178, %fd659, 0d7FF0000000000000;
	setp.gt.f64 	%p179, %fd659, 0d3FF0000000000000;
	selp.b32 	%r304, 2146435072, 0, %p179;
	xor.b32  	%r305, %r304, 2146435072;
	selp.b32 	%r306, %r305, %r304, %p152;
	setp.eq.f32 	%p180, %f88, 0fBF800000;
	selp.b32 	%r82, 1072693248, %r306, %p180;
	abs.f64 	%fd660, %fd45;
	{ // callseq 122, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd660;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd66, [retval0+0];
	} // callseq 122
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd45;
	}
	setp.lt.s32 	%p181, %r83, 0;
	and.pred  	%p12, %p181, %p144;
	selp.b32 	%r307, %r83, 0, %p144;
	or.b32  	%r308, %r307, 2146435072;
	selp.b32 	%r84, %r308, %r307, %p146;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r309}, %fd46;
	}
	and.b32  	%r85, %r309, 2146435072;
	setp.ne.s32 	%p182, %r85, 2146435072;
	setp.gtu.f64 	%p183, %fd660, 0d7FF0000000000000;
	{ // callseq 123, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd660;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd67, [retval0+0];
	} // callseq 123
	and.pred  	%p13, %p181, %p149;
	setp.gt.f64 	%p184, %fd660, 0d3FF0000000000000;
	selp.b32 	%r310, 2146435072, 0, %p184;
	xor.b32  	%r311, %r310, 2146435072;
	selp.b32 	%r312, %r311, %r310, %p146;
	setp.eq.f32 	%p185, %f3068, 0fBF800000;
	selp.b32 	%r86, 1072693248, %r312, %p185;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r313}, %fd47;
	}
	and.b32  	%r87, %r313, 2146435072;
	setp.ne.s32 	%p186, %r87, 2146435072;
	and.pred  	%p187, %p155, %p12;
	selp.b32 	%r88, %r57, %r56, %p187;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r89}, %fd645;
	}
	abs.f64 	%fd662, %fd645;
	{ // callseq 124, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd662;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd651;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd68, [retval0+0];
	} // callseq 124
	setp.lt.s32 	%p188, %r89, 0;
	and.pred  	%p14, %p188, %p156;
	selp.b32 	%r314, %r311, %r310, %p152;
	selp.b32 	%r90, 1072693248, %r314, %p185;
	selp.b32 	%r315, %r89, 0, %p156;
	or.b32  	%r316, %r315, 2146435072;
	selp.b32 	%r91, %r316, %r315, %p157;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r317}, %fd36;
	}
	and.b32  	%r92, %r317, 2146435072;
	setp.ne.s32 	%p189, %r92, 2146435072;
	setp.gtu.f64 	%p190, %fd662, 0d7FF0000000000000;
	abs.f64 	%fd663, %fd49;
	{ // callseq 125, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd663;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd69, [retval0+0];
	} // callseq 125
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r93}, %fd49;
	}
	setp.lt.s32 	%p191, %r93, 0;
	and.pred  	%p15, %p191, %p144;
	setp.gt.f64 	%p192, %fd662, 0d3FF0000000000000;
	selp.b32 	%r318, 2146435072, 0, %p192;
	xor.b32  	%r319, %r318, 2146435072;
	selp.b32 	%r320, %r319, %r318, %p157;
	selp.b32 	%r94, 1072693248, %r320, %p193;
	selp.b32 	%r321, %r93, 0, %p144;
	or.b32  	%r322, %r321, 2146435072;
	selp.b32 	%r95, %r322, %r321, %p146;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r323}, %fd50;
	}
	and.b32  	%r96, %r323, 2146435072;
	setp.ne.s32 	%p194, %r96, 2146435072;
	and.pred  	%p195, %p163, %p14;
	selp.b32 	%r97, %r289, %r288, %p195;
	setp.gtu.f64 	%p196, %fd663, 0d7FF0000000000000;
	{ // callseq 126, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd663;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd70, [retval0+0];
	} // callseq 126
	and.pred  	%p16, %p191, %p149;
	setp.gt.f64 	%p197, %fd663, 0d3FF0000000000000;
	selp.b32 	%r324, 2146435072, 0, %p197;
	xor.b32  	%r325, %r324, 2146435072;
	selp.b32 	%r326, %r325, %r324, %p146;
	setp.eq.f32 	%p198, %f3069, 0fBF800000;
	selp.b32 	%r98, 1072693248, %r326, %p198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r327}, %fd51;
	}
	and.b32  	%r99, %r327, 2146435072;
	setp.ne.s32 	%p199, %r99, 2146435072;
	and.pred  	%p200, %p155, %p15;
	selp.b32 	%r100, %r57, %r56, %p200;
	selp.b32 	%r328, %r325, %r324, %p152;
	selp.b32 	%r101, 1072693248, %r328, %p198;
	or.pred  	%p17, %p147, %p148;
	or.pred  	%p18, %p153, %p148;
	or.pred  	%p19, %p158, %p148;
	or.pred  	%p20, %p161, %p165;
	or.pred  	%p21, %p168, %p165;
	or.pred  	%p22, %p169, %p165;
	or.pred  	%p23, %p172, %p173;
	or.pred  	%p24, %p177, %p178;
	or.pred  	%p25, %p182, %p183;
	or.pred  	%p26, %p186, %p183;
	or.pred  	%p27, %p189, %p190;
	or.pred  	%p28, %p194, %p196;
	or.pred  	%p29, %p199, %p196;
	shr.s32 	%r329, %r47, 31;
	and.b32  	%r102, %r329, 2146435072;

$L__BB6_56:
	not.pred 	%p201, %p4;
	mov.f64 	%fd1079, %fd54;
	@%p201 bra 	$L__BB6_58;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r330}, %fd54;
	}
	xor.b32  	%r331, %r330, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r332, %temp}, %fd54;
	}
	mov.b64 	%fd1079, {%r332, %r331};

$L__BB6_58:
	setp.eq.f32 	%p202, %f69, 0f00000000;
	@%p202 bra 	$L__BB6_62;
	bra.uni 	$L__BB6_59;

$L__BB6_62:
	mov.u32 	%r333, 0;
	selp.b32 	%r335, %r49, 0, %p144;
	or.b32  	%r336, %r335, 2146435072;
	selp.b32 	%r337, %r336, %r335, %p146;
	mov.b64 	%fd1079, {%r333, %r337};
	bra.uni 	$L__BB6_63;

$L__BB6_59:
	setp.gt.s32 	%p203, %r49, -1;
	@%p203 bra 	$L__BB6_63;

	cvt.rzi.f64.f64 	%fd665, %fd646;
	setp.eq.f64 	%p204, %fd665, 0d4000000000000000;
	@%p204 bra 	$L__BB6_63;

	mov.f64 	%fd1079, 0dFFF8000000000000;

$L__BB6_63:
	cvt.f64.f32 	%fd1054, %f69;
	add.f64 	%fd1053, %fd1052, 0d4000000000000000;
	selp.f64 	%fd1080, %fd1079, %fd1053, %p147;
	@%p17 bra 	$L__BB6_68;

	setp.eq.s32 	%p208, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r338, %temp}, %fd646;
	}
	setp.eq.s32 	%p209, %r338, 0;
	and.pred  	%p210, %p208, %p209;
	@%p210 bra 	$L__BB6_67;
	bra.uni 	$L__BB6_65;

$L__BB6_67:
	mov.u32 	%r345, 0;
	mov.b64 	%fd1080, {%r345, %r54};
	bra.uni 	$L__BB6_68;

$L__BB6_65:
	and.b32  	%r339, %r49, 2147483647;
	setp.ne.s32 	%p211, %r339, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r340, %temp}, %fd41;
	}
	setp.ne.s32 	%p212, %r340, 0;
	or.pred  	%p213, %p211, %p212;
	mov.f64 	%fd1080, %fd1079;
	@%p213 bra 	$L__BB6_68;

	and.pred  	%p215, %p155, %p4;
	selp.b32 	%r343, %r57, %r56, %p215;
	mov.u32 	%r344, 0;
	mov.b64 	%fd1080, {%r344, %r343};

$L__BB6_68:
	not.pred 	%p216, %p5;
	mov.f64 	%fd1082, %fd55;
	@%p216 bra 	$L__BB6_70;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r346}, %fd55;
	}
	xor.b32  	%r347, %r346, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r348, %temp}, %fd55;
	}
	mov.b64 	%fd1082, {%r348, %r347};

$L__BB6_70:
	@%p202 bra 	$L__BB6_74;
	bra.uni 	$L__BB6_71;

$L__BB6_74:
	mov.u32 	%r349, 0;
	selp.b32 	%r351, %r49, 0, %p149;
	or.b32  	%r352, %r351, 2146435072;
	selp.b32 	%r353, %r352, %r351, %p152;
	mov.b64 	%fd1082, {%r349, %r353};
	bra.uni 	$L__BB6_75;

$L__BB6_71:
	setp.gt.s32 	%p218, %r49, -1;
	@%p218 bra 	$L__BB6_75;

	cvt.rzi.f64.f64 	%fd670, %fd649;
	setp.eq.f64 	%p219, %fd670, 0d4008000000000000;
	@%p219 bra 	$L__BB6_75;

	mov.f64 	%fd1082, 0dFFF8000000000000;

$L__BB6_75:
	cvt.f64.f32 	%fd1056, %f69;
	add.f64 	%fd1055, %fd1052, 0d4008000000000000;
	selp.f64 	%fd1083, %fd1082, %fd1055, %p153;
	@%p18 bra 	$L__BB6_80;

	setp.eq.s32 	%p223, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r354, %temp}, %fd649;
	}
	setp.eq.s32 	%p224, %r354, 0;
	and.pred  	%p225, %p223, %p224;
	@%p225 bra 	$L__BB6_79;
	bra.uni 	$L__BB6_77;

$L__BB6_79:
	mov.u32 	%r361, 0;
	mov.b64 	%fd1083, {%r361, %r59};
	bra.uni 	$L__BB6_80;

$L__BB6_77:
	and.b32  	%r355, %r49, 2147483647;
	setp.ne.s32 	%p226, %r355, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r356, %temp}, %fd41;
	}
	setp.ne.s32 	%p227, %r356, 0;
	or.pred  	%p228, %p226, %p227;
	mov.f64 	%fd1083, %fd1082;
	@%p228 bra 	$L__BB6_80;

	setp.ne.s32 	%p229, %r58, 1071644672;
	and.pred  	%p230, %p229, %p5;
	selp.b32 	%r359, %r63, %r62, %p230;
	mov.u32 	%r360, 0;
	mov.b64 	%fd1083, {%r360, %r359};

$L__BB6_80:
	setp.eq.f32 	%p231, %f69, 0f3F800000;
	selp.f64 	%fd674, 0d3FF0000000000000, %fd1083, %p231;
	cvt.f64.f32 	%fd675, %f548;
	add.f64 	%fd676, %fd1080, 0d3FF0000000000000;
	selp.f64 	%fd677, 0d4000000000000000, %fd676, %p231;
	fma.rn.f64 	%fd87, %fd674, %fd675, %fd677;
	not.pred 	%p232, %p6;
	mov.f64 	%fd1085, %fd56;
	@%p232 bra 	$L__BB6_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r362}, %fd56;
	}
	xor.b32  	%r363, %r362, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r364, %temp}, %fd56;
	}
	mov.b64 	%fd1085, {%r364, %r363};

$L__BB6_82:
	@%p202 bra 	$L__BB6_86;
	bra.uni 	$L__BB6_83;

$L__BB6_86:
	mov.u32 	%r365, 0;
	mov.b64 	%fd1085, {%r365, %r60};
	bra.uni 	$L__BB6_87;

$L__BB6_83:
	setp.gt.s32 	%p234, %r49, -1;
	@%p234 bra 	$L__BB6_87;

	cvt.rzi.f64.f64 	%fd679, %fd651;
	setp.eq.f64 	%p235, %fd679, 0d4010000000000000;
	@%p235 bra 	$L__BB6_87;

	mov.f64 	%fd1085, 0dFFF8000000000000;

$L__BB6_87:
	cvt.f64.f32 	%fd1058, %f69;
	add.f64 	%fd1057, %fd1052, 0d4010000000000000;
	selp.f64 	%fd1086, %fd1085, %fd1057, %p158;
	@%p19 bra 	$L__BB6_92;

	setp.eq.s32 	%p237, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r366, %temp}, %fd651;
	}
	setp.eq.s32 	%p238, %r366, 0;
	and.pred  	%p239, %p237, %p238;
	@%p239 bra 	$L__BB6_91;
	bra.uni 	$L__BB6_89;

$L__BB6_91:
	mov.u32 	%r370, 0;
	mov.b64 	%fd1086, {%r370, %r66};
	bra.uni 	$L__BB6_92;

$L__BB6_89:
	and.b32  	%r367, %r49, 2147483647;
	setp.ne.s32 	%p240, %r367, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r368, %temp}, %fd41;
	}
	setp.ne.s32 	%p241, %r368, 0;
	or.pred  	%p242, %p240, %p241;
	mov.f64 	%fd1086, %fd1085;
	@%p242 bra 	$L__BB6_92;

	mov.u32 	%r369, 0;
	mov.b64 	%fd1086, {%r369, %r68};

$L__BB6_92:
	selp.f64 	%fd683, 0d3FF0000000000000, %fd1086, %p231;
	cvt.f64.f32 	%fd684, %f550;
	fma.rn.f64 	%fd685, %fd683, %fd684, %fd87;
	cvt.rn.f32.f64 	%f102, %fd685;
	not.pred 	%p244, %p7;
	mov.f64 	%fd1088, %fd57;
	@%p244 bra 	$L__BB6_94;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r371}, %fd57;
	}
	xor.b32  	%r372, %r371, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r373, %temp}, %fd57;
	}
	mov.b64 	%fd1088, {%r373, %r372};

$L__BB6_94:
	setp.eq.f32 	%p245, %f71, 0f00000000;
	@%p245 bra 	$L__BB6_98;
	bra.uni 	$L__BB6_95;

$L__BB6_98:
	mov.u32 	%r374, 0;
	selp.b32 	%r376, %r64, 0, %p144;
	or.b32  	%r377, %r376, 2146435072;
	selp.b32 	%r378, %r377, %r376, %p146;
	mov.b64 	%fd1088, {%r374, %r378};
	bra.uni 	$L__BB6_99;

$L__BB6_95:
	setp.gt.s32 	%p246, %r64, -1;
	@%p246 bra 	$L__BB6_99;

	cvt.rzi.f64.f64 	%fd687, %fd646;
	setp.eq.f64 	%p247, %fd687, 0d4000000000000000;
	@%p247 bra 	$L__BB6_99;

	mov.f64 	%fd1088, 0dFFF8000000000000;

$L__BB6_99:
	cvt.f64.f32 	%fd1060, %f71;
	add.f64 	%fd1059, %fd1051, 0d4000000000000000;
	selp.f64 	%fd1089, %fd1088, %fd1059, %p161;
	@%p20 bra 	$L__BB6_104;

	setp.eq.s32 	%p251, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r379, %temp}, %fd646;
	}
	setp.eq.s32 	%p252, %r379, 0;
	and.pred  	%p253, %p251, %p252;
	@%p253 bra 	$L__BB6_103;
	bra.uni 	$L__BB6_101;

$L__BB6_103:
	mov.u32 	%r386, 0;
	mov.b64 	%fd1089, {%r386, %r69};
	bra.uni 	$L__BB6_104;

$L__BB6_101:
	and.b32  	%r380, %r64, 2147483647;
	setp.ne.s32 	%p254, %r380, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r381, %temp}, %fd42;
	}
	setp.ne.s32 	%p255, %r381, 0;
	or.pred  	%p256, %p254, %p255;
	mov.f64 	%fd1089, %fd1088;
	@%p256 bra 	$L__BB6_104;

	and.pred  	%p258, %p155, %p7;
	selp.b32 	%r384, %r57, %r56, %p258;
	mov.u32 	%r385, 0;
	mov.b64 	%fd1089, {%r385, %r384};

$L__BB6_104:
	not.pred 	%p259, %p8;
	mov.f64 	%fd1091, %fd58;
	@%p259 bra 	$L__BB6_106;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r387}, %fd58;
	}
	xor.b32  	%r388, %r387, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r389, %temp}, %fd58;
	}
	mov.b64 	%fd1091, {%r389, %r388};

$L__BB6_106:
	@%p245 bra 	$L__BB6_110;
	bra.uni 	$L__BB6_107;

$L__BB6_110:
	mov.u32 	%r390, 0;
	selp.b32 	%r392, %r64, 0, %p149;
	or.b32  	%r393, %r392, 2146435072;
	selp.b32 	%r394, %r393, %r392, %p152;
	mov.b64 	%fd1091, {%r390, %r394};
	bra.uni 	$L__BB6_111;

$L__BB6_107:
	setp.gt.s32 	%p261, %r64, -1;
	@%p261 bra 	$L__BB6_111;

	cvt.rzi.f64.f64 	%fd692, %fd649;
	setp.eq.f64 	%p262, %fd692, 0d4008000000000000;
	@%p262 bra 	$L__BB6_111;

	mov.f64 	%fd1091, 0dFFF8000000000000;

$L__BB6_111:
	cvt.f64.f32 	%fd1062, %f71;
	add.f64 	%fd1061, %fd1051, 0d4008000000000000;
	selp.f64 	%fd1092, %fd1091, %fd1061, %p168;
	@%p21 bra 	$L__BB6_116;

	setp.eq.s32 	%p266, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r395, %temp}, %fd649;
	}
	setp.eq.s32 	%p267, %r395, 0;
	and.pred  	%p268, %p266, %p267;
	@%p268 bra 	$L__BB6_115;
	bra.uni 	$L__BB6_113;

$L__BB6_115:
	mov.u32 	%r402, 0;
	mov.b64 	%fd1092, {%r402, %r71};
	bra.uni 	$L__BB6_116;

$L__BB6_113:
	and.b32  	%r396, %r64, 2147483647;
	setp.ne.s32 	%p269, %r396, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r397, %temp}, %fd42;
	}
	setp.ne.s32 	%p270, %r397, 0;
	or.pred  	%p271, %p269, %p270;
	mov.f64 	%fd1092, %fd1091;
	@%p271 bra 	$L__BB6_116;

	setp.ne.s32 	%p272, %r58, 1071644672;
	and.pred  	%p273, %p272, %p8;
	selp.b32 	%r400, %r63, %r62, %p273;
	mov.u32 	%r401, 0;
	mov.b64 	%fd1092, {%r401, %r400};

$L__BB6_116:
	setp.eq.f32 	%p274, %f71, 0f3F800000;
	selp.f64 	%fd696, 0d3FF0000000000000, %fd1092, %p274;
	cvt.f64.f32 	%fd697, %f549;
	add.f64 	%fd698, %fd1089, 0d3FF0000000000000;
	selp.f64 	%fd699, 0d4000000000000000, %fd698, %p274;
	fma.rn.f64 	%fd112, %fd696, %fd697, %fd699;
	not.pred 	%p275, %p9;
	mov.f64 	%fd1094, %fd59;
	@%p275 bra 	$L__BB6_118;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r403}, %fd59;
	}
	xor.b32  	%r404, %r403, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r405, %temp}, %fd59;
	}
	mov.b64 	%fd1094, {%r405, %r404};

$L__BB6_118:
	@%p245 bra 	$L__BB6_122;
	bra.uni 	$L__BB6_119;

$L__BB6_122:
	mov.u32 	%r406, 0;
	mov.b64 	%fd1094, {%r406, %r72};
	bra.uni 	$L__BB6_123;

$L__BB6_119:
	setp.gt.s32 	%p277, %r64, -1;
	@%p277 bra 	$L__BB6_123;

	cvt.rzi.f64.f64 	%fd701, %fd651;
	setp.eq.f64 	%p278, %fd701, 0d4010000000000000;
	@%p278 bra 	$L__BB6_123;

	mov.f64 	%fd1094, 0dFFF8000000000000;

$L__BB6_123:
	cvt.f64.f32 	%fd1064, %f71;
	add.f64 	%fd1063, %fd1051, 0d4010000000000000;
	selp.f64 	%fd1095, %fd1094, %fd1063, %p169;
	@%p22 bra 	$L__BB6_128;

	setp.eq.s32 	%p280, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r407, %temp}, %fd651;
	}
	setp.eq.s32 	%p281, %r407, 0;
	and.pred  	%p282, %p280, %p281;
	@%p282 bra 	$L__BB6_127;
	bra.uni 	$L__BB6_125;

$L__BB6_127:
	mov.u32 	%r411, 0;
	mov.b64 	%fd1095, {%r411, %r74};
	bra.uni 	$L__BB6_128;

$L__BB6_125:
	and.b32  	%r408, %r64, 2147483647;
	setp.ne.s32 	%p283, %r408, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r409, %temp}, %fd42;
	}
	setp.ne.s32 	%p284, %r409, 0;
	or.pred  	%p285, %p283, %p284;
	mov.f64 	%fd1095, %fd1094;
	@%p285 bra 	$L__BB6_128;

	mov.u32 	%r410, 0;
	mov.b64 	%fd1095, {%r410, %r75};

$L__BB6_128:
	selp.f64 	%fd705, 0d3FF0000000000000, %fd1095, %p274;
	cvt.f64.f32 	%fd706, %f551;
	fma.rn.f64 	%fd707, %fd705, %fd706, %fd112;
	cvt.rn.f32.f64 	%f103, %fd707;
	sqrt.rn.f32 	%f104, %f102;
	mul.f32 	%f105, %f104, %f547;
	sqrt.rn.f32 	%f106, %f103;
	mul.f32 	%f107, %f106, %f554;
	mov.f32 	%f658, 0f3F000000;
	div.rn.f32 	%f659, %f658, %f105;
	div.rn.f32 	%f660, %f659, %f105;
	sqrt.rn.f32 	%f108, %f660;
	mul.f32 	%f109, %f108, %f87;
	abs.f32 	%f661, %f109;
	setp.ltu.f32 	%p287, %f661, 0f3F8060FE;
	setp.ge.f32 	%p288, %f661, 0f3F8060FE;
	mul.f32 	%f662, %f109, %f109;
	selp.f32 	%f663, %f661, %f662, %p288;
	selp.f32 	%f664, 0f3789CA3C, 0f38B1E96A, %p288;
	selp.f32 	%f665, 0fB9F560B9, 0fBA574D20, %p288;
	fma.rn.f32 	%f666, %f664, %f663, %f665;
	selp.f32 	%f667, 0f3BAC840B, 0f3BAAD5EA, %p288;
	fma.rn.f32 	%f668, %f666, %f663, %f667;
	selp.f32 	%f669, 0fBD0C8162, 0fBCDC1BE7, %p288;
	fma.rn.f32 	%f670, %f668, %f663, %f669;
	selp.f32 	%f671, 0f3E1CF906, 0f3DE718AF, %p288;
	fma.rn.f32 	%f672, %f670, %f663, %f671;
	selp.f32 	%f673, 0f3F6A937E, 0fBEC093AC, %p288;
	fma.rn.f32 	%f674, %f672, %f663, %f673;
	selp.f32 	%f675, 0f3F20D842, 0f3E0375D3, %p288;
	fma.rn.f32 	%f676, %f674, %f663, %f675;
	neg.f32 	%f677, %f661;
	selp.f32 	%f678, %f677, %f109, %p288;
	fma.rn.f32 	%f3244, %f676, %f678, %f678;
	@%p287 bra 	$L__BB6_130;

	mov.f32 	%f3147, 0f3F800000;
	ex2.approx.ftz.f32 	%f679, %f3244;
	sub.f32 	%f681, %f3147, %f679;
	mov.b32 	%r412, %f681;
	mov.b32 	%r413, %f109;
	and.b32  	%r414, %r413, -2147483648;
	or.b32  	%r415, %r414, %r412;
	mov.b32 	%f3244, %r415;

$L__BB6_130:
	mul.f32 	%f113, %f108, %f88;
	abs.f32 	%f682, %f113;
	setp.ltu.f32 	%p289, %f682, 0f3F8060FE;
	setp.ge.f32 	%p290, %f682, 0f3F8060FE;
	mul.f32 	%f683, %f113, %f113;
	selp.f32 	%f684, %f682, %f683, %p290;
	selp.f32 	%f685, 0f3789CA3C, 0f38B1E96A, %p290;
	selp.f32 	%f686, 0fB9F560B9, 0fBA574D20, %p290;
	fma.rn.f32 	%f687, %f685, %f684, %f686;
	selp.f32 	%f688, 0f3BAC840B, 0f3BAAD5EA, %p290;
	fma.rn.f32 	%f689, %f687, %f684, %f688;
	selp.f32 	%f690, 0fBD0C8162, 0fBCDC1BE7, %p290;
	fma.rn.f32 	%f691, %f689, %f684, %f690;
	selp.f32 	%f692, 0f3E1CF906, 0f3DE718AF, %p290;
	fma.rn.f32 	%f693, %f691, %f684, %f692;
	selp.f32 	%f694, 0f3F6A937E, 0fBEC093AC, %p290;
	fma.rn.f32 	%f695, %f693, %f684, %f694;
	selp.f32 	%f696, 0f3F20D842, 0f3E0375D3, %p290;
	fma.rn.f32 	%f697, %f695, %f684, %f696;
	neg.f32 	%f698, %f682;
	selp.f32 	%f699, %f698, %f113, %p290;
	fma.rn.f32 	%f3245, %f697, %f699, %f699;
	@%p289 bra 	$L__BB6_132;

	mov.f32 	%f3146, 0f3F800000;
	ex2.approx.ftz.f32 	%f700, %f3245;
	sub.f32 	%f702, %f3146, %f700;
	mov.b32 	%r416, %f702;
	mov.b32 	%r417, %f113;
	and.b32  	%r418, %r417, -2147483648;
	or.b32  	%r419, %r418, %r416;
	mov.b32 	%f3245, %r419;

$L__BB6_132:
	mov.f32 	%f3070, 0f3F000000;
	sub.f32 	%f703, %f3244, %f3245;
	mul.f32 	%f117, %f703, 0f3F000000;
	div.rn.f32 	%f705, %f3070, %f107;
	div.rn.f32 	%f706, %f705, %f107;
	cvt.rn.f32.s32 	%f118, %r1375;
	sub.f32 	%f119, %f118, %f3294;
	add.f32 	%f120, %f119, 0f3F000000;
	sqrt.rn.f32 	%f121, %f706;
	mul.f32 	%f122, %f121, %f120;
	abs.f32 	%f707, %f122;
	setp.ltu.f32 	%p291, %f707, 0f3F8060FE;
	setp.ge.f32 	%p292, %f707, 0f3F8060FE;
	mul.f32 	%f708, %f122, %f122;
	selp.f32 	%f709, %f707, %f708, %p292;
	selp.f32 	%f710, 0f3789CA3C, 0f38B1E96A, %p292;
	selp.f32 	%f711, 0fB9F560B9, 0fBA574D20, %p292;
	fma.rn.f32 	%f712, %f710, %f709, %f711;
	selp.f32 	%f713, 0f3BAC840B, 0f3BAAD5EA, %p292;
	fma.rn.f32 	%f714, %f712, %f709, %f713;
	selp.f32 	%f715, 0fBD0C8162, 0fBCDC1BE7, %p292;
	fma.rn.f32 	%f716, %f714, %f709, %f715;
	selp.f32 	%f717, 0f3E1CF906, 0f3DE718AF, %p292;
	fma.rn.f32 	%f718, %f716, %f709, %f717;
	selp.f32 	%f719, 0f3F6A937E, 0fBEC093AC, %p292;
	fma.rn.f32 	%f720, %f718, %f709, %f719;
	selp.f32 	%f721, 0f3F20D842, 0f3E0375D3, %p292;
	fma.rn.f32 	%f722, %f720, %f709, %f721;
	neg.f32 	%f723, %f707;
	selp.f32 	%f724, %f723, %f122, %p292;
	fma.rn.f32 	%f3246, %f722, %f724, %f724;
	@%p291 bra 	$L__BB6_134;

	mov.f32 	%f3145, 0f3F800000;
	ex2.approx.ftz.f32 	%f725, %f3246;
	sub.f32 	%f727, %f3145, %f725;
	mov.b32 	%r420, %f727;
	mov.b32 	%r421, %f122;
	and.b32  	%r422, %r421, -2147483648;
	or.b32  	%r423, %r422, %r420;
	mov.b32 	%f3246, %r423;

$L__BB6_134:
	cvt.rn.f32.s32 	%f3072, %r1375;
	sub.f32 	%f3071, %f3072, %f3294;
	add.f32 	%f126, %f3071, 0fBF000000;
	mul.f32 	%f127, %f121, %f126;
	abs.f32 	%f728, %f127;
	setp.ltu.f32 	%p293, %f728, 0f3F8060FE;
	setp.ge.f32 	%p294, %f728, 0f3F8060FE;
	mul.f32 	%f729, %f127, %f127;
	selp.f32 	%f730, %f728, %f729, %p294;
	selp.f32 	%f731, 0f3789CA3C, 0f38B1E96A, %p294;
	selp.f32 	%f732, 0fB9F560B9, 0fBA574D20, %p294;
	fma.rn.f32 	%f733, %f731, %f730, %f732;
	selp.f32 	%f734, 0f3BAC840B, 0f3BAAD5EA, %p294;
	fma.rn.f32 	%f735, %f733, %f730, %f734;
	selp.f32 	%f736, 0fBD0C8162, 0fBCDC1BE7, %p294;
	fma.rn.f32 	%f737, %f735, %f730, %f736;
	selp.f32 	%f738, 0f3E1CF906, 0f3DE718AF, %p294;
	fma.rn.f32 	%f739, %f737, %f730, %f738;
	selp.f32 	%f740, 0f3F6A937E, 0fBEC093AC, %p294;
	fma.rn.f32 	%f741, %f739, %f730, %f740;
	selp.f32 	%f742, 0f3F20D842, 0f3E0375D3, %p294;
	fma.rn.f32 	%f743, %f741, %f730, %f742;
	neg.f32 	%f744, %f728;
	selp.f32 	%f745, %f744, %f127, %p294;
	fma.rn.f32 	%f3247, %f743, %f745, %f745;
	@%p293 bra 	$L__BB6_136;

	mov.f32 	%f3144, 0f3F800000;
	ex2.approx.ftz.f32 	%f746, %f3247;
	sub.f32 	%f748, %f3144, %f746;
	mov.b32 	%r424, %f748;
	mov.b32 	%r425, %f127;
	and.b32  	%r426, %r425, -2147483648;
	or.b32  	%r427, %r426, %r424;
	mov.b32 	%f3247, %r427;

$L__BB6_136:
	cvt.rn.f32.s32 	%f3075, %r1374;
	add.f32 	%f3074, %f3075, 0f3F000000;
	sub.f32 	%f3073, %f3074, %f3295;
	sub.f32 	%f750, %f3246, %f3247;
	mul.f32 	%f131, %f750, 0f3F000000;
	div.rn.f32 	%f132, %f3073, %f105;
	abs.f32 	%f133, %f132;
	setp.lt.f32 	%p295, %f133, 0f00800000;
	mul.f32 	%f751, %f133, 0f4B800000;
	selp.f32 	%f752, %f751, %f133, %p295;
	selp.f32 	%f753, 0fC3170000, 0fC2FE0000, %p295;
	mov.b32 	%r428, %f752;
	and.b32  	%r429, %r428, 8388607;
	or.b32  	%r430, %r429, 1065353216;
	mov.b32 	%f754, %r430;
	shr.u32 	%r431, %r428, 23;
	cvt.rn.f32.u32 	%f755, %r431;
	add.f32 	%f756, %f753, %f755;
	setp.gt.f32 	%p296, %f754, 0f3FB504F3;
	mul.f32 	%f757, %f754, 0f3F000000;
	add.f32 	%f758, %f756, 0f3F800000;
	selp.f32 	%f759, %f758, %f756, %p296;
	selp.f32 	%f760, %f757, %f754, %p296;
	add.f32 	%f761, %f760, 0fBF800000;
	add.f32 	%f762, %f760, 0f3F800000;
	rcp.approx.ftz.f32 	%f763, %f762;
	add.f32 	%f764, %f761, %f761;
	mul.f32 	%f766, %f764, %f763;
	mul.f32 	%f767, %f766, %f766;
	mov.f32 	%f768, 0f3C4CAF63;
	mov.f32 	%f769, 0f3B18F0FE;
	fma.rn.f32 	%f770, %f769, %f767, %f768;
	mov.f32 	%f771, 0f3DAAAABD;
	fma.rn.f32 	%f772, %f770, %f767, %f771;
	mul.rn.f32 	%f773, %f772, %f767;
	mul.rn.f32 	%f774, %f773, %f766;
	sub.f32 	%f775, %f761, %f766;
	add.f32 	%f776, %f775, %f775;
	neg.f32 	%f777, %f766;
	fma.rn.f32 	%f778, %f777, %f761, %f776;
	mul.rn.f32 	%f779, %f763, %f778;
	add.f32 	%f780, %f774, %f766;
	sub.f32 	%f781, %f766, %f780;
	add.f32 	%f782, %f774, %f781;
	add.f32 	%f783, %f779, %f782;
	add.f32 	%f784, %f780, %f783;
	sub.f32 	%f785, %f780, %f784;
	add.f32 	%f786, %f783, %f785;
	mov.f32 	%f787, 0f3F317200;
	mul.rn.f32 	%f788, %f759, %f787;
	mov.f32 	%f789, 0f35BFBE8E;
	mul.rn.f32 	%f790, %f759, %f789;
	add.f32 	%f791, %f788, %f784;
	sub.f32 	%f792, %f788, %f791;
	add.f32 	%f793, %f784, %f792;
	add.f32 	%f794, %f786, %f793;
	add.f32 	%f795, %f790, %f794;
	add.f32 	%f796, %f791, %f795;
	sub.f32 	%f797, %f791, %f796;
	add.f32 	%f798, %f795, %f797;
	mul.rn.f32 	%f799, %f613, %f796;
	neg.f32 	%f800, %f799;
	fma.rn.f32 	%f801, %f613, %f796, %f800;
	fma.rn.f32 	%f802, %f613, %f798, %f801;
	mov.f32 	%f3279, 0f00000000;
	fma.rn.f32 	%f804, %f3279, %f796, %f802;
	add.rn.f32 	%f805, %f799, %f804;
	neg.f32 	%f806, %f805;
	add.rn.f32 	%f807, %f799, %f806;
	add.rn.f32 	%f808, %f807, %f804;
	mov.b32 	%r432, %f805;
	setp.eq.s32 	%p297, %r432, 1118925336;
	add.s32 	%r433, %r432, -1;
	mov.b32 	%f809, %r433;
	add.f32 	%f810, %f808, 0f37000000;
	selp.f32 	%f134, %f810, %f808, %p297;
	selp.f32 	%f811, %f809, %f805, %p297;
	mov.f32 	%f812, 0f3FB8AA3B;
	mul.rn.f32 	%f813, %f811, %f812;
	cvt.rzi.f32.f32 	%f814, %f813;
	abs.f32 	%f815, %f814;
	setp.gt.f32 	%p298, %f815, 0f42FC0000;
	mov.b32 	%r434, %f814;
	and.b32  	%r435, %r434, -2147483648;
	or.b32  	%r436, %r435, 1123811328;
	mov.b32 	%f816, %r436;
	selp.f32 	%f817, %f816, %f814, %p298;
	mov.f32 	%f818, 0fBF317218;
	fma.rn.f32 	%f819, %f817, %f818, %f811;
	mov.f32 	%f820, 0f3102E308;
	fma.rn.f32 	%f821, %f817, %f820, %f819;
	mul.f32 	%f822, %f821, 0f3FB8AA3B;
	add.f32 	%f823, %f817, 0f4B40007F;
	mov.b32 	%r437, %f823;
	shl.b32 	%r438, %r437, 23;
	mov.b32 	%f824, %r438;
	ex2.approx.ftz.f32 	%f825, %f822;
	mul.f32 	%f135, %f825, %f824;
	setp.eq.f32 	%p299, %f135, 0f7F800000;
	mov.f32 	%f3248, 0f7F800000;
	@%p299 bra 	$L__BB6_138;

	fma.rn.f32 	%f3248, %f135, %f134, %f135;

$L__BB6_138:
	mov.f32 	%f3080, 0f3F800000;
	cvt.rzi.f32.f32 	%f3079, %f3080;
	add.f32 	%f3078, %f3079, %f3079;
	sub.f32 	%f3077, %f613, %f3078;
	abs.f32 	%f3076, %f3077;
	setp.lt.f32 	%p300, %f132, 0f00000000;
	setp.eq.f32 	%p301, %f3076, 0f3F800000;
	and.pred  	%p30, %p300, %p301;
	setp.eq.f32 	%p302, %f132, 0f00000000;
	@%p302 bra 	$L__BB6_142;
	bra.uni 	$L__BB6_139;

$L__BB6_142:
	add.f32 	%f830, %f132, %f132;
	selp.f32 	%f3250, %f830, 0f00000000, %p301;
	bra.uni 	$L__BB6_143;

$L__BB6_139:
	mov.b32 	%r439, %f3248;
	xor.b32  	%r440, %r439, -2147483648;
	mov.b32 	%f826, %r440;
	selp.f32 	%f3250, %f826, %f3248, %p30;
	setp.geu.f32 	%p303, %f132, 0f00000000;
	@%p303 bra 	$L__BB6_143;

	cvt.rzi.f32.f32 	%f828, %f613;
	setp.eq.f32 	%p304, %f828, 0f40000000;
	@%p304 bra 	$L__BB6_143;

	mov.f32 	%f3250, 0f7FFFFFFF;

$L__BB6_143:
	add.f32 	%f831, %f133, 0f40000000;
	mov.b32 	%r441, %f831;
	setp.lt.s32 	%p306, %r441, 2139095040;
	@%p306 bra 	$L__BB6_148;

	setp.gtu.f32 	%p307, %f133, 0f7F800000;
	@%p307 bra 	$L__BB6_147;
	bra.uni 	$L__BB6_145;

$L__BB6_147:
	add.f32 	%f3250, %f132, 0f40000000;
	bra.uni 	$L__BB6_148;

$L__BB6_145:
	setp.neu.f32 	%p308, %f133, 0f7F800000;
	@%p308 bra 	$L__BB6_148;

	selp.f32 	%f3250, 0fFF800000, 0f7F800000, %p30;

$L__BB6_148:
	mov.f32 	%f3088, 0f3102E308;
	mov.f32 	%f3087, 0fBF317218;
	mov.f32 	%f3086, 0f35BFBE8E;
	mov.f32 	%f3085, 0f3F317200;
	mov.f32 	%f3084, 0f3DAAAABD;
	mov.f32 	%f3083, 0f3C4CAF63;
	mov.f32 	%f3082, 0f3B18F0FE;
	mov.f32 	%f3081, 0f3F000000;
	mul.f32 	%f833, %f3250, 0fBF000000;
	setp.eq.f32 	%p309, %f132, 0f3F800000;
	selp.f32 	%f834, 0fBF000000, %f833, %p309;
	mov.f32 	%f836, 0f3BBB989D;
	fma.rn.f32 	%f837, %f834, %f836, %f3081;
	mov.f32 	%f839, 0f437C0000;
	cvt.sat.f32.f32 	%f840, %f837;
	mov.f32 	%f841, 0f4B400001;
	fma.rm.f32 	%f842, %f840, %f839, %f841;
	add.f32 	%f843, %f842, 0fCB40007F;
	neg.f32 	%f844, %f843;
	fma.rn.f32 	%f845, %f834, %f812, %f844;
	mov.f32 	%f846, 0f32A57060;
	fma.rn.f32 	%f847, %f834, %f846, %f845;
	mov.b32 	%r442, %f842;
	shl.b32 	%r443, %r442, 23;
	mov.b32 	%f848, %r443;
	ex2.approx.ftz.f32 	%f849, %f847;
	mul.f32 	%f144, %f849, %f848;
	div.rn.f32 	%f145, %f88, %f105;
	abs.f32 	%f146, %f145;
	setp.lt.f32 	%p310, %f146, 0f00800000;
	mul.f32 	%f850, %f146, 0f4B800000;
	selp.f32 	%f851, %f850, %f146, %p310;
	selp.f32 	%f852, 0fC3170000, 0fC2FE0000, %p310;
	mov.b32 	%r444, %f851;
	and.b32  	%r445, %r444, 8388607;
	or.b32  	%r446, %r445, 1065353216;
	mov.b32 	%f853, %r446;
	shr.u32 	%r447, %r444, 23;
	cvt.rn.f32.u32 	%f854, %r447;
	add.f32 	%f855, %f852, %f854;
	setp.gt.f32 	%p311, %f853, 0f3FB504F3;
	mul.f32 	%f856, %f853, 0f3F000000;
	add.f32 	%f857, %f855, 0f3F800000;
	selp.f32 	%f858, %f857, %f855, %p311;
	selp.f32 	%f859, %f856, %f853, %p311;
	add.f32 	%f860, %f859, 0fBF800000;
	add.f32 	%f861, %f859, 0f3F800000;
	rcp.approx.ftz.f32 	%f862, %f861;
	add.f32 	%f863, %f860, %f860;
	mul.f32 	%f865, %f863, %f862;
	mul.f32 	%f866, %f865, %f865;
	fma.rn.f32 	%f869, %f3082, %f866, %f3083;
	fma.rn.f32 	%f871, %f869, %f866, %f3084;
	mul.rn.f32 	%f872, %f871, %f866;
	mul.rn.f32 	%f873, %f872, %f865;
	sub.f32 	%f874, %f860, %f865;
	add.f32 	%f875, %f874, %f874;
	neg.f32 	%f876, %f865;
	fma.rn.f32 	%f877, %f876, %f860, %f875;
	mul.rn.f32 	%f878, %f862, %f877;
	add.f32 	%f879, %f873, %f865;
	sub.f32 	%f880, %f865, %f879;
	add.f32 	%f881, %f873, %f880;
	add.f32 	%f882, %f878, %f881;
	add.f32 	%f883, %f879, %f882;
	sub.f32 	%f884, %f879, %f883;
	add.f32 	%f885, %f882, %f884;
	mul.rn.f32 	%f887, %f858, %f3085;
	mul.rn.f32 	%f889, %f858, %f3086;
	add.f32 	%f890, %f887, %f883;
	sub.f32 	%f891, %f887, %f890;
	add.f32 	%f892, %f883, %f891;
	add.f32 	%f893, %f885, %f892;
	add.f32 	%f894, %f889, %f893;
	add.f32 	%f895, %f890, %f894;
	sub.f32 	%f896, %f890, %f895;
	add.f32 	%f897, %f894, %f896;
	mul.rn.f32 	%f898, %f613, %f895;
	neg.f32 	%f899, %f898;
	fma.rn.f32 	%f900, %f613, %f895, %f899;
	fma.rn.f32 	%f901, %f613, %f897, %f900;
	fma.rn.f32 	%f903, %f3279, %f895, %f901;
	add.rn.f32 	%f904, %f898, %f903;
	neg.f32 	%f905, %f904;
	add.rn.f32 	%f906, %f898, %f905;
	add.rn.f32 	%f907, %f906, %f903;
	mov.b32 	%r448, %f904;
	setp.eq.s32 	%p312, %r448, 1118925336;
	add.s32 	%r449, %r448, -1;
	mov.b32 	%f908, %r449;
	add.f32 	%f909, %f907, 0f37000000;
	selp.f32 	%f147, %f909, %f907, %p312;
	selp.f32 	%f910, %f908, %f904, %p312;
	mul.rn.f32 	%f911, %f910, %f812;
	cvt.rzi.f32.f32 	%f912, %f911;
	abs.f32 	%f913, %f912;
	setp.gt.f32 	%p313, %f913, 0f42FC0000;
	mov.b32 	%r450, %f912;
	and.b32  	%r451, %r450, -2147483648;
	or.b32  	%r452, %r451, 1123811328;
	mov.b32 	%f914, %r452;
	selp.f32 	%f915, %f914, %f912, %p313;
	fma.rn.f32 	%f917, %f915, %f3087, %f910;
	fma.rn.f32 	%f919, %f915, %f3088, %f917;
	mul.f32 	%f920, %f919, 0f3FB8AA3B;
	add.f32 	%f921, %f915, 0f4B40007F;
	mov.b32 	%r453, %f921;
	shl.b32 	%r454, %r453, 23;
	mov.b32 	%f922, %r454;
	ex2.approx.ftz.f32 	%f923, %f920;
	mul.f32 	%f148, %f923, %f922;
	setp.eq.f32 	%p314, %f148, 0f7F800000;
	mov.f32 	%f3251, 0f7F800000;
	@%p314 bra 	$L__BB6_150;

	fma.rn.f32 	%f3251, %f148, %f147, %f148;

$L__BB6_150:
	setp.lt.f32 	%p315, %f145, 0f00000000;
	and.pred  	%p31, %p315, %p301;
	setp.eq.f32 	%p317, %f145, 0f00000000;
	@%p317 bra 	$L__BB6_154;
	bra.uni 	$L__BB6_151;

$L__BB6_154:
	add.f32 	%f928, %f145, %f145;
	selp.f32 	%f3253, %f928, 0f00000000, %p301;
	bra.uni 	$L__BB6_155;

$L__BB6_151:
	mov.b32 	%r455, %f3251;
	xor.b32  	%r456, %r455, -2147483648;
	mov.b32 	%f924, %r456;
	selp.f32 	%f3253, %f924, %f3251, %p31;
	setp.geu.f32 	%p318, %f145, 0f00000000;
	@%p318 bra 	$L__BB6_155;

	cvt.rzi.f32.f32 	%f926, %f613;
	setp.eq.f32 	%p319, %f926, 0f40000000;
	@%p319 bra 	$L__BB6_155;

	mov.f32 	%f3253, 0f7FFFFFFF;

$L__BB6_155:
	add.f32 	%f929, %f146, 0f40000000;
	mov.b32 	%r457, %f929;
	setp.lt.s32 	%p321, %r457, 2139095040;
	@%p321 bra 	$L__BB6_160;

	setp.gtu.f32 	%p322, %f146, 0f7F800000;
	@%p322 bra 	$L__BB6_159;
	bra.uni 	$L__BB6_157;

$L__BB6_159:
	add.f32 	%f3253, %f145, 0f40000000;
	bra.uni 	$L__BB6_160;

$L__BB6_157:
	setp.neu.f32 	%p323, %f146, 0f7F800000;
	@%p323 bra 	$L__BB6_160;

	selp.f32 	%f3253, 0fFF800000, 0f7F800000, %p31;

$L__BB6_160:
	mov.f32 	%f3093, 0f32A57060;
	mov.f32 	%f3092, 0f4B400001;
	mov.f32 	%f3091, 0f437C0000;
	mov.f32 	%f3090, 0f3BBB989D;
	mov.f32 	%f3089, 0f3F000000;
	mul.f32 	%f930, %f3253, 0fBF000000;
	setp.eq.f32 	%p324, %f145, 0f3F800000;
	selp.f32 	%f931, 0fBF000000, %f930, %p324;
	fma.rn.f32 	%f934, %f931, %f3090, %f3089;
	cvt.sat.f32.f32 	%f937, %f934;
	fma.rm.f32 	%f939, %f937, %f3091, %f3092;
	add.f32 	%f940, %f939, 0fCB40007F;
	neg.f32 	%f941, %f940;
	fma.rn.f32 	%f942, %f931, %f812, %f941;
	fma.rn.f32 	%f944, %f931, %f3093, %f942;
	mov.b32 	%r458, %f939;
	shl.b32 	%r459, %r458, 23;
	mov.b32 	%f945, %r459;
	ex2.approx.ftz.f32 	%f946, %f944;
	mul.f32 	%f157, %f946, %f945;
	sub.f32 	%f947, %f144, %f157;
	div.rn.f32 	%f158, %f72, %f105;
	mul.f32 	%f948, %f158, %f947;
	mul.f32 	%f159, %f131, %f948;
	cvt.f64.f32 	%fd121, %f105;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r104}, %fd121;
	}
	abs.f64 	%fd122, %fd121;
	{ // callseq 127, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd122;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1097, [retval0+0];
	} // callseq 127
	setp.lt.s32 	%p325, %r104, 0;
	and.pred  	%p32, %p325, %p149;
	not.pred 	%p327, %p32;
	@%p327 bra 	$L__BB6_162;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r460}, %fd1097;
	}
	xor.b32  	%r461, %r460, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r462, %temp}, %fd1097;
	}
	mov.b64 	%fd1097, {%r462, %r461};

$L__BB6_162:
	setp.eq.f32 	%p328, %f105, 0f00000000;
	@%p328 bra 	$L__BB6_166;
	bra.uni 	$L__BB6_163;

$L__BB6_166:
	mov.u32 	%r463, 0;
	selp.b32 	%r464, %r104, 0, %p149;
	or.b32  	%r465, %r464, 2146435072;
	selp.b32 	%r466, %r465, %r464, %p152;
	mov.b64 	%fd1097, {%r463, %r466};
	bra.uni 	$L__BB6_167;

$L__BB6_163:
	setp.gt.s32 	%p329, %r104, -1;
	@%p329 bra 	$L__BB6_167;

	cvt.rzi.f64.f64 	%fd710, %fd649;
	setp.eq.f64 	%p330, %fd710, 0d4008000000000000;
	@%p330 bra 	$L__BB6_167;

	mov.f64 	%fd1097, 0dFFF8000000000000;

$L__BB6_167:
	add.f64 	%fd128, %fd121, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r467}, %fd128;
	}
	and.b32  	%r468, %r467, 2146435072;
	setp.ne.s32 	%p333, %r468, 2146435072;
	mov.f64 	%fd1098, %fd1097;
	@%p333 bra 	$L__BB6_173;

	setp.gtu.f64 	%p334, %fd122, 0d7FF0000000000000;
	mov.f64 	%fd1098, %fd128;
	@%p334 bra 	$L__BB6_173;

	setp.eq.s32 	%p335, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r469, %temp}, %fd649;
	}
	setp.eq.s32 	%p336, %r469, 0;
	and.pred  	%p337, %p335, %p336;
	@%p337 bra 	$L__BB6_172;
	bra.uni 	$L__BB6_170;

$L__BB6_172:
	mov.u32 	%r474, 0;
	setp.gt.f64 	%p344, %fd122, 0d3FF0000000000000;
	selp.b32 	%r475, 2146435072, 0, %p344;
	xor.b32  	%r476, %r475, 2146435072;
	selp.b32 	%r477, %r476, %r475, %p152;
	setp.eq.f32 	%p345, %f105, 0fBF800000;
	selp.b32 	%r478, 1072693248, %r477, %p345;
	mov.b64 	%fd1098, {%r474, %r478};
	bra.uni 	$L__BB6_173;

$L__BB6_170:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r470, %temp}, %fd121;
	}
	and.b32  	%r471, %r104, 2147483647;
	setp.ne.s32 	%p338, %r471, 2146435072;
	setp.ne.s32 	%p339, %r470, 0;
	or.pred  	%p340, %p338, %p339;
	mov.f64 	%fd1098, %fd1097;
	@%p340 bra 	$L__BB6_173;

	setp.ne.s32 	%p341, %r58, 1071644672;
	and.pred  	%p342, %p341, %p32;
	selp.b32 	%r472, %r63, %r62, %p342;
	mov.u32 	%r473, 0;
	mov.b64 	%fd1098, {%r473, %r472};

$L__BB6_173:
	cvt.rn.f32.s32 	%f3104, %r1375;
	mov.f32 	%f3103, 0f3102E308;
	mov.f32 	%f3102, 0fBF317218;
	mov.f32 	%f3101, 0f35BFBE8E;
	mov.f32 	%f3100, 0f3F317200;
	mov.f32 	%f3099, 0f3DAAAABD;
	mov.f32 	%f3098, 0f3C4CAF63;
	mov.f32 	%f3097, 0f3B18F0FE;
	cvt.rn.f32.s32 	%f3096, %r1374;
	add.f32 	%f3095, %f3096, 0f3F000000;
	sub.f32 	%f3094, %f3095, %f3295;
	setp.eq.f32 	%p346, %f105, 0f3F800000;
	selp.f64 	%fd713, 0d3FF0000000000000, %fd1098, %p346;
	cvt.f64.f32 	%fd714, %f72;
	div.rn.f64 	%fd715, %fd714, %fd713;
	mul.f32 	%f950, %f88, %f157;
	mul.f32 	%f951, %f3094, %f144;
	sub.f32 	%f952, %f951, %f950;
	cvt.f64.f32 	%fd716, %f952;
	mul.f64 	%fd717, %fd715, %fd716;
	cvt.f64.f32 	%fd718, %f131;
	mul.f64 	%fd719, %fd717, %fd718;
	cvt.rn.f32.f64 	%f160, %fd719;
	add.f32 	%f953, %f3104, 0f3F000000;
	sub.f32 	%f161, %f953, %f3294;
	div.rn.f32 	%f162, %f161, %f107;
	abs.f32 	%f163, %f162;
	setp.lt.f32 	%p347, %f163, 0f00800000;
	mul.f32 	%f954, %f163, 0f4B800000;
	selp.f32 	%f955, %f954, %f163, %p347;
	selp.f32 	%f956, 0fC3170000, 0fC2FE0000, %p347;
	mov.b32 	%r479, %f955;
	and.b32  	%r480, %r479, 8388607;
	or.b32  	%r481, %r480, 1065353216;
	mov.b32 	%f957, %r481;
	shr.u32 	%r482, %r479, 23;
	cvt.rn.f32.u32 	%f958, %r482;
	add.f32 	%f959, %f956, %f958;
	setp.gt.f32 	%p348, %f957, 0f3FB504F3;
	mul.f32 	%f960, %f957, 0f3F000000;
	add.f32 	%f961, %f959, 0f3F800000;
	selp.f32 	%f962, %f961, %f959, %p348;
	selp.f32 	%f963, %f960, %f957, %p348;
	add.f32 	%f964, %f963, 0fBF800000;
	add.f32 	%f965, %f963, 0f3F800000;
	rcp.approx.ftz.f32 	%f966, %f965;
	add.f32 	%f967, %f964, %f964;
	mul.f32 	%f969, %f967, %f966;
	mul.f32 	%f970, %f969, %f969;
	fma.rn.f32 	%f973, %f3097, %f970, %f3098;
	fma.rn.f32 	%f975, %f973, %f970, %f3099;
	mul.rn.f32 	%f976, %f975, %f970;
	mul.rn.f32 	%f977, %f976, %f969;
	sub.f32 	%f978, %f964, %f969;
	add.f32 	%f979, %f978, %f978;
	neg.f32 	%f980, %f969;
	fma.rn.f32 	%f981, %f980, %f964, %f979;
	mul.rn.f32 	%f982, %f966, %f981;
	add.f32 	%f983, %f977, %f969;
	sub.f32 	%f984, %f969, %f983;
	add.f32 	%f985, %f977, %f984;
	add.f32 	%f986, %f982, %f985;
	add.f32 	%f987, %f983, %f986;
	sub.f32 	%f988, %f983, %f987;
	add.f32 	%f989, %f986, %f988;
	mul.rn.f32 	%f991, %f962, %f3100;
	mul.rn.f32 	%f993, %f962, %f3101;
	add.f32 	%f994, %f991, %f987;
	sub.f32 	%f995, %f991, %f994;
	add.f32 	%f996, %f987, %f995;
	add.f32 	%f997, %f989, %f996;
	add.f32 	%f998, %f993, %f997;
	add.f32 	%f999, %f994, %f998;
	sub.f32 	%f1000, %f994, %f999;
	add.f32 	%f1001, %f998, %f1000;
	mul.rn.f32 	%f1002, %f613, %f999;
	neg.f32 	%f1003, %f1002;
	fma.rn.f32 	%f1004, %f613, %f999, %f1003;
	fma.rn.f32 	%f1005, %f613, %f1001, %f1004;
	fma.rn.f32 	%f1007, %f3279, %f999, %f1005;
	add.rn.f32 	%f1008, %f1002, %f1007;
	neg.f32 	%f1009, %f1008;
	add.rn.f32 	%f1010, %f1002, %f1009;
	add.rn.f32 	%f1011, %f1010, %f1007;
	mov.b32 	%r483, %f1008;
	setp.eq.s32 	%p349, %r483, 1118925336;
	add.s32 	%r484, %r483, -1;
	mov.b32 	%f1012, %r484;
	add.f32 	%f1013, %f1011, 0f37000000;
	selp.f32 	%f164, %f1013, %f1011, %p349;
	selp.f32 	%f1014, %f1012, %f1008, %p349;
	mul.rn.f32 	%f1016, %f1014, %f812;
	cvt.rzi.f32.f32 	%f1017, %f1016;
	abs.f32 	%f1018, %f1017;
	setp.gt.f32 	%p350, %f1018, 0f42FC0000;
	mov.b32 	%r485, %f1017;
	and.b32  	%r486, %r485, -2147483648;
	or.b32  	%r487, %r486, 1123811328;
	mov.b32 	%f1019, %r487;
	selp.f32 	%f1020, %f1019, %f1017, %p350;
	fma.rn.f32 	%f1022, %f1020, %f3102, %f1014;
	fma.rn.f32 	%f1024, %f1020, %f3103, %f1022;
	mul.f32 	%f1025, %f1024, 0f3FB8AA3B;
	add.f32 	%f1026, %f1020, 0f4B40007F;
	mov.b32 	%r488, %f1026;
	shl.b32 	%r489, %r488, 23;
	mov.b32 	%f1027, %r489;
	ex2.approx.ftz.f32 	%f1028, %f1025;
	mul.f32 	%f165, %f1028, %f1027;
	setp.eq.f32 	%p351, %f165, 0f7F800000;
	mov.f32 	%f3254, 0f7F800000;
	@%p351 bra 	$L__BB6_175;

	fma.rn.f32 	%f3254, %f165, %f164, %f165;

$L__BB6_175:
	setp.lt.f32 	%p352, %f162, 0f00000000;
	and.pred  	%p33, %p352, %p301;
	setp.eq.f32 	%p354, %f162, 0f00000000;
	@%p354 bra 	$L__BB6_179;
	bra.uni 	$L__BB6_176;

$L__BB6_179:
	add.f32 	%f1033, %f162, %f162;
	selp.f32 	%f3256, %f1033, 0f00000000, %p301;
	bra.uni 	$L__BB6_180;

$L__BB6_176:
	mov.b32 	%r490, %f3254;
	xor.b32  	%r491, %r490, -2147483648;
	mov.b32 	%f1029, %r491;
	selp.f32 	%f3256, %f1029, %f3254, %p33;
	setp.geu.f32 	%p355, %f162, 0f00000000;
	@%p355 bra 	$L__BB6_180;

	cvt.rzi.f32.f32 	%f1031, %f613;
	setp.eq.f32 	%p356, %f1031, 0f40000000;
	@%p356 bra 	$L__BB6_180;

	mov.f32 	%f3256, 0f7FFFFFFF;

$L__BB6_180:
	abs.f32 	%f3152, %f162;
	add.f32 	%f1034, %f3152, 0f40000000;
	mov.b32 	%r492, %f1034;
	setp.lt.s32 	%p358, %r492, 2139095040;
	@%p358 bra 	$L__BB6_185;

	abs.f32 	%f3156, %f162;
	setp.gtu.f32 	%p359, %f3156, 0f7F800000;
	@%p359 bra 	$L__BB6_184;
	bra.uni 	$L__BB6_182;

$L__BB6_184:
	add.f32 	%f3256, %f162, 0f40000000;
	bra.uni 	$L__BB6_185;

$L__BB6_182:
	abs.f32 	%f3157, %f162;
	setp.neu.f32 	%p360, %f3157, 0f7F800000;
	@%p360 bra 	$L__BB6_185;

	selp.f32 	%f3256, 0fFF800000, 0f7F800000, %p33;

$L__BB6_185:
	mov.f32 	%f3116, 0f32A57060;
	mov.f32 	%f3115, 0f4B400001;
	mov.f32 	%f3114, 0f437C0000;
	mov.f32 	%f3113, 0f3BBB989D;
	mov.f32 	%f3112, 0f3102E308;
	mov.f32 	%f3111, 0fBF317218;
	mov.f32 	%f3110, 0f35BFBE8E;
	mov.f32 	%f3109, 0f3F317200;
	mov.f32 	%f3108, 0f3DAAAABD;
	mov.f32 	%f3107, 0f3C4CAF63;
	mov.f32 	%f3106, 0f3B18F0FE;
	mov.f32 	%f3105, 0f3F000000;
	mul.f32 	%f1036, %f3256, 0fBF000000;
	setp.eq.f32 	%p361, %f162, 0f3F800000;
	selp.f32 	%f1037, 0fBF000000, %f1036, %p361;
	fma.rn.f32 	%f1040, %f1037, %f3113, %f3105;
	cvt.sat.f32.f32 	%f1043, %f1040;
	fma.rm.f32 	%f1045, %f1043, %f3114, %f3115;
	add.f32 	%f1046, %f1045, 0fCB40007F;
	neg.f32 	%f1047, %f1046;
	fma.rn.f32 	%f1048, %f1037, %f812, %f1047;
	fma.rn.f32 	%f1050, %f1037, %f3116, %f1048;
	mov.b32 	%r493, %f1045;
	shl.b32 	%r494, %r493, 23;
	mov.b32 	%f1051, %r494;
	ex2.approx.ftz.f32 	%f1052, %f1050;
	mul.f32 	%f174, %f1052, %f1051;
	div.rn.f32 	%f175, %f126, %f107;
	abs.f32 	%f176, %f175;
	setp.lt.f32 	%p362, %f176, 0f00800000;
	mul.f32 	%f1053, %f176, 0f4B800000;
	selp.f32 	%f1054, %f1053, %f176, %p362;
	selp.f32 	%f1055, 0fC3170000, 0fC2FE0000, %p362;
	mov.b32 	%r495, %f1054;
	and.b32  	%r496, %r495, 8388607;
	or.b32  	%r497, %r496, 1065353216;
	mov.b32 	%f1056, %r497;
	shr.u32 	%r498, %r495, 23;
	cvt.rn.f32.u32 	%f1057, %r498;
	add.f32 	%f1058, %f1055, %f1057;
	setp.gt.f32 	%p363, %f1056, 0f3FB504F3;
	mul.f32 	%f1059, %f1056, 0f3F000000;
	add.f32 	%f1060, %f1058, 0f3F800000;
	selp.f32 	%f1061, %f1060, %f1058, %p363;
	selp.f32 	%f1062, %f1059, %f1056, %p363;
	add.f32 	%f1063, %f1062, 0fBF800000;
	add.f32 	%f1064, %f1062, 0f3F800000;
	rcp.approx.ftz.f32 	%f1065, %f1064;
	add.f32 	%f1066, %f1063, %f1063;
	mul.f32 	%f1068, %f1066, %f1065;
	mul.f32 	%f1069, %f1068, %f1068;
	fma.rn.f32 	%f1072, %f3106, %f1069, %f3107;
	fma.rn.f32 	%f1074, %f1072, %f1069, %f3108;
	mul.rn.f32 	%f1075, %f1074, %f1069;
	mul.rn.f32 	%f1076, %f1075, %f1068;
	sub.f32 	%f1077, %f1063, %f1068;
	add.f32 	%f1078, %f1077, %f1077;
	neg.f32 	%f1079, %f1068;
	fma.rn.f32 	%f1080, %f1079, %f1063, %f1078;
	mul.rn.f32 	%f1081, %f1065, %f1080;
	add.f32 	%f1082, %f1076, %f1068;
	sub.f32 	%f1083, %f1068, %f1082;
	add.f32 	%f1084, %f1076, %f1083;
	add.f32 	%f1085, %f1081, %f1084;
	add.f32 	%f1086, %f1082, %f1085;
	sub.f32 	%f1087, %f1082, %f1086;
	add.f32 	%f1088, %f1085, %f1087;
	mul.rn.f32 	%f1090, %f1061, %f3109;
	mul.rn.f32 	%f1092, %f1061, %f3110;
	add.f32 	%f1093, %f1090, %f1086;
	sub.f32 	%f1094, %f1090, %f1093;
	add.f32 	%f1095, %f1086, %f1094;
	add.f32 	%f1096, %f1088, %f1095;
	add.f32 	%f1097, %f1092, %f1096;
	add.f32 	%f1098, %f1093, %f1097;
	sub.f32 	%f1099, %f1093, %f1098;
	add.f32 	%f1100, %f1097, %f1099;
	mul.rn.f32 	%f1101, %f613, %f1098;
	neg.f32 	%f1102, %f1101;
	fma.rn.f32 	%f1103, %f613, %f1098, %f1102;
	fma.rn.f32 	%f1104, %f613, %f1100, %f1103;
	fma.rn.f32 	%f1106, %f3279, %f1098, %f1104;
	add.rn.f32 	%f1107, %f1101, %f1106;
	neg.f32 	%f1108, %f1107;
	add.rn.f32 	%f1109, %f1101, %f1108;
	add.rn.f32 	%f1110, %f1109, %f1106;
	mov.b32 	%r499, %f1107;
	setp.eq.s32 	%p364, %r499, 1118925336;
	add.s32 	%r500, %r499, -1;
	mov.b32 	%f1111, %r500;
	add.f32 	%f1112, %f1110, 0f37000000;
	selp.f32 	%f177, %f1112, %f1110, %p364;
	selp.f32 	%f1113, %f1111, %f1107, %p364;
	mul.rn.f32 	%f1114, %f1113, %f812;
	cvt.rzi.f32.f32 	%f1115, %f1114;
	abs.f32 	%f1116, %f1115;
	setp.gt.f32 	%p365, %f1116, 0f42FC0000;
	mov.b32 	%r501, %f1115;
	and.b32  	%r502, %r501, -2147483648;
	or.b32  	%r503, %r502, 1123811328;
	mov.b32 	%f1117, %r503;
	selp.f32 	%f1118, %f1117, %f1115, %p365;
	fma.rn.f32 	%f1120, %f1118, %f3111, %f1113;
	fma.rn.f32 	%f1122, %f1118, %f3112, %f1120;
	mul.f32 	%f1123, %f1122, 0f3FB8AA3B;
	add.f32 	%f1124, %f1118, 0f4B40007F;
	mov.b32 	%r504, %f1124;
	shl.b32 	%r505, %r504, 23;
	mov.b32 	%f1125, %r505;
	ex2.approx.ftz.f32 	%f1126, %f1123;
	mul.f32 	%f178, %f1126, %f1125;
	setp.eq.f32 	%p366, %f178, 0f7F800000;
	mov.f32 	%f3257, 0f7F800000;
	@%p366 bra 	$L__BB6_187;

	fma.rn.f32 	%f3257, %f178, %f177, %f178;

$L__BB6_187:
	setp.lt.f32 	%p367, %f175, 0f00000000;
	and.pred  	%p34, %p367, %p301;
	setp.eq.f32 	%p369, %f175, 0f00000000;
	@%p369 bra 	$L__BB6_191;
	bra.uni 	$L__BB6_188;

$L__BB6_191:
	add.f32 	%f1131, %f175, %f175;
	selp.f32 	%f3259, %f1131, 0f00000000, %p301;
	bra.uni 	$L__BB6_192;

$L__BB6_188:
	mov.b32 	%r506, %f3257;
	xor.b32  	%r507, %r506, -2147483648;
	mov.b32 	%f1127, %r507;
	selp.f32 	%f3259, %f1127, %f3257, %p34;
	setp.geu.f32 	%p370, %f175, 0f00000000;
	@%p370 bra 	$L__BB6_192;

	cvt.rzi.f32.f32 	%f1129, %f613;
	setp.eq.f32 	%p371, %f1129, 0f40000000;
	@%p371 bra 	$L__BB6_192;

	mov.f32 	%f3259, 0f7FFFFFFF;

$L__BB6_192:
	abs.f32 	%f3158, %f175;
	add.f32 	%f1132, %f3158, 0f40000000;
	mov.b32 	%r508, %f1132;
	setp.lt.s32 	%p373, %r508, 2139095040;
	@%p373 bra 	$L__BB6_197;

	abs.f32 	%f3159, %f175;
	setp.gtu.f32 	%p374, %f3159, 0f7F800000;
	@%p374 bra 	$L__BB6_196;
	bra.uni 	$L__BB6_194;

$L__BB6_196:
	add.f32 	%f3259, %f175, 0f40000000;
	bra.uni 	$L__BB6_197;

$L__BB6_194:
	abs.f32 	%f3160, %f175;
	setp.neu.f32 	%p375, %f3160, 0f7F800000;
	@%p375 bra 	$L__BB6_197;

	selp.f32 	%f3259, 0fFF800000, 0f7F800000, %p34;

$L__BB6_197:
	mov.f32 	%f3121, 0f32A57060;
	mov.f32 	%f3120, 0f4B400001;
	mov.f32 	%f3119, 0f437C0000;
	mov.f32 	%f3118, 0f3BBB989D;
	mov.f32 	%f3117, 0f3F000000;
	mul.f32 	%f1133, %f3259, 0fBF000000;
	setp.eq.f32 	%p376, %f175, 0f3F800000;
	selp.f32 	%f1134, 0fBF000000, %f1133, %p376;
	fma.rn.f32 	%f1137, %f1134, %f3118, %f3117;
	cvt.sat.f32.f32 	%f1140, %f1137;
	fma.rm.f32 	%f1142, %f1140, %f3119, %f3120;
	add.f32 	%f1143, %f1142, 0fCB40007F;
	neg.f32 	%f1144, %f1143;
	fma.rn.f32 	%f1145, %f1134, %f812, %f1144;
	fma.rn.f32 	%f1147, %f1134, %f3121, %f1145;
	mov.b32 	%r509, %f1142;
	shl.b32 	%r510, %r509, 23;
	mov.b32 	%f1148, %r510;
	ex2.approx.ftz.f32 	%f1149, %f1147;
	mul.f32 	%f187, %f1149, %f1148;
	sub.f32 	%f1150, %f174, %f187;
	div.rn.f32 	%f188, %f72, %f107;
	mul.f32 	%f1151, %f188, %f1150;
	mul.f32 	%f189, %f117, %f1151;
	cvt.f64.f32 	%fd132, %f107;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r105}, %fd132;
	}
	abs.f64 	%fd133, %fd132;
	{ // callseq 128, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd133;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1100, [retval0+0];
	} // callseq 128
	setp.lt.s32 	%p377, %r105, 0;
	and.pred  	%p35, %p377, %p149;
	not.pred 	%p379, %p35;
	@%p379 bra 	$L__BB6_199;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r511}, %fd1100;
	}
	xor.b32  	%r512, %r511, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r513, %temp}, %fd1100;
	}
	mov.b64 	%fd1100, {%r513, %r512};

$L__BB6_199:
	setp.eq.f32 	%p380, %f107, 0f00000000;
	@%p380 bra 	$L__BB6_203;
	bra.uni 	$L__BB6_200;

$L__BB6_203:
	mov.u32 	%r514, 0;
	selp.b32 	%r515, %r105, 0, %p149;
	or.b32  	%r516, %r515, 2146435072;
	selp.b32 	%r517, %r516, %r515, %p152;
	mov.b64 	%fd1100, {%r514, %r517};
	bra.uni 	$L__BB6_204;

$L__BB6_200:
	setp.gt.s32 	%p381, %r105, -1;
	@%p381 bra 	$L__BB6_204;

	cvt.rzi.f64.f64 	%fd722, %fd649;
	setp.eq.f64 	%p382, %fd722, 0d4008000000000000;
	@%p382 bra 	$L__BB6_204;

	mov.f64 	%fd1100, 0dFFF8000000000000;

$L__BB6_204:
	add.f64 	%fd139, %fd132, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r518}, %fd139;
	}
	and.b32  	%r519, %r518, 2146435072;
	setp.ne.s32 	%p385, %r519, 2146435072;
	mov.f64 	%fd1101, %fd1100;
	@%p385 bra 	$L__BB6_210;

	setp.gtu.f64 	%p386, %fd133, 0d7FF0000000000000;
	mov.f64 	%fd1101, %fd139;
	@%p386 bra 	$L__BB6_210;

	setp.eq.s32 	%p387, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r520, %temp}, %fd649;
	}
	setp.eq.s32 	%p388, %r520, 0;
	and.pred  	%p389, %p387, %p388;
	@%p389 bra 	$L__BB6_209;
	bra.uni 	$L__BB6_207;

$L__BB6_209:
	mov.u32 	%r525, 0;
	setp.gt.f64 	%p396, %fd133, 0d3FF0000000000000;
	selp.b32 	%r526, 2146435072, 0, %p396;
	xor.b32  	%r527, %r526, 2146435072;
	selp.b32 	%r528, %r527, %r526, %p152;
	setp.eq.f32 	%p397, %f107, 0fBF800000;
	selp.b32 	%r529, 1072693248, %r528, %p397;
	mov.b64 	%fd1101, {%r525, %r529};
	bra.uni 	$L__BB6_210;

$L__BB6_207:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r521, %temp}, %fd132;
	}
	and.b32  	%r522, %r105, 2147483647;
	setp.ne.s32 	%p390, %r522, 2146435072;
	setp.ne.s32 	%p391, %r521, 0;
	or.pred  	%p392, %p390, %p391;
	mov.f64 	%fd1101, %fd1100;
	@%p392 bra 	$L__BB6_210;

	setp.ne.s32 	%p393, %r58, 1071644672;
	and.pred  	%p394, %p393, %p35;
	selp.b32 	%r523, %r63, %r62, %p394;
	mov.u32 	%r524, 0;
	mov.b64 	%fd1101, {%r524, %r523};

$L__BB6_210:
	cvt.rn.f32.s32 	%f3155, %r1375;
	add.f32 	%f3154, %f3155, 0f3F000000;
	sub.f32 	%f3153, %f3154, %f3294;
	cvt.f64.f32 	%fd1069, %f72;
	cvt.rn.f32.s32 	%f3129, %r1374;
	mov.f32 	%f3128, 0f3102E308;
	mov.f32 	%f3127, 0fBF317218;
	mov.f32 	%f3126, 0f35BFBE8E;
	mov.f32 	%f3125, 0f3F317200;
	mov.f32 	%f3124, 0f3DAAAABD;
	mov.f32 	%f3123, 0f3C4CAF63;
	mov.f32 	%f3122, 0f3B18F0FE;
	setp.eq.f32 	%p398, %f107, 0f3F800000;
	selp.f64 	%fd725, 0d3FF0000000000000, %fd1101, %p398;
	div.rn.f64 	%fd727, %fd1069, %fd725;
	mul.f32 	%f1153, %f126, %f187;
	mul.f32 	%f1154, %f3153, %f174;
	sub.f32 	%f1155, %f1154, %f1153;
	cvt.f64.f32 	%fd728, %f1155;
	mul.f64 	%fd729, %fd727, %fd728;
	cvt.f64.f32 	%fd730, %f117;
	mul.f64 	%fd731, %fd729, %fd730;
	cvt.rn.f32.f64 	%f190, %fd731;
	add.f32 	%f1156, %f3129, 0f3F800000;
	sub.f32 	%f1157, %f1156, %f3295;
	div.rn.f32 	%f191, %f1157, %f105;
	abs.f32 	%f192, %f191;
	setp.lt.f32 	%p399, %f192, 0f00800000;
	mul.f32 	%f1158, %f192, 0f4B800000;
	selp.f32 	%f1159, %f1158, %f192, %p399;
	selp.f32 	%f1160, 0fC3170000, 0fC2FE0000, %p399;
	mov.b32 	%r530, %f1159;
	and.b32  	%r531, %r530, 8388607;
	or.b32  	%r532, %r531, 1065353216;
	mov.b32 	%f1161, %r532;
	shr.u32 	%r533, %r530, 23;
	cvt.rn.f32.u32 	%f1162, %r533;
	add.f32 	%f1163, %f1160, %f1162;
	setp.gt.f32 	%p400, %f1161, 0f3FB504F3;
	mul.f32 	%f1164, %f1161, 0f3F000000;
	add.f32 	%f1165, %f1163, 0f3F800000;
	selp.f32 	%f1166, %f1165, %f1163, %p400;
	selp.f32 	%f1167, %f1164, %f1161, %p400;
	add.f32 	%f1168, %f1167, 0fBF800000;
	add.f32 	%f1169, %f1167, 0f3F800000;
	rcp.approx.ftz.f32 	%f1170, %f1169;
	add.f32 	%f1171, %f1168, %f1168;
	mul.f32 	%f1173, %f1171, %f1170;
	mul.f32 	%f1174, %f1173, %f1173;
	fma.rn.f32 	%f1177, %f3122, %f1174, %f3123;
	fma.rn.f32 	%f1179, %f1177, %f1174, %f3124;
	mul.rn.f32 	%f1180, %f1179, %f1174;
	mul.rn.f32 	%f1181, %f1180, %f1173;
	sub.f32 	%f1182, %f1168, %f1173;
	add.f32 	%f1183, %f1182, %f1182;
	neg.f32 	%f1184, %f1173;
	fma.rn.f32 	%f1185, %f1184, %f1168, %f1183;
	mul.rn.f32 	%f1186, %f1170, %f1185;
	add.f32 	%f1187, %f1181, %f1173;
	sub.f32 	%f1188, %f1173, %f1187;
	add.f32 	%f1189, %f1181, %f1188;
	add.f32 	%f1190, %f1186, %f1189;
	add.f32 	%f1191, %f1187, %f1190;
	sub.f32 	%f1192, %f1187, %f1191;
	add.f32 	%f1193, %f1190, %f1192;
	mul.rn.f32 	%f1195, %f1166, %f3125;
	mul.rn.f32 	%f1197, %f1166, %f3126;
	add.f32 	%f1198, %f1195, %f1191;
	sub.f32 	%f1199, %f1195, %f1198;
	add.f32 	%f1200, %f1191, %f1199;
	add.f32 	%f1201, %f1193, %f1200;
	add.f32 	%f1202, %f1197, %f1201;
	add.f32 	%f1203, %f1198, %f1202;
	sub.f32 	%f1204, %f1198, %f1203;
	add.f32 	%f1205, %f1202, %f1204;
	mul.rn.f32 	%f1206, %f613, %f1203;
	neg.f32 	%f1207, %f1206;
	fma.rn.f32 	%f1208, %f613, %f1203, %f1207;
	fma.rn.f32 	%f1209, %f613, %f1205, %f1208;
	fma.rn.f32 	%f1211, %f3279, %f1203, %f1209;
	add.rn.f32 	%f1212, %f1206, %f1211;
	neg.f32 	%f1213, %f1212;
	add.rn.f32 	%f1214, %f1206, %f1213;
	add.rn.f32 	%f1215, %f1214, %f1211;
	mov.b32 	%r534, %f1212;
	setp.eq.s32 	%p401, %r534, 1118925336;
	add.s32 	%r535, %r534, -1;
	mov.b32 	%f1216, %r535;
	add.f32 	%f1217, %f1215, 0f37000000;
	selp.f32 	%f193, %f1217, %f1215, %p401;
	selp.f32 	%f1218, %f1216, %f1212, %p401;
	mul.rn.f32 	%f1220, %f1218, %f812;
	cvt.rzi.f32.f32 	%f1221, %f1220;
	abs.f32 	%f1222, %f1221;
	setp.gt.f32 	%p402, %f1222, 0f42FC0000;
	mov.b32 	%r536, %f1221;
	and.b32  	%r537, %r536, -2147483648;
	or.b32  	%r538, %r537, 1123811328;
	mov.b32 	%f1223, %r538;
	selp.f32 	%f1224, %f1223, %f1221, %p402;
	fma.rn.f32 	%f1226, %f1224, %f3127, %f1218;
	fma.rn.f32 	%f1228, %f1224, %f3128, %f1226;
	mul.f32 	%f1229, %f1228, 0f3FB8AA3B;
	add.f32 	%f1230, %f1224, 0f4B40007F;
	mov.b32 	%r539, %f1230;
	shl.b32 	%r540, %r539, 23;
	mov.b32 	%f1231, %r540;
	ex2.approx.ftz.f32 	%f1232, %f1229;
	mul.f32 	%f194, %f1232, %f1231;
	setp.eq.f32 	%p403, %f194, 0f7F800000;
	mov.f32 	%f3260, 0f7F800000;
	@%p403 bra 	$L__BB6_212;

	fma.rn.f32 	%f3260, %f194, %f193, %f194;

$L__BB6_212:
	setp.lt.f32 	%p404, %f191, 0f00000000;
	and.pred  	%p36, %p404, %p301;
	setp.eq.f32 	%p406, %f191, 0f00000000;
	@%p406 bra 	$L__BB6_216;
	bra.uni 	$L__BB6_213;

$L__BB6_216:
	add.f32 	%f1237, %f191, %f191;
	selp.f32 	%f3262, %f1237, 0f00000000, %p301;
	bra.uni 	$L__BB6_217;

$L__BB6_213:
	mov.b32 	%r541, %f3260;
	xor.b32  	%r542, %r541, -2147483648;
	mov.b32 	%f1233, %r542;
	selp.f32 	%f3262, %f1233, %f3260, %p36;
	setp.geu.f32 	%p407, %f191, 0f00000000;
	@%p407 bra 	$L__BB6_217;

	cvt.rzi.f32.f32 	%f1235, %f613;
	setp.eq.f32 	%p408, %f1235, 0f40000000;
	@%p408 bra 	$L__BB6_217;

	mov.f32 	%f3262, 0f7FFFFFFF;

$L__BB6_217:
	abs.f32 	%f3161, %f191;
	add.f32 	%f1238, %f3161, 0f40000000;
	mov.b32 	%r543, %f1238;
	setp.lt.s32 	%p410, %r543, 2139095040;
	@%p410 bra 	$L__BB6_222;

	abs.f32 	%f3162, %f191;
	setp.gtu.f32 	%p411, %f3162, 0f7F800000;
	@%p411 bra 	$L__BB6_221;
	bra.uni 	$L__BB6_219;

$L__BB6_221:
	add.f32 	%f3262, %f191, 0f40000000;
	bra.uni 	$L__BB6_222;

$L__BB6_219:
	abs.f32 	%f3163, %f191;
	setp.neu.f32 	%p412, %f3163, 0f7F800000;
	@%p412 bra 	$L__BB6_222;

	selp.f32 	%f3262, 0fFF800000, 0f7F800000, %p36;

$L__BB6_222:
	cvt.rn.f32.s32 	%f3143, %r1374;
	sub.f32 	%f3142, %f3143, %f3295;
	mov.f32 	%f3141, 0f32A57060;
	mov.f32 	%f3140, 0f4B400001;
	mov.f32 	%f3139, 0f437C0000;
	mov.f32 	%f3138, 0f3BBB989D;
	mov.f32 	%f3137, 0f3102E308;
	mov.f32 	%f3136, 0fBF317218;
	mov.f32 	%f3135, 0f35BFBE8E;
	mov.f32 	%f3134, 0f3F317200;
	mov.f32 	%f3133, 0f3DAAAABD;
	mov.f32 	%f3132, 0f3C4CAF63;
	mov.f32 	%f3131, 0f3B18F0FE;
	mov.f32 	%f3130, 0f3F000000;
	mul.f32 	%f1240, %f3262, 0fBF000000;
	setp.eq.f32 	%p413, %f191, 0f3F800000;
	selp.f32 	%f1241, 0fBF000000, %f1240, %p413;
	fma.rn.f32 	%f1244, %f1241, %f3138, %f3130;
	cvt.sat.f32.f32 	%f1247, %f1244;
	fma.rm.f32 	%f1249, %f1247, %f3139, %f3140;
	add.f32 	%f1250, %f1249, 0fCB40007F;
	neg.f32 	%f1251, %f1250;
	fma.rn.f32 	%f1252, %f1241, %f812, %f1251;
	fma.rn.f32 	%f1254, %f1241, %f3141, %f1252;
	mov.b32 	%r544, %f1249;
	shl.b32 	%r545, %r544, 23;
	mov.b32 	%f1255, %r545;
	ex2.approx.ftz.f32 	%f1256, %f1254;
	mul.f32 	%f203, %f1256, %f1255;
	div.rn.f32 	%f204, %f3142, %f105;
	abs.f32 	%f205, %f204;
	setp.lt.f32 	%p414, %f205, 0f00800000;
	mul.f32 	%f1257, %f205, 0f4B800000;
	selp.f32 	%f1258, %f1257, %f205, %p414;
	selp.f32 	%f1259, 0fC3170000, 0fC2FE0000, %p414;
	mov.b32 	%r546, %f1258;
	and.b32  	%r547, %r546, 8388607;
	or.b32  	%r548, %r547, 1065353216;
	mov.b32 	%f1260, %r548;
	shr.u32 	%r549, %r546, 23;
	cvt.rn.f32.u32 	%f1261, %r549;
	add.f32 	%f1262, %f1259, %f1261;
	setp.gt.f32 	%p415, %f1260, 0f3FB504F3;
	mul.f32 	%f1263, %f1260, 0f3F000000;
	add.f32 	%f1264, %f1262, 0f3F800000;
	selp.f32 	%f1265, %f1264, %f1262, %p415;
	selp.f32 	%f1266, %f1263, %f1260, %p415;
	add.f32 	%f1267, %f1266, 0fBF800000;
	add.f32 	%f1268, %f1266, 0f3F800000;
	rcp.approx.ftz.f32 	%f1269, %f1268;
	add.f32 	%f1270, %f1267, %f1267;
	mul.f32 	%f1272, %f1270, %f1269;
	mul.f32 	%f1273, %f1272, %f1272;
	fma.rn.f32 	%f1276, %f3131, %f1273, %f3132;
	fma.rn.f32 	%f1278, %f1276, %f1273, %f3133;
	mul.rn.f32 	%f1279, %f1278, %f1273;
	mul.rn.f32 	%f1280, %f1279, %f1272;
	sub.f32 	%f1281, %f1267, %f1272;
	add.f32 	%f1282, %f1281, %f1281;
	neg.f32 	%f1283, %f1272;
	fma.rn.f32 	%f1284, %f1283, %f1267, %f1282;
	mul.rn.f32 	%f1285, %f1269, %f1284;
	add.f32 	%f1286, %f1280, %f1272;
	sub.f32 	%f1287, %f1272, %f1286;
	add.f32 	%f1288, %f1280, %f1287;
	add.f32 	%f1289, %f1285, %f1288;
	add.f32 	%f1290, %f1286, %f1289;
	sub.f32 	%f1291, %f1286, %f1290;
	add.f32 	%f1292, %f1289, %f1291;
	mul.rn.f32 	%f1294, %f1265, %f3134;
	mul.rn.f32 	%f1296, %f1265, %f3135;
	add.f32 	%f1297, %f1294, %f1290;
	sub.f32 	%f1298, %f1294, %f1297;
	add.f32 	%f1299, %f1290, %f1298;
	add.f32 	%f1300, %f1292, %f1299;
	add.f32 	%f1301, %f1296, %f1300;
	add.f32 	%f1302, %f1297, %f1301;
	sub.f32 	%f1303, %f1297, %f1302;
	add.f32 	%f1304, %f1301, %f1303;
	mul.rn.f32 	%f1305, %f613, %f1302;
	neg.f32 	%f1306, %f1305;
	fma.rn.f32 	%f1307, %f613, %f1302, %f1306;
	fma.rn.f32 	%f1308, %f613, %f1304, %f1307;
	fma.rn.f32 	%f1310, %f3279, %f1302, %f1308;
	add.rn.f32 	%f1311, %f1305, %f1310;
	neg.f32 	%f1312, %f1311;
	add.rn.f32 	%f1313, %f1305, %f1312;
	add.rn.f32 	%f1314, %f1313, %f1310;
	mov.b32 	%r550, %f1311;
	setp.eq.s32 	%p416, %r550, 1118925336;
	add.s32 	%r551, %r550, -1;
	mov.b32 	%f1315, %r551;
	add.f32 	%f1316, %f1314, 0f37000000;
	selp.f32 	%f206, %f1316, %f1314, %p416;
	selp.f32 	%f1317, %f1315, %f1311, %p416;
	mul.rn.f32 	%f1318, %f1317, %f812;
	cvt.rzi.f32.f32 	%f1319, %f1318;
	abs.f32 	%f1320, %f1319;
	setp.gt.f32 	%p417, %f1320, 0f42FC0000;
	mov.b32 	%r552, %f1319;
	and.b32  	%r553, %r552, -2147483648;
	or.b32  	%r554, %r553, 1123811328;
	mov.b32 	%f1321, %r554;
	selp.f32 	%f1322, %f1321, %f1319, %p417;
	fma.rn.f32 	%f1324, %f1322, %f3136, %f1317;
	fma.rn.f32 	%f1326, %f1322, %f3137, %f1324;
	mul.f32 	%f1327, %f1326, 0f3FB8AA3B;
	add.f32 	%f1328, %f1322, 0f4B40007F;
	mov.b32 	%r555, %f1328;
	shl.b32 	%r556, %r555, 23;
	mov.b32 	%f1329, %r556;
	ex2.approx.ftz.f32 	%f1330, %f1327;
	mul.f32 	%f207, %f1330, %f1329;
	setp.eq.f32 	%p418, %f207, 0f7F800000;
	mov.f32 	%f3263, 0f7F800000;
	@%p418 bra 	$L__BB6_224;

	fma.rn.f32 	%f3263, %f207, %f206, %f207;

$L__BB6_224:
	setp.lt.f32 	%p419, %f204, 0f00000000;
	and.pred  	%p37, %p419, %p301;
	setp.eq.f32 	%p421, %f204, 0f00000000;
	@%p421 bra 	$L__BB6_228;
	bra.uni 	$L__BB6_225;

$L__BB6_228:
	add.f32 	%f1335, %f204, %f204;
	selp.f32 	%f3265, %f1335, 0f00000000, %p301;
	bra.uni 	$L__BB6_229;

$L__BB6_225:
	mov.b32 	%r557, %f3263;
	xor.b32  	%r558, %r557, -2147483648;
	mov.b32 	%f1331, %r558;
	selp.f32 	%f3265, %f1331, %f3263, %p37;
	setp.geu.f32 	%p422, %f204, 0f00000000;
	@%p422 bra 	$L__BB6_229;

	cvt.rzi.f32.f32 	%f1333, %f613;
	setp.eq.f32 	%p423, %f1333, 0f40000000;
	@%p423 bra 	$L__BB6_229;

	mov.f32 	%f3265, 0f7FFFFFFF;

$L__BB6_229:
	abs.f32 	%f2997, %f204;
	add.f32 	%f1336, %f2997, 0f40000000;
	mov.b32 	%r559, %f1336;
	setp.lt.s32 	%p425, %r559, 2139095040;
	@%p425 bra 	$L__BB6_234;

	abs.f32 	%f3150, %f204;
	setp.gtu.f32 	%p426, %f3150, 0f7F800000;
	@%p426 bra 	$L__BB6_233;
	bra.uni 	$L__BB6_231;

$L__BB6_233:
	add.f32 	%f3265, %f204, 0f40000000;
	bra.uni 	$L__BB6_234;

$L__BB6_231:
	abs.f32 	%f3151, %f204;
	setp.neu.f32 	%p427, %f3151, 0f7F800000;
	@%p427 bra 	$L__BB6_234;

	selp.f32 	%f3265, 0fFF800000, 0f7F800000, %p37;

$L__BB6_234:
	cvt.f64.f32 	%fd1044, %f105;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1352}, %fd1044;
	}
	setp.lt.s32 	%p1283, %r1352, 0;
	mov.f64 	%fd1043, 0d4014000000000000;
	cvt.rn.f32.s32 	%f3004, %r1374;
	sub.f32 	%f3003, %f3004, %f3295;
	mov.f32 	%f3002, 0f32A57060;
	mov.f32 	%f3001, 0f4B400001;
	mov.f32 	%f3000, 0f437C0000;
	mov.f32 	%f2999, 0f3BBB989D;
	mov.f32 	%f2998, 0f3F000000;
	and.b32  	%r560, %r78, 2146435072;
	setp.eq.s32 	%p428, %r560, 1074790400;
	mul.f32 	%f1337, %f3265, 0fBF000000;
	setp.eq.f32 	%p429, %f204, 0f3F800000;
	selp.f32 	%f1338, 0fBF000000, %f1337, %p429;
	fma.rn.f32 	%f1341, %f1338, %f2999, %f2998;
	cvt.sat.f32.f32 	%f1344, %f1341;
	fma.rm.f32 	%f1346, %f1344, %f3000, %f3001;
	add.f32 	%f1347, %f1346, 0fCB40007F;
	neg.f32 	%f1348, %f1347;
	fma.rn.f32 	%f1349, %f1338, %f812, %f1348;
	fma.rn.f32 	%f1351, %f1338, %f3002, %f1349;
	mov.b32 	%r561, %f1346;
	shl.b32 	%r562, %r561, 23;
	mov.b32 	%f1352, %r562;
	ex2.approx.ftz.f32 	%f1353, %f1351;
	mul.f32 	%f216, %f1353, %f1352;
	add.f32 	%f1354, %f3003, 0f3F800000;
	mul.f32 	%f1355, %f1354, %f203;
	mul.f32 	%f1356, %f3003, %f216;
	sub.f32 	%f1357, %f1355, %f1356;
	div.rn.f32 	%f1358, %f158, %f105;
	mul.f32 	%f1359, %f1358, %f1357;
	mul.f32 	%f217, %f131, %f1359;
	{ // callseq 129, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd122;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd1043;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1103, [retval0+0];
	} // callseq 129
	and.pred  	%p38, %p1283, %p428;
	not.pred 	%p431, %p38;
	@%p431 bra 	$L__BB6_236;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r563}, %fd1103;
	}
	xor.b32  	%r564, %r563, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r565, %temp}, %fd1103;
	}
	mov.b64 	%fd1103, {%r565, %r564};

$L__BB6_236:
	setp.eq.f32 	%p1284, %f105, 0f00000000;
	@%p1284 bra 	$L__BB6_240;
	bra.uni 	$L__BB6_237;

$L__BB6_240:
	setp.lt.s32 	%p435, %r78, 0;
	mov.u32 	%r566, 0;
	selp.b32 	%r568, %r104, 0, %p428;
	or.b32  	%r569, %r568, 2146435072;
	selp.b32 	%r570, %r569, %r568, %p435;
	mov.b64 	%fd1103, {%r566, %r570};
	bra.uni 	$L__BB6_241;

$L__BB6_237:
	setp.gt.s32 	%p433, %r104, -1;
	@%p433 bra 	$L__BB6_241;

	mov.f64 	%fd1068, 0d4014000000000000;
	cvt.rzi.f64.f64 	%fd734, %fd1068;
	setp.eq.f64 	%p434, %fd734, 0d4014000000000000;
	@%p434 bra 	$L__BB6_241;

	mov.f64 	%fd1103, 0dFFF8000000000000;

$L__BB6_241:
	add.f64 	%fd148, %fd121, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r571}, %fd148;
	}
	and.b32  	%r572, %r571, 2146435072;
	setp.ne.s32 	%p437, %r572, 2146435072;
	mov.f64 	%fd1104, %fd1103;
	@%p437 bra 	$L__BB6_247;

	setp.gtu.f64 	%p438, %fd122, 0d7FF0000000000000;
	mov.f64 	%fd1104, %fd148;
	@%p438 bra 	$L__BB6_247;

	mov.f64 	%fd1067, 0d4014000000000000;
	and.b32  	%r573, %r78, 2147483647;
	setp.eq.s32 	%p439, %r573, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r574, %temp}, %fd1067;
	}
	setp.eq.s32 	%p440, %r574, 0;
	and.pred  	%p441, %p439, %p440;
	@%p441 bra 	$L__BB6_246;
	bra.uni 	$L__BB6_244;

$L__BB6_246:
	setp.lt.s32 	%p448, %r78, 0;
	mov.u32 	%r582, 0;
	setp.gt.f64 	%p449, %fd122, 0d3FF0000000000000;
	selp.b32 	%r583, 2146435072, 0, %p449;
	xor.b32  	%r584, %r583, 2146435072;
	selp.b32 	%r585, %r584, %r583, %p448;
	setp.eq.f32 	%p450, %f105, 0fBF800000;
	selp.b32 	%r586, 1072693248, %r585, %p450;
	mov.b64 	%fd1104, {%r582, %r586};
	bra.uni 	$L__BB6_247;

$L__BB6_244:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r575, %temp}, %fd121;
	}
	and.b32  	%r576, %r104, 2147483647;
	setp.ne.s32 	%p442, %r576, 2146435072;
	setp.ne.s32 	%p443, %r575, 0;
	or.pred  	%p444, %p442, %p443;
	mov.f64 	%fd1104, %fd1103;
	@%p444 bra 	$L__BB6_247;

	setp.ne.s32 	%p445, %r573, 1071644672;
	and.pred  	%p446, %p445, %p38;
	setp.gt.s32 	%p447, %r78, -1;
	selp.b32 	%r578, 2146435072, 0, %p447;
	mov.u32 	%r579, 0;
	or.b32  	%r580, %r578, -2147483648;
	selp.b32 	%r581, %r580, %r578, %p446;
	mov.b64 	%fd1104, {%r579, %r581};

$L__BB6_247:
	not.pred 	%p451, %p10;
	mov.f64 	%fd1106, %fd61;
	@%p451 bra 	$L__BB6_249;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r587}, %fd61;
	}
	xor.b32  	%r588, %r587, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r589, %temp}, %fd61;
	}
	mov.b64 	%fd1106, {%r589, %r588};

$L__BB6_249:
	setp.eq.f32 	%p1285, %f105, 0f3F800000;
	setp.eq.f32 	%p452, %f87, 0f00000000;
	selp.f64 	%fd154, 0d3FF0000000000000, %fd1104, %p1285;
	@%p452 bra 	$L__BB6_253;
	bra.uni 	$L__BB6_250;

$L__BB6_253:
	mov.u32 	%r590, 0;
	selp.b32 	%r592, %r76, 0, %p149;
	or.b32  	%r593, %r592, 2146435072;
	selp.b32 	%r594, %r593, %r592, %p152;
	mov.b64 	%fd1106, {%r590, %r594};
	bra.uni 	$L__BB6_254;

$L__BB6_250:
	setp.gt.s32 	%p454, %r76, -1;
	@%p454 bra 	$L__BB6_254;

	cvt.rzi.f64.f64 	%fd738, %fd649;
	setp.eq.f64 	%p455, %fd738, 0d4008000000000000;
	@%p455 bra 	$L__BB6_254;

	mov.f64 	%fd1106, 0dFFF8000000000000;

$L__BB6_254:
	selp.f64 	%fd1107, %fd1106, %fd62, %p172;
	@%p23 bra 	$L__BB6_259;

	setp.eq.s32 	%p459, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r595, %temp}, %fd649;
	}
	setp.eq.s32 	%p460, %r595, 0;
	and.pred  	%p461, %p459, %p460;
	@%p461 bra 	$L__BB6_258;
	bra.uni 	$L__BB6_256;

$L__BB6_258:
	mov.u32 	%r602, 0;
	mov.b64 	%fd1107, {%r602, %r80};
	bra.uni 	$L__BB6_259;

$L__BB6_256:
	cvt.rn.f32.s32 	%f3007, %r1374;
	sub.f32 	%f3006, %f3007, %f3295;
	add.f32 	%f3005, %f3006, 0f3F000000;
	cvt.f64.f32 	%fd1045, %f3005;
	and.b32  	%r596, %r76, 2147483647;
	setp.ne.s32 	%p462, %r596, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r597, %temp}, %fd1045;
	}
	setp.ne.s32 	%p463, %r597, 0;
	or.pred  	%p464, %p462, %p463;
	mov.f64 	%fd1107, %fd1106;
	@%p464 bra 	$L__BB6_259;

	setp.ne.s32 	%p465, %r58, 1071644672;
	and.pred  	%p466, %p465, %p10;
	selp.b32 	%r600, %r63, %r62, %p466;
	mov.u32 	%r601, 0;
	mov.b64 	%fd1107, {%r601, %r600};

$L__BB6_259:
	setp.eq.f32 	%p467, %f87, 0f3F800000;
	selp.f64 	%fd741, 0d3FF0000000000000, %fd1107, %p467;
	cvt.f64.f32 	%fd742, %f203;
	mul.f64 	%fd161, %fd741, %fd742;
	not.pred 	%p468, %p11;
	mov.f64 	%fd1109, %fd64;
	@%p468 bra 	$L__BB6_261;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r603}, %fd64;
	}
	xor.b32  	%r604, %r603, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r605, %temp}, %fd64;
	}
	mov.b64 	%fd1109, {%r605, %r604};

$L__BB6_261:
	setp.eq.f32 	%p469, %f88, 0f00000000;
	@%p469 bra 	$L__BB6_265;
	bra.uni 	$L__BB6_262;

$L__BB6_265:
	mov.u32 	%r606, 0;
	selp.b32 	%r608, %r79, 0, %p149;
	or.b32  	%r609, %r608, 2146435072;
	selp.b32 	%r610, %r609, %r608, %p152;
	mov.b64 	%fd1109, {%r606, %r610};
	bra.uni 	$L__BB6_266;

$L__BB6_262:
	setp.gt.s32 	%p470, %r79, -1;
	@%p470 bra 	$L__BB6_266;

	cvt.rzi.f64.f64 	%fd744, %fd649;
	setp.eq.f64 	%p471, %fd744, 0d4008000000000000;
	@%p471 bra 	$L__BB6_266;

	mov.f64 	%fd1109, 0dFFF8000000000000;

$L__BB6_266:
	selp.f64 	%fd1110, %fd1109, %fd65, %p177;
	@%p24 bra 	$L__BB6_271;

	setp.eq.s32 	%p475, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r611, %temp}, %fd649;
	}
	setp.eq.s32 	%p476, %r611, 0;
	and.pred  	%p477, %p475, %p476;
	@%p477 bra 	$L__BB6_270;
	bra.uni 	$L__BB6_268;

$L__BB6_270:
	mov.u32 	%r618, 0;
	mov.b64 	%fd1110, {%r618, %r82};
	bra.uni 	$L__BB6_271;

$L__BB6_268:
	cvt.rn.f32.s32 	%f3010, %r1374;
	sub.f32 	%f3009, %f3010, %f3295;
	add.f32 	%f3008, %f3009, 0fBF000000;
	cvt.f64.f32 	%fd1046, %f3008;
	and.b32  	%r612, %r79, 2147483647;
	setp.ne.s32 	%p478, %r612, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r613, %temp}, %fd1046;
	}
	setp.ne.s32 	%p479, %r613, 0;
	or.pred  	%p480, %p478, %p479;
	mov.f64 	%fd1110, %fd1109;
	@%p480 bra 	$L__BB6_271;

	setp.ne.s32 	%p481, %r58, 1071644672;
	and.pred  	%p482, %p481, %p11;
	selp.b32 	%r616, %r63, %r62, %p482;
	mov.u32 	%r617, 0;
	mov.b64 	%fd1110, {%r617, %r616};

$L__BB6_271:
	cvt.f64.f32 	%fd1047, %f131;
	cvt.rn.f32.s32 	%f3018, %r1375;
	mov.f32 	%f3017, 0f3102E308;
	mov.f32 	%f3016, 0fBF317218;
	mov.f32 	%f3015, 0f35BFBE8E;
	mov.f32 	%f3014, 0f3F317200;
	mov.f32 	%f3013, 0f3DAAAABD;
	mov.f32 	%f3012, 0f3C4CAF63;
	mov.f32 	%f3011, 0f3B18F0FE;
	setp.eq.f32 	%p483, %f88, 0f3F800000;
	selp.f64 	%fd747, 0d3FF0000000000000, %fd1110, %p483;
	cvt.f64.f32 	%fd748, %f216;
	mul.f64 	%fd749, %fd747, %fd748;
	sub.f64 	%fd750, %fd161, %fd749;
	div.rn.f64 	%fd751, %fd43, %fd154;
	mul.f64 	%fd752, %fd751, %fd750;
	mul.f64 	%fd754, %fd752, %fd1047;
	mov.f32 	%f1361, 0fC0000000;
	div.rn.f32 	%f1362, %f1361, %f105;
	mul.f32 	%f1363, %f1362, %f217;
	cvt.f64.f32 	%fd755, %f1363;
	sub.f64 	%fd756, %fd755, %fd754;
	cvt.rn.f32.f64 	%f218, %fd756;
	add.f32 	%f1364, %f3018, 0f3F800000;
	sub.f32 	%f1365, %f1364, %f3294;
	div.rn.f32 	%f219, %f1365, %f107;
	abs.f32 	%f220, %f219;
	setp.lt.f32 	%p484, %f220, 0f00800000;
	mul.f32 	%f1366, %f220, 0f4B800000;
	selp.f32 	%f1367, %f1366, %f220, %p484;
	selp.f32 	%f1368, 0fC3170000, 0fC2FE0000, %p484;
	mov.b32 	%r619, %f1367;
	and.b32  	%r620, %r619, 8388607;
	or.b32  	%r621, %r620, 1065353216;
	mov.b32 	%f1369, %r621;
	shr.u32 	%r622, %r619, 23;
	cvt.rn.f32.u32 	%f1370, %r622;
	add.f32 	%f1371, %f1368, %f1370;
	setp.gt.f32 	%p485, %f1369, 0f3FB504F3;
	mul.f32 	%f1372, %f1369, 0f3F000000;
	add.f32 	%f1373, %f1371, 0f3F800000;
	selp.f32 	%f1374, %f1373, %f1371, %p485;
	selp.f32 	%f1375, %f1372, %f1369, %p485;
	add.f32 	%f1376, %f1375, 0fBF800000;
	add.f32 	%f1377, %f1375, 0f3F800000;
	rcp.approx.ftz.f32 	%f1378, %f1377;
	add.f32 	%f1379, %f1376, %f1376;
	mul.f32 	%f1381, %f1379, %f1378;
	mul.f32 	%f1382, %f1381, %f1381;
	fma.rn.f32 	%f1385, %f3011, %f1382, %f3012;
	fma.rn.f32 	%f1387, %f1385, %f1382, %f3013;
	mul.rn.f32 	%f1388, %f1387, %f1382;
	mul.rn.f32 	%f1389, %f1388, %f1381;
	sub.f32 	%f1390, %f1376, %f1381;
	add.f32 	%f1391, %f1390, %f1390;
	neg.f32 	%f1392, %f1381;
	fma.rn.f32 	%f1393, %f1392, %f1376, %f1391;
	mul.rn.f32 	%f1394, %f1378, %f1393;
	add.f32 	%f1395, %f1389, %f1381;
	sub.f32 	%f1396, %f1381, %f1395;
	add.f32 	%f1397, %f1389, %f1396;
	add.f32 	%f1398, %f1394, %f1397;
	add.f32 	%f1399, %f1395, %f1398;
	sub.f32 	%f1400, %f1395, %f1399;
	add.f32 	%f1401, %f1398, %f1400;
	mul.rn.f32 	%f1403, %f1374, %f3014;
	mul.rn.f32 	%f1405, %f1374, %f3015;
	add.f32 	%f1406, %f1403, %f1399;
	sub.f32 	%f1407, %f1403, %f1406;
	add.f32 	%f1408, %f1399, %f1407;
	add.f32 	%f1409, %f1401, %f1408;
	add.f32 	%f1410, %f1405, %f1409;
	add.f32 	%f1411, %f1406, %f1410;
	sub.f32 	%f1412, %f1406, %f1411;
	add.f32 	%f1413, %f1410, %f1412;
	mul.rn.f32 	%f1414, %f613, %f1411;
	neg.f32 	%f1415, %f1414;
	fma.rn.f32 	%f1416, %f613, %f1411, %f1415;
	fma.rn.f32 	%f1417, %f613, %f1413, %f1416;
	fma.rn.f32 	%f1419, %f3279, %f1411, %f1417;
	add.rn.f32 	%f1420, %f1414, %f1419;
	neg.f32 	%f1421, %f1420;
	add.rn.f32 	%f1422, %f1414, %f1421;
	add.rn.f32 	%f1423, %f1422, %f1419;
	mov.b32 	%r623, %f1420;
	setp.eq.s32 	%p486, %r623, 1118925336;
	add.s32 	%r624, %r623, -1;
	mov.b32 	%f1424, %r624;
	add.f32 	%f1425, %f1423, 0f37000000;
	selp.f32 	%f221, %f1425, %f1423, %p486;
	selp.f32 	%f1426, %f1424, %f1420, %p486;
	mul.rn.f32 	%f1428, %f1426, %f812;
	cvt.rzi.f32.f32 	%f1429, %f1428;
	abs.f32 	%f1430, %f1429;
	setp.gt.f32 	%p487, %f1430, 0f42FC0000;
	mov.b32 	%r625, %f1429;
	and.b32  	%r626, %r625, -2147483648;
	or.b32  	%r627, %r626, 1123811328;
	mov.b32 	%f1431, %r627;
	selp.f32 	%f1432, %f1431, %f1429, %p487;
	fma.rn.f32 	%f1434, %f1432, %f3016, %f1426;
	fma.rn.f32 	%f1436, %f1432, %f3017, %f1434;
	mul.f32 	%f1437, %f1436, 0f3FB8AA3B;
	add.f32 	%f1438, %f1432, 0f4B40007F;
	mov.b32 	%r628, %f1438;
	shl.b32 	%r629, %r628, 23;
	mov.b32 	%f1439, %r629;
	ex2.approx.ftz.f32 	%f1440, %f1437;
	mul.f32 	%f222, %f1440, %f1439;
	setp.eq.f32 	%p488, %f222, 0f7F800000;
	mov.f32 	%f3266, 0f7F800000;
	@%p488 bra 	$L__BB6_273;

	fma.rn.f32 	%f3266, %f222, %f221, %f222;

$L__BB6_273:
	setp.lt.f32 	%p489, %f219, 0f00000000;
	and.pred  	%p39, %p489, %p301;
	setp.eq.f32 	%p491, %f219, 0f00000000;
	@%p491 bra 	$L__BB6_277;
	bra.uni 	$L__BB6_274;

$L__BB6_277:
	add.f32 	%f1445, %f219, %f219;
	selp.f32 	%f3268, %f1445, 0f00000000, %p301;
	bra.uni 	$L__BB6_278;

$L__BB6_274:
	mov.b32 	%r630, %f3266;
	xor.b32  	%r631, %r630, -2147483648;
	mov.b32 	%f1441, %r631;
	selp.f32 	%f3268, %f1441, %f3266, %p39;
	setp.geu.f32 	%p492, %f219, 0f00000000;
	@%p492 bra 	$L__BB6_278;

	cvt.rzi.f32.f32 	%f1443, %f613;
	setp.eq.f32 	%p493, %f1443, 0f40000000;
	@%p493 bra 	$L__BB6_278;

	mov.f32 	%f3268, 0f7FFFFFFF;

$L__BB6_278:
	abs.f32 	%f3164, %f219;
	add.f32 	%f1446, %f3164, 0f40000000;
	mov.b32 	%r632, %f1446;
	setp.lt.s32 	%p495, %r632, 2139095040;
	@%p495 bra 	$L__BB6_283;

	abs.f32 	%f3166, %f219;
	setp.gtu.f32 	%p496, %f3166, 0f7F800000;
	@%p496 bra 	$L__BB6_282;
	bra.uni 	$L__BB6_280;

$L__BB6_282:
	add.f32 	%f3268, %f219, 0f40000000;
	bra.uni 	$L__BB6_283;

$L__BB6_280:
	abs.f32 	%f3167, %f219;
	setp.neu.f32 	%p497, %f3167, 0f7F800000;
	@%p497 bra 	$L__BB6_283;

	selp.f32 	%f3268, 0fFF800000, 0f7F800000, %p39;

$L__BB6_283:
	mov.f32 	%f3032, 0f32A57060;
	mov.f32 	%f3031, 0f4B400001;
	mov.f32 	%f3030, 0f437C0000;
	mov.f32 	%f3029, 0f3BBB989D;
	mov.f32 	%f3028, 0f3102E308;
	mov.f32 	%f3027, 0fBF317218;
	mov.f32 	%f3026, 0f35BFBE8E;
	mov.f32 	%f3025, 0f3F317200;
	mov.f32 	%f3024, 0f3DAAAABD;
	mov.f32 	%f3023, 0f3C4CAF63;
	mov.f32 	%f3022, 0f3B18F0FE;
	cvt.rn.f32.s32 	%f3021, %r1375;
	sub.f32 	%f3020, %f3021, %f3294;
	mov.f32 	%f3019, 0f3F000000;
	mul.f32 	%f1448, %f3268, 0fBF000000;
	setp.eq.f32 	%p498, %f219, 0f3F800000;
	selp.f32 	%f1449, 0fBF000000, %f1448, %p498;
	fma.rn.f32 	%f1452, %f1449, %f3029, %f3019;
	cvt.sat.f32.f32 	%f1455, %f1452;
	fma.rm.f32 	%f1457, %f1455, %f3030, %f3031;
	add.f32 	%f1458, %f1457, 0fCB40007F;
	neg.f32 	%f1459, %f1458;
	fma.rn.f32 	%f1460, %f1449, %f812, %f1459;
	fma.rn.f32 	%f1462, %f1449, %f3032, %f1460;
	mov.b32 	%r633, %f1457;
	shl.b32 	%r634, %r633, 23;
	mov.b32 	%f1463, %r634;
	ex2.approx.ftz.f32 	%f1464, %f1462;
	mul.f32 	%f231, %f1464, %f1463;
	div.rn.f32 	%f232, %f3020, %f107;
	abs.f32 	%f233, %f232;
	setp.lt.f32 	%p499, %f233, 0f00800000;
	mul.f32 	%f1465, %f233, 0f4B800000;
	selp.f32 	%f1466, %f1465, %f233, %p499;
	selp.f32 	%f1467, 0fC3170000, 0fC2FE0000, %p499;
	mov.b32 	%r635, %f1466;
	and.b32  	%r636, %r635, 8388607;
	or.b32  	%r637, %r636, 1065353216;
	mov.b32 	%f1468, %r637;
	shr.u32 	%r638, %r635, 23;
	cvt.rn.f32.u32 	%f1469, %r638;
	add.f32 	%f1470, %f1467, %f1469;
	setp.gt.f32 	%p500, %f1468, 0f3FB504F3;
	mul.f32 	%f1471, %f1468, 0f3F000000;
	add.f32 	%f1472, %f1470, 0f3F800000;
	selp.f32 	%f1473, %f1472, %f1470, %p500;
	selp.f32 	%f1474, %f1471, %f1468, %p500;
	add.f32 	%f1475, %f1474, 0fBF800000;
	add.f32 	%f1476, %f1474, 0f3F800000;
	rcp.approx.ftz.f32 	%f1477, %f1476;
	add.f32 	%f1478, %f1475, %f1475;
	mul.f32 	%f1480, %f1478, %f1477;
	mul.f32 	%f1481, %f1480, %f1480;
	fma.rn.f32 	%f1484, %f3022, %f1481, %f3023;
	fma.rn.f32 	%f1486, %f1484, %f1481, %f3024;
	mul.rn.f32 	%f1487, %f1486, %f1481;
	mul.rn.f32 	%f1488, %f1487, %f1480;
	sub.f32 	%f1489, %f1475, %f1480;
	add.f32 	%f1490, %f1489, %f1489;
	neg.f32 	%f1491, %f1480;
	fma.rn.f32 	%f1492, %f1491, %f1475, %f1490;
	mul.rn.f32 	%f1493, %f1477, %f1492;
	add.f32 	%f1494, %f1488, %f1480;
	sub.f32 	%f1495, %f1480, %f1494;
	add.f32 	%f1496, %f1488, %f1495;
	add.f32 	%f1497, %f1493, %f1496;
	add.f32 	%f1498, %f1494, %f1497;
	sub.f32 	%f1499, %f1494, %f1498;
	add.f32 	%f1500, %f1497, %f1499;
	mul.rn.f32 	%f1502, %f1473, %f3025;
	mul.rn.f32 	%f1504, %f1473, %f3026;
	add.f32 	%f1505, %f1502, %f1498;
	sub.f32 	%f1506, %f1502, %f1505;
	add.f32 	%f1507, %f1498, %f1506;
	add.f32 	%f1508, %f1500, %f1507;
	add.f32 	%f1509, %f1504, %f1508;
	add.f32 	%f1510, %f1505, %f1509;
	sub.f32 	%f1511, %f1505, %f1510;
	add.f32 	%f1512, %f1509, %f1511;
	mul.rn.f32 	%f1513, %f613, %f1510;
	neg.f32 	%f1514, %f1513;
	fma.rn.f32 	%f1515, %f613, %f1510, %f1514;
	fma.rn.f32 	%f1516, %f613, %f1512, %f1515;
	fma.rn.f32 	%f1518, %f3279, %f1510, %f1516;
	add.rn.f32 	%f1519, %f1513, %f1518;
	neg.f32 	%f1520, %f1519;
	add.rn.f32 	%f1521, %f1513, %f1520;
	add.rn.f32 	%f1522, %f1521, %f1518;
	mov.b32 	%r639, %f1519;
	setp.eq.s32 	%p501, %r639, 1118925336;
	add.s32 	%r640, %r639, -1;
	mov.b32 	%f1523, %r640;
	add.f32 	%f1524, %f1522, 0f37000000;
	selp.f32 	%f234, %f1524, %f1522, %p501;
	selp.f32 	%f1525, %f1523, %f1519, %p501;
	mul.rn.f32 	%f1526, %f1525, %f812;
	cvt.rzi.f32.f32 	%f1527, %f1526;
	abs.f32 	%f1528, %f1527;
	setp.gt.f32 	%p502, %f1528, 0f42FC0000;
	mov.b32 	%r641, %f1527;
	and.b32  	%r642, %r641, -2147483648;
	or.b32  	%r643, %r642, 1123811328;
	mov.b32 	%f1529, %r643;
	selp.f32 	%f1530, %f1529, %f1527, %p502;
	fma.rn.f32 	%f1532, %f1530, %f3027, %f1525;
	fma.rn.f32 	%f1534, %f1530, %f3028, %f1532;
	mul.f32 	%f1535, %f1534, 0f3FB8AA3B;
	add.f32 	%f1536, %f1530, 0f4B40007F;
	mov.b32 	%r644, %f1536;
	shl.b32 	%r645, %r644, 23;
	mov.b32 	%f1537, %r645;
	ex2.approx.ftz.f32 	%f1538, %f1535;
	mul.f32 	%f235, %f1538, %f1537;
	setp.eq.f32 	%p503, %f235, 0f7F800000;
	mov.f32 	%f3269, 0f7F800000;
	@%p503 bra 	$L__BB6_285;

	fma.rn.f32 	%f3269, %f235, %f234, %f235;

$L__BB6_285:
	setp.lt.f32 	%p504, %f232, 0f00000000;
	and.pred  	%p40, %p504, %p301;
	setp.eq.f32 	%p506, %f232, 0f00000000;
	@%p506 bra 	$L__BB6_289;
	bra.uni 	$L__BB6_286;

$L__BB6_289:
	add.f32 	%f1543, %f232, %f232;
	selp.f32 	%f3271, %f1543, 0f00000000, %p301;
	bra.uni 	$L__BB6_290;

$L__BB6_286:
	mov.b32 	%r646, %f3269;
	xor.b32  	%r647, %r646, -2147483648;
	mov.b32 	%f1539, %r647;
	selp.f32 	%f3271, %f1539, %f3269, %p40;
	setp.geu.f32 	%p507, %f232, 0f00000000;
	@%p507 bra 	$L__BB6_290;

	cvt.rzi.f32.f32 	%f1541, %f613;
	setp.eq.f32 	%p508, %f1541, 0f40000000;
	@%p508 bra 	$L__BB6_290;

	mov.f32 	%f3271, 0f7FFFFFFF;

$L__BB6_290:
	abs.f32 	%f3168, %f232;
	add.f32 	%f1544, %f3168, 0f40000000;
	mov.b32 	%r648, %f1544;
	setp.lt.s32 	%p510, %r648, 2139095040;
	@%p510 bra 	$L__BB6_295;

	abs.f32 	%f3169, %f232;
	setp.gtu.f32 	%p511, %f3169, 0f7F800000;
	@%p511 bra 	$L__BB6_294;
	bra.uni 	$L__BB6_292;

$L__BB6_294:
	add.f32 	%f3271, %f232, 0f40000000;
	bra.uni 	$L__BB6_295;

$L__BB6_292:
	abs.f32 	%f3170, %f232;
	setp.neu.f32 	%p512, %f3170, 0f7F800000;
	@%p512 bra 	$L__BB6_295;

	selp.f32 	%f3271, 0fFF800000, 0f7F800000, %p40;

$L__BB6_295:
	cvt.f64.f32 	%fd1049, %f107;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1353}, %fd1049;
	}
	setp.lt.s32 	%p1286, %r1353, 0;
	mov.f64 	%fd1048, 0d4014000000000000;
	mov.f32 	%f3039, 0f32A57060;
	mov.f32 	%f3038, 0f4B400001;
	mov.f32 	%f3037, 0f437C0000;
	mov.f32 	%f3036, 0f3BBB989D;
	cvt.rn.f32.s32 	%f3035, %r1375;
	sub.f32 	%f3034, %f3035, %f3294;
	mov.f32 	%f3033, 0f3F000000;
	mul.f32 	%f1545, %f3271, 0fBF000000;
	setp.eq.f32 	%p514, %f232, 0f3F800000;
	selp.f32 	%f1546, 0fBF000000, %f1545, %p514;
	fma.rn.f32 	%f1549, %f1546, %f3036, %f3033;
	cvt.sat.f32.f32 	%f1552, %f1549;
	fma.rm.f32 	%f1554, %f1552, %f3037, %f3038;
	add.f32 	%f1555, %f1554, 0fCB40007F;
	neg.f32 	%f1556, %f1555;
	fma.rn.f32 	%f1557, %f1546, %f812, %f1556;
	fma.rn.f32 	%f1559, %f1546, %f3039, %f1557;
	mov.b32 	%r650, %f1554;
	shl.b32 	%r651, %r650, 23;
	mov.b32 	%f1560, %r651;
	ex2.approx.ftz.f32 	%f1561, %f1559;
	mul.f32 	%f244, %f1561, %f1560;
	add.f32 	%f1562, %f3034, 0f3F800000;
	mul.f32 	%f1563, %f1562, %f231;
	mul.f32 	%f1564, %f3034, %f244;
	sub.f32 	%f1565, %f1563, %f1564;
	div.rn.f32 	%f1566, %f188, %f107;
	mul.f32 	%f1567, %f1566, %f1565;
	mul.f32 	%f245, %f117, %f1567;
	{ // callseq 130, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd133;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd1048;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1112, [retval0+0];
	} // callseq 130
	and.pred  	%p41, %p1286, %p428;
	not.pred 	%p516, %p41;
	@%p516 bra 	$L__BB6_297;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r652}, %fd1112;
	}
	xor.b32  	%r653, %r652, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r654, %temp}, %fd1112;
	}
	mov.b64 	%fd1112, {%r654, %r653};

$L__BB6_297:
	setp.eq.f32 	%p1287, %f107, 0f00000000;
	@%p1287 bra 	$L__BB6_301;
	bra.uni 	$L__BB6_298;

$L__BB6_301:
	setp.lt.s32 	%p520, %r78, 0;
	mov.u32 	%r655, 0;
	selp.b32 	%r657, %r105, 0, %p428;
	or.b32  	%r658, %r657, 2146435072;
	selp.b32 	%r659, %r658, %r657, %p520;
	mov.b64 	%fd1112, {%r655, %r659};
	bra.uni 	$L__BB6_302;

$L__BB6_298:
	setp.gt.s32 	%p518, %r105, -1;
	@%p518 bra 	$L__BB6_302;

	mov.f64 	%fd1066, 0d4014000000000000;
	cvt.rzi.f64.f64 	%fd759, %fd1066;
	setp.eq.f64 	%p519, %fd759, 0d4014000000000000;
	@%p519 bra 	$L__BB6_302;

	mov.f64 	%fd1112, 0dFFF8000000000000;

$L__BB6_302:
	add.f64 	%fd175, %fd132, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r660}, %fd175;
	}
	and.b32  	%r661, %r660, 2146435072;
	setp.ne.s32 	%p522, %r661, 2146435072;
	mov.f64 	%fd1113, %fd1112;
	@%p522 bra 	$L__BB6_308;

	setp.gtu.f64 	%p523, %fd133, 0d7FF0000000000000;
	mov.f64 	%fd1113, %fd175;
	@%p523 bra 	$L__BB6_308;

	mov.f64 	%fd1065, 0d4014000000000000;
	and.b32  	%r662, %r78, 2147483647;
	setp.eq.s32 	%p524, %r662, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r663, %temp}, %fd1065;
	}
	setp.eq.s32 	%p525, %r663, 0;
	and.pred  	%p526, %p524, %p525;
	@%p526 bra 	$L__BB6_307;
	bra.uni 	$L__BB6_305;

$L__BB6_307:
	setp.lt.s32 	%p533, %r78, 0;
	mov.u32 	%r671, 0;
	setp.gt.f64 	%p534, %fd133, 0d3FF0000000000000;
	selp.b32 	%r672, 2146435072, 0, %p534;
	xor.b32  	%r673, %r672, 2146435072;
	selp.b32 	%r674, %r673, %r672, %p533;
	setp.eq.f32 	%p535, %f107, 0fBF800000;
	selp.b32 	%r675, 1072693248, %r674, %p535;
	mov.b64 	%fd1113, {%r671, %r675};
	bra.uni 	$L__BB6_308;

$L__BB6_305:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r664, %temp}, %fd132;
	}
	and.b32  	%r665, %r105, 2147483647;
	setp.ne.s32 	%p527, %r665, 2146435072;
	setp.ne.s32 	%p528, %r664, 0;
	or.pred  	%p529, %p527, %p528;
	mov.f64 	%fd1113, %fd1112;
	@%p529 bra 	$L__BB6_308;

	setp.ne.s32 	%p530, %r662, 1071644672;
	and.pred  	%p531, %p530, %p41;
	setp.gt.s32 	%p532, %r78, -1;
	selp.b32 	%r667, 2146435072, 0, %p532;
	mov.u32 	%r668, 0;
	or.b32  	%r669, %r667, -2147483648;
	selp.b32 	%r670, %r669, %r667, %p531;
	mov.b64 	%fd1113, {%r668, %r670};

$L__BB6_308:
	cvt.f64.f32 	%fd179, %f120;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd179;
	}
	abs.f64 	%fd180, %fd179;
	{ // callseq 131, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd180;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1115, [retval0+0];
	} // callseq 131
	setp.lt.s32 	%p536, %r106, 0;
	and.pred  	%p42, %p536, %p149;
	not.pred 	%p538, %p42;
	@%p538 bra 	$L__BB6_310;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r676}, %fd1115;
	}
	xor.b32  	%r677, %r676, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r678, %temp}, %fd1115;
	}
	mov.b64 	%fd1115, {%r678, %r677};

$L__BB6_310:
	setp.eq.f32 	%p1288, %f107, 0f3F800000;
	setp.eq.f32 	%p539, %f120, 0f00000000;
	selp.f64 	%fd184, 0d3FF0000000000000, %fd1113, %p1288;
	@%p539 bra 	$L__BB6_314;
	bra.uni 	$L__BB6_311;

$L__BB6_314:
	mov.u32 	%r679, 0;
	selp.b32 	%r680, %r106, 0, %p149;
	or.b32  	%r681, %r680, 2146435072;
	selp.b32 	%r682, %r681, %r680, %p152;
	mov.b64 	%fd1115, {%r679, %r682};
	bra.uni 	$L__BB6_315;

$L__BB6_311:
	setp.gt.s32 	%p541, %r106, -1;
	@%p541 bra 	$L__BB6_315;

	cvt.rzi.f64.f64 	%fd764, %fd649;
	setp.eq.f64 	%p542, %fd764, 0d4008000000000000;
	@%p542 bra 	$L__BB6_315;

	mov.f64 	%fd1115, 0dFFF8000000000000;

$L__BB6_315:
	add.f64 	%fd187, %fd179, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r683}, %fd187;
	}
	and.b32  	%r684, %r683, 2146435072;
	setp.ne.s32 	%p545, %r684, 2146435072;
	mov.f64 	%fd1116, %fd1115;
	@%p545 bra 	$L__BB6_321;

	setp.gtu.f64 	%p546, %fd180, 0d7FF0000000000000;
	mov.f64 	%fd1116, %fd187;
	@%p546 bra 	$L__BB6_321;

	setp.eq.s32 	%p547, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r685, %temp}, %fd649;
	}
	setp.eq.s32 	%p548, %r685, 0;
	and.pred  	%p549, %p547, %p548;
	@%p549 bra 	$L__BB6_320;
	bra.uni 	$L__BB6_318;

$L__BB6_320:
	mov.u32 	%r690, 0;
	setp.gt.f64 	%p556, %fd180, 0d3FF0000000000000;
	selp.b32 	%r691, 2146435072, 0, %p556;
	xor.b32  	%r692, %r691, 2146435072;
	selp.b32 	%r693, %r692, %r691, %p152;
	setp.eq.f32 	%p557, %f120, 0fBF800000;
	selp.b32 	%r694, 1072693248, %r693, %p557;
	mov.b64 	%fd1116, {%r690, %r694};
	bra.uni 	$L__BB6_321;

$L__BB6_318:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r686, %temp}, %fd179;
	}
	and.b32  	%r687, %r106, 2147483647;
	setp.ne.s32 	%p550, %r687, 2146435072;
	setp.ne.s32 	%p551, %r686, 0;
	or.pred  	%p552, %p550, %p551;
	mov.f64 	%fd1116, %fd1115;
	@%p552 bra 	$L__BB6_321;

	setp.ne.s32 	%p553, %r58, 1071644672;
	and.pred  	%p554, %p553, %p42;
	selp.b32 	%r688, %r63, %r62, %p554;
	mov.u32 	%r689, 0;
	mov.b64 	%fd1116, {%r689, %r688};

$L__BB6_321:
	setp.eq.f32 	%p558, %f120, 0f3F800000;
	selp.f64 	%fd767, 0d3FF0000000000000, %fd1116, %p558;
	cvt.f64.f32 	%fd768, %f231;
	mul.f64 	%fd191, %fd767, %fd768;
	cvt.f64.f32 	%fd192, %f126;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r107}, %fd192;
	}
	abs.f64 	%fd193, %fd192;
	{ // callseq 132, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd193;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd649;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1118, [retval0+0];
	} // callseq 132
	setp.lt.s32 	%p559, %r107, 0;
	and.pred  	%p43, %p559, %p149;
	not.pred 	%p561, %p43;
	@%p561 bra 	$L__BB6_323;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r695}, %fd1118;
	}
	xor.b32  	%r696, %r695, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r697, %temp}, %fd1118;
	}
	mov.b64 	%fd1118, {%r697, %r696};

$L__BB6_323:
	setp.eq.f32 	%p562, %f126, 0f00000000;
	@%p562 bra 	$L__BB6_327;
	bra.uni 	$L__BB6_324;

$L__BB6_327:
	mov.u32 	%r698, 0;
	selp.b32 	%r699, %r107, 0, %p149;
	or.b32  	%r700, %r699, 2146435072;
	selp.b32 	%r701, %r700, %r699, %p152;
	mov.b64 	%fd1118, {%r698, %r701};
	bra.uni 	$L__BB6_328;

$L__BB6_324:
	setp.gt.s32 	%p563, %r107, -1;
	@%p563 bra 	$L__BB6_328;

	cvt.rzi.f64.f64 	%fd771, %fd649;
	setp.eq.f64 	%p564, %fd771, 0d4008000000000000;
	@%p564 bra 	$L__BB6_328;

	mov.f64 	%fd1118, 0dFFF8000000000000;

$L__BB6_328:
	add.f64 	%fd199, %fd192, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r702}, %fd199;
	}
	and.b32  	%r703, %r702, 2146435072;
	setp.ne.s32 	%p567, %r703, 2146435072;
	mov.f64 	%fd1119, %fd1118;
	@%p567 bra 	$L__BB6_334;

	setp.gtu.f64 	%p568, %fd193, 0d7FF0000000000000;
	mov.f64 	%fd1119, %fd199;
	@%p568 bra 	$L__BB6_334;

	setp.eq.s32 	%p569, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r704, %temp}, %fd649;
	}
	setp.eq.s32 	%p570, %r704, 0;
	and.pred  	%p571, %p569, %p570;
	@%p571 bra 	$L__BB6_333;
	bra.uni 	$L__BB6_331;

$L__BB6_333:
	mov.u32 	%r709, 0;
	setp.gt.f64 	%p578, %fd193, 0d3FF0000000000000;
	selp.b32 	%r710, 2146435072, 0, %p578;
	xor.b32  	%r711, %r710, 2146435072;
	selp.b32 	%r712, %r711, %r710, %p152;
	setp.eq.f32 	%p579, %f126, 0fBF800000;
	selp.b32 	%r713, 1072693248, %r712, %p579;
	mov.b64 	%fd1119, {%r709, %r713};
	bra.uni 	$L__BB6_334;

$L__BB6_331:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r705, %temp}, %fd192;
	}
	and.b32  	%r706, %r107, 2147483647;
	setp.ne.s32 	%p572, %r706, 2146435072;
	setp.ne.s32 	%p573, %r705, 0;
	or.pred  	%p574, %p572, %p573;
	mov.f64 	%fd1119, %fd1118;
	@%p574 bra 	$L__BB6_334;

	setp.ne.s32 	%p575, %r58, 1071644672;
	and.pred  	%p576, %p575, %p43;
	selp.b32 	%r707, %r63, %r62, %p576;
	mov.u32 	%r708, 0;
	mov.b64 	%fd1119, {%r708, %r707};

$L__BB6_334:
	mov.f32 	%f3165, 0fC0000000;
	cvt.f64.f32 	%fd1050, %f117;
	setp.eq.f32 	%p580, %f126, 0f3F800000;
	selp.f64 	%fd774, 0d3FF0000000000000, %fd1119, %p580;
	cvt.f64.f32 	%fd775, %f244;
	mul.f64 	%fd776, %fd774, %fd775;
	sub.f64 	%fd777, %fd191, %fd776;
	div.rn.f64 	%fd778, %fd43, %fd184;
	mul.f64 	%fd779, %fd778, %fd777;
	mul.f64 	%fd781, %fd779, %fd1050;
	div.rn.f32 	%f1569, %f3165, %f107;
	mul.f32 	%f1570, %f1569, %f245;
	cvt.f64.f32 	%fd782, %f1570;
	sub.f64 	%fd203, %fd782, %fd781;
	div.rn.f32 	%f246, %f52, %f104;
	div.rn.f32 	%f247, %f53, %f106;
	not.pred 	%p581, %p12;
	mov.f64 	%fd1121, %fd66;
	@%p581 bra 	$L__BB6_336;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r714}, %fd66;
	}
	xor.b32  	%r715, %r714, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r716, %temp}, %fd66;
	}
	mov.b64 	%fd1121, {%r716, %r715};

$L__BB6_336:
	sub.f32 	%f3040, %f3291, %f552;
	setp.eq.f32 	%p582, %f3040, 0f00000000;
	@%p582 bra 	$L__BB6_340;
	bra.uni 	$L__BB6_337;

$L__BB6_340:
	mov.u32 	%r717, 0;
	mov.b64 	%fd1121, {%r717, %r84};
	bra.uni 	$L__BB6_341;

$L__BB6_337:
	setp.gt.s32 	%p583, %r83, -1;
	@%p583 bra 	$L__BB6_341;

	cvt.rzi.f64.f64 	%fd784, %fd646;
	setp.eq.f64 	%p584, %fd784, 0d4000000000000000;
	@%p584 bra 	$L__BB6_341;

	mov.f64 	%fd1121, 0dFFF8000000000000;

$L__BB6_341:
	selp.f64 	%fd1122, %fd1121, %fd46, %p182;
	@%p25 bra 	$L__BB6_346;

	setp.eq.s32 	%p586, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r718, %temp}, %fd646;
	}
	setp.eq.s32 	%p587, %r718, 0;
	and.pred  	%p588, %p586, %p587;
	@%p588 bra 	$L__BB6_345;
	bra.uni 	$L__BB6_343;

$L__BB6_345:
	mov.u32 	%r722, 0;
	mov.b64 	%fd1122, {%r722, %r86};
	bra.uni 	$L__BB6_346;

$L__BB6_343:
	and.b32  	%r719, %r83, 2147483647;
	setp.ne.s32 	%p589, %r719, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r720, %temp}, %fd45;
	}
	setp.ne.s32 	%p590, %r720, 0;
	or.pred  	%p591, %p589, %p590;
	mov.f64 	%fd1122, %fd1121;
	@%p591 bra 	$L__BB6_346;

	mov.u32 	%r721, 0;
	mov.b64 	%fd1122, {%r721, %r88};

$L__BB6_346:
	cvt.f64.f32 	%fd212, %f55;
	not.pred 	%p592, %p13;
	mov.f64 	%fd1124, %fd67;
	@%p592 bra 	$L__BB6_348;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r723}, %fd67;
	}
	xor.b32  	%r724, %r723, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r725, %temp}, %fd67;
	}
	mov.b64 	%fd1124, {%r725, %r724};

$L__BB6_348:
	@%p582 bra 	$L__BB6_352;
	bra.uni 	$L__BB6_349;

$L__BB6_352:
	mov.u32 	%r726, 0;
	selp.b32 	%r728, %r83, 0, %p149;
	or.b32  	%r729, %r728, 2146435072;
	selp.b32 	%r730, %r729, %r728, %p152;
	mov.b64 	%fd1124, {%r726, %r730};
	bra.uni 	$L__BB6_353;

$L__BB6_349:
	setp.gt.s32 	%p594, %r83, -1;
	@%p594 bra 	$L__BB6_353;

	cvt.rzi.f64.f64 	%fd788, %fd649;
	setp.eq.f64 	%p595, %fd788, 0d4008000000000000;
	@%p595 bra 	$L__BB6_353;

	mov.f64 	%fd1124, 0dFFF8000000000000;

$L__BB6_353:
	selp.f64 	%fd1125, %fd1124, %fd47, %p186;
	@%p26 bra 	$L__BB6_358;

	setp.eq.s32 	%p599, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r731, %temp}, %fd649;
	}
	setp.eq.s32 	%p600, %r731, 0;
	and.pred  	%p601, %p599, %p600;
	@%p601 bra 	$L__BB6_357;
	bra.uni 	$L__BB6_355;

$L__BB6_357:
	mov.u32 	%r738, 0;
	mov.b64 	%fd1125, {%r738, %r90};
	bra.uni 	$L__BB6_358;

$L__BB6_355:
	and.b32  	%r732, %r83, 2147483647;
	setp.ne.s32 	%p602, %r732, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r733, %temp}, %fd45;
	}
	setp.ne.s32 	%p603, %r733, 0;
	or.pred  	%p604, %p602, %p603;
	mov.f64 	%fd1125, %fd1124;
	@%p604 bra 	$L__BB6_358;

	setp.ne.s32 	%p605, %r58, 1071644672;
	and.pred  	%p606, %p605, %p13;
	selp.b32 	%r736, %r63, %r62, %p606;
	mov.u32 	%r737, 0;
	mov.b64 	%fd1125, {%r737, %r736};

$L__BB6_358:
	not.pred 	%p607, %p14;
	mov.f64 	%fd1127, %fd68;
	@%p607 bra 	$L__BB6_360;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r739}, %fd68;
	}
	xor.b32  	%r740, %r739, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r741, %temp}, %fd68;
	}
	mov.b64 	%fd1127, {%r741, %r740};

$L__BB6_360:
	setp.eq.f32 	%p608, %f553, 0f00000000;
	@%p608 bra 	$L__BB6_364;
	bra.uni 	$L__BB6_361;

$L__BB6_364:
	mov.u32 	%r742, 0;
	mov.b64 	%fd1127, {%r742, %r91};
	bra.uni 	$L__BB6_365;

$L__BB6_361:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1354}, %fd645;
	}
	setp.gt.s32 	%p609, %r1354, -1;
	@%p609 bra 	$L__BB6_365;

	cvt.rzi.f64.f64 	%fd792, %fd651;
	setp.eq.f64 	%p610, %fd792, 0d4010000000000000;
	@%p610 bra 	$L__BB6_365;

	mov.f64 	%fd1127, 0dFFF8000000000000;

$L__BB6_365:
	selp.f64 	%fd1128, %fd1127, %fd36, %p189;
	@%p27 bra 	$L__BB6_370;

	setp.eq.s32 	%p612, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r743, %temp}, %fd651;
	}
	setp.eq.s32 	%p613, %r743, 0;
	and.pred  	%p614, %p612, %p613;
	@%p614 bra 	$L__BB6_369;
	bra.uni 	$L__BB6_367;

$L__BB6_369:
	mov.u32 	%r747, 0;
	mov.b64 	%fd1128, {%r747, %r94};
	bra.uni 	$L__BB6_370;

$L__BB6_367:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1355}, %fd645;
	}
	and.b32  	%r744, %r1355, 2147483647;
	setp.ne.s32 	%p615, %r744, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r745, %temp}, %fd645;
	}
	setp.ne.s32 	%p616, %r745, 0;
	or.pred  	%p617, %p615, %p616;
	mov.f64 	%fd1128, %fd1127;
	@%p617 bra 	$L__BB6_370;

	mov.u32 	%r746, 0;
	mov.b64 	%fd1128, {%r746, %r97};

$L__BB6_370:
	sub.f32 	%f3041, %f3291, %f552;
	setp.eq.f32 	%p618, %f553, 0f3F800000;
	selp.f64 	%fd796, 0d3FF0000000000000, %fd1128, %p618;
	setp.eq.f32 	%p619, %f3041, 0f3F800000;
	selp.f64 	%fd797, 0d3FF0000000000000, %fd1125, %p619;
	mul.f64 	%fd798, %fd797, %fd35;
	div.rn.f64 	%fd799, %fd798, %fd796;
	selp.f64 	%fd800, 0d3FF0000000000000, %fd1122, %p619;
	mul.f64 	%fd801, %fd800, %fd34;
	div.rn.f64 	%fd802, %fd801, %fd212;
	add.f64 	%fd803, %fd802, %fd44;
	add.f64 	%fd804, %fd803, %fd799;
	cvt.rn.f32.f64 	%f248, %fd804;
	mul.f32 	%f249, %f246, %f248;
	not.pred 	%p620, %p15;
	mov.f64 	%fd1130, %fd69;
	@%p620 bra 	$L__BB6_372;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r748}, %fd69;
	}
	xor.b32  	%r749, %r748, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r750, %temp}, %fd69;
	}
	mov.b64 	%fd1130, {%r750, %r749};

$L__BB6_372:
	add.f32 	%f3042, %f3291, %f552;
	setp.eq.f32 	%p621, %f3042, 0f00000000;
	@%p621 bra 	$L__BB6_376;
	bra.uni 	$L__BB6_373;

$L__BB6_376:
	mov.u32 	%r751, 0;
	mov.b64 	%fd1130, {%r751, %r95};
	bra.uni 	$L__BB6_377;

$L__BB6_373:
	setp.gt.s32 	%p622, %r93, -1;
	@%p622 bra 	$L__BB6_377;

	cvt.rzi.f64.f64 	%fd806, %fd646;
	setp.eq.f64 	%p623, %fd806, 0d4000000000000000;
	@%p623 bra 	$L__BB6_377;

	mov.f64 	%fd1130, 0dFFF8000000000000;

$L__BB6_377:
	selp.f64 	%fd1131, %fd1130, %fd50, %p194;
	@%p28 bra 	$L__BB6_382;

	setp.eq.s32 	%p625, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r752, %temp}, %fd646;
	}
	setp.eq.s32 	%p626, %r752, 0;
	and.pred  	%p627, %p625, %p626;
	@%p627 bra 	$L__BB6_381;
	bra.uni 	$L__BB6_379;

$L__BB6_381:
	mov.u32 	%r756, 0;
	mov.b64 	%fd1131, {%r756, %r98};
	bra.uni 	$L__BB6_382;

$L__BB6_379:
	and.b32  	%r753, %r93, 2147483647;
	setp.ne.s32 	%p628, %r753, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r754, %temp}, %fd49;
	}
	setp.ne.s32 	%p629, %r754, 0;
	or.pred  	%p630, %p628, %p629;
	mov.f64 	%fd1131, %fd1130;
	@%p630 bra 	$L__BB6_382;

	mov.u32 	%r755, 0;
	mov.b64 	%fd1131, {%r755, %r100};

$L__BB6_382:
	add.f32 	%f3043, %f3291, %f552;
	setp.eq.f32 	%p631, %f3043, 0f3F800000;
	selp.f64 	%fd809, 0d3FF0000000000000, %fd1131, %p631;
	mul.f64 	%fd810, %fd809, %fd37;
	div.rn.f64 	%fd237, %fd810, %fd212;
	not.pred 	%p632, %p16;
	mov.f64 	%fd1133, %fd70;
	@%p632 bra 	$L__BB6_384;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r757}, %fd70;
	}
	xor.b32  	%r758, %r757, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r759, %temp}, %fd70;
	}
	mov.b64 	%fd1133, {%r759, %r758};

$L__BB6_384:
	@%p621 bra 	$L__BB6_388;
	bra.uni 	$L__BB6_385;

$L__BB6_388:
	mov.u32 	%r760, 0;
	selp.b32 	%r762, %r93, 0, %p149;
	or.b32  	%r763, %r762, 2146435072;
	selp.b32 	%r764, %r763, %r762, %p152;
	mov.b64 	%fd1133, {%r760, %r764};
	bra.uni 	$L__BB6_389;

$L__BB6_385:
	setp.gt.s32 	%p634, %r93, -1;
	@%p634 bra 	$L__BB6_389;

	cvt.rzi.f64.f64 	%fd812, %fd649;
	setp.eq.f64 	%p635, %fd812, 0d4008000000000000;
	@%p635 bra 	$L__BB6_389;

	mov.f64 	%fd1133, 0dFFF8000000000000;

$L__BB6_389:
	selp.f64 	%fd1134, %fd1133, %fd51, %p199;
	@%p29 bra 	$L__BB6_394;

	setp.eq.s32 	%p639, %r58, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r765, %temp}, %fd649;
	}
	setp.eq.s32 	%p640, %r765, 0;
	and.pred  	%p641, %p639, %p640;
	@%p641 bra 	$L__BB6_393;
	bra.uni 	$L__BB6_391;

$L__BB6_393:
	mov.u32 	%r772, 0;
	mov.b64 	%fd1134, {%r772, %r101};
	bra.uni 	$L__BB6_394;

$L__BB6_391:
	and.b32  	%r766, %r93, 2147483647;
	setp.ne.s32 	%p642, %r766, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r767, %temp}, %fd49;
	}
	setp.ne.s32 	%p643, %r767, 0;
	or.pred  	%p644, %p642, %p643;
	mov.f64 	%fd1134, %fd1133;
	@%p644 bra 	$L__BB6_394;

	setp.ne.s32 	%p645, %r58, 1071644672;
	and.pred  	%p646, %p645, %p16;
	selp.b32 	%r770, %r63, %r62, %p646;
	mov.u32 	%r771, 0;
	mov.b64 	%fd1134, {%r771, %r770};

$L__BB6_394:
	mov.f64 	%fd1136, %fd68;
	@%p607 bra 	$L__BB6_396;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r773}, %fd68;
	}
	xor.b32  	%r774, %r773, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r775, %temp}, %fd68;
	}
	mov.b64 	%fd1136, {%r775, %r774};

$L__BB6_396:
	@%p608 bra 	$L__BB6_400;
	bra.uni 	$L__BB6_397;

$L__BB6_400:
	mov.u32 	%r776, 0;
	mov.b64 	%fd1136, {%r776, %r91};
	bra.uni 	$L__BB6_401;

$L__BB6_397:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1356}, %fd645;
	}
	setp.gt.s32 	%p649, %r1356, -1;
	@%p649 bra 	$L__BB6_401;

	cvt.rzi.f64.f64 	%fd816, %fd651;
	setp.eq.f64 	%p650, %fd816, 0d4010000000000000;
	@%p650 bra 	$L__BB6_401;

	mov.f64 	%fd1136, 0dFFF8000000000000;

$L__BB6_401:
	selp.f64 	%fd1137, %fd1136, %fd36, %p189;
	@%p27 bra 	$L__BB6_406;

	setp.eq.s32 	%p652, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r777, %temp}, %fd651;
	}
	setp.eq.s32 	%p653, %r777, 0;
	and.pred  	%p654, %p652, %p653;
	@%p654 bra 	$L__BB6_405;
	bra.uni 	$L__BB6_403;

$L__BB6_405:
	mov.u32 	%r781, 0;
	mov.b64 	%fd1137, {%r781, %r94};
	bra.uni 	$L__BB6_406;

$L__BB6_403:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1357}, %fd645;
	}
	and.b32  	%r778, %r1357, 2147483647;
	setp.ne.s32 	%p655, %r778, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r779, %temp}, %fd645;
	}
	setp.ne.s32 	%p656, %r779, 0;
	or.pred  	%p657, %p655, %p656;
	mov.f64 	%fd1137, %fd1136;
	@%p657 bra 	$L__BB6_406;

	mov.u32 	%r780, 0;
	mov.b64 	%fd1137, {%r780, %r97};

$L__BB6_406:
	mov.f32 	%f3051, 0f3FC00000;
	mov.f32 	%f3050, 0f3102E308;
	mov.f32 	%f3049, 0fBF317218;
	mov.f32 	%f3048, 0f35BFBE8E;
	mov.f32 	%f3047, 0f3F317200;
	mov.f32 	%f3046, 0f3DAAAABD;
	mov.f32 	%f3045, 0f3C4CAF63;
	mov.f32 	%f3044, 0f3B18F0FE;
	selp.f64 	%fd820, 0d3FF0000000000000, %fd1137, %p618;
	selp.f64 	%fd821, 0d3FF0000000000000, %fd1134, %p631;
	mul.f64 	%fd822, %fd821, %fd38;
	div.rn.f64 	%fd823, %fd822, %fd820;
	add.f64 	%fd824, %fd237, %fd48;
	add.f64 	%fd825, %fd824, %fd823;
	cvt.rn.f32.f64 	%f250, %fd825;
	mul.f32 	%f251, %f247, %f250;
	mul.f32 	%f1572, %f245, %f251;
	fma.rn.f32 	%f252, %f217, %f249, %f1572;
	abs.f32 	%f253, %f102;
	setp.lt.f32 	%p660, %f253, 0f00800000;
	mul.f32 	%f1573, %f253, 0f4B800000;
	selp.f32 	%f1574, %f1573, %f253, %p660;
	selp.f32 	%f1575, 0fC3170000, 0fC2FE0000, %p660;
	mov.b32 	%r782, %f1574;
	and.b32  	%r783, %r782, 8388607;
	or.b32  	%r784, %r783, 1065353216;
	mov.b32 	%f1576, %r784;
	shr.u32 	%r785, %r782, 23;
	cvt.rn.f32.u32 	%f1577, %r785;
	add.f32 	%f1578, %f1575, %f1577;
	setp.gt.f32 	%p661, %f1576, 0f3FB504F3;
	mul.f32 	%f1579, %f1576, 0f3F000000;
	add.f32 	%f1580, %f1578, 0f3F800000;
	selp.f32 	%f1581, %f1580, %f1578, %p661;
	selp.f32 	%f1582, %f1579, %f1576, %p661;
	add.f32 	%f1583, %f1582, 0fBF800000;
	add.f32 	%f1584, %f1582, 0f3F800000;
	rcp.approx.ftz.f32 	%f1585, %f1584;
	add.f32 	%f1586, %f1583, %f1583;
	mul.f32 	%f1587, %f1586, %f1585;
	mul.f32 	%f1588, %f1587, %f1587;
	fma.rn.f32 	%f1591, %f3044, %f1588, %f3045;
	fma.rn.f32 	%f1593, %f1591, %f1588, %f3046;
	mul.rn.f32 	%f1594, %f1593, %f1588;
	mul.rn.f32 	%f1595, %f1594, %f1587;
	sub.f32 	%f1596, %f1583, %f1587;
	add.f32 	%f1597, %f1596, %f1596;
	neg.f32 	%f1598, %f1587;
	fma.rn.f32 	%f1599, %f1598, %f1583, %f1597;
	mul.rn.f32 	%f1600, %f1585, %f1599;
	add.f32 	%f1601, %f1595, %f1587;
	sub.f32 	%f1602, %f1587, %f1601;
	add.f32 	%f1603, %f1595, %f1602;
	add.f32 	%f1604, %f1600, %f1603;
	add.f32 	%f1605, %f1601, %f1604;
	sub.f32 	%f1606, %f1601, %f1605;
	add.f32 	%f1607, %f1604, %f1606;
	mul.rn.f32 	%f1609, %f1581, %f3047;
	mul.rn.f32 	%f1611, %f1581, %f3048;
	add.f32 	%f1612, %f1609, %f1605;
	sub.f32 	%f1613, %f1609, %f1612;
	add.f32 	%f1614, %f1605, %f1613;
	add.f32 	%f1615, %f1607, %f1614;
	add.f32 	%f1616, %f1611, %f1615;
	add.f32 	%f1617, %f1612, %f1616;
	sub.f32 	%f1618, %f1612, %f1617;
	add.f32 	%f1619, %f1616, %f1618;
	mul.rn.f32 	%f1621, %f3051, %f1617;
	neg.f32 	%f1622, %f1621;
	fma.rn.f32 	%f1623, %f3051, %f1617, %f1622;
	fma.rn.f32 	%f1624, %f3051, %f1619, %f1623;
	fma.rn.f32 	%f1626, %f3279, %f1617, %f1624;
	add.rn.f32 	%f1627, %f1621, %f1626;
	neg.f32 	%f1628, %f1627;
	add.rn.f32 	%f1629, %f1621, %f1628;
	add.rn.f32 	%f1630, %f1629, %f1626;
	mov.b32 	%r786, %f1627;
	setp.eq.s32 	%p662, %r786, 1118925336;
	add.s32 	%r787, %r786, -1;
	mov.b32 	%f1631, %r787;
	add.f32 	%f1632, %f1630, 0f37000000;
	selp.f32 	%f254, %f1632, %f1630, %p662;
	selp.f32 	%f1633, %f1631, %f1627, %p662;
	mul.rn.f32 	%f1635, %f1633, %f812;
	cvt.rzi.f32.f32 	%f1636, %f1635;
	abs.f32 	%f1637, %f1636;
	setp.gt.f32 	%p663, %f1637, 0f42FC0000;
	mov.b32 	%r788, %f1636;
	and.b32  	%r789, %r788, -2147483648;
	or.b32  	%r790, %r789, 1123811328;
	mov.b32 	%f1638, %r790;
	selp.f32 	%f1639, %f1638, %f1636, %p663;
	fma.rn.f32 	%f1641, %f1639, %f3049, %f1633;
	fma.rn.f32 	%f1643, %f1639, %f3050, %f1641;
	mul.f32 	%f1644, %f1643, 0f3FB8AA3B;
	add.f32 	%f1645, %f1639, 0f4B40007F;
	mov.b32 	%r791, %f1645;
	shl.b32 	%r792, %r791, 23;
	mov.b32 	%f1646, %r792;
	ex2.approx.ftz.f32 	%f1647, %f1644;
	mul.f32 	%f255, %f1647, %f1646;
	setp.eq.f32 	%p664, %f255, 0f7F800000;
	mov.f32 	%f3272, 0f7F800000;
	@%p664 bra 	$L__BB6_408;

	fma.rn.f32 	%f3272, %f255, %f254, %f255;

$L__BB6_408:
	mov.f32 	%f3057, 0f3F400000;
	cvt.rzi.f32.f32 	%f3056, %f3057;
	add.f32 	%f3055, %f3056, %f3056;
	mov.f32 	%f3054, 0f3FC00000;
	sub.f32 	%f3053, %f3054, %f3055;
	abs.f32 	%f3052, %f3053;
	setp.lt.f32 	%p665, %f102, 0f00000000;
	setp.eq.f32 	%p666, %f3052, 0f3F800000;
	and.pred  	%p44, %p665, %p666;
	setp.eq.f32 	%p667, %f102, 0f00000000;
	@%p667 bra 	$L__BB6_412;
	bra.uni 	$L__BB6_409;

$L__BB6_412:
	add.f32 	%f1652, %f102, %f102;
	selp.f32 	%f3274, %f1652, 0f00000000, %p666;
	bra.uni 	$L__BB6_413;

$L__BB6_409:
	mov.b32 	%r793, %f3272;
	xor.b32  	%r794, %r793, -2147483648;
	mov.b32 	%f1648, %r794;
	selp.f32 	%f3274, %f1648, %f3272, %p44;
	setp.geu.f32 	%p668, %f102, 0f00000000;
	@%p668 bra 	$L__BB6_413;

	mov.f32 	%f3149, 0f3FC00000;
	cvt.rzi.f32.f32 	%f1650, %f3149;
	setp.eq.f32 	%p669, %f1650, 0f3FC00000;
	@%p669 bra 	$L__BB6_413;

	mov.f32 	%f3274, 0f7FFFFFFF;

$L__BB6_413:
	abs.f32 	%f3171, %f102;
	add.f32 	%f1653, %f3171, 0f3FC00000;
	mov.b32 	%r795, %f1653;
	setp.lt.s32 	%p671, %r795, 2139095040;
	@%p671 bra 	$L__BB6_418;

	abs.f32 	%f3185, %f102;
	setp.gtu.f32 	%p672, %f3185, 0f7F800000;
	@%p672 bra 	$L__BB6_417;
	bra.uni 	$L__BB6_415;

$L__BB6_417:
	add.f32 	%f3274, %f102, 0f3FC00000;
	bra.uni 	$L__BB6_418;

$L__BB6_415:
	abs.f32 	%f3186, %f102;
	setp.neu.f32 	%p673, %f3186, 0f7F800000;
	@%p673 bra 	$L__BB6_418;

	selp.f32 	%f3274, 0fFF800000, 0f7F800000, %p44;

$L__BB6_418:
	mov.f32 	%f3065, 0f3FC00000;
	mov.f32 	%f3064, 0f3102E308;
	mov.f32 	%f3063, 0fBF317218;
	mov.f32 	%f3062, 0f35BFBE8E;
	mov.f32 	%f3061, 0f3F317200;
	mov.f32 	%f3060, 0f3DAAAABD;
	mov.f32 	%f3059, 0f3C4CAF63;
	mov.f32 	%f3058, 0f3B18F0FE;
	setp.eq.f32 	%p674, %f102, 0f3F800000;
	selp.f32 	%f1655, 0f3F800000, %f3274, %p674;
	div.rn.f32 	%f264, %f56, %f1655;
	abs.f32 	%f265, %f103;
	setp.lt.f32 	%p675, %f265, 0f00800000;
	mul.f32 	%f1656, %f265, 0f4B800000;
	selp.f32 	%f1657, %f1656, %f265, %p675;
	selp.f32 	%f1658, 0fC3170000, 0fC2FE0000, %p675;
	mov.b32 	%r796, %f1657;
	and.b32  	%r797, %r796, 8388607;
	or.b32  	%r798, %r797, 1065353216;
	mov.b32 	%f1659, %r798;
	shr.u32 	%r799, %r796, 23;
	cvt.rn.f32.u32 	%f1660, %r799;
	add.f32 	%f1661, %f1658, %f1660;
	setp.gt.f32 	%p676, %f1659, 0f3FB504F3;
	mul.f32 	%f1662, %f1659, 0f3F000000;
	add.f32 	%f1663, %f1661, 0f3F800000;
	selp.f32 	%f1664, %f1663, %f1661, %p676;
	selp.f32 	%f1665, %f1662, %f1659, %p676;
	add.f32 	%f1666, %f1665, 0fBF800000;
	add.f32 	%f1667, %f1665, 0f3F800000;
	rcp.approx.ftz.f32 	%f1668, %f1667;
	add.f32 	%f1669, %f1666, %f1666;
	mul.f32 	%f1670, %f1669, %f1668;
	mul.f32 	%f1671, %f1670, %f1670;
	fma.rn.f32 	%f1674, %f3058, %f1671, %f3059;
	fma.rn.f32 	%f1676, %f1674, %f1671, %f3060;
	mul.rn.f32 	%f1677, %f1676, %f1671;
	mul.rn.f32 	%f1678, %f1677, %f1670;
	sub.f32 	%f1679, %f1666, %f1670;
	add.f32 	%f1680, %f1679, %f1679;
	neg.f32 	%f1681, %f1670;
	fma.rn.f32 	%f1682, %f1681, %f1666, %f1680;
	mul.rn.f32 	%f1683, %f1668, %f1682;
	add.f32 	%f1684, %f1678, %f1670;
	sub.f32 	%f1685, %f1670, %f1684;
	add.f32 	%f1686, %f1678, %f1685;
	add.f32 	%f1687, %f1683, %f1686;
	add.f32 	%f1688, %f1684, %f1687;
	sub.f32 	%f1689, %f1684, %f1688;
	add.f32 	%f1690, %f1687, %f1689;
	mul.rn.f32 	%f1692, %f1664, %f3061;
	mul.rn.f32 	%f1694, %f1664, %f3062;
	add.f32 	%f1695, %f1692, %f1688;
	sub.f32 	%f1696, %f1692, %f1695;
	add.f32 	%f1697, %f1688, %f1696;
	add.f32 	%f1698, %f1690, %f1697;
	add.f32 	%f1699, %f1694, %f1698;
	add.f32 	%f1700, %f1695, %f1699;
	sub.f32 	%f1701, %f1695, %f1700;
	add.f32 	%f1702, %f1699, %f1701;
	mul.rn.f32 	%f1704, %f3065, %f1700;
	neg.f32 	%f1705, %f1704;
	fma.rn.f32 	%f1706, %f3065, %f1700, %f1705;
	fma.rn.f32 	%f1707, %f3065, %f1702, %f1706;
	fma.rn.f32 	%f1709, %f3279, %f1700, %f1707;
	add.rn.f32 	%f1710, %f1704, %f1709;
	neg.f32 	%f1711, %f1710;
	add.rn.f32 	%f1712, %f1704, %f1711;
	add.rn.f32 	%f1713, %f1712, %f1709;
	mov.b32 	%r800, %f1710;
	setp.eq.s32 	%p677, %r800, 1118925336;
	add.s32 	%r801, %r800, -1;
	mov.b32 	%f1714, %r801;
	add.f32 	%f1715, %f1713, 0f37000000;
	selp.f32 	%f266, %f1715, %f1713, %p677;
	selp.f32 	%f1716, %f1714, %f1710, %p677;
	mul.rn.f32 	%f1718, %f1716, %f812;
	cvt.rzi.f32.f32 	%f1719, %f1718;
	abs.f32 	%f1720, %f1719;
	setp.gt.f32 	%p678, %f1720, 0f42FC0000;
	mov.b32 	%r802, %f1719;
	and.b32  	%r803, %r802, -2147483648;
	or.b32  	%r804, %r803, 1123811328;
	mov.b32 	%f1721, %r804;
	selp.f32 	%f1722, %f1721, %f1719, %p678;
	fma.rn.f32 	%f1724, %f1722, %f3063, %f1716;
	fma.rn.f32 	%f1726, %f1722, %f3064, %f1724;
	mul.f32 	%f1727, %f1726, 0f3FB8AA3B;
	add.f32 	%f1728, %f1722, 0f4B40007F;
	mov.b32 	%r805, %f1728;
	shl.b32 	%r806, %r805, 23;
	mov.b32 	%f1729, %r806;
	ex2.approx.ftz.f32 	%f1730, %f1727;
	mul.f32 	%f267, %f1730, %f1729;
	setp.eq.f32 	%p679, %f267, 0f7F800000;
	mov.f32 	%f3275, 0f7F800000;
	@%p679 bra 	$L__BB6_420;

	fma.rn.f32 	%f3275, %f267, %f266, %f267;

$L__BB6_420:
	setp.lt.f32 	%p680, %f103, 0f00000000;
	and.pred  	%p45, %p680, %p666;
	setp.eq.f32 	%p682, %f103, 0f00000000;
	@%p682 bra 	$L__BB6_424;
	bra.uni 	$L__BB6_421;

$L__BB6_424:
	add.f32 	%f1735, %f103, %f103;
	selp.f32 	%f3277, %f1735, 0f00000000, %p666;
	bra.uni 	$L__BB6_425;

$L__BB6_421:
	mov.b32 	%r807, %f3275;
	xor.b32  	%r808, %r807, -2147483648;
	mov.b32 	%f1731, %r808;
	selp.f32 	%f3277, %f1731, %f3275, %p45;
	setp.geu.f32 	%p683, %f103, 0f00000000;
	@%p683 bra 	$L__BB6_425;

	mov.f32 	%f3148, 0f3FC00000;
	cvt.rzi.f32.f32 	%f1733, %f3148;
	setp.eq.f32 	%p684, %f1733, 0f3FC00000;
	@%p684 bra 	$L__BB6_425;

	mov.f32 	%f3277, 0f7FFFFFFF;

$L__BB6_425:
	abs.f32 	%f3187, %f103;
	add.f32 	%f1736, %f3187, 0f3FC00000;
	mov.b32 	%r809, %f1736;
	setp.lt.s32 	%p686, %r809, 2139095040;
	@%p686 bra 	$L__BB6_430;

	abs.f32 	%f3188, %f103;
	setp.gtu.f32 	%p687, %f3188, 0f7F800000;
	@%p687 bra 	$L__BB6_429;
	bra.uni 	$L__BB6_427;

$L__BB6_429:
	add.f32 	%f3277, %f103, 0f3FC00000;
	bra.uni 	$L__BB6_430;

$L__BB6_427:
	abs.f32 	%f3189, %f103;
	setp.neu.f32 	%p688, %f3189, 0f7F800000;
	@%p688 bra 	$L__BB6_430;

	selp.f32 	%f3277, 0fFF800000, 0f7F800000, %p45;

$L__BB6_430:
	cvt.rn.f32.f64 	%f3172, %fd804;
	setp.eq.f32 	%p689, %f103, 0f3F800000;
	selp.f32 	%f276, 0f3F800000, %f3277, %p689;
	cvt.f64.f32 	%fd254, %f3172;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r108}, %fd254;
	}
	abs.f64 	%fd255, %fd254;
	{ // callseq 133, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd255;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1139, [retval0+0];
	} // callseq 133
	setp.lt.s32 	%p690, %r108, 0;
	and.pred  	%p46, %p690, %p144;
	not.pred 	%p692, %p46;
	@%p692 bra 	$L__BB6_432;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r810}, %fd1139;
	}
	xor.b32  	%r811, %r810, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r812, %temp}, %fd1139;
	}
	mov.b64 	%fd1139, {%r812, %r811};

$L__BB6_432:
	cvt.rn.f32.f64 	%f3173, %fd804;
	setp.eq.f32 	%p693, %f3173, 0f00000000;
	@%p693 bra 	$L__BB6_436;
	bra.uni 	$L__BB6_433;

$L__BB6_436:
	mov.u32 	%r813, 0;
	selp.b32 	%r814, %r108, 0, %p144;
	or.b32  	%r815, %r814, 2146435072;
	selp.b32 	%r816, %r815, %r814, %p146;
	mov.b64 	%fd1139, {%r813, %r816};
	bra.uni 	$L__BB6_437;

$L__BB6_433:
	setp.gt.s32 	%p694, %r108, -1;
	@%p694 bra 	$L__BB6_437;

	cvt.rzi.f64.f64 	%fd828, %fd646;
	setp.eq.f64 	%p695, %fd828, 0d4000000000000000;
	@%p695 bra 	$L__BB6_437;

	mov.f64 	%fd1139, 0dFFF8000000000000;

$L__BB6_437:
	add.f64 	%fd261, %fd254, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r817}, %fd261;
	}
	and.b32  	%r818, %r817, 2146435072;
	setp.ne.s32 	%p698, %r818, 2146435072;
	mov.f64 	%fd1140, %fd1139;
	@%p698 bra 	$L__BB6_443;

	setp.gtu.f64 	%p699, %fd255, 0d7FF0000000000000;
	mov.f64 	%fd1140, %fd261;
	@%p699 bra 	$L__BB6_443;

	setp.eq.s32 	%p700, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r819, %temp}, %fd646;
	}
	setp.eq.s32 	%p701, %r819, 0;
	and.pred  	%p702, %p700, %p701;
	@%p702 bra 	$L__BB6_442;
	bra.uni 	$L__BB6_440;

$L__BB6_442:
	cvt.rn.f32.f64 	%f3184, %fd804;
	mov.u32 	%r824, 0;
	setp.gt.f64 	%p709, %fd255, 0d3FF0000000000000;
	selp.b32 	%r825, 2146435072, 0, %p709;
	xor.b32  	%r826, %r825, 2146435072;
	selp.b32 	%r827, %r826, %r825, %p146;
	setp.eq.f32 	%p710, %f3184, 0fBF800000;
	selp.b32 	%r828, 1072693248, %r827, %p710;
	mov.b64 	%fd1140, {%r824, %r828};
	bra.uni 	$L__BB6_443;

$L__BB6_440:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r820, %temp}, %fd254;
	}
	and.b32  	%r821, %r108, 2147483647;
	setp.ne.s32 	%p703, %r821, 2146435072;
	setp.ne.s32 	%p704, %r820, 0;
	or.pred  	%p705, %p703, %p704;
	mov.f64 	%fd1140, %fd1139;
	@%p705 bra 	$L__BB6_443;

	and.pred  	%p707, %p155, %p46;
	selp.b32 	%r822, %r57, %r56, %p707;
	mov.u32 	%r823, 0;
	mov.b64 	%fd1140, {%r823, %r822};

$L__BB6_443:
	cvt.rn.f32.f64 	%f3174, %fd804;
	not.pred 	%p1289, %p12;
	setp.eq.f32 	%p711, %f3174, 0f3F800000;
	selp.f64 	%fd831, 0d3FF0000000000000, %fd1140, %p711;
	cvt.f64.f32 	%fd832, %f264;
	mul.f64 	%fd265, %fd831, %fd832;
	mov.f64 	%fd1142, %fd66;
	@%p1289 bra 	$L__BB6_445;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r829}, %fd66;
	}
	xor.b32  	%r830, %r829, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r831, %temp}, %fd66;
	}
	mov.b64 	%fd1142, {%r831, %r830};

$L__BB6_445:
	@%p582 bra 	$L__BB6_449;
	bra.uni 	$L__BB6_446;

$L__BB6_449:
	mov.u32 	%r832, 0;
	mov.b64 	%fd1142, {%r832, %r84};
	bra.uni 	$L__BB6_450;

$L__BB6_446:
	setp.gt.s32 	%p714, %r83, -1;
	@%p714 bra 	$L__BB6_450;

	cvt.rzi.f64.f64 	%fd834, %fd646;
	setp.eq.f64 	%p715, %fd834, 0d4000000000000000;
	@%p715 bra 	$L__BB6_450;

	mov.f64 	%fd1142, 0dFFF8000000000000;

$L__BB6_450:
	selp.f64 	%fd1143, %fd1142, %fd46, %p182;
	@%p25 bra 	$L__BB6_455;

	setp.eq.s32 	%p717, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r833, %temp}, %fd646;
	}
	setp.eq.s32 	%p718, %r833, 0;
	and.pred  	%p719, %p717, %p718;
	@%p719 bra 	$L__BB6_454;
	bra.uni 	$L__BB6_452;

$L__BB6_454:
	mov.u32 	%r837, 0;
	mov.b64 	%fd1143, {%r837, %r86};
	bra.uni 	$L__BB6_455;

$L__BB6_452:
	and.b32  	%r834, %r83, 2147483647;
	setp.ne.s32 	%p720, %r834, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r835, %temp}, %fd45;
	}
	setp.ne.s32 	%p721, %r835, 0;
	or.pred  	%p722, %p720, %p721;
	mov.f64 	%fd1143, %fd1142;
	@%p722 bra 	$L__BB6_455;

	mov.u32 	%r836, 0;
	mov.b64 	%fd1143, {%r836, %r88};

$L__BB6_455:
	mov.f64 	%fd1145, %fd68;
	@%p607 bra 	$L__BB6_457;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r838}, %fd68;
	}
	xor.b32  	%r839, %r838, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r840, %temp}, %fd68;
	}
	mov.b64 	%fd1145, {%r840, %r839};

$L__BB6_457:
	@%p608 bra 	$L__BB6_461;
	bra.uni 	$L__BB6_458;

$L__BB6_461:
	mov.u32 	%r841, 0;
	mov.b64 	%fd1145, {%r841, %r91};
	bra.uni 	$L__BB6_462;

$L__BB6_458:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1358}, %fd645;
	}
	setp.gt.s32 	%p725, %r1358, -1;
	@%p725 bra 	$L__BB6_462;

	cvt.rzi.f64.f64 	%fd838, %fd651;
	setp.eq.f64 	%p726, %fd838, 0d4010000000000000;
	@%p726 bra 	$L__BB6_462;

	mov.f64 	%fd1145, 0dFFF8000000000000;

$L__BB6_462:
	selp.f64 	%fd1146, %fd1145, %fd36, %p189;
	@%p27 bra 	$L__BB6_467;

	setp.eq.s32 	%p728, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r842, %temp}, %fd651;
	}
	setp.eq.s32 	%p729, %r842, 0;
	and.pred  	%p730, %p728, %p729;
	@%p730 bra 	$L__BB6_466;
	bra.uni 	$L__BB6_464;

$L__BB6_466:
	mov.u32 	%r846, 0;
	mov.b64 	%fd1146, {%r846, %r94};
	bra.uni 	$L__BB6_467;

$L__BB6_464:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1359}, %fd645;
	}
	and.b32  	%r843, %r1359, 2147483647;
	setp.ne.s32 	%p731, %r843, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r844, %temp}, %fd645;
	}
	setp.ne.s32 	%p732, %r844, 0;
	or.pred  	%p733, %p731, %p732;
	mov.f64 	%fd1146, %fd1145;
	@%p733 bra 	$L__BB6_467;

	mov.u32 	%r845, 0;
	mov.b64 	%fd1146, {%r845, %r97};

$L__BB6_467:
	cvt.rn.f32.f64 	%f3176, %fd825;
	sub.f32 	%f3175, %f3291, %f552;
	setp.eq.f32 	%p1290, %f3175, 0f3F800000;
	selp.f64 	%fd842, 0d3FF0000000000000, %fd1146, %p618;
	selp.f64 	%fd843, 0d3FF0000000000000, %fd1143, %p1290;
	mul.f64 	%fd844, %fd843, %fd39;
	div.rn.f64 	%fd845, %fd844, %fd842;
	add.f64 	%fd846, %fd845, %fd52;
	cvt.rn.f32.f64 	%f1737, %fd846;
	mul.f32 	%f1738, %f246, %f1737;
	cvt.f64.f32 	%fd847, %f1738;
	add.f64 	%fd282, %fd265, %fd847;
	cvt.f64.f32 	%fd283, %f3176;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r109}, %fd283;
	}
	abs.f64 	%fd284, %fd283;
	{ // callseq 134, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd284;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1148, [retval0+0];
	} // callseq 134
	setp.lt.s32 	%p736, %r109, 0;
	and.pred  	%p47, %p736, %p144;
	not.pred 	%p738, %p47;
	@%p738 bra 	$L__BB6_469;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r847}, %fd1148;
	}
	xor.b32  	%r848, %r847, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r849, %temp}, %fd1148;
	}
	mov.b64 	%fd1148, {%r849, %r848};

$L__BB6_469:
	cvt.rn.f32.f64 	%f3177, %fd825;
	setp.eq.f32 	%p739, %f3177, 0f00000000;
	@%p739 bra 	$L__BB6_473;
	bra.uni 	$L__BB6_470;

$L__BB6_473:
	mov.u32 	%r850, 0;
	selp.b32 	%r851, %r109, 0, %p144;
	or.b32  	%r852, %r851, 2146435072;
	selp.b32 	%r853, %r852, %r851, %p146;
	mov.b64 	%fd1148, {%r850, %r853};
	bra.uni 	$L__BB6_474;

$L__BB6_470:
	setp.gt.s32 	%p740, %r109, -1;
	@%p740 bra 	$L__BB6_474;

	cvt.rzi.f64.f64 	%fd850, %fd646;
	setp.eq.f64 	%p741, %fd850, 0d4000000000000000;
	@%p741 bra 	$L__BB6_474;

	mov.f64 	%fd1148, 0dFFF8000000000000;

$L__BB6_474:
	add.f64 	%fd290, %fd283, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r854}, %fd290;
	}
	and.b32  	%r855, %r854, 2146435072;
	setp.ne.s32 	%p744, %r855, 2146435072;
	mov.f64 	%fd1149, %fd1148;
	@%p744 bra 	$L__BB6_480;

	setp.gtu.f64 	%p745, %fd284, 0d7FF0000000000000;
	mov.f64 	%fd1149, %fd290;
	@%p745 bra 	$L__BB6_480;

	setp.eq.s32 	%p746, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r856, %temp}, %fd646;
	}
	setp.eq.s32 	%p747, %r856, 0;
	and.pred  	%p748, %p746, %p747;
	@%p748 bra 	$L__BB6_479;
	bra.uni 	$L__BB6_477;

$L__BB6_479:
	cvt.rn.f32.f64 	%f3183, %fd825;
	mov.u32 	%r861, 0;
	setp.gt.f64 	%p755, %fd284, 0d3FF0000000000000;
	selp.b32 	%r862, 2146435072, 0, %p755;
	xor.b32  	%r863, %r862, 2146435072;
	selp.b32 	%r864, %r863, %r862, %p146;
	setp.eq.f32 	%p756, %f3183, 0fBF800000;
	selp.b32 	%r865, 1072693248, %r864, %p756;
	mov.b64 	%fd1149, {%r861, %r865};
	bra.uni 	$L__BB6_480;

$L__BB6_477:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r857, %temp}, %fd283;
	}
	and.b32  	%r858, %r109, 2147483647;
	setp.ne.s32 	%p749, %r858, 2146435072;
	setp.ne.s32 	%p750, %r857, 0;
	or.pred  	%p751, %p749, %p750;
	mov.f64 	%fd1149, %fd1148;
	@%p751 bra 	$L__BB6_480;

	and.pred  	%p753, %p155, %p47;
	selp.b32 	%r859, %r57, %r56, %p753;
	mov.u32 	%r860, 0;
	mov.b64 	%fd1149, {%r860, %r859};

$L__BB6_480:
	cvt.rn.f32.f64 	%f3178, %fd825;
	not.pred 	%p1291, %p15;
	setp.eq.f32 	%p757, %f3178, 0f3F800000;
	selp.f64 	%fd853, 0d3FF0000000000000, %fd1149, %p757;
	div.rn.f32 	%f1739, %f57, %f276;
	cvt.f64.f32 	%fd854, %f1739;
	mul.f64 	%fd294, %fd853, %fd854;
	mov.f64 	%fd1151, %fd69;
	@%p1291 bra 	$L__BB6_482;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r866}, %fd69;
	}
	xor.b32  	%r867, %r866, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r868, %temp}, %fd69;
	}
	mov.b64 	%fd1151, {%r868, %r867};

$L__BB6_482:
	@%p621 bra 	$L__BB6_486;
	bra.uni 	$L__BB6_483;

$L__BB6_486:
	mov.u32 	%r869, 0;
	mov.b64 	%fd1151, {%r869, %r95};
	bra.uni 	$L__BB6_487;

$L__BB6_483:
	setp.gt.s32 	%p760, %r93, -1;
	@%p760 bra 	$L__BB6_487;

	cvt.rzi.f64.f64 	%fd856, %fd646;
	setp.eq.f64 	%p761, %fd856, 0d4000000000000000;
	@%p761 bra 	$L__BB6_487;

	mov.f64 	%fd1151, 0dFFF8000000000000;

$L__BB6_487:
	selp.f64 	%fd1152, %fd1151, %fd50, %p194;
	@%p28 bra 	$L__BB6_492;

	setp.eq.s32 	%p763, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r870, %temp}, %fd646;
	}
	setp.eq.s32 	%p764, %r870, 0;
	and.pred  	%p765, %p763, %p764;
	@%p765 bra 	$L__BB6_491;
	bra.uni 	$L__BB6_489;

$L__BB6_491:
	mov.u32 	%r874, 0;
	mov.b64 	%fd1152, {%r874, %r98};
	bra.uni 	$L__BB6_492;

$L__BB6_489:
	and.b32  	%r871, %r93, 2147483647;
	setp.ne.s32 	%p766, %r871, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r872, %temp}, %fd49;
	}
	setp.ne.s32 	%p767, %r872, 0;
	or.pred  	%p768, %p766, %p767;
	mov.f64 	%fd1152, %fd1151;
	@%p768 bra 	$L__BB6_492;

	mov.u32 	%r873, 0;
	mov.b64 	%fd1152, {%r873, %r100};

$L__BB6_492:
	mov.f64 	%fd1154, %fd68;
	@%p607 bra 	$L__BB6_494;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r875}, %fd68;
	}
	xor.b32  	%r876, %r875, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r877, %temp}, %fd68;
	}
	mov.b64 	%fd1154, {%r877, %r876};

$L__BB6_494:
	@%p608 bra 	$L__BB6_498;
	bra.uni 	$L__BB6_495;

$L__BB6_498:
	mov.u32 	%r878, 0;
	mov.b64 	%fd1154, {%r878, %r91};
	bra.uni 	$L__BB6_499;

$L__BB6_495:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1360}, %fd645;
	}
	setp.gt.s32 	%p771, %r1360, -1;
	@%p771 bra 	$L__BB6_499;

	cvt.rzi.f64.f64 	%fd860, %fd651;
	setp.eq.f64 	%p772, %fd860, 0d4010000000000000;
	@%p772 bra 	$L__BB6_499;

	mov.f64 	%fd1154, 0dFFF8000000000000;

$L__BB6_499:
	selp.f64 	%fd1155, %fd1154, %fd36, %p189;
	@%p27 bra 	$L__BB6_504;

	setp.eq.s32 	%p774, %r65, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r879, %temp}, %fd651;
	}
	setp.eq.s32 	%p775, %r879, 0;
	and.pred  	%p776, %p774, %p775;
	@%p776 bra 	$L__BB6_503;
	bra.uni 	$L__BB6_501;

$L__BB6_503:
	mov.u32 	%r883, 0;
	mov.b64 	%fd1155, {%r883, %r94};
	bra.uni 	$L__BB6_504;

$L__BB6_501:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1361}, %fd645;
	}
	and.b32  	%r880, %r1361, 2147483647;
	setp.ne.s32 	%p777, %r880, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r881, %temp}, %fd645;
	}
	setp.ne.s32 	%p778, %r881, 0;
	or.pred  	%p779, %p777, %p778;
	mov.f64 	%fd1155, %fd1154;
	@%p779 bra 	$L__BB6_504;

	mov.u32 	%r882, 0;
	mov.b64 	%fd1155, {%r882, %r97};

$L__BB6_504:
	cvt.rn.f32.f64 	%f3182, %fd825;
	mul.f32 	%f3181, %f247, %f3182;
	cvt.rn.f32.f64 	%f3180, %fd804;
	mul.f32 	%f3179, %f246, %f3180;
	cvt.rn.f32.s32 	%f3067, %r1374;
	cvt.rn.f32.s32 	%f3066, %r1375;
	selp.f64 	%fd864, 0d3FF0000000000000, %fd1155, %p618;
	selp.f64 	%fd865, 0d3FF0000000000000, %fd1152, %p631;
	mul.f64 	%fd866, %fd865, %fd40;
	div.rn.f64 	%fd867, %fd866, %fd864;
	add.f64 	%fd868, %fd867, %fd53;
	cvt.rn.f32.f64 	%f1741, %fd868;
	mul.f32 	%f1742, %f247, %f1741;
	cvt.f64.f32 	%fd869, %f1742;
	add.f64 	%fd870, %fd294, %fd869;
	cvt.rn.f32.f64 	%f1743, %fd870;
	mul.f32 	%f1744, %f3179, %f3179;
	cvt.rn.f32.f64 	%f1745, %fd282;
	mul.f32 	%f1746, %f217, %f1745;
	fma.rn.f32 	%f1747, %f1744, %f218, %f1746;
	mul.f32 	%f1748, %f3181, %f3181;
	cvt.rn.f32.f64 	%f1749, %fd203;
	fma.rn.f32 	%f1750, %f1748, %f1749, %f1747;
	fma.rn.f32 	%f277, %f245, %f1743, %f1750;
	mul.f32 	%f1751, %f117, %f3293;
	fma.rn.f32 	%f278, %f131, %f1751, %f3292;
	mad.lo.s32 	%r884, %r1375, %r182, %r1374;
	add.s32 	%r885, %r884, %r2;
	mul.wide.s32 	%rd31, %r885, 4;
	add.s64 	%rd32, %rd1, %rd31;
	ld.global.f32 	%f279, [%rd32];
	add.f32 	%f1752, %f73, %f3066;
	fma.rn.f32 	%f1753, %f1752, %f61, %f74;
	add.f32 	%f1754, %f1753, %f3067;
	cvt.rzi.s32.f32 	%r886, %f1754;
	mul.wide.s32 	%rd34, %r886, 4;
	add.s64 	%rd35, %rd33, %rd34;
	ld.global.f32 	%f3290, [%rd35];
	mul.f32 	%f281, %f117, %f131;
	setp.leu.f32 	%p782, %f278, 0f3C23D70A;
	mov.f32 	%f3278, %f3279;
	@%p782 bra 	$L__BB6_506;

	sub.f32 	%f1755, %f279, %f278;
	add.f32 	%f1756, %f278, %f3290;
	div.rn.f32 	%f3278, %f1755, %f1756;

$L__BB6_506:
	@%p782 bra 	$L__BB6_521;

	add.f32 	%f284, %f278, %f3290;
	cvt.f64.f32 	%fd311, %f284;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r110}, %fd311;
	}
	abs.f64 	%fd312, %fd311;
	{ // callseq 135, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd312;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1157, [retval0+0];
	} // callseq 135
	setp.lt.s32 	%p785, %r110, 0;
	and.pred  	%p48, %p785, %p144;
	not.pred 	%p786, %p48;
	@%p786 bra 	$L__BB6_509;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r887}, %fd1157;
	}
	xor.b32  	%r888, %r887, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r889, %temp}, %fd1157;
	}
	mov.b64 	%fd1157, {%r889, %r888};

$L__BB6_509:
	setp.eq.f32 	%p787, %f284, 0f00000000;
	@%p787 bra 	$L__BB6_513;
	bra.uni 	$L__BB6_510;

$L__BB6_513:
	mov.u32 	%r890, 0;
	selp.b32 	%r891, %r110, 0, %p144;
	or.b32  	%r892, %r891, 2146435072;
	selp.b32 	%r893, %r892, %r891, %p146;
	mov.b64 	%fd1157, {%r890, %r893};
	bra.uni 	$L__BB6_514;

$L__BB6_510:
	setp.gt.s32 	%p788, %r110, -1;
	@%p788 bra 	$L__BB6_514;

	cvt.rzi.f64.f64 	%fd873, %fd646;
	setp.eq.f64 	%p789, %fd873, 0d4000000000000000;
	@%p789 bra 	$L__BB6_514;

	mov.f64 	%fd1157, 0dFFF8000000000000;

$L__BB6_514:
	add.f64 	%fd318, %fd311, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r894}, %fd318;
	}
	and.b32  	%r895, %r894, 2146435072;
	setp.ne.s32 	%p792, %r895, 2146435072;
	mov.f64 	%fd1158, %fd1157;
	@%p792 bra 	$L__BB6_520;

	setp.gtu.f64 	%p793, %fd312, 0d7FF0000000000000;
	mov.f64 	%fd1158, %fd318;
	@%p793 bra 	$L__BB6_520;

	setp.eq.s32 	%p794, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r896, %temp}, %fd646;
	}
	setp.eq.s32 	%p795, %r896, 0;
	and.pred  	%p796, %p794, %p795;
	@%p796 bra 	$L__BB6_519;
	bra.uni 	$L__BB6_517;

$L__BB6_519:
	mov.u32 	%r901, 0;
	setp.gt.f64 	%p803, %fd312, 0d3FF0000000000000;
	selp.b32 	%r902, 2146435072, 0, %p803;
	xor.b32  	%r903, %r902, 2146435072;
	selp.b32 	%r904, %r903, %r902, %p146;
	setp.eq.f32 	%p804, %f284, 0fBF800000;
	selp.b32 	%r905, 1072693248, %r904, %p804;
	mov.b64 	%fd1158, {%r901, %r905};
	bra.uni 	$L__BB6_520;

$L__BB6_517:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r897, %temp}, %fd311;
	}
	and.b32  	%r898, %r110, 2147483647;
	setp.ne.s32 	%p797, %r898, 2146435072;
	setp.ne.s32 	%p798, %r897, 0;
	or.pred  	%p799, %p797, %p798;
	mov.f64 	%fd1158, %fd1157;
	@%p799 bra 	$L__BB6_520;

	and.pred  	%p801, %p155, %p48;
	selp.b32 	%r899, %r57, %r56, %p801;
	mov.u32 	%r900, 0;
	mov.b64 	%fd1158, {%r900, %r899};

$L__BB6_520:
	setp.eq.f32 	%p805, %f284, 0f3F800000;
	selp.f64 	%fd876, 0d3FF0000000000000, %fd1158, %p805;
	add.f32 	%f1758, %f279, %f3290;
	cvt.f64.f32 	%fd877, %f1758;
	div.rn.f64 	%fd878, %fd877, %fd876;
	cvt.rn.f32.f64 	%f3279, %fd878;

$L__BB6_521:
	mov.f32 	%f1759, 0f47C35000;
	min.f32 	%f1760, %f3279, %f1759;
	cvt.f64.f32 	%fd322, %f1760;
	min.f32 	%f287, %f3278, %f1759;
	fma.rn.f32 	%f3238, %f287, %f159, %f3238;
	mul.f32 	%f1761, %f287, %f160;
	cvt.f64.f32 	%fd323, %f1761;
	cvt.f64.f32 	%fd324, %f159;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r111}, %fd324;
	}
	abs.f64 	%fd325, %fd324;
	{ // callseq 136, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd325;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1159, [retval0+0];
	} // callseq 136
	@%p144 bra 	$L__BB6_567;
	bra.uni 	$L__BB6_522;

$L__BB6_567:
	setp.gt.s32 	%p867, %r111, -1;
	@%p867 bra 	$L__BB6_569;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r954}, %fd1159;
	}
	xor.b32  	%r955, %r954, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r956, %temp}, %fd1159;
	}
	mov.b64 	%fd1159, {%r956, %r955};

$L__BB6_569:
	setp.eq.f32 	%p868, %f159, 0f00000000;
	@%p868 bra 	$L__BB6_573;
	bra.uni 	$L__BB6_570;

$L__BB6_573:
	mov.u32 	%r957, 0;
	or.b32  	%r958, %r111, 2146435072;
	selp.b32 	%r959, %r958, %r111, %p146;
	mov.b64 	%fd1159, {%r957, %r959};
	bra.uni 	$L__BB6_574;

$L__BB6_522:
	setp.eq.f32 	%p807, %f159, 0f00000000;
	@%p807 bra 	$L__BB6_526;
	bra.uni 	$L__BB6_523;

$L__BB6_526:
	mov.u32 	%r906, 0;
	mov.b64 	%fd1159, {%r906, %r102};
	bra.uni 	$L__BB6_527;

$L__BB6_570:
	@%p867 bra 	$L__BB6_574;

	cvt.rzi.f64.f64 	%fd921, %fd646;
	setp.eq.f64 	%p870, %fd921, 0d4000000000000000;
	@%p870 bra 	$L__BB6_574;

	mov.f64 	%fd1159, 0dFFF8000000000000;

$L__BB6_574:
	add.f64 	%fd369, %fd324, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r960}, %fd369;
	}
	and.b32  	%r961, %r960, 2146435072;
	setp.ne.s32 	%p872, %r961, 2146435072;
	mov.f64 	%fd1169, %fd1159;
	@%p872 bra 	$L__BB6_580;

	setp.gtu.f64 	%p873, %fd325, 0d7FF0000000000000;
	mov.f64 	%fd1169, %fd369;
	@%p873 bra 	$L__BB6_580;

	setp.eq.s32 	%p874, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r962, %temp}, %fd646;
	}
	setp.eq.s32 	%p875, %r962, 0;
	and.pred  	%p876, %p874, %p875;
	@%p876 bra 	$L__BB6_579;
	bra.uni 	$L__BB6_577;

$L__BB6_579:
	mov.u32 	%r967, 0;
	setp.gt.f64 	%p884, %fd325, 0d3FF0000000000000;
	selp.b32 	%r968, 2146435072, 0, %p884;
	xor.b32  	%r969, %r968, 2146435072;
	selp.b32 	%r970, %r969, %r968, %p146;
	setp.eq.f32 	%p885, %f159, 0fBF800000;
	selp.b32 	%r971, 1072693248, %r970, %p885;
	mov.b64 	%fd1169, {%r967, %r971};
	bra.uni 	$L__BB6_580;

$L__BB6_523:
	setp.gt.s32 	%p808, %r111, -1;
	@%p808 bra 	$L__BB6_527;

	cvt.rzi.f64.f64 	%fd881, %fd646;
	setp.eq.f64 	%p809, %fd881, 0d4000000000000000;
	@%p809 bra 	$L__BB6_527;

	mov.f64 	%fd1159, 0dFFF8000000000000;

$L__BB6_527:
	add.f64 	%fd329, %fd324, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r907}, %fd329;
	}
	and.b32  	%r908, %r907, 2146435072;
	setp.ne.s32 	%p810, %r908, 2146435072;
	mov.f64 	%fd1160, %fd1159;
	@%p810 bra 	$L__BB6_533;

	setp.gtu.f64 	%p811, %fd325, 0d7FF0000000000000;
	mov.f64 	%fd1160, %fd329;
	@%p811 bra 	$L__BB6_533;

	setp.eq.s32 	%p812, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r909, %temp}, %fd646;
	}
	setp.eq.s32 	%p813, %r909, 0;
	and.pred  	%p814, %p812, %p813;
	@%p814 bra 	$L__BB6_532;
	bra.uni 	$L__BB6_530;

$L__BB6_532:
	mov.u32 	%r913, 0;
	setp.gt.f64 	%p819, %fd325, 0d3FF0000000000000;
	selp.b32 	%r914, 2146435072, 0, %p819;
	xor.b32  	%r915, %r914, 2146435072;
	selp.b32 	%r916, %r915, %r914, %p146;
	setp.eq.f32 	%p820, %f159, 0fBF800000;
	selp.b32 	%r917, 1072693248, %r916, %p820;
	mov.b64 	%fd1160, {%r913, %r917};
	bra.uni 	$L__BB6_533;

$L__BB6_577:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r963, %temp}, %fd324;
	}
	and.b32  	%r964, %r111, 2147483647;
	setp.ne.s32 	%p877, %r964, 2146435072;
	setp.ne.s32 	%p878, %r963, 0;
	or.pred  	%p879, %p877, %p878;
	mov.f64 	%fd1169, %fd1159;
	@%p879 bra 	$L__BB6_580;

	setp.lt.s32 	%p880, %r111, 0;
	mov.u32 	%r965, 0;
	and.pred  	%p882, %p155, %p880;
	selp.b32 	%r966, %r57, %r56, %p882;
	mov.b64 	%fd1169, {%r965, %r966};

$L__BB6_580:
	setp.eq.f32 	%p886, %f159, 0f3F800000;
	selp.f64 	%fd924, 0d3FF0000000000000, %fd1169, %p886;
	mul.f64 	%fd925, %fd924, %fd322;
	sub.f64 	%fd926, %fd323, %fd925;
	cvt.f64.f32 	%fd927, %f3243;
	add.f64 	%fd1183, %fd926, %fd927;
	cvt.f64.f32 	%fd374, %f189;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r115}, %fd374;
	}
	abs.f64 	%fd375, %fd374;
	{ // callseq 140, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd375;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1171, [retval0+0];
	} // callseq 140
	setp.gt.s32 	%p887, %r115, -1;
	@%p887 bra 	$L__BB6_582;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r972}, %fd1171;
	}
	xor.b32  	%r973, %r972, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r974, %temp}, %fd1171;
	}
	mov.b64 	%fd1171, {%r974, %r973};

$L__BB6_582:
	setp.eq.f32 	%p888, %f189, 0f00000000;
	@%p888 bra 	$L__BB6_586;
	bra.uni 	$L__BB6_583;

$L__BB6_586:
	mov.u32 	%r975, 0;
	or.b32  	%r976, %r115, 2146435072;
	selp.b32 	%r977, %r976, %r115, %p146;
	mov.b64 	%fd1171, {%r975, %r977};
	bra.uni 	$L__BB6_587;

$L__BB6_583:
	@%p887 bra 	$L__BB6_587;

	cvt.rzi.f64.f64 	%fd930, %fd646;
	setp.eq.f64 	%p890, %fd930, 0d4000000000000000;
	@%p890 bra 	$L__BB6_587;

	mov.f64 	%fd1171, 0dFFF8000000000000;

$L__BB6_587:
	add.f64 	%fd381, %fd374, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r978}, %fd381;
	}
	and.b32  	%r979, %r978, 2146435072;
	setp.ne.s32 	%p892, %r979, 2146435072;
	mov.f64 	%fd1172, %fd1171;
	@%p892 bra 	$L__BB6_593;

	setp.gtu.f64 	%p893, %fd375, 0d7FF0000000000000;
	mov.f64 	%fd1172, %fd381;
	@%p893 bra 	$L__BB6_593;

	setp.eq.s32 	%p894, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r980, %temp}, %fd646;
	}
	setp.eq.s32 	%p895, %r980, 0;
	and.pred  	%p896, %p894, %p895;
	@%p896 bra 	$L__BB6_592;
	bra.uni 	$L__BB6_590;

$L__BB6_592:
	mov.u32 	%r985, 0;
	setp.gt.f64 	%p904, %fd375, 0d3FF0000000000000;
	selp.b32 	%r986, 2146435072, 0, %p904;
	xor.b32  	%r987, %r986, 2146435072;
	selp.b32 	%r988, %r987, %r986, %p146;
	setp.eq.f32 	%p905, %f189, 0fBF800000;
	selp.b32 	%r989, 1072693248, %r988, %p905;
	mov.b64 	%fd1172, {%r985, %r989};
	bra.uni 	$L__BB6_593;

$L__BB6_530:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r910, %temp}, %fd324;
	}
	and.b32  	%r911, %r111, 2147483647;
	setp.ne.s32 	%p815, %r911, 2146435072;
	setp.ne.s32 	%p816, %r910, 0;
	or.pred  	%p817, %p815, %p816;
	mov.f64 	%fd1160, %fd1159;
	@%p817 bra 	$L__BB6_533;

	mov.u32 	%r912, 0;
	mov.b64 	%fd1160, {%r912, %r56};

$L__BB6_533:
	setp.eq.f32 	%p821, %f159, 0f3F800000;
	selp.f64 	%fd884, 0d3FF0000000000000, %fd1160, %p821;
	mul.f64 	%fd885, %fd884, %fd322;
	sub.f64 	%fd886, %fd323, %fd885;
	cvt.f64.f32 	%fd887, %f3243;
	add.f64 	%fd1183, %fd886, %fd887;
	cvt.f64.f32 	%fd334, %f189;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd334;
	}
	abs.f64 	%fd335, %fd334;
	setp.eq.f32 	%p822, %f189, 0f00000000;
	@%p822 bra 	$L__BB6_537;
	bra.uni 	$L__BB6_534;

$L__BB6_537:
	mov.u32 	%r918, 0;
	mov.b64 	%fd1161, {%r918, %r102};
	bra.uni 	$L__BB6_538;

$L__BB6_534:
	{ // callseq 137, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd335;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1161, [retval0+0];
	} // callseq 137
	setp.gt.s32 	%p823, %r112, -1;
	@%p823 bra 	$L__BB6_538;

	cvt.rzi.f64.f64 	%fd890, %fd646;
	setp.eq.f64 	%p824, %fd890, 0d4000000000000000;
	@%p824 bra 	$L__BB6_538;

	mov.f64 	%fd1161, 0dFFF8000000000000;

$L__BB6_538:
	add.f64 	%fd339, %fd334, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r919}, %fd339;
	}
	and.b32  	%r920, %r919, 2146435072;
	setp.ne.s32 	%p825, %r920, 2146435072;
	mov.f64 	%fd1162, %fd1161;
	@%p825 bra 	$L__BB6_544;

	setp.gtu.f64 	%p826, %fd335, 0d7FF0000000000000;
	mov.f64 	%fd1162, %fd339;
	@%p826 bra 	$L__BB6_544;

	setp.eq.s32 	%p827, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r921, %temp}, %fd646;
	}
	setp.eq.s32 	%p828, %r921, 0;
	and.pred  	%p829, %p827, %p828;
	@%p829 bra 	$L__BB6_543;
	bra.uni 	$L__BB6_541;

$L__BB6_543:
	mov.u32 	%r925, 0;
	setp.gt.f64 	%p834, %fd335, 0d3FF0000000000000;
	selp.b32 	%r926, 2146435072, 0, %p834;
	xor.b32  	%r927, %r926, 2146435072;
	selp.b32 	%r928, %r927, %r926, %p146;
	setp.eq.f32 	%p835, %f189, 0fBF800000;
	selp.b32 	%r929, 1072693248, %r928, %p835;
	mov.b64 	%fd1162, {%r925, %r929};
	bra.uni 	$L__BB6_544;

$L__BB6_590:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r981, %temp}, %fd374;
	}
	and.b32  	%r982, %r115, 2147483647;
	setp.ne.s32 	%p897, %r982, 2146435072;
	setp.ne.s32 	%p898, %r981, 0;
	or.pred  	%p899, %p897, %p898;
	mov.f64 	%fd1172, %fd1171;
	@%p899 bra 	$L__BB6_593;

	setp.lt.s32 	%p900, %r115, 0;
	mov.u32 	%r983, 0;
	and.pred  	%p902, %p155, %p900;
	selp.b32 	%r984, %r57, %r56, %p902;
	mov.b64 	%fd1172, {%r983, %r984};

$L__BB6_593:
	setp.eq.f32 	%p906, %f189, 0f3F800000;
	selp.f64 	%fd933, 0d3FF0000000000000, %fd1172, %p906;
	mul.f64 	%fd934, %fd933, %fd322;
	mul.f32 	%f1765, %f287, %f190;
	cvt.f64.f32 	%fd935, %f1765;
	sub.f64 	%fd936, %fd935, %fd934;
	cvt.f64.f32 	%fd937, %f3242;
	add.f64 	%fd1182, %fd936, %fd937;
	cvt.f64.f32 	%fd386, %f281;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r116}, %fd386;
	}
	abs.f64 	%fd387, %fd386;
	{ // callseq 141, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd387;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1174, [retval0+0];
	} // callseq 141
	setp.gt.s32 	%p907, %r116, -1;
	@%p907 bra 	$L__BB6_595;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r990}, %fd1174;
	}
	xor.b32  	%r991, %r990, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r992, %temp}, %fd1174;
	}
	mov.b64 	%fd1174, {%r992, %r991};

$L__BB6_595:
	setp.eq.f32 	%p908, %f281, 0f00000000;
	@%p908 bra 	$L__BB6_599;
	bra.uni 	$L__BB6_596;

$L__BB6_599:
	mov.u32 	%r993, 0;
	or.b32  	%r994, %r116, 2146435072;
	selp.b32 	%r995, %r994, %r116, %p146;
	mov.b64 	%fd1174, {%r993, %r995};
	bra.uni 	$L__BB6_600;

$L__BB6_596:
	@%p907 bra 	$L__BB6_600;

	cvt.rzi.f64.f64 	%fd940, %fd646;
	setp.eq.f64 	%p910, %fd940, 0d4000000000000000;
	@%p910 bra 	$L__BB6_600;

	mov.f64 	%fd1174, 0dFFF8000000000000;

$L__BB6_600:
	add.f64 	%fd393, %fd386, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r996}, %fd393;
	}
	and.b32  	%r997, %r996, 2146435072;
	setp.ne.s32 	%p912, %r997, 2146435072;
	mov.f64 	%fd1175, %fd1174;
	@%p912 bra 	$L__BB6_606;

	setp.gtu.f64 	%p913, %fd387, 0d7FF0000000000000;
	mov.f64 	%fd1175, %fd393;
	@%p913 bra 	$L__BB6_606;

	setp.eq.s32 	%p914, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r998, %temp}, %fd646;
	}
	setp.eq.s32 	%p915, %r998, 0;
	and.pred  	%p916, %p914, %p915;
	@%p916 bra 	$L__BB6_605;
	bra.uni 	$L__BB6_603;

$L__BB6_605:
	mov.u32 	%r1003, 0;
	setp.gt.f64 	%p924, %fd387, 0d3FF0000000000000;
	selp.b32 	%r1004, 2146435072, 0, %p924;
	xor.b32  	%r1005, %r1004, 2146435072;
	selp.b32 	%r1006, %r1005, %r1004, %p146;
	setp.eq.f32 	%p925, %f281, 0fBF800000;
	selp.b32 	%r1007, 1072693248, %r1006, %p925;
	mov.b64 	%fd1175, {%r1003, %r1007};
	bra.uni 	$L__BB6_606;

$L__BB6_541:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r922, %temp}, %fd334;
	}
	and.b32  	%r923, %r112, 2147483647;
	setp.ne.s32 	%p830, %r923, 2146435072;
	setp.ne.s32 	%p831, %r922, 0;
	or.pred  	%p832, %p830, %p831;
	mov.f64 	%fd1162, %fd1161;
	@%p832 bra 	$L__BB6_544;

	mov.u32 	%r924, 0;
	mov.b64 	%fd1162, {%r924, %r56};

$L__BB6_544:
	setp.eq.f32 	%p836, %f189, 0f3F800000;
	selp.f64 	%fd893, 0d3FF0000000000000, %fd1162, %p836;
	mul.f64 	%fd894, %fd893, %fd322;
	mul.f32 	%f1762, %f287, %f190;
	cvt.f64.f32 	%fd895, %f1762;
	sub.f64 	%fd896, %fd895, %fd894;
	cvt.f64.f32 	%fd897, %f3242;
	add.f64 	%fd1182, %fd896, %fd897;
	cvt.f64.f32 	%fd344, %f281;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd344;
	}
	abs.f64 	%fd345, %fd344;
	setp.eq.f32 	%p837, %f281, 0f00000000;
	@%p837 bra 	$L__BB6_548;
	bra.uni 	$L__BB6_545;

$L__BB6_548:
	mov.u32 	%r930, 0;
	mov.b64 	%fd1163, {%r930, %r102};
	bra.uni 	$L__BB6_549;

$L__BB6_545:
	{ // callseq 138, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd345;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1163, [retval0+0];
	} // callseq 138
	setp.gt.s32 	%p838, %r113, -1;
	@%p838 bra 	$L__BB6_549;

	cvt.rzi.f64.f64 	%fd900, %fd646;
	setp.eq.f64 	%p839, %fd900, 0d4000000000000000;
	@%p839 bra 	$L__BB6_549;

	mov.f64 	%fd1163, 0dFFF8000000000000;

$L__BB6_549:
	add.f64 	%fd349, %fd344, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r931}, %fd349;
	}
	and.b32  	%r932, %r931, 2146435072;
	setp.ne.s32 	%p840, %r932, 2146435072;
	mov.f64 	%fd1164, %fd1163;
	@%p840 bra 	$L__BB6_555;

	setp.gtu.f64 	%p841, %fd345, 0d7FF0000000000000;
	mov.f64 	%fd1164, %fd349;
	@%p841 bra 	$L__BB6_555;

	setp.eq.s32 	%p842, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r933, %temp}, %fd646;
	}
	setp.eq.s32 	%p843, %r933, 0;
	and.pred  	%p844, %p842, %p843;
	@%p844 bra 	$L__BB6_554;
	bra.uni 	$L__BB6_552;

$L__BB6_554:
	mov.u32 	%r937, 0;
	setp.gt.f64 	%p849, %fd345, 0d3FF0000000000000;
	selp.b32 	%r938, 2146435072, 0, %p849;
	xor.b32  	%r939, %r938, 2146435072;
	selp.b32 	%r940, %r939, %r938, %p146;
	setp.eq.f32 	%p850, %f281, 0fBF800000;
	selp.b32 	%r941, 1072693248, %r940, %p850;
	mov.b64 	%fd1164, {%r937, %r941};
	bra.uni 	$L__BB6_555;

$L__BB6_603:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r999, %temp}, %fd386;
	}
	and.b32  	%r1000, %r116, 2147483647;
	setp.ne.s32 	%p917, %r1000, 2146435072;
	setp.ne.s32 	%p918, %r999, 0;
	or.pred  	%p919, %p917, %p918;
	mov.f64 	%fd1175, %fd1174;
	@%p919 bra 	$L__BB6_606;

	setp.lt.s32 	%p920, %r116, 0;
	mov.u32 	%r1001, 0;
	and.pred  	%p922, %p155, %p920;
	selp.b32 	%r1002, %r57, %r56, %p922;
	mov.b64 	%fd1175, {%r1001, %r1002};

$L__BB6_606:
	mul.f32 	%f1766, %f287, 0f00000000;
	cvt.f64.f32 	%fd943, %f1766;
	setp.eq.f32 	%p926, %f281, 0f3F800000;
	selp.f64 	%fd944, 0d3FF0000000000000, %fd1175, %p926;
	mul.f64 	%fd945, %fd944, %fd322;
	sub.f64 	%fd946, %fd943, %fd945;
	cvt.f64.f32 	%fd947, %f3241;
	add.f64 	%fd1181, %fd946, %fd947;
	cvt.f64.f32 	%fd948, %f3240;
	sub.f64 	%fd949, %fd943, %fd322;
	add.f64 	%fd1180, %fd949, %fd948;
	cvt.f64.f32 	%fd399, %f252;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r117}, %fd399;
	}
	abs.f64 	%fd400, %fd399;
	{ // callseq 142, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd400;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1177, [retval0+0];
	} // callseq 142
	setp.gt.s32 	%p927, %r117, -1;
	@%p927 bra 	$L__BB6_608;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1008}, %fd1177;
	}
	xor.b32  	%r1009, %r1008, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1010, %temp}, %fd1177;
	}
	mov.b64 	%fd1177, {%r1010, %r1009};

$L__BB6_608:
	setp.eq.f32 	%p928, %f252, 0f00000000;
	@%p928 bra 	$L__BB6_612;
	bra.uni 	$L__BB6_609;

$L__BB6_612:
	mov.u32 	%r1011, 0;
	or.b32  	%r1012, %r117, 2146435072;
	selp.b32 	%r1013, %r1012, %r117, %p146;
	mov.b64 	%fd1177, {%r1011, %r1013};
	bra.uni 	$L__BB6_613;

$L__BB6_609:
	@%p927 bra 	$L__BB6_613;

	cvt.rzi.f64.f64 	%fd952, %fd646;
	setp.eq.f64 	%p930, %fd952, 0d4000000000000000;
	@%p930 bra 	$L__BB6_613;

	mov.f64 	%fd1177, 0dFFF8000000000000;

$L__BB6_613:
	add.f64 	%fd406, %fd399, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1014}, %fd406;
	}
	and.b32  	%r1015, %r1014, 2146435072;
	setp.ne.s32 	%p932, %r1015, 2146435072;
	mov.f64 	%fd1178, %fd1177;
	@%p932 bra 	$L__BB6_619;

	setp.gtu.f64 	%p933, %fd400, 0d7FF0000000000000;
	mov.f64 	%fd1178, %fd406;
	@%p933 bra 	$L__BB6_619;

	setp.eq.s32 	%p934, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1016, %temp}, %fd646;
	}
	setp.eq.s32 	%p935, %r1016, 0;
	and.pred  	%p936, %p934, %p935;
	@%p936 bra 	$L__BB6_618;
	bra.uni 	$L__BB6_616;

$L__BB6_618:
	mov.u32 	%r1021, 0;
	setp.gt.f64 	%p944, %fd400, 0d3FF0000000000000;
	selp.b32 	%r1022, 2146435072, 0, %p944;
	xor.b32  	%r1023, %r1022, 2146435072;
	selp.b32 	%r1024, %r1023, %r1022, %p146;
	setp.eq.f32 	%p945, %f252, 0fBF800000;
	selp.b32 	%r1025, 1072693248, %r1024, %p945;
	mov.b64 	%fd1178, {%r1021, %r1025};
	bra.uni 	$L__BB6_619;

$L__BB6_552:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r934, %temp}, %fd344;
	}
	and.b32  	%r935, %r113, 2147483647;
	setp.ne.s32 	%p845, %r935, 2146435072;
	setp.ne.s32 	%p846, %r934, 0;
	or.pred  	%p847, %p845, %p846;
	mov.f64 	%fd1164, %fd1163;
	@%p847 bra 	$L__BB6_555;

	mov.u32 	%r936, 0;
	mov.b64 	%fd1164, {%r936, %r56};

$L__BB6_555:
	mul.f32 	%f1763, %f287, 0f00000000;
	cvt.f64.f32 	%fd903, %f1763;
	setp.eq.f32 	%p851, %f281, 0f3F800000;
	selp.f64 	%fd904, 0d3FF0000000000000, %fd1164, %p851;
	mul.f64 	%fd905, %fd904, %fd322;
	sub.f64 	%fd906, %fd903, %fd905;
	cvt.f64.f32 	%fd907, %f3241;
	add.f64 	%fd1181, %fd906, %fd907;
	cvt.f64.f32 	%fd908, %f3240;
	sub.f64 	%fd909, %fd903, %fd322;
	add.f64 	%fd1180, %fd909, %fd908;
	cvt.f64.f32 	%fd355, %f252;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd355;
	}
	abs.f64 	%fd356, %fd355;
	setp.eq.f32 	%p852, %f252, 0f00000000;
	@%p852 bra 	$L__BB6_559;
	bra.uni 	$L__BB6_556;

$L__BB6_559:
	mov.u32 	%r942, 0;
	mov.b64 	%fd1165, {%r942, %r102};
	bra.uni 	$L__BB6_560;

$L__BB6_556:
	{ // callseq 139, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd356;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd646;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1165, [retval0+0];
	} // callseq 139
	setp.gt.s32 	%p853, %r114, -1;
	@%p853 bra 	$L__BB6_560;

	cvt.rzi.f64.f64 	%fd912, %fd646;
	setp.eq.f64 	%p854, %fd912, 0d4000000000000000;
	@%p854 bra 	$L__BB6_560;

	mov.f64 	%fd1165, 0dFFF8000000000000;

$L__BB6_560:
	add.f64 	%fd360, %fd355, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r943}, %fd360;
	}
	and.b32  	%r944, %r943, 2146435072;
	setp.ne.s32 	%p855, %r944, 2146435072;
	mov.f64 	%fd1166, %fd1165;
	@%p855 bra 	$L__BB6_566;

	setp.gtu.f64 	%p856, %fd356, 0d7FF0000000000000;
	mov.f64 	%fd1166, %fd360;
	@%p856 bra 	$L__BB6_566;

	setp.eq.s32 	%p857, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r945, %temp}, %fd646;
	}
	setp.eq.s32 	%p858, %r945, 0;
	and.pred  	%p859, %p857, %p858;
	@%p859 bra 	$L__BB6_565;
	bra.uni 	$L__BB6_563;

$L__BB6_565:
	mov.u32 	%r949, 0;
	setp.gt.f64 	%p864, %fd356, 0d3FF0000000000000;
	selp.b32 	%r950, 2146435072, 0, %p864;
	xor.b32  	%r951, %r950, 2146435072;
	selp.b32 	%r952, %r951, %r950, %p146;
	setp.eq.f32 	%p865, %f252, 0fBF800000;
	selp.b32 	%r953, 1072693248, %r952, %p865;
	mov.b64 	%fd1166, {%r949, %r953};
	bra.uni 	$L__BB6_566;

$L__BB6_616:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1017, %temp}, %fd399;
	}
	and.b32  	%r1018, %r117, 2147483647;
	setp.ne.s32 	%p937, %r1018, 2146435072;
	setp.ne.s32 	%p938, %r1017, 0;
	or.pred  	%p939, %p937, %p938;
	mov.f64 	%fd1178, %fd1177;
	@%p939 bra 	$L__BB6_619;

	setp.lt.s32 	%p940, %r117, 0;
	mov.u32 	%r1019, 0;
	and.pred  	%p942, %p155, %p940;
	selp.b32 	%r1020, %r57, %r56, %p942;
	mov.b64 	%fd1178, {%r1019, %r1020};

$L__BB6_619:
	setp.eq.f32 	%p946, %f252, 0f3F800000;
	selp.f64 	%fd955, 0d3FF0000000000000, %fd1178, %p946;
	mul.f64 	%fd956, %fd955, %fd322;
	mul.f32 	%f1767, %f287, %f277;
	cvt.f64.f32 	%fd957, %f1767;
	sub.f64 	%fd958, %fd957, %fd956;
	cvt.f64.f32 	%fd959, %f3239;
	add.f64 	%fd1179, %fd958, %fd959;
	bra.uni 	$L__BB6_620;

$L__BB6_563:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r946, %temp}, %fd355;
	}
	and.b32  	%r947, %r114, 2147483647;
	setp.ne.s32 	%p860, %r947, 2146435072;
	setp.ne.s32 	%p861, %r946, 0;
	or.pred  	%p862, %p860, %p861;
	mov.f64 	%fd1166, %fd1165;
	@%p862 bra 	$L__BB6_566;

	mov.u32 	%r948, 0;
	mov.b64 	%fd1166, {%r948, %r56};

$L__BB6_566:
	setp.eq.f32 	%p866, %f252, 0f3F800000;
	selp.f64 	%fd915, 0d3FF0000000000000, %fd1166, %p866;
	mul.f64 	%fd916, %fd915, %fd322;
	mul.f32 	%f1764, %f287, %f277;
	cvt.f64.f32 	%fd917, %f1764;
	sub.f64 	%fd918, %fd917, %fd916;
	cvt.f64.f32 	%fd919, %f3239;
	add.f64 	%fd1179, %fd918, %fd919;

$L__BB6_620:
	cvt.rn.f32.f64 	%f3243, %fd1183;
	cvt.rn.f32.f64 	%f3242, %fd1182;
	cvt.rn.f32.f64 	%f3241, %fd1181;
	cvt.rn.f32.f64 	%f3240, %fd1180;
	cvt.rn.f32.f64 	%f3239, %fd1179;
	fma.rn.f32 	%f3237, %f287, %f189, %f3237;
	fma.rn.f32 	%f3236, %f287, %f281, %f3236;
	add.f32 	%f3235, %f3235, %f287;
	fma.rn.f32 	%f3234, %f287, %f252, %f3234;
	add.s32 	%r1375, %r1375, 1;
	setp.lt.s32 	%p947, %r1375, %r182;
	@%p947 bra 	$L__BB6_56;

	add.s32 	%r1374, %r1374, 1;
	setp.lt.s32 	%p948, %r1374, %r182;
	@%p948 bra 	$L__BB6_55;

$L__BB6_622:
	ld.param.u32 	%r1362, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_14];
	div.rn.f32 	%f1768, %f3238, %f3243;
	mov.f32 	%f1769, 0fBF800000;
	max.f32 	%f1770, %f1768, %f1769;
	mov.f32 	%f1771, 0f3F800000;
	min.f32 	%f1772, %f1770, %f1771;
	sub.f32 	%f3295, %f3295, %f1772;
	div.rn.f32 	%f1773, %f3237, %f3242;
	max.f32 	%f1774, %f1773, %f1769;
	min.f32 	%f1775, %f1774, %f1771;
	sub.f32 	%f3294, %f3294, %f1775;
	neg.f32 	%f1776, %f3293;
	div.rn.f32 	%f1777, %f3236, %f3241;
	max.f32 	%f1778, %f1777, %f1776;
	min.f32 	%f1779, %f1778, %f3293;
	sub.f32 	%f1780, %f3293, %f1779;
	neg.f32 	%f1781, %f3292;
	div.rn.f32 	%f1782, %f3235, %f3240;
	max.f32 	%f1783, %f1782, %f1781;
	min.f32 	%f1784, %f1783, %f3292;
	sub.f32 	%f1785, %f3292, %f1784;
	div.rn.f32 	%f1786, %f3234, %f3239;
	mov.f32 	%f1787, 0fBDCCCCCD;
	max.f32 	%f1788, %f1786, %f1787;
	mov.f32 	%f1789, 0f3DCCCCCD;
	min.f32 	%f1790, %f1788, %f1789;
	sub.f32 	%f3291, %f3291, %f1790;
	max.f32 	%f3293, %f1780, %f1771;
	mov.f32 	%f1791, 0f3C23D70A;
	max.f32 	%f3292, %f1785, %f1791;
	add.s32 	%r1373, %r1373, 1;
	setp.lt.s32 	%p949, %r1373, %r1362;
	@%p949 bra 	$L__BB6_53;

$L__BB6_623:
	mov.f32 	%f1807, 0f00000000;
	mov.f32 	%f3313, %f1807;
	mov.f32 	%f3314, %f1807;
	mov.f32 	%f3315, %f1807;
	mov.f32 	%f3318, %f1807;
	mov.f32 	%f3322, %f1807;
	mov.f32 	%f3316, %f1807;
	mov.f32 	%f3317, %f1807;
	mov.f32 	%f3319, %f1807;
	mov.f32 	%f3323, %f1807;
	mov.f32 	%f3320, %f1807;
	mov.f32 	%f3321, %f1807;
	mov.f32 	%f3324, %f1807;
	mov.f32 	%f3325, %f1807;
	mov.f32 	%f3326, %f1807;
	mov.f32 	%f3327, %f1807;
	mov.f32 	%f3359, %f1807;
	@%p80 bra 	$L__BB6_884;

	sub.f32 	%f320, %f3291, %f552;
	div.rn.f32 	%f321, %f320, %f553;
	cvt.f64.f32 	%fd416, %f321;
	add.f64 	%fd417, %fd416, 0d4000000000000000;
	mov.f64 	%fd960, 0d4000000000000000;
	cvt.f64.f32 	%fd418, %f548;
	setp.eq.f32 	%p951, %f321, 0fBF800000;
	add.f64 	%fd419, %fd416, 0d4008000000000000;
	mov.f64 	%fd961, 0d4008000000000000;
	cvt.f64.f32 	%fd420, %f550;
	add.f64 	%fd421, %fd416, 0d4010000000000000;
	mov.f64 	%fd962, 0d4010000000000000;
	add.f32 	%f322, %f3291, %f552;
	div.rn.f32 	%f323, %f322, %f553;
	cvt.f64.f32 	%fd422, %f323;
	add.f64 	%fd423, %fd422, 0d4000000000000000;
	cvt.f64.f32 	%fd424, %f549;
	setp.eq.f32 	%p952, %f323, 0fBF800000;
	add.f64 	%fd425, %fd422, 0d4008000000000000;
	cvt.f64.f32 	%fd426, %f551;
	add.f64 	%fd427, %fd422, 0d4010000000000000;
	div.rn.f32 	%f324, %f3293, 0fC0206C98;
	mul.f32 	%f325, %f547, 0f3F000000;
	mul.f32 	%f326, %f554, 0f3F000000;
	add.f32 	%f1824, %f320, %f320;
	mov.f32 	%f1825, 0f40000000;
	mul.f32 	%f1826, %f553, %f553;
	div.rn.f32 	%f1827, %f1824, %f1826;
	cvt.f64.f32 	%fd428, %f1827;
	mul.f32 	%f1828, %f548, 0f40400000;
	cvt.f64.f32 	%fd429, %f1828;
	cvt.f64.f32 	%fd430, %f320;
	add.f64 	%fd431, %fd430, 0d4000000000000000;
	mul.f32 	%f1829, %f1826, %f553;
	cvt.f64.f32 	%fd432, %f1829;
	mul.f32 	%f1830, %f550, 0f40800000;
	cvt.f64.f32 	%fd433, %f1830;
	setp.eq.f32 	%p953, %f320, 0fBF800000;
	add.f64 	%fd434, %fd430, 0d4008000000000000;
	cvt.f64.f32 	%fd435, %f553;
	add.f64 	%fd436, %fd435, 0d4010000000000000;
	add.f32 	%f1831, %f322, %f322;
	div.rn.f32 	%f1832, %f1831, %f1826;
	cvt.f64.f32 	%fd437, %f1832;
	mul.f32 	%f1833, %f549, 0f40400000;
	cvt.f64.f32 	%fd438, %f1833;
	cvt.f64.f32 	%fd439, %f322;
	add.f64 	%fd440, %fd439, 0d4000000000000000;
	mul.f32 	%f1834, %f551, 0f40800000;
	cvt.f64.f32 	%fd441, %f1834;
	setp.eq.f32 	%p954, %f322, 0fBF800000;
	add.f64 	%fd442, %fd439, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd416;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1027}, %fd960;
	}
	and.b32  	%r1028, %r1027, 2146435072;
	setp.eq.s32 	%p955, %r1028, 1062207488;
	abs.f64 	%fd963, %fd416;
	{ // callseq 143, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd963;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd960;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd443, [retval0+0];
	} // callseq 143
	mov.u32 	%r1026, 0;
	setp.lt.s32 	%p956, %r121, 0;
	and.pred  	%p49, %p956, %p955;
	selp.b32 	%r1029, %r121, 0, %p955;
	setp.lt.s32 	%p957, %r1027, 0;
	or.b32  	%r1030, %r1029, 2146435072;
	selp.b32 	%r122, %r1030, %r1029, %p957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1031}, %fd417;
	}
	and.b32  	%r123, %r1031, 2146435072;
	setp.ne.s32 	%p958, %r123, 2146435072;
	setp.gtu.f64 	%p959, %fd963, 0d7FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1032}, %fd961;
	}
	and.b32  	%r1033, %r1032, 2146435072;
	setp.eq.s32 	%p960, %r1033, 1073741824;
	{ // callseq 144, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd963;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd961;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd444, [retval0+0];
	} // callseq 144
	and.pred  	%p50, %p956, %p960;
	and.b32  	%r124, %r1027, 2147483647;
	setp.gt.f64 	%p961, %fd963, 0d3FF0000000000000;
	selp.b32 	%r1034, 2146435072, 0, %p961;
	xor.b32  	%r1035, %r1034, 2146435072;
	selp.b32 	%r1036, %r1035, %r1034, %p957;
	selp.b32 	%r125, 1072693248, %r1036, %p951;
	and.b32  	%r126, %r121, 2147483647;
	selp.b32 	%r1037, %r121, 0, %p960;
	setp.lt.s32 	%p962, %r1032, 0;
	or.b32  	%r1038, %r1037, 2146435072;
	selp.b32 	%r127, %r1038, %r1037, %p962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1039}, %fd419;
	}
	and.b32  	%r128, %r1039, 2146435072;
	setp.ne.s32 	%p963, %r128, 2146435072;
	setp.gt.s32 	%p964, %r1027, -1;
	selp.b32 	%r1040, 2146435072, 0, %p964;
	setp.ne.s32 	%p965, %r124, 1071644672;
	and.pred  	%p966, %p965, %p49;
	or.b32  	%r1041, %r1040, -2147483648;
	selp.b32 	%r129, %r1041, %r1040, %p966;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1042}, %fd962;
	}
	and.b32  	%r1043, %r1042, 2146435072;
	setp.eq.s32 	%p967, %r1043, 1072693248;
	{ // callseq 145, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd963;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd962;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd445, [retval0+0];
	} // callseq 145
	and.pred  	%p51, %p956, %p967;
	and.b32  	%r130, %r1032, 2147483647;
	selp.b32 	%r1044, %r1035, %r1034, %p962;
	selp.b32 	%r131, 1072693248, %r1044, %p951;
	selp.b32 	%r1045, %r121, 0, %p967;
	setp.lt.s32 	%p968, %r1042, 0;
	or.b32  	%r1046, %r1045, 2146435072;
	selp.b32 	%r132, %r1046, %r1045, %p968;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1047}, %fd421;
	}
	and.b32  	%r133, %r1047, 2146435072;
	setp.ne.s32 	%p969, %r133, 2146435072;
	setp.gt.s32 	%p970, %r1032, -1;
	selp.b32 	%r1048, 2146435072, 0, %p970;
	setp.ne.s32 	%p971, %r130, 1071644672;
	and.pred  	%p972, %p971, %p50;
	or.b32  	%r1049, %r1048, -2147483648;
	selp.b32 	%r134, %r1049, %r1048, %p972;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r135}, %fd422;
	}
	abs.f64 	%fd964, %fd422;
	{ // callseq 146, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd964;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd960;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd446, [retval0+0];
	} // callseq 146
	setp.lt.s32 	%p973, %r135, 0;
	and.pred  	%p52, %p973, %p955;
	and.b32  	%r136, %r1042, 2147483647;
	selp.b32 	%r1050, %r1035, %r1034, %p968;
	selp.b32 	%r137, 1072693248, %r1050, %p951;
	selp.b32 	%r1051, %r135, 0, %p955;
	or.b32  	%r1052, %r1051, 2146435072;
	selp.b32 	%r138, %r1052, %r1051, %p957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1053}, %fd423;
	}
	and.b32  	%r139, %r1053, 2146435072;
	setp.ne.s32 	%p974, %r139, 2146435072;
	setp.gt.s32 	%p975, %r1042, -1;
	selp.b32 	%r1054, 2146435072, 0, %p975;
	setp.ne.s32 	%p976, %r136, 1071644672;
	and.pred  	%p977, %p976, %p51;
	or.b32  	%r1055, %r1054, -2147483648;
	selp.b32 	%r140, %r1055, %r1054, %p977;
	setp.gtu.f64 	%p978, %fd964, 0d7FF0000000000000;
	{ // callseq 147, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd964;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd961;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd447, [retval0+0];
	} // callseq 147
	and.pred  	%p53, %p973, %p960;
	setp.gt.f64 	%p979, %fd964, 0d3FF0000000000000;
	selp.b32 	%r1056, 2146435072, 0, %p979;
	xor.b32  	%r1057, %r1056, 2146435072;
	selp.b32 	%r1058, %r1057, %r1056, %p957;
	selp.b32 	%r141, 1072693248, %r1058, %p952;
	and.b32  	%r142, %r135, 2147483647;
	selp.b32 	%r1059, %r135, 0, %p960;
	or.b32  	%r1060, %r1059, 2146435072;
	selp.b32 	%r143, %r1060, %r1059, %p962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1061}, %fd425;
	}
	and.b32  	%r144, %r1061, 2146435072;
	setp.ne.s32 	%p980, %r144, 2146435072;
	and.pred  	%p981, %p965, %p52;
	selp.b32 	%r145, %r1041, %r1040, %p981;
	{ // callseq 148, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd964;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd962;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd448, [retval0+0];
	} // callseq 148
	and.pred  	%p54, %p973, %p967;
	selp.b32 	%r1062, %r1057, %r1056, %p962;
	selp.b32 	%r146, 1072693248, %r1062, %p952;
	selp.b32 	%r1063, %r135, 0, %p967;
	or.b32  	%r1064, %r1063, 2146435072;
	selp.b32 	%r147, %r1064, %r1063, %p968;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1065}, %fd427;
	}
	and.b32  	%r148, %r1065, 2146435072;
	setp.ne.s32 	%p982, %r148, 2146435072;
	and.pred  	%p983, %p971, %p53;
	selp.b32 	%r149, %r1049, %r1048, %p983;
	selp.b32 	%r1066, %r1057, %r1056, %p968;
	selp.b32 	%r150, 1072693248, %r1066, %p952;
	and.pred  	%p984, %p976, %p54;
	selp.b32 	%r151, %r1055, %r1054, %p984;
	mov.f32 	%f1835, 0f3F800000;
	cvt.rzi.f32.f32 	%f1836, %f1835;
	add.f32 	%f1837, %f1836, %f1836;
	sub.f32 	%f1838, %f1825, %f1837;
	abs.f32 	%f327, %f1838;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r152}, %fd430;
	}
	abs.f64 	%fd965, %fd430;
	{ // callseq 149, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd965;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd960;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd449, [retval0+0];
	} // callseq 149
	setp.lt.s32 	%p985, %r152, 0;
	and.pred  	%p55, %p985, %p955;
	selp.b32 	%r1067, %r152, 0, %p955;
	or.b32  	%r1068, %r1067, 2146435072;
	selp.b32 	%r153, %r1068, %r1067, %p957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1069}, %fd431;
	}
	and.b32  	%r154, %r1069, 2146435072;
	setp.ne.s32 	%p986, %r154, 2146435072;
	setp.gtu.f64 	%p987, %fd965, 0d7FF0000000000000;
	{ // callseq 150, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd965;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd961;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd450, [retval0+0];
	} // callseq 150
	and.pred  	%p56, %p985, %p960;
	setp.gt.f64 	%p988, %fd965, 0d3FF0000000000000;
	selp.b32 	%r1070, 2146435072, 0, %p988;
	xor.b32  	%r1071, %r1070, 2146435072;
	selp.b32 	%r1072, %r1071, %r1070, %p957;
	selp.b32 	%r155, 1072693248, %r1072, %p953;
	and.b32  	%r156, %r152, 2147483647;
	selp.b32 	%r1073, %r152, 0, %p960;
	or.b32  	%r1074, %r1073, 2146435072;
	selp.b32 	%r157, %r1074, %r1073, %p962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1075}, %fd434;
	}
	and.b32  	%r158, %r1075, 2146435072;
	setp.ne.s32 	%p989, %r158, 2146435072;
	and.pred  	%p990, %p965, %p55;
	selp.b32 	%r159, %r1041, %r1040, %p990;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r160}, %fd435;
	}
	abs.f64 	%fd966, %fd435;
	{ // callseq 151, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd966;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd962;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd451, [retval0+0];
	} // callseq 151
	setp.lt.s32 	%p991, %r160, 0;
	and.pred  	%p57, %p991, %p967;
	selp.b32 	%r1076, %r1071, %r1070, %p962;
	selp.b32 	%r161, 1072693248, %r1076, %p953;
	selp.b32 	%r1077, %r160, 0, %p967;
	or.b32  	%r1078, %r1077, 2146435072;
	selp.b32 	%r162, %r1078, %r1077, %p968;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1079}, %fd436;
	}
	and.b32  	%r163, %r1079, 2146435072;
	setp.ne.s32 	%p992, %r163, 2146435072;
	and.pred  	%p993, %p971, %p56;
	selp.b32 	%r164, %r1049, %r1048, %p993;
	setp.gtu.f64 	%p994, %fd966, 0d7FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r165}, %fd439;
	}
	abs.f64 	%fd967, %fd439;
	{ // callseq 152, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd967;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd960;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd452, [retval0+0];
	} // callseq 152
	setp.lt.s32 	%p995, %r165, 0;
	and.pred  	%p58, %p995, %p955;
	setp.gt.f64 	%p996, %fd966, 0d3FF0000000000000;
	selp.b32 	%r1080, 2146435072, 0, %p996;
	xor.b32  	%r1081, %r1080, 2146435072;
	selp.b32 	%r1082, %r1081, %r1080, %p968;
	setp.eq.f32 	%p997, %f553, 0fBF800000;
	selp.b32 	%r166, 1072693248, %r1082, %p997;
	and.b32  	%r167, %r160, 2147483647;
	selp.b32 	%r1083, %r165, 0, %p955;
	or.b32  	%r1084, %r1083, 2146435072;
	selp.b32 	%r168, %r1084, %r1083, %p957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1085}, %fd440;
	}
	and.b32  	%r169, %r1085, 2146435072;
	setp.ne.s32 	%p998, %r169, 2146435072;
	and.pred  	%p999, %p976, %p57;
	selp.b32 	%r170, %r1055, %r1054, %p999;
	setp.gtu.f64 	%p1000, %fd967, 0d7FF0000000000000;
	{ // callseq 153, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd967;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd961;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd453, [retval0+0];
	} // callseq 153
	and.pred  	%p59, %p995, %p960;
	setp.gt.f64 	%p1001, %fd967, 0d3FF0000000000000;
	selp.b32 	%r1086, 2146435072, 0, %p1001;
	xor.b32  	%r1087, %r1086, 2146435072;
	selp.b32 	%r1088, %r1087, %r1086, %p957;
	selp.b32 	%r171, 1072693248, %r1088, %p954;
	and.b32  	%r172, %r165, 2147483647;
	selp.b32 	%r1089, %r165, 0, %p960;
	or.b32  	%r1090, %r1089, 2146435072;
	selp.b32 	%r173, %r1090, %r1089, %p962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1091}, %fd442;
	}
	and.b32  	%r174, %r1091, 2146435072;
	setp.ne.s32 	%p1002, %r174, 2146435072;
	and.pred  	%p1003, %p965, %p58;
	selp.b32 	%r175, %r1041, %r1040, %p1003;
	selp.b32 	%r1092, %r1087, %r1086, %p962;
	selp.b32 	%r176, 1072693248, %r1092, %p954;
	and.pred  	%p1004, %p971, %p59;
	selp.b32 	%r177, %r1049, %r1048, %p1004;
	or.pred  	%p60, %p958, %p959;
	or.pred  	%p61, %p963, %p959;
	or.pred  	%p62, %p969, %p959;
	or.pred  	%p63, %p974, %p978;
	or.pred  	%p64, %p980, %p978;
	or.pred  	%p65, %p982, %p978;
	or.pred  	%p66, %p986, %p987;
	or.pred  	%p67, %p989, %p987;
	or.pred  	%p68, %p992, %p994;
	or.pred  	%p69, %p998, %p1000;
	or.pred  	%p70, %p1002, %p1000;
	mov.u32 	%r1376, %r1026;

$L__BB6_625:
	cvt.rn.f32.s32 	%f1839, %r1376;
	sub.f32 	%f344, %f1839, %f3295;
	add.f32 	%f345, %f344, 0f3F000000;
	add.f32 	%f346, %f344, 0fBF000000;
	add.f32 	%f1840, %f1839, 0f3F000000;
	sub.f32 	%f347, %f1840, %f3295;
	add.f32 	%f1841, %f1839, 0f3F800000;
	sub.f32 	%f348, %f1841, %f3295;
	add.f32 	%f349, %f344, 0f3F800000;
	mov.u32 	%r1377, %r1026;

$L__BB6_626:
	not.pred 	%p1005, %p49;
	mov.f64 	%fd1185, %fd443;
	@%p1005 bra 	$L__BB6_628;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1094}, %fd443;
	}
	xor.b32  	%r1095, %r1094, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1096, %temp}, %fd443;
	}
	mov.b64 	%fd1185, {%r1096, %r1095};

$L__BB6_628:
	setp.eq.f32 	%p1006, %f321, 0f00000000;
	@%p1006 bra 	$L__BB6_632;
	bra.uni 	$L__BB6_629;

$L__BB6_632:
	mov.u32 	%r1097, 0;
	mov.b64 	%fd1185, {%r1097, %r122};
	bra.uni 	$L__BB6_633;

$L__BB6_629:
	setp.gt.s32 	%p1007, %r121, -1;
	@%p1007 bra 	$L__BB6_633;

	cvt.rzi.f64.f64 	%fd969, %fd960;
	setp.eq.f64 	%p1008, %fd969, 0d4000000000000000;
	@%p1008 bra 	$L__BB6_633;

	mov.f64 	%fd1185, 0dFFF8000000000000;

$L__BB6_633:
	selp.f64 	%fd1186, %fd1185, %fd417, %p958;
	@%p60 bra 	$L__BB6_638;

	setp.eq.s32 	%p1010, %r124, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1098, %temp}, %fd960;
	}
	setp.eq.s32 	%p1011, %r1098, 0;
	and.pred  	%p1012, %p1010, %p1011;
	@%p1012 bra 	$L__BB6_637;
	bra.uni 	$L__BB6_635;

$L__BB6_637:
	mov.u32 	%r1101, 0;
	mov.b64 	%fd1186, {%r1101, %r125};
	bra.uni 	$L__BB6_638;

$L__BB6_635:
	setp.ne.s32 	%p1013, %r126, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1099, %temp}, %fd416;
	}
	setp.ne.s32 	%p1014, %r1099, 0;
	or.pred  	%p1015, %p1013, %p1014;
	mov.f64 	%fd1186, %fd1185;
	@%p1015 bra 	$L__BB6_638;

	mov.u32 	%r1100, 0;
	mov.b64 	%fd1186, {%r1100, %r129};

$L__BB6_638:
	not.pred 	%p1016, %p50;
	mov.f64 	%fd1188, %fd444;
	@%p1016 bra 	$L__BB6_640;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1102}, %fd444;
	}
	xor.b32  	%r1103, %r1102, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1104, %temp}, %fd444;
	}
	mov.b64 	%fd1188, {%r1104, %r1103};

$L__BB6_640:
	@%p1006 bra 	$L__BB6_644;
	bra.uni 	$L__BB6_641;

$L__BB6_644:
	mov.u32 	%r1105, 0;
	mov.b64 	%fd1188, {%r1105, %r127};
	bra.uni 	$L__BB6_645;

$L__BB6_641:
	setp.gt.s32 	%p1018, %r121, -1;
	@%p1018 bra 	$L__BB6_645;

	cvt.rzi.f64.f64 	%fd973, %fd961;
	setp.eq.f64 	%p1019, %fd973, 0d4008000000000000;
	@%p1019 bra 	$L__BB6_645;

	mov.f64 	%fd1188, 0dFFF8000000000000;

$L__BB6_645:
	selp.f64 	%fd1189, %fd1188, %fd419, %p963;
	@%p61 bra 	$L__BB6_650;

	setp.eq.s32 	%p1021, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1106, %temp}, %fd961;
	}
	setp.eq.s32 	%p1022, %r1106, 0;
	and.pred  	%p1023, %p1021, %p1022;
	@%p1023 bra 	$L__BB6_649;
	bra.uni 	$L__BB6_647;

$L__BB6_649:
	mov.u32 	%r1109, 0;
	mov.b64 	%fd1189, {%r1109, %r131};
	bra.uni 	$L__BB6_650;

$L__BB6_647:
	setp.ne.s32 	%p1024, %r126, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1107, %temp}, %fd416;
	}
	setp.ne.s32 	%p1025, %r1107, 0;
	or.pred  	%p1026, %p1024, %p1025;
	mov.f64 	%fd1189, %fd1188;
	@%p1026 bra 	$L__BB6_650;

	mov.u32 	%r1108, 0;
	mov.b64 	%fd1189, {%r1108, %r134};

$L__BB6_650:
	setp.eq.f32 	%p1027, %f321, 0f3F800000;
	selp.f64 	%fd976, 0d3FF0000000000000, %fd1189, %p1027;
	add.f64 	%fd977, %fd1186, 0d3FF0000000000000;
	selp.f64 	%fd978, 0d4000000000000000, %fd977, %p1027;
	fma.rn.f64 	%fd470, %fd976, %fd418, %fd978;
	not.pred 	%p1028, %p51;
	mov.f64 	%fd1191, %fd445;
	@%p1028 bra 	$L__BB6_652;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1110}, %fd445;
	}
	xor.b32  	%r1111, %r1110, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1112, %temp}, %fd445;
	}
	mov.b64 	%fd1191, {%r1112, %r1111};

$L__BB6_652:
	@%p1006 bra 	$L__BB6_656;
	bra.uni 	$L__BB6_653;

$L__BB6_656:
	mov.u32 	%r1113, 0;
	mov.b64 	%fd1191, {%r1113, %r132};
	bra.uni 	$L__BB6_657;

$L__BB6_653:
	setp.gt.s32 	%p1030, %r121, -1;
	@%p1030 bra 	$L__BB6_657;

	cvt.rzi.f64.f64 	%fd980, %fd962;
	setp.eq.f64 	%p1031, %fd980, 0d4010000000000000;
	@%p1031 bra 	$L__BB6_657;

	mov.f64 	%fd1191, 0dFFF8000000000000;

$L__BB6_657:
	selp.f64 	%fd1192, %fd1191, %fd421, %p969;
	@%p62 bra 	$L__BB6_662;

	setp.eq.s32 	%p1033, %r136, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1114, %temp}, %fd962;
	}
	setp.eq.s32 	%p1034, %r1114, 0;
	and.pred  	%p1035, %p1033, %p1034;
	@%p1035 bra 	$L__BB6_661;
	bra.uni 	$L__BB6_659;

$L__BB6_661:
	mov.u32 	%r1117, 0;
	mov.b64 	%fd1192, {%r1117, %r137};
	bra.uni 	$L__BB6_662;

$L__BB6_659:
	setp.ne.s32 	%p1036, %r126, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1115, %temp}, %fd416;
	}
	setp.ne.s32 	%p1037, %r1115, 0;
	or.pred  	%p1038, %p1036, %p1037;
	mov.f64 	%fd1192, %fd1191;
	@%p1038 bra 	$L__BB6_662;

	mov.u32 	%r1116, 0;
	mov.b64 	%fd1192, {%r1116, %r140};

$L__BB6_662:
	selp.f64 	%fd983, 0d3FF0000000000000, %fd1192, %p1027;
	fma.rn.f64 	%fd479, %fd983, %fd420, %fd470;
	not.pred 	%p1040, %p52;
	mov.f64 	%fd1194, %fd446;
	@%p1040 bra 	$L__BB6_664;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1118}, %fd446;
	}
	xor.b32  	%r1119, %r1118, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1120, %temp}, %fd446;
	}
	mov.b64 	%fd1194, {%r1120, %r1119};

$L__BB6_664:
	setp.eq.f32 	%p1041, %f323, 0f00000000;
	@%p1041 bra 	$L__BB6_668;
	bra.uni 	$L__BB6_665;

$L__BB6_668:
	mov.u32 	%r1121, 0;
	mov.b64 	%fd1194, {%r1121, %r138};
	bra.uni 	$L__BB6_669;

$L__BB6_665:
	setp.gt.s32 	%p1042, %r135, -1;
	@%p1042 bra 	$L__BB6_669;

	cvt.rzi.f64.f64 	%fd985, %fd960;
	setp.eq.f64 	%p1043, %fd985, 0d4000000000000000;
	@%p1043 bra 	$L__BB6_669;

	mov.f64 	%fd1194, 0dFFF8000000000000;

$L__BB6_669:
	selp.f64 	%fd1195, %fd1194, %fd423, %p974;
	@%p63 bra 	$L__BB6_674;

	setp.eq.s32 	%p1045, %r124, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1122, %temp}, %fd960;
	}
	setp.eq.s32 	%p1046, %r1122, 0;
	and.pred  	%p1047, %p1045, %p1046;
	@%p1047 bra 	$L__BB6_673;
	bra.uni 	$L__BB6_671;

$L__BB6_673:
	mov.u32 	%r1125, 0;
	mov.b64 	%fd1195, {%r1125, %r141};
	bra.uni 	$L__BB6_674;

$L__BB6_671:
	setp.ne.s32 	%p1048, %r142, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1123, %temp}, %fd422;
	}
	setp.ne.s32 	%p1049, %r1123, 0;
	or.pred  	%p1050, %p1048, %p1049;
	mov.f64 	%fd1195, %fd1194;
	@%p1050 bra 	$L__BB6_674;

	mov.u32 	%r1124, 0;
	mov.b64 	%fd1195, {%r1124, %r145};

$L__BB6_674:
	not.pred 	%p1051, %p53;
	mov.f64 	%fd1197, %fd447;
	@%p1051 bra 	$L__BB6_676;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1126}, %fd447;
	}
	xor.b32  	%r1127, %r1126, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1128, %temp}, %fd447;
	}
	mov.b64 	%fd1197, {%r1128, %r1127};

$L__BB6_676:
	@%p1041 bra 	$L__BB6_680;
	bra.uni 	$L__BB6_677;

$L__BB6_680:
	mov.u32 	%r1129, 0;
	mov.b64 	%fd1197, {%r1129, %r143};
	bra.uni 	$L__BB6_681;

$L__BB6_677:
	setp.gt.s32 	%p1053, %r135, -1;
	@%p1053 bra 	$L__BB6_681;

	cvt.rzi.f64.f64 	%fd989, %fd961;
	setp.eq.f64 	%p1054, %fd989, 0d4008000000000000;
	@%p1054 bra 	$L__BB6_681;

	mov.f64 	%fd1197, 0dFFF8000000000000;

$L__BB6_681:
	selp.f64 	%fd1198, %fd1197, %fd425, %p980;
	@%p64 bra 	$L__BB6_686;

	setp.eq.s32 	%p1056, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1130, %temp}, %fd961;
	}
	setp.eq.s32 	%p1057, %r1130, 0;
	and.pred  	%p1058, %p1056, %p1057;
	@%p1058 bra 	$L__BB6_685;
	bra.uni 	$L__BB6_683;

$L__BB6_685:
	mov.u32 	%r1133, 0;
	mov.b64 	%fd1198, {%r1133, %r146};
	bra.uni 	$L__BB6_686;

$L__BB6_683:
	setp.ne.s32 	%p1059, %r142, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1131, %temp}, %fd422;
	}
	setp.ne.s32 	%p1060, %r1131, 0;
	or.pred  	%p1061, %p1059, %p1060;
	mov.f64 	%fd1198, %fd1197;
	@%p1061 bra 	$L__BB6_686;

	mov.u32 	%r1132, 0;
	mov.b64 	%fd1198, {%r1132, %r149};

$L__BB6_686:
	setp.eq.f32 	%p1062, %f323, 0f3F800000;
	selp.f64 	%fd992, 0d3FF0000000000000, %fd1198, %p1062;
	add.f64 	%fd993, %fd1195, 0d3FF0000000000000;
	selp.f64 	%fd994, 0d4000000000000000, %fd993, %p1062;
	fma.rn.f64 	%fd496, %fd992, %fd424, %fd994;
	not.pred 	%p1063, %p54;
	mov.f64 	%fd1200, %fd448;
	@%p1063 bra 	$L__BB6_688;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1134}, %fd448;
	}
	xor.b32  	%r1135, %r1134, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1136, %temp}, %fd448;
	}
	mov.b64 	%fd1200, {%r1136, %r1135};

$L__BB6_688:
	@%p1041 bra 	$L__BB6_692;
	bra.uni 	$L__BB6_689;

$L__BB6_692:
	mov.u32 	%r1137, 0;
	mov.b64 	%fd1200, {%r1137, %r147};
	bra.uni 	$L__BB6_693;

$L__BB6_689:
	setp.gt.s32 	%p1065, %r135, -1;
	@%p1065 bra 	$L__BB6_693;

	cvt.rzi.f64.f64 	%fd996, %fd962;
	setp.eq.f64 	%p1066, %fd996, 0d4010000000000000;
	@%p1066 bra 	$L__BB6_693;

	mov.f64 	%fd1200, 0dFFF8000000000000;

$L__BB6_693:
	selp.f64 	%fd1201, %fd1200, %fd427, %p982;
	@%p65 bra 	$L__BB6_698;

	setp.eq.s32 	%p1068, %r136, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1138, %temp}, %fd962;
	}
	setp.eq.s32 	%p1069, %r1138, 0;
	and.pred  	%p1070, %p1068, %p1069;
	@%p1070 bra 	$L__BB6_697;
	bra.uni 	$L__BB6_695;

$L__BB6_697:
	mov.u32 	%r1141, 0;
	mov.b64 	%fd1201, {%r1141, %r150};
	bra.uni 	$L__BB6_698;

$L__BB6_695:
	setp.ne.s32 	%p1071, %r142, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1139, %temp}, %fd422;
	}
	setp.ne.s32 	%p1072, %r1139, 0;
	or.pred  	%p1073, %p1071, %p1072;
	mov.f64 	%fd1201, %fd1200;
	@%p1073 bra 	$L__BB6_698;

	mov.u32 	%r1140, 0;
	mov.b64 	%fd1201, {%r1140, %r151};

$L__BB6_698:
	selp.f64 	%fd999, 0d3FF0000000000000, %fd1201, %p1062;
	fma.rn.f64 	%fd1000, %fd999, %fd426, %fd496;
	cvt.rn.f32.f64 	%f1842, %fd1000;
	cvt.rn.f32.f64 	%f1843, %fd479;
	sqrt.rn.f32 	%f366, %f1843;
	mul.f32 	%f367, %f366, %f547;
	sqrt.rn.f32 	%f368, %f1842;
	mul.f32 	%f369, %f368, %f554;
	mov.f32 	%f1844, 0f3F000000;
	div.rn.f32 	%f1845, %f1844, %f367;
	div.rn.f32 	%f1846, %f1845, %f367;
	sqrt.rn.f32 	%f370, %f1846;
	mul.f32 	%f371, %f370, %f345;
	abs.f32 	%f1847, %f371;
	setp.ltu.f32 	%p1075, %f1847, 0f3F8060FE;
	setp.ge.f32 	%p1076, %f1847, 0f3F8060FE;
	mul.f32 	%f1848, %f371, %f371;
	selp.f32 	%f1849, %f1847, %f1848, %p1076;
	selp.f32 	%f1850, 0f3789CA3C, 0f38B1E96A, %p1076;
	selp.f32 	%f1851, 0fB9F560B9, 0fBA574D20, %p1076;
	fma.rn.f32 	%f1852, %f1850, %f1849, %f1851;
	selp.f32 	%f1853, 0f3BAC840B, 0f3BAAD5EA, %p1076;
	fma.rn.f32 	%f1854, %f1852, %f1849, %f1853;
	selp.f32 	%f1855, 0fBD0C8162, 0fBCDC1BE7, %p1076;
	fma.rn.f32 	%f1856, %f1854, %f1849, %f1855;
	selp.f32 	%f1857, 0f3E1CF906, 0f3DE718AF, %p1076;
	fma.rn.f32 	%f1858, %f1856, %f1849, %f1857;
	selp.f32 	%f1859, 0f3F6A937E, 0fBEC093AC, %p1076;
	fma.rn.f32 	%f1860, %f1858, %f1849, %f1859;
	selp.f32 	%f1861, 0f3F20D842, 0f3E0375D3, %p1076;
	fma.rn.f32 	%f1862, %f1860, %f1849, %f1861;
	neg.f32 	%f1863, %f1847;
	selp.f32 	%f1864, %f1863, %f371, %p1076;
	fma.rn.f32 	%f3329, %f1862, %f1864, %f1864;
	@%p1075 bra 	$L__BB6_700;

	ex2.approx.ftz.f32 	%f1865, %f3329;
	sub.f32 	%f1867, %f1835, %f1865;
	mov.b32 	%r1142, %f1867;
	mov.b32 	%r1143, %f371;
	and.b32  	%r1144, %r1143, -2147483648;
	or.b32  	%r1145, %r1144, %r1142;
	mov.b32 	%f3329, %r1145;

$L__BB6_700:
	mul.f32 	%f375, %f370, %f346;
	abs.f32 	%f1868, %f375;
	setp.ltu.f32 	%p1077, %f1868, 0f3F8060FE;
	setp.ge.f32 	%p1078, %f1868, 0f3F8060FE;
	mul.f32 	%f1869, %f375, %f375;
	selp.f32 	%f1870, %f1868, %f1869, %p1078;
	selp.f32 	%f1871, 0f3789CA3C, 0f38B1E96A, %p1078;
	selp.f32 	%f1872, 0fB9F560B9, 0fBA574D20, %p1078;
	fma.rn.f32 	%f1873, %f1871, %f1870, %f1872;
	selp.f32 	%f1874, 0f3BAC840B, 0f3BAAD5EA, %p1078;
	fma.rn.f32 	%f1875, %f1873, %f1870, %f1874;
	selp.f32 	%f1876, 0fBD0C8162, 0fBCDC1BE7, %p1078;
	fma.rn.f32 	%f1877, %f1875, %f1870, %f1876;
	selp.f32 	%f1878, 0f3E1CF906, 0f3DE718AF, %p1078;
	fma.rn.f32 	%f1879, %f1877, %f1870, %f1878;
	selp.f32 	%f1880, 0f3F6A937E, 0fBEC093AC, %p1078;
	fma.rn.f32 	%f1881, %f1879, %f1870, %f1880;
	selp.f32 	%f1882, 0f3F20D842, 0f3E0375D3, %p1078;
	fma.rn.f32 	%f1883, %f1881, %f1870, %f1882;
	neg.f32 	%f1884, %f1868;
	selp.f32 	%f1885, %f1884, %f375, %p1078;
	fma.rn.f32 	%f3330, %f1883, %f1885, %f1885;
	@%p1077 bra 	$L__BB6_702;

	ex2.approx.ftz.f32 	%f1886, %f3330;
	sub.f32 	%f1888, %f1835, %f1886;
	mov.b32 	%r1146, %f1888;
	mov.b32 	%r1147, %f375;
	and.b32  	%r1148, %r1147, -2147483648;
	or.b32  	%r1149, %r1148, %r1146;
	mov.b32 	%f3330, %r1149;

$L__BB6_702:
	sub.f32 	%f1889, %f3329, %f3330;
	mul.f32 	%f379, %f1889, 0f3F000000;
	div.rn.f32 	%f1891, %f1844, %f369;
	div.rn.f32 	%f1892, %f1891, %f369;
	cvt.rn.f32.s32 	%f380, %r1377;
	sub.f32 	%f381, %f380, %f3294;
	add.f32 	%f1893, %f381, 0f3F000000;
	sqrt.rn.f32 	%f382, %f1892;
	mul.f32 	%f383, %f382, %f1893;
	abs.f32 	%f1894, %f383;
	setp.ltu.f32 	%p1079, %f1894, 0f3F8060FE;
	setp.ge.f32 	%p1080, %f1894, 0f3F8060FE;
	mul.f32 	%f1895, %f383, %f383;
	selp.f32 	%f1896, %f1894, %f1895, %p1080;
	selp.f32 	%f1897, 0f3789CA3C, 0f38B1E96A, %p1080;
	selp.f32 	%f1898, 0fB9F560B9, 0fBA574D20, %p1080;
	fma.rn.f32 	%f1899, %f1897, %f1896, %f1898;
	selp.f32 	%f1900, 0f3BAC840B, 0f3BAAD5EA, %p1080;
	fma.rn.f32 	%f1901, %f1899, %f1896, %f1900;
	selp.f32 	%f1902, 0fBD0C8162, 0fBCDC1BE7, %p1080;
	fma.rn.f32 	%f1903, %f1901, %f1896, %f1902;
	selp.f32 	%f1904, 0f3E1CF906, 0f3DE718AF, %p1080;
	fma.rn.f32 	%f1905, %f1903, %f1896, %f1904;
	selp.f32 	%f1906, 0f3F6A937E, 0fBEC093AC, %p1080;
	fma.rn.f32 	%f1907, %f1905, %f1896, %f1906;
	selp.f32 	%f1908, 0f3F20D842, 0f3E0375D3, %p1080;
	fma.rn.f32 	%f1909, %f1907, %f1896, %f1908;
	neg.f32 	%f1910, %f1894;
	selp.f32 	%f1911, %f1910, %f383, %p1080;
	fma.rn.f32 	%f3331, %f1909, %f1911, %f1911;
	@%p1079 bra 	$L__BB6_704;

	ex2.approx.ftz.f32 	%f1912, %f3331;
	sub.f32 	%f1914, %f1835, %f1912;
	mov.b32 	%r1150, %f1914;
	mov.b32 	%r1151, %f383;
	and.b32  	%r1152, %r1151, -2147483648;
	or.b32  	%r1153, %r1152, %r1150;
	mov.b32 	%f3331, %r1153;

$L__BB6_704:
	add.f32 	%f387, %f381, 0fBF000000;
	mul.f32 	%f388, %f382, %f387;
	abs.f32 	%f1915, %f388;
	setp.ltu.f32 	%p1081, %f1915, 0f3F8060FE;
	setp.ge.f32 	%p1082, %f1915, 0f3F8060FE;
	mul.f32 	%f1916, %f388, %f388;
	selp.f32 	%f1917, %f1915, %f1916, %p1082;
	selp.f32 	%f1918, 0f3789CA3C, 0f38B1E96A, %p1082;
	selp.f32 	%f1919, 0fB9F560B9, 0fBA574D20, %p1082;
	fma.rn.f32 	%f1920, %f1918, %f1917, %f1919;
	selp.f32 	%f1921, 0f3BAC840B, 0f3BAAD5EA, %p1082;
	fma.rn.f32 	%f1922, %f1920, %f1917, %f1921;
	selp.f32 	%f1923, 0fBD0C8162, 0fBCDC1BE7, %p1082;
	fma.rn.f32 	%f1924, %f1922, %f1917, %f1923;
	selp.f32 	%f1925, 0f3E1CF906, 0f3DE718AF, %p1082;
	fma.rn.f32 	%f1926, %f1924, %f1917, %f1925;
	selp.f32 	%f1927, 0f3F6A937E, 0fBEC093AC, %p1082;
	fma.rn.f32 	%f1928, %f1926, %f1917, %f1927;
	selp.f32 	%f1929, 0f3F20D842, 0f3E0375D3, %p1082;
	fma.rn.f32 	%f1930, %f1928, %f1917, %f1929;
	neg.f32 	%f1931, %f1915;
	selp.f32 	%f1932, %f1931, %f388, %p1082;
	fma.rn.f32 	%f3332, %f1930, %f1932, %f1932;
	@%p1081 bra 	$L__BB6_706;

	ex2.approx.ftz.f32 	%f1933, %f3332;
	sub.f32 	%f1935, %f1835, %f1933;
	mov.b32 	%r1154, %f1935;
	mov.b32 	%r1155, %f388;
	and.b32  	%r1156, %r1155, -2147483648;
	or.b32  	%r1157, %r1156, %r1154;
	mov.b32 	%f3332, %r1157;

$L__BB6_706:
	sub.f32 	%f1937, %f3331, %f3332;
	mul.f32 	%f392, %f1937, 0f3F000000;
	div.rn.f32 	%f393, %f347, %f367;
	abs.f32 	%f394, %f393;
	setp.lt.f32 	%p1083, %f394, 0f00800000;
	mul.f32 	%f1938, %f394, 0f4B800000;
	selp.f32 	%f1939, %f1938, %f394, %p1083;
	selp.f32 	%f1940, 0fC3170000, 0fC2FE0000, %p1083;
	mov.b32 	%r1158, %f1939;
	and.b32  	%r1159, %r1158, 8388607;
	or.b32  	%r1160, %r1159, 1065353216;
	mov.b32 	%f1941, %r1160;
	shr.u32 	%r1161, %r1158, 23;
	cvt.rn.f32.u32 	%f1942, %r1161;
	add.f32 	%f1943, %f1940, %f1942;
	setp.gt.f32 	%p1084, %f1941, 0f3FB504F3;
	mul.f32 	%f1944, %f1941, 0f3F000000;
	add.f32 	%f1945, %f1943, 0f3F800000;
	selp.f32 	%f1946, %f1945, %f1943, %p1084;
	selp.f32 	%f1947, %f1944, %f1941, %p1084;
	add.f32 	%f1948, %f1947, 0fBF800000;
	add.f32 	%f1949, %f1947, 0f3F800000;
	rcp.approx.ftz.f32 	%f1950, %f1949;
	add.f32 	%f1951, %f1948, %f1948;
	mul.f32 	%f1953, %f1951, %f1950;
	mul.f32 	%f1954, %f1953, %f1953;
	mov.f32 	%f1955, 0f3C4CAF63;
	mov.f32 	%f1956, 0f3B18F0FE;
	fma.rn.f32 	%f1957, %f1956, %f1954, %f1955;
	mov.f32 	%f1958, 0f3DAAAABD;
	fma.rn.f32 	%f1959, %f1957, %f1954, %f1958;
	mul.rn.f32 	%f1960, %f1959, %f1954;
	mul.rn.f32 	%f1961, %f1960, %f1953;
	sub.f32 	%f1962, %f1948, %f1953;
	add.f32 	%f1963, %f1962, %f1962;
	neg.f32 	%f1964, %f1953;
	fma.rn.f32 	%f1965, %f1964, %f1948, %f1963;
	mul.rn.f32 	%f1966, %f1950, %f1965;
	add.f32 	%f1967, %f1961, %f1953;
	sub.f32 	%f1968, %f1953, %f1967;
	add.f32 	%f1969, %f1961, %f1968;
	add.f32 	%f1970, %f1966, %f1969;
	add.f32 	%f1971, %f1967, %f1970;
	sub.f32 	%f1972, %f1967, %f1971;
	add.f32 	%f1973, %f1970, %f1972;
	mov.f32 	%f1974, 0f3F317200;
	mul.rn.f32 	%f1975, %f1946, %f1974;
	mov.f32 	%f1976, 0f35BFBE8E;
	mul.rn.f32 	%f1977, %f1946, %f1976;
	add.f32 	%f1978, %f1975, %f1971;
	sub.f32 	%f1979, %f1975, %f1978;
	add.f32 	%f1980, %f1971, %f1979;
	add.f32 	%f1981, %f1973, %f1980;
	add.f32 	%f1982, %f1977, %f1981;
	add.f32 	%f1983, %f1978, %f1982;
	sub.f32 	%f1984, %f1978, %f1983;
	add.f32 	%f1985, %f1982, %f1984;
	mul.rn.f32 	%f1986, %f1825, %f1983;
	neg.f32 	%f1987, %f1986;
	fma.rn.f32 	%f1988, %f1825, %f1983, %f1987;
	fma.rn.f32 	%f1989, %f1825, %f1985, %f1988;
	mov.f32 	%f1990, 0f00000000;
	fma.rn.f32 	%f1991, %f1990, %f1983, %f1989;
	add.rn.f32 	%f1992, %f1986, %f1991;
	neg.f32 	%f1993, %f1992;
	add.rn.f32 	%f1994, %f1986, %f1993;
	add.rn.f32 	%f1995, %f1994, %f1991;
	mov.b32 	%r1162, %f1992;
	setp.eq.s32 	%p1085, %r1162, 1118925336;
	add.s32 	%r1163, %r1162, -1;
	mov.b32 	%f1996, %r1163;
	add.f32 	%f1997, %f1995, 0f37000000;
	selp.f32 	%f395, %f1997, %f1995, %p1085;
	selp.f32 	%f1998, %f1996, %f1992, %p1085;
	mov.f32 	%f1999, 0f3FB8AA3B;
	mul.rn.f32 	%f2000, %f1998, %f1999;
	cvt.rzi.f32.f32 	%f2001, %f2000;
	abs.f32 	%f2002, %f2001;
	setp.gt.f32 	%p1086, %f2002, 0f42FC0000;
	mov.b32 	%r1164, %f2001;
	and.b32  	%r1165, %r1164, -2147483648;
	or.b32  	%r1166, %r1165, 1123811328;
	mov.b32 	%f2003, %r1166;
	selp.f32 	%f2004, %f2003, %f2001, %p1086;
	mov.f32 	%f2005, 0fBF317218;
	fma.rn.f32 	%f2006, %f2004, %f2005, %f1998;
	mov.f32 	%f2007, 0f3102E308;
	fma.rn.f32 	%f2008, %f2004, %f2007, %f2006;
	mul.f32 	%f2009, %f2008, 0f3FB8AA3B;
	add.f32 	%f2010, %f2004, 0f4B40007F;
	mov.b32 	%r1167, %f2010;
	shl.b32 	%r1168, %r1167, 23;
	mov.b32 	%f2011, %r1168;
	ex2.approx.ftz.f32 	%f2012, %f2009;
	mul.f32 	%f396, %f2012, %f2011;
	setp.eq.f32 	%p1087, %f396, 0f7F800000;
	mov.f32 	%f3333, 0f7F800000;
	@%p1087 bra 	$L__BB6_708;

	fma.rn.f32 	%f3333, %f396, %f395, %f396;

$L__BB6_708:
	setp.lt.f32 	%p1088, %f393, 0f00000000;
	setp.eq.f32 	%p1089, %f327, 0f3F800000;
	and.pred  	%p71, %p1088, %p1089;
	setp.eq.f32 	%p1090, %f393, 0f00000000;
	@%p1090 bra 	$L__BB6_712;
	bra.uni 	$L__BB6_709;

$L__BB6_712:
	add.f32 	%f2017, %f393, %f393;
	selp.f32 	%f3335, %f2017, 0f00000000, %p1089;
	bra.uni 	$L__BB6_713;

$L__BB6_709:
	mov.b32 	%r1169, %f3333;
	xor.b32  	%r1170, %r1169, -2147483648;
	mov.b32 	%f2013, %r1170;
	selp.f32 	%f3335, %f2013, %f3333, %p71;
	setp.geu.f32 	%p1091, %f393, 0f00000000;
	@%p1091 bra 	$L__BB6_713;

	cvt.rzi.f32.f32 	%f2015, %f1825;
	setp.eq.f32 	%p1092, %f2015, 0f40000000;
	@%p1092 bra 	$L__BB6_713;

	mov.f32 	%f3335, 0f7FFFFFFF;

$L__BB6_713:
	add.f32 	%f2018, %f394, 0f40000000;
	mov.b32 	%r1171, %f2018;
	setp.lt.s32 	%p1094, %r1171, 2139095040;
	@%p1094 bra 	$L__BB6_718;

	setp.gtu.f32 	%p1095, %f394, 0f7F800000;
	@%p1095 bra 	$L__BB6_717;
	bra.uni 	$L__BB6_715;

$L__BB6_717:
	add.f32 	%f3335, %f393, 0f40000000;
	bra.uni 	$L__BB6_718;

$L__BB6_715:
	setp.neu.f32 	%p1096, %f394, 0f7F800000;
	@%p1096 bra 	$L__BB6_718;

	selp.f32 	%f3335, 0fFF800000, 0f7F800000, %p71;

$L__BB6_718:
	mul.f32 	%f2020, %f3335, 0fBF000000;
	setp.eq.f32 	%p1097, %f393, 0f3F800000;
	selp.f32 	%f2021, 0fBF000000, %f2020, %p1097;
	mov.f32 	%f2023, 0f3BBB989D;
	fma.rn.f32 	%f2024, %f2021, %f2023, %f1844;
	mov.f32 	%f2026, 0f437C0000;
	cvt.sat.f32.f32 	%f2027, %f2024;
	mov.f32 	%f2028, 0f4B400001;
	fma.rm.f32 	%f2029, %f2027, %f2026, %f2028;
	add.f32 	%f2030, %f2029, 0fCB40007F;
	neg.f32 	%f2031, %f2030;
	fma.rn.f32 	%f2032, %f2021, %f1999, %f2031;
	mov.f32 	%f2033, 0f32A57060;
	fma.rn.f32 	%f2034, %f2021, %f2033, %f2032;
	mov.b32 	%r1172, %f2029;
	shl.b32 	%r1173, %r1172, 23;
	mov.b32 	%f2035, %r1173;
	ex2.approx.ftz.f32 	%f2036, %f2034;
	mul.f32 	%f405, %f2036, %f2035;
	div.rn.f32 	%f406, %f346, %f367;
	abs.f32 	%f407, %f406;
	setp.lt.f32 	%p1098, %f407, 0f00800000;
	mul.f32 	%f2037, %f407, 0f4B800000;
	selp.f32 	%f2038, %f2037, %f407, %p1098;
	selp.f32 	%f2039, 0fC3170000, 0fC2FE0000, %p1098;
	mov.b32 	%r1174, %f2038;
	and.b32  	%r1175, %r1174, 8388607;
	or.b32  	%r1176, %r1175, 1065353216;
	mov.b32 	%f2040, %r1176;
	shr.u32 	%r1177, %r1174, 23;
	cvt.rn.f32.u32 	%f2041, %r1177;
	add.f32 	%f2042, %f2039, %f2041;
	setp.gt.f32 	%p1099, %f2040, 0f3FB504F3;
	mul.f32 	%f2043, %f2040, 0f3F000000;
	add.f32 	%f2044, %f2042, 0f3F800000;
	selp.f32 	%f2045, %f2044, %f2042, %p1099;
	selp.f32 	%f2046, %f2043, %f2040, %p1099;
	add.f32 	%f2047, %f2046, 0fBF800000;
	add.f32 	%f2048, %f2046, 0f3F800000;
	rcp.approx.ftz.f32 	%f2049, %f2048;
	add.f32 	%f2050, %f2047, %f2047;
	mul.f32 	%f2052, %f2050, %f2049;
	mul.f32 	%f2053, %f2052, %f2052;
	fma.rn.f32 	%f2056, %f1956, %f2053, %f1955;
	fma.rn.f32 	%f2058, %f2056, %f2053, %f1958;
	mul.rn.f32 	%f2059, %f2058, %f2053;
	mul.rn.f32 	%f2060, %f2059, %f2052;
	sub.f32 	%f2061, %f2047, %f2052;
	add.f32 	%f2062, %f2061, %f2061;
	neg.f32 	%f2063, %f2052;
	fma.rn.f32 	%f2064, %f2063, %f2047, %f2062;
	mul.rn.f32 	%f2065, %f2049, %f2064;
	add.f32 	%f2066, %f2060, %f2052;
	sub.f32 	%f2067, %f2052, %f2066;
	add.f32 	%f2068, %f2060, %f2067;
	add.f32 	%f2069, %f2065, %f2068;
	add.f32 	%f2070, %f2066, %f2069;
	sub.f32 	%f2071, %f2066, %f2070;
	add.f32 	%f2072, %f2069, %f2071;
	mul.rn.f32 	%f2074, %f2045, %f1974;
	mul.rn.f32 	%f2076, %f2045, %f1976;
	add.f32 	%f2077, %f2074, %f2070;
	sub.f32 	%f2078, %f2074, %f2077;
	add.f32 	%f2079, %f2070, %f2078;
	add.f32 	%f2080, %f2072, %f2079;
	add.f32 	%f2081, %f2076, %f2080;
	add.f32 	%f2082, %f2077, %f2081;
	sub.f32 	%f2083, %f2077, %f2082;
	add.f32 	%f2084, %f2081, %f2083;
	mul.rn.f32 	%f2085, %f1825, %f2082;
	neg.f32 	%f2086, %f2085;
	fma.rn.f32 	%f2087, %f1825, %f2082, %f2086;
	fma.rn.f32 	%f2088, %f1825, %f2084, %f2087;
	fma.rn.f32 	%f2090, %f1990, %f2082, %f2088;
	add.rn.f32 	%f2091, %f2085, %f2090;
	neg.f32 	%f2092, %f2091;
	add.rn.f32 	%f2093, %f2085, %f2092;
	add.rn.f32 	%f2094, %f2093, %f2090;
	mov.b32 	%r1178, %f2091;
	setp.eq.s32 	%p1100, %r1178, 1118925336;
	add.s32 	%r1179, %r1178, -1;
	mov.b32 	%f2095, %r1179;
	add.f32 	%f2096, %f2094, 0f37000000;
	selp.f32 	%f408, %f2096, %f2094, %p1100;
	selp.f32 	%f2097, %f2095, %f2091, %p1100;
	mul.rn.f32 	%f2098, %f2097, %f1999;
	cvt.rzi.f32.f32 	%f2099, %f2098;
	abs.f32 	%f2100, %f2099;
	setp.gt.f32 	%p1101, %f2100, 0f42FC0000;
	mov.b32 	%r1180, %f2099;
	and.b32  	%r1181, %r1180, -2147483648;
	or.b32  	%r1182, %r1181, 1123811328;
	mov.b32 	%f2101, %r1182;
	selp.f32 	%f2102, %f2101, %f2099, %p1101;
	fma.rn.f32 	%f2104, %f2102, %f2005, %f2097;
	fma.rn.f32 	%f2106, %f2102, %f2007, %f2104;
	mul.f32 	%f2107, %f2106, 0f3FB8AA3B;
	add.f32 	%f2108, %f2102, 0f4B40007F;
	mov.b32 	%r1183, %f2108;
	shl.b32 	%r1184, %r1183, 23;
	mov.b32 	%f2109, %r1184;
	ex2.approx.ftz.f32 	%f2110, %f2107;
	mul.f32 	%f409, %f2110, %f2109;
	setp.eq.f32 	%p1102, %f409, 0f7F800000;
	mov.f32 	%f3336, 0f7F800000;
	@%p1102 bra 	$L__BB6_720;

	fma.rn.f32 	%f3336, %f409, %f408, %f409;

$L__BB6_720:
	setp.lt.f32 	%p1103, %f406, 0f00000000;
	and.pred  	%p72, %p1103, %p1089;
	setp.eq.f32 	%p1105, %f406, 0f00000000;
	@%p1105 bra 	$L__BB6_724;
	bra.uni 	$L__BB6_721;

$L__BB6_724:
	add.f32 	%f2115, %f406, %f406;
	selp.f32 	%f3338, %f2115, 0f00000000, %p1089;
	bra.uni 	$L__BB6_725;

$L__BB6_721:
	mov.b32 	%r1185, %f3336;
	xor.b32  	%r1186, %r1185, -2147483648;
	mov.b32 	%f2111, %r1186;
	selp.f32 	%f3338, %f2111, %f3336, %p72;
	setp.geu.f32 	%p1106, %f406, 0f00000000;
	@%p1106 bra 	$L__BB6_725;

	cvt.rzi.f32.f32 	%f2113, %f1825;
	setp.eq.f32 	%p1107, %f2113, 0f40000000;
	@%p1107 bra 	$L__BB6_725;

	mov.f32 	%f3338, 0f7FFFFFFF;

$L__BB6_725:
	add.f32 	%f2116, %f407, 0f40000000;
	mov.b32 	%r1187, %f2116;
	setp.lt.s32 	%p1109, %r1187, 2139095040;
	@%p1109 bra 	$L__BB6_730;

	setp.gtu.f32 	%p1110, %f407, 0f7F800000;
	@%p1110 bra 	$L__BB6_729;
	bra.uni 	$L__BB6_727;

$L__BB6_729:
	add.f32 	%f3338, %f406, 0f40000000;
	bra.uni 	$L__BB6_730;

$L__BB6_727:
	setp.neu.f32 	%p1111, %f407, 0f7F800000;
	@%p1111 bra 	$L__BB6_730;

	selp.f32 	%f3338, 0fFF800000, 0f7F800000, %p72;

$L__BB6_730:
	mul.f32 	%f2118, %f3338, 0fBF000000;
	setp.eq.f32 	%p1112, %f406, 0f3F800000;
	selp.f32 	%f2119, 0fBF000000, %f2118, %p1112;
	fma.rn.f32 	%f2122, %f2119, %f2023, %f1844;
	cvt.sat.f32.f32 	%f2125, %f2122;
	fma.rm.f32 	%f2127, %f2125, %f2026, %f2028;
	add.f32 	%f2128, %f2127, 0fCB40007F;
	neg.f32 	%f2129, %f2128;
	fma.rn.f32 	%f2130, %f2119, %f1999, %f2129;
	fma.rn.f32 	%f2132, %f2119, %f2033, %f2130;
	mov.b32 	%r1188, %f2127;
	shl.b32 	%r1189, %r1188, 23;
	mov.b32 	%f2133, %r1189;
	ex2.approx.ftz.f32 	%f2134, %f2132;
	mul.f32 	%f2135, %f2134, %f2133;
	sub.f32 	%f2136, %f405, %f2135;
	div.rn.f32 	%f418, %f324, %f367;
	mul.f32 	%f2137, %f418, %f2136;
	mul.f32 	%f419, %f392, %f2137;
	add.f32 	%f2138, %f380, 0f3F000000;
	sub.f32 	%f2139, %f2138, %f3294;
	div.rn.f32 	%f420, %f2139, %f369;
	abs.f32 	%f421, %f420;
	setp.lt.f32 	%p1113, %f421, 0f00800000;
	mul.f32 	%f2140, %f421, 0f4B800000;
	selp.f32 	%f2141, %f2140, %f421, %p1113;
	selp.f32 	%f2142, 0fC3170000, 0fC2FE0000, %p1113;
	mov.b32 	%r1190, %f2141;
	and.b32  	%r1191, %r1190, 8388607;
	or.b32  	%r1192, %r1191, 1065353216;
	mov.b32 	%f2143, %r1192;
	shr.u32 	%r1193, %r1190, 23;
	cvt.rn.f32.u32 	%f2144, %r1193;
	add.f32 	%f2145, %f2142, %f2144;
	setp.gt.f32 	%p1114, %f2143, 0f3FB504F3;
	mul.f32 	%f2146, %f2143, 0f3F000000;
	add.f32 	%f2147, %f2145, 0f3F800000;
	selp.f32 	%f2148, %f2147, %f2145, %p1114;
	selp.f32 	%f2149, %f2146, %f2143, %p1114;
	add.f32 	%f2150, %f2149, 0fBF800000;
	add.f32 	%f2151, %f2149, 0f3F800000;
	rcp.approx.ftz.f32 	%f2152, %f2151;
	add.f32 	%f2153, %f2150, %f2150;
	mul.f32 	%f2155, %f2153, %f2152;
	mul.f32 	%f2156, %f2155, %f2155;
	fma.rn.f32 	%f2159, %f1956, %f2156, %f1955;
	fma.rn.f32 	%f2161, %f2159, %f2156, %f1958;
	mul.rn.f32 	%f2162, %f2161, %f2156;
	mul.rn.f32 	%f2163, %f2162, %f2155;
	sub.f32 	%f2164, %f2150, %f2155;
	add.f32 	%f2165, %f2164, %f2164;
	neg.f32 	%f2166, %f2155;
	fma.rn.f32 	%f2167, %f2166, %f2150, %f2165;
	mul.rn.f32 	%f2168, %f2152, %f2167;
	add.f32 	%f2169, %f2163, %f2155;
	sub.f32 	%f2170, %f2155, %f2169;
	add.f32 	%f2171, %f2163, %f2170;
	add.f32 	%f2172, %f2168, %f2171;
	add.f32 	%f2173, %f2169, %f2172;
	sub.f32 	%f2174, %f2169, %f2173;
	add.f32 	%f2175, %f2172, %f2174;
	mul.rn.f32 	%f2177, %f2148, %f1974;
	mul.rn.f32 	%f2179, %f2148, %f1976;
	add.f32 	%f2180, %f2177, %f2173;
	sub.f32 	%f2181, %f2177, %f2180;
	add.f32 	%f2182, %f2173, %f2181;
	add.f32 	%f2183, %f2175, %f2182;
	add.f32 	%f2184, %f2179, %f2183;
	add.f32 	%f2185, %f2180, %f2184;
	sub.f32 	%f2186, %f2180, %f2185;
	add.f32 	%f2187, %f2184, %f2186;
	mul.rn.f32 	%f2188, %f1825, %f2185;
	neg.f32 	%f2189, %f2188;
	fma.rn.f32 	%f2190, %f1825, %f2185, %f2189;
	fma.rn.f32 	%f2191, %f1825, %f2187, %f2190;
	fma.rn.f32 	%f2193, %f1990, %f2185, %f2191;
	add.rn.f32 	%f2194, %f2188, %f2193;
	neg.f32 	%f2195, %f2194;
	add.rn.f32 	%f2196, %f2188, %f2195;
	add.rn.f32 	%f2197, %f2196, %f2193;
	mov.b32 	%r1194, %f2194;
	setp.eq.s32 	%p1115, %r1194, 1118925336;
	add.s32 	%r1195, %r1194, -1;
	mov.b32 	%f2198, %r1195;
	add.f32 	%f2199, %f2197, 0f37000000;
	selp.f32 	%f422, %f2199, %f2197, %p1115;
	selp.f32 	%f2200, %f2198, %f2194, %p1115;
	mul.rn.f32 	%f2201, %f2200, %f1999;
	cvt.rzi.f32.f32 	%f2202, %f2201;
	abs.f32 	%f2203, %f2202;
	setp.gt.f32 	%p1116, %f2203, 0f42FC0000;
	mov.b32 	%r1196, %f2202;
	and.b32  	%r1197, %r1196, -2147483648;
	or.b32  	%r1198, %r1197, 1123811328;
	mov.b32 	%f2204, %r1198;
	selp.f32 	%f2205, %f2204, %f2202, %p1116;
	fma.rn.f32 	%f2207, %f2205, %f2005, %f2200;
	fma.rn.f32 	%f2209, %f2205, %f2007, %f2207;
	mul.f32 	%f2210, %f2209, 0f3FB8AA3B;
	add.f32 	%f2211, %f2205, 0f4B40007F;
	mov.b32 	%r1199, %f2211;
	shl.b32 	%r1200, %r1199, 23;
	mov.b32 	%f2212, %r1200;
	ex2.approx.ftz.f32 	%f2213, %f2210;
	mul.f32 	%f423, %f2213, %f2212;
	setp.eq.f32 	%p1117, %f423, 0f7F800000;
	mov.f32 	%f3339, 0f7F800000;
	@%p1117 bra 	$L__BB6_732;

	fma.rn.f32 	%f3339, %f423, %f422, %f423;

$L__BB6_732:
	setp.lt.f32 	%p1118, %f420, 0f00000000;
	and.pred  	%p73, %p1118, %p1089;
	setp.eq.f32 	%p1120, %f420, 0f00000000;
	@%p1120 bra 	$L__BB6_736;
	bra.uni 	$L__BB6_733;

$L__BB6_736:
	add.f32 	%f2218, %f420, %f420;
	selp.f32 	%f3341, %f2218, 0f00000000, %p1089;
	bra.uni 	$L__BB6_737;

$L__BB6_733:
	mov.b32 	%r1201, %f3339;
	xor.b32  	%r1202, %r1201, -2147483648;
	mov.b32 	%f2214, %r1202;
	selp.f32 	%f3341, %f2214, %f3339, %p73;
	setp.geu.f32 	%p1121, %f420, 0f00000000;
	@%p1121 bra 	$L__BB6_737;

	cvt.rzi.f32.f32 	%f2216, %f1825;
	setp.eq.f32 	%p1122, %f2216, 0f40000000;
	@%p1122 bra 	$L__BB6_737;

	mov.f32 	%f3341, 0f7FFFFFFF;

$L__BB6_737:
	add.f32 	%f2219, %f421, 0f40000000;
	mov.b32 	%r1203, %f2219;
	setp.lt.s32 	%p1124, %r1203, 2139095040;
	@%p1124 bra 	$L__BB6_742;

	setp.gtu.f32 	%p1125, %f421, 0f7F800000;
	@%p1125 bra 	$L__BB6_741;
	bra.uni 	$L__BB6_739;

$L__BB6_741:
	add.f32 	%f3341, %f420, 0f40000000;
	bra.uni 	$L__BB6_742;

$L__BB6_739:
	setp.neu.f32 	%p1126, %f421, 0f7F800000;
	@%p1126 bra 	$L__BB6_742;

	selp.f32 	%f3341, 0fFF800000, 0f7F800000, %p73;

$L__BB6_742:
	mul.f32 	%f2221, %f3341, 0fBF000000;
	setp.eq.f32 	%p1127, %f420, 0f3F800000;
	selp.f32 	%f2222, 0fBF000000, %f2221, %p1127;
	fma.rn.f32 	%f2225, %f2222, %f2023, %f1844;
	cvt.sat.f32.f32 	%f2228, %f2225;
	fma.rm.f32 	%f2230, %f2228, %f2026, %f2028;
	add.f32 	%f2231, %f2230, 0fCB40007F;
	neg.f32 	%f2232, %f2231;
	fma.rn.f32 	%f2233, %f2222, %f1999, %f2232;
	fma.rn.f32 	%f2235, %f2222, %f2033, %f2233;
	mov.b32 	%r1204, %f2230;
	shl.b32 	%r1205, %r1204, 23;
	mov.b32 	%f2236, %r1205;
	ex2.approx.ftz.f32 	%f2237, %f2235;
	mul.f32 	%f432, %f2237, %f2236;
	div.rn.f32 	%f433, %f387, %f369;
	abs.f32 	%f434, %f433;
	setp.lt.f32 	%p1128, %f434, 0f00800000;
	mul.f32 	%f2238, %f434, 0f4B800000;
	selp.f32 	%f2239, %f2238, %f434, %p1128;
	selp.f32 	%f2240, 0fC3170000, 0fC2FE0000, %p1128;
	mov.b32 	%r1206, %f2239;
	and.b32  	%r1207, %r1206, 8388607;
	or.b32  	%r1208, %r1207, 1065353216;
	mov.b32 	%f2241, %r1208;
	shr.u32 	%r1209, %r1206, 23;
	cvt.rn.f32.u32 	%f2242, %r1209;
	add.f32 	%f2243, %f2240, %f2242;
	setp.gt.f32 	%p1129, %f2241, 0f3FB504F3;
	mul.f32 	%f2244, %f2241, 0f3F000000;
	add.f32 	%f2245, %f2243, 0f3F800000;
	selp.f32 	%f2246, %f2245, %f2243, %p1129;
	selp.f32 	%f2247, %f2244, %f2241, %p1129;
	add.f32 	%f2248, %f2247, 0fBF800000;
	add.f32 	%f2249, %f2247, 0f3F800000;
	rcp.approx.ftz.f32 	%f2250, %f2249;
	add.f32 	%f2251, %f2248, %f2248;
	mul.f32 	%f2253, %f2251, %f2250;
	mul.f32 	%f2254, %f2253, %f2253;
	fma.rn.f32 	%f2257, %f1956, %f2254, %f1955;
	fma.rn.f32 	%f2259, %f2257, %f2254, %f1958;
	mul.rn.f32 	%f2260, %f2259, %f2254;
	mul.rn.f32 	%f2261, %f2260, %f2253;
	sub.f32 	%f2262, %f2248, %f2253;
	add.f32 	%f2263, %f2262, %f2262;
	neg.f32 	%f2264, %f2253;
	fma.rn.f32 	%f2265, %f2264, %f2248, %f2263;
	mul.rn.f32 	%f2266, %f2250, %f2265;
	add.f32 	%f2267, %f2261, %f2253;
	sub.f32 	%f2268, %f2253, %f2267;
	add.f32 	%f2269, %f2261, %f2268;
	add.f32 	%f2270, %f2266, %f2269;
	add.f32 	%f2271, %f2267, %f2270;
	sub.f32 	%f2272, %f2267, %f2271;
	add.f32 	%f2273, %f2270, %f2272;
	mul.rn.f32 	%f2275, %f2246, %f1974;
	mul.rn.f32 	%f2277, %f2246, %f1976;
	add.f32 	%f2278, %f2275, %f2271;
	sub.f32 	%f2279, %f2275, %f2278;
	add.f32 	%f2280, %f2271, %f2279;
	add.f32 	%f2281, %f2273, %f2280;
	add.f32 	%f2282, %f2277, %f2281;
	add.f32 	%f2283, %f2278, %f2282;
	sub.f32 	%f2284, %f2278, %f2283;
	add.f32 	%f2285, %f2282, %f2284;
	mul.rn.f32 	%f2286, %f1825, %f2283;
	neg.f32 	%f2287, %f2286;
	fma.rn.f32 	%f2288, %f1825, %f2283, %f2287;
	fma.rn.f32 	%f2289, %f1825, %f2285, %f2288;
	fma.rn.f32 	%f2291, %f1990, %f2283, %f2289;
	add.rn.f32 	%f2292, %f2286, %f2291;
	neg.f32 	%f2293, %f2292;
	add.rn.f32 	%f2294, %f2286, %f2293;
	add.rn.f32 	%f2295, %f2294, %f2291;
	mov.b32 	%r1210, %f2292;
	setp.eq.s32 	%p1130, %r1210, 1118925336;
	add.s32 	%r1211, %r1210, -1;
	mov.b32 	%f2296, %r1211;
	add.f32 	%f2297, %f2295, 0f37000000;
	selp.f32 	%f435, %f2297, %f2295, %p1130;
	selp.f32 	%f2298, %f2296, %f2292, %p1130;
	mul.rn.f32 	%f2299, %f2298, %f1999;
	cvt.rzi.f32.f32 	%f2300, %f2299;
	abs.f32 	%f2301, %f2300;
	setp.gt.f32 	%p1131, %f2301, 0f42FC0000;
	mov.b32 	%r1212, %f2300;
	and.b32  	%r1213, %r1212, -2147483648;
	or.b32  	%r1214, %r1213, 1123811328;
	mov.b32 	%f2302, %r1214;
	selp.f32 	%f2303, %f2302, %f2300, %p1131;
	fma.rn.f32 	%f2305, %f2303, %f2005, %f2298;
	fma.rn.f32 	%f2307, %f2303, %f2007, %f2305;
	mul.f32 	%f2308, %f2307, 0f3FB8AA3B;
	add.f32 	%f2309, %f2303, 0f4B40007F;
	mov.b32 	%r1215, %f2309;
	shl.b32 	%r1216, %r1215, 23;
	mov.b32 	%f2310, %r1216;
	ex2.approx.ftz.f32 	%f2311, %f2308;
	mul.f32 	%f436, %f2311, %f2310;
	setp.eq.f32 	%p1132, %f436, 0f7F800000;
	mov.f32 	%f3342, 0f7F800000;
	@%p1132 bra 	$L__BB6_744;

	fma.rn.f32 	%f3342, %f436, %f435, %f436;

$L__BB6_744:
	setp.lt.f32 	%p1133, %f433, 0f00000000;
	and.pred  	%p74, %p1133, %p1089;
	setp.eq.f32 	%p1135, %f433, 0f00000000;
	@%p1135 bra 	$L__BB6_748;
	bra.uni 	$L__BB6_745;

$L__BB6_748:
	add.f32 	%f2316, %f433, %f433;
	selp.f32 	%f3344, %f2316, 0f00000000, %p1089;
	bra.uni 	$L__BB6_749;

$L__BB6_745:
	mov.b32 	%r1217, %f3342;
	xor.b32  	%r1218, %r1217, -2147483648;
	mov.b32 	%f2312, %r1218;
	selp.f32 	%f3344, %f2312, %f3342, %p74;
	setp.geu.f32 	%p1136, %f433, 0f00000000;
	@%p1136 bra 	$L__BB6_749;

	cvt.rzi.f32.f32 	%f2314, %f1825;
	setp.eq.f32 	%p1137, %f2314, 0f40000000;
	@%p1137 bra 	$L__BB6_749;

	mov.f32 	%f3344, 0f7FFFFFFF;

$L__BB6_749:
	add.f32 	%f2317, %f434, 0f40000000;
	mov.b32 	%r1219, %f2317;
	setp.lt.s32 	%p1139, %r1219, 2139095040;
	@%p1139 bra 	$L__BB6_754;

	setp.gtu.f32 	%p1140, %f434, 0f7F800000;
	@%p1140 bra 	$L__BB6_753;
	bra.uni 	$L__BB6_751;

$L__BB6_753:
	add.f32 	%f3344, %f433, 0f40000000;
	bra.uni 	$L__BB6_754;

$L__BB6_751:
	setp.neu.f32 	%p1141, %f434, 0f7F800000;
	@%p1141 bra 	$L__BB6_754;

	selp.f32 	%f3344, 0fFF800000, 0f7F800000, %p74;

$L__BB6_754:
	mul.f32 	%f2319, %f3344, 0fBF000000;
	setp.eq.f32 	%p1142, %f433, 0f3F800000;
	selp.f32 	%f2320, 0fBF000000, %f2319, %p1142;
	fma.rn.f32 	%f2323, %f2320, %f2023, %f1844;
	cvt.sat.f32.f32 	%f2326, %f2323;
	fma.rm.f32 	%f2328, %f2326, %f2026, %f2028;
	add.f32 	%f2329, %f2328, 0fCB40007F;
	neg.f32 	%f2330, %f2329;
	fma.rn.f32 	%f2331, %f2320, %f1999, %f2330;
	fma.rn.f32 	%f2333, %f2320, %f2033, %f2331;
	mov.b32 	%r1220, %f2328;
	shl.b32 	%r1221, %r1220, 23;
	mov.b32 	%f2334, %r1221;
	ex2.approx.ftz.f32 	%f2335, %f2333;
	mul.f32 	%f2336, %f2335, %f2334;
	sub.f32 	%f2337, %f432, %f2336;
	div.rn.f32 	%f445, %f324, %f369;
	mul.f32 	%f2338, %f445, %f2337;
	mul.f32 	%f446, %f379, %f2338;
	div.rn.f32 	%f447, %f348, %f367;
	abs.f32 	%f448, %f447;
	setp.lt.f32 	%p1143, %f448, 0f00800000;
	mul.f32 	%f2339, %f448, 0f4B800000;
	selp.f32 	%f2340, %f2339, %f448, %p1143;
	selp.f32 	%f2341, 0fC3170000, 0fC2FE0000, %p1143;
	mov.b32 	%r1222, %f2340;
	and.b32  	%r1223, %r1222, 8388607;
	or.b32  	%r1224, %r1223, 1065353216;
	mov.b32 	%f2342, %r1224;
	shr.u32 	%r1225, %r1222, 23;
	cvt.rn.f32.u32 	%f2343, %r1225;
	add.f32 	%f2344, %f2341, %f2343;
	setp.gt.f32 	%p1144, %f2342, 0f3FB504F3;
	mul.f32 	%f2345, %f2342, 0f3F000000;
	add.f32 	%f2346, %f2344, 0f3F800000;
	selp.f32 	%f2347, %f2346, %f2344, %p1144;
	selp.f32 	%f2348, %f2345, %f2342, %p1144;
	add.f32 	%f2349, %f2348, 0fBF800000;
	add.f32 	%f2350, %f2348, 0f3F800000;
	rcp.approx.ftz.f32 	%f2351, %f2350;
	add.f32 	%f2352, %f2349, %f2349;
	mul.f32 	%f2354, %f2352, %f2351;
	mul.f32 	%f2355, %f2354, %f2354;
	fma.rn.f32 	%f2358, %f1956, %f2355, %f1955;
	fma.rn.f32 	%f2360, %f2358, %f2355, %f1958;
	mul.rn.f32 	%f2361, %f2360, %f2355;
	mul.rn.f32 	%f2362, %f2361, %f2354;
	sub.f32 	%f2363, %f2349, %f2354;
	add.f32 	%f2364, %f2363, %f2363;
	neg.f32 	%f2365, %f2354;
	fma.rn.f32 	%f2366, %f2365, %f2349, %f2364;
	mul.rn.f32 	%f2367, %f2351, %f2366;
	add.f32 	%f2368, %f2362, %f2354;
	sub.f32 	%f2369, %f2354, %f2368;
	add.f32 	%f2370, %f2362, %f2369;
	add.f32 	%f2371, %f2367, %f2370;
	add.f32 	%f2372, %f2368, %f2371;
	sub.f32 	%f2373, %f2368, %f2372;
	add.f32 	%f2374, %f2371, %f2373;
	mul.rn.f32 	%f2376, %f2347, %f1974;
	mul.rn.f32 	%f2378, %f2347, %f1976;
	add.f32 	%f2379, %f2376, %f2372;
	sub.f32 	%f2380, %f2376, %f2379;
	add.f32 	%f2381, %f2372, %f2380;
	add.f32 	%f2382, %f2374, %f2381;
	add.f32 	%f2383, %f2378, %f2382;
	add.f32 	%f2384, %f2379, %f2383;
	sub.f32 	%f2385, %f2379, %f2384;
	add.f32 	%f2386, %f2383, %f2385;
	mul.rn.f32 	%f2387, %f1825, %f2384;
	neg.f32 	%f2388, %f2387;
	fma.rn.f32 	%f2389, %f1825, %f2384, %f2388;
	fma.rn.f32 	%f2390, %f1825, %f2386, %f2389;
	fma.rn.f32 	%f2392, %f1990, %f2384, %f2390;
	add.rn.f32 	%f2393, %f2387, %f2392;
	neg.f32 	%f2394, %f2393;
	add.rn.f32 	%f2395, %f2387, %f2394;
	add.rn.f32 	%f2396, %f2395, %f2392;
	mov.b32 	%r1226, %f2393;
	setp.eq.s32 	%p1145, %r1226, 1118925336;
	add.s32 	%r1227, %r1226, -1;
	mov.b32 	%f2397, %r1227;
	add.f32 	%f2398, %f2396, 0f37000000;
	selp.f32 	%f449, %f2398, %f2396, %p1145;
	selp.f32 	%f2399, %f2397, %f2393, %p1145;
	mul.rn.f32 	%f2400, %f2399, %f1999;
	cvt.rzi.f32.f32 	%f2401, %f2400;
	abs.f32 	%f2402, %f2401;
	setp.gt.f32 	%p1146, %f2402, 0f42FC0000;
	mov.b32 	%r1228, %f2401;
	and.b32  	%r1229, %r1228, -2147483648;
	or.b32  	%r1230, %r1229, 1123811328;
	mov.b32 	%f2403, %r1230;
	selp.f32 	%f2404, %f2403, %f2401, %p1146;
	fma.rn.f32 	%f2406, %f2404, %f2005, %f2399;
	fma.rn.f32 	%f2408, %f2404, %f2007, %f2406;
	mul.f32 	%f2409, %f2408, 0f3FB8AA3B;
	add.f32 	%f2410, %f2404, 0f4B40007F;
	mov.b32 	%r1231, %f2410;
	shl.b32 	%r1232, %r1231, 23;
	mov.b32 	%f2411, %r1232;
	ex2.approx.ftz.f32 	%f2412, %f2409;
	mul.f32 	%f450, %f2412, %f2411;
	setp.eq.f32 	%p1147, %f450, 0f7F800000;
	mov.f32 	%f3345, 0f7F800000;
	@%p1147 bra 	$L__BB6_756;

	fma.rn.f32 	%f3345, %f450, %f449, %f450;

$L__BB6_756:
	setp.lt.f32 	%p1148, %f447, 0f00000000;
	and.pred  	%p75, %p1148, %p1089;
	setp.eq.f32 	%p1150, %f447, 0f00000000;
	@%p1150 bra 	$L__BB6_760;
	bra.uni 	$L__BB6_757;

$L__BB6_760:
	add.f32 	%f2417, %f447, %f447;
	selp.f32 	%f3347, %f2417, 0f00000000, %p1089;
	bra.uni 	$L__BB6_761;

$L__BB6_757:
	mov.b32 	%r1233, %f3345;
	xor.b32  	%r1234, %r1233, -2147483648;
	mov.b32 	%f2413, %r1234;
	selp.f32 	%f3347, %f2413, %f3345, %p75;
	setp.geu.f32 	%p1151, %f447, 0f00000000;
	@%p1151 bra 	$L__BB6_761;

	cvt.rzi.f32.f32 	%f2415, %f1825;
	setp.eq.f32 	%p1152, %f2415, 0f40000000;
	@%p1152 bra 	$L__BB6_761;

	mov.f32 	%f3347, 0f7FFFFFFF;

$L__BB6_761:
	add.f32 	%f2418, %f448, 0f40000000;
	mov.b32 	%r1235, %f2418;
	setp.lt.s32 	%p1154, %r1235, 2139095040;
	@%p1154 bra 	$L__BB6_766;

	setp.gtu.f32 	%p1155, %f448, 0f7F800000;
	@%p1155 bra 	$L__BB6_765;
	bra.uni 	$L__BB6_763;

$L__BB6_765:
	add.f32 	%f3347, %f447, 0f40000000;
	bra.uni 	$L__BB6_766;

$L__BB6_763:
	setp.neu.f32 	%p1156, %f448, 0f7F800000;
	@%p1156 bra 	$L__BB6_766;

	selp.f32 	%f3347, 0fFF800000, 0f7F800000, %p75;

$L__BB6_766:
	mul.f32 	%f2420, %f3347, 0fBF000000;
	setp.eq.f32 	%p1157, %f447, 0f3F800000;
	selp.f32 	%f2421, 0fBF000000, %f2420, %p1157;
	fma.rn.f32 	%f2424, %f2421, %f2023, %f1844;
	cvt.sat.f32.f32 	%f2427, %f2424;
	fma.rm.f32 	%f2429, %f2427, %f2026, %f2028;
	add.f32 	%f2430, %f2429, 0fCB40007F;
	neg.f32 	%f2431, %f2430;
	fma.rn.f32 	%f2432, %f2421, %f1999, %f2431;
	fma.rn.f32 	%f2434, %f2421, %f2033, %f2432;
	mov.b32 	%r1236, %f2429;
	shl.b32 	%r1237, %r1236, 23;
	mov.b32 	%f2435, %r1237;
	ex2.approx.ftz.f32 	%f2436, %f2434;
	mul.f32 	%f459, %f2436, %f2435;
	div.rn.f32 	%f460, %f344, %f367;
	abs.f32 	%f461, %f460;
	setp.lt.f32 	%p1158, %f461, 0f00800000;
	mul.f32 	%f2437, %f461, 0f4B800000;
	selp.f32 	%f2438, %f2437, %f461, %p1158;
	selp.f32 	%f2439, 0fC3170000, 0fC2FE0000, %p1158;
	mov.b32 	%r1238, %f2438;
	and.b32  	%r1239, %r1238, 8388607;
	or.b32  	%r1240, %r1239, 1065353216;
	mov.b32 	%f2440, %r1240;
	shr.u32 	%r1241, %r1238, 23;
	cvt.rn.f32.u32 	%f2441, %r1241;
	add.f32 	%f2442, %f2439, %f2441;
	setp.gt.f32 	%p1159, %f2440, 0f3FB504F3;
	mul.f32 	%f2443, %f2440, 0f3F000000;
	add.f32 	%f2444, %f2442, 0f3F800000;
	selp.f32 	%f2445, %f2444, %f2442, %p1159;
	selp.f32 	%f2446, %f2443, %f2440, %p1159;
	add.f32 	%f2447, %f2446, 0fBF800000;
	add.f32 	%f2448, %f2446, 0f3F800000;
	rcp.approx.ftz.f32 	%f2449, %f2448;
	add.f32 	%f2450, %f2447, %f2447;
	mul.f32 	%f2452, %f2450, %f2449;
	mul.f32 	%f2453, %f2452, %f2452;
	fma.rn.f32 	%f2456, %f1956, %f2453, %f1955;
	fma.rn.f32 	%f2458, %f2456, %f2453, %f1958;
	mul.rn.f32 	%f2459, %f2458, %f2453;
	mul.rn.f32 	%f2460, %f2459, %f2452;
	sub.f32 	%f2461, %f2447, %f2452;
	add.f32 	%f2462, %f2461, %f2461;
	neg.f32 	%f2463, %f2452;
	fma.rn.f32 	%f2464, %f2463, %f2447, %f2462;
	mul.rn.f32 	%f2465, %f2449, %f2464;
	add.f32 	%f2466, %f2460, %f2452;
	sub.f32 	%f2467, %f2452, %f2466;
	add.f32 	%f2468, %f2460, %f2467;
	add.f32 	%f2469, %f2465, %f2468;
	add.f32 	%f2470, %f2466, %f2469;
	sub.f32 	%f2471, %f2466, %f2470;
	add.f32 	%f2472, %f2469, %f2471;
	mul.rn.f32 	%f2474, %f2445, %f1974;
	mul.rn.f32 	%f2476, %f2445, %f1976;
	add.f32 	%f2477, %f2474, %f2470;
	sub.f32 	%f2478, %f2474, %f2477;
	add.f32 	%f2479, %f2470, %f2478;
	add.f32 	%f2480, %f2472, %f2479;
	add.f32 	%f2481, %f2476, %f2480;
	add.f32 	%f2482, %f2477, %f2481;
	sub.f32 	%f2483, %f2477, %f2482;
	add.f32 	%f2484, %f2481, %f2483;
	mul.rn.f32 	%f2485, %f1825, %f2482;
	neg.f32 	%f2486, %f2485;
	fma.rn.f32 	%f2487, %f1825, %f2482, %f2486;
	fma.rn.f32 	%f2488, %f1825, %f2484, %f2487;
	fma.rn.f32 	%f2490, %f1990, %f2482, %f2488;
	add.rn.f32 	%f2491, %f2485, %f2490;
	neg.f32 	%f2492, %f2491;
	add.rn.f32 	%f2493, %f2485, %f2492;
	add.rn.f32 	%f2494, %f2493, %f2490;
	mov.b32 	%r1242, %f2491;
	setp.eq.s32 	%p1160, %r1242, 1118925336;
	add.s32 	%r1243, %r1242, -1;
	mov.b32 	%f2495, %r1243;
	add.f32 	%f2496, %f2494, 0f37000000;
	selp.f32 	%f462, %f2496, %f2494, %p1160;
	selp.f32 	%f2497, %f2495, %f2491, %p1160;
	mul.rn.f32 	%f2498, %f2497, %f1999;
	cvt.rzi.f32.f32 	%f2499, %f2498;
	abs.f32 	%f2500, %f2499;
	setp.gt.f32 	%p1161, %f2500, 0f42FC0000;
	mov.b32 	%r1244, %f2499;
	and.b32  	%r1245, %r1244, -2147483648;
	or.b32  	%r1246, %r1245, 1123811328;
	mov.b32 	%f2501, %r1246;
	selp.f32 	%f2502, %f2501, %f2499, %p1161;
	fma.rn.f32 	%f2504, %f2502, %f2005, %f2497;
	fma.rn.f32 	%f2506, %f2502, %f2007, %f2504;
	mul.f32 	%f2507, %f2506, 0f3FB8AA3B;
	add.f32 	%f2508, %f2502, 0f4B40007F;
	mov.b32 	%r1247, %f2508;
	shl.b32 	%r1248, %r1247, 23;
	mov.b32 	%f2509, %r1248;
	ex2.approx.ftz.f32 	%f2510, %f2507;
	mul.f32 	%f463, %f2510, %f2509;
	setp.eq.f32 	%p1162, %f463, 0f7F800000;
	mov.f32 	%f3348, 0f7F800000;
	@%p1162 bra 	$L__BB6_768;

	fma.rn.f32 	%f3348, %f463, %f462, %f463;

$L__BB6_768:
	setp.lt.f32 	%p1163, %f460, 0f00000000;
	and.pred  	%p76, %p1163, %p1089;
	setp.eq.f32 	%p1165, %f460, 0f00000000;
	@%p1165 bra 	$L__BB6_772;
	bra.uni 	$L__BB6_769;

$L__BB6_772:
	add.f32 	%f2515, %f460, %f460;
	selp.f32 	%f3350, %f2515, 0f00000000, %p1089;
	bra.uni 	$L__BB6_773;

$L__BB6_769:
	mov.b32 	%r1249, %f3348;
	xor.b32  	%r1250, %r1249, -2147483648;
	mov.b32 	%f2511, %r1250;
	selp.f32 	%f3350, %f2511, %f3348, %p76;
	setp.geu.f32 	%p1166, %f460, 0f00000000;
	@%p1166 bra 	$L__BB6_773;

	cvt.rzi.f32.f32 	%f2513, %f1825;
	setp.eq.f32 	%p1167, %f2513, 0f40000000;
	@%p1167 bra 	$L__BB6_773;

	mov.f32 	%f3350, 0f7FFFFFFF;

$L__BB6_773:
	add.f32 	%f2516, %f461, 0f40000000;
	mov.b32 	%r1251, %f2516;
	setp.lt.s32 	%p1169, %r1251, 2139095040;
	@%p1169 bra 	$L__BB6_778;

	setp.gtu.f32 	%p1170, %f461, 0f7F800000;
	@%p1170 bra 	$L__BB6_777;
	bra.uni 	$L__BB6_775;

$L__BB6_777:
	add.f32 	%f3350, %f460, 0f40000000;
	bra.uni 	$L__BB6_778;

$L__BB6_775:
	setp.neu.f32 	%p1171, %f461, 0f7F800000;
	@%p1171 bra 	$L__BB6_778;

	selp.f32 	%f3350, 0fFF800000, 0f7F800000, %p76;

$L__BB6_778:
	mul.f32 	%f2518, %f3350, 0fBF000000;
	setp.eq.f32 	%p1172, %f460, 0f3F800000;
	selp.f32 	%f2519, 0fBF000000, %f2518, %p1172;
	fma.rn.f32 	%f2522, %f2519, %f2023, %f1844;
	cvt.sat.f32.f32 	%f2525, %f2522;
	fma.rm.f32 	%f2527, %f2525, %f2026, %f2028;
	add.f32 	%f2528, %f2527, 0fCB40007F;
	neg.f32 	%f2529, %f2528;
	fma.rn.f32 	%f2530, %f2519, %f1999, %f2529;
	fma.rn.f32 	%f2532, %f2519, %f2033, %f2530;
	mov.b32 	%r1252, %f2527;
	shl.b32 	%r1253, %r1252, 23;
	mov.b32 	%f2533, %r1253;
	ex2.approx.ftz.f32 	%f2534, %f2532;
	mul.f32 	%f2535, %f2534, %f2533;
	mul.f32 	%f2536, %f344, %f2535;
	mul.f32 	%f2537, %f349, %f459;
	sub.f32 	%f2538, %f2537, %f2536;
	div.rn.f32 	%f2539, %f418, %f367;
	mul.f32 	%f2540, %f2539, %f2538;
	mul.f32 	%f472, %f392, %f2540;
	add.f32 	%f2541, %f380, 0f3F800000;
	sub.f32 	%f2542, %f2541, %f3294;
	div.rn.f32 	%f473, %f2542, %f369;
	abs.f32 	%f474, %f473;
	setp.lt.f32 	%p1173, %f474, 0f00800000;
	mul.f32 	%f2543, %f474, 0f4B800000;
	selp.f32 	%f2544, %f2543, %f474, %p1173;
	selp.f32 	%f2545, 0fC3170000, 0fC2FE0000, %p1173;
	mov.b32 	%r1254, %f2544;
	and.b32  	%r1255, %r1254, 8388607;
	or.b32  	%r1256, %r1255, 1065353216;
	mov.b32 	%f2546, %r1256;
	shr.u32 	%r1257, %r1254, 23;
	cvt.rn.f32.u32 	%f2547, %r1257;
	add.f32 	%f2548, %f2545, %f2547;
	setp.gt.f32 	%p1174, %f2546, 0f3FB504F3;
	mul.f32 	%f2549, %f2546, 0f3F000000;
	add.f32 	%f2550, %f2548, 0f3F800000;
	selp.f32 	%f2551, %f2550, %f2548, %p1174;
	selp.f32 	%f2552, %f2549, %f2546, %p1174;
	add.f32 	%f2553, %f2552, 0fBF800000;
	add.f32 	%f2554, %f2552, 0f3F800000;
	rcp.approx.ftz.f32 	%f2555, %f2554;
	add.f32 	%f2556, %f2553, %f2553;
	mul.f32 	%f2558, %f2556, %f2555;
	mul.f32 	%f2559, %f2558, %f2558;
	fma.rn.f32 	%f2562, %f1956, %f2559, %f1955;
	fma.rn.f32 	%f2564, %f2562, %f2559, %f1958;
	mul.rn.f32 	%f2565, %f2564, %f2559;
	mul.rn.f32 	%f2566, %f2565, %f2558;
	sub.f32 	%f2567, %f2553, %f2558;
	add.f32 	%f2568, %f2567, %f2567;
	neg.f32 	%f2569, %f2558;
	fma.rn.f32 	%f2570, %f2569, %f2553, %f2568;
	mul.rn.f32 	%f2571, %f2555, %f2570;
	add.f32 	%f2572, %f2566, %f2558;
	sub.f32 	%f2573, %f2558, %f2572;
	add.f32 	%f2574, %f2566, %f2573;
	add.f32 	%f2575, %f2571, %f2574;
	add.f32 	%f2576, %f2572, %f2575;
	sub.f32 	%f2577, %f2572, %f2576;
	add.f32 	%f2578, %f2575, %f2577;
	mul.rn.f32 	%f2580, %f2551, %f1974;
	mul.rn.f32 	%f2582, %f2551, %f1976;
	add.f32 	%f2583, %f2580, %f2576;
	sub.f32 	%f2584, %f2580, %f2583;
	add.f32 	%f2585, %f2576, %f2584;
	add.f32 	%f2586, %f2578, %f2585;
	add.f32 	%f2587, %f2582, %f2586;
	add.f32 	%f2588, %f2583, %f2587;
	sub.f32 	%f2589, %f2583, %f2588;
	add.f32 	%f2590, %f2587, %f2589;
	mul.rn.f32 	%f2591, %f1825, %f2588;
	neg.f32 	%f2592, %f2591;
	fma.rn.f32 	%f2593, %f1825, %f2588, %f2592;
	fma.rn.f32 	%f2594, %f1825, %f2590, %f2593;
	fma.rn.f32 	%f2596, %f1990, %f2588, %f2594;
	add.rn.f32 	%f2597, %f2591, %f2596;
	neg.f32 	%f2598, %f2597;
	add.rn.f32 	%f2599, %f2591, %f2598;
	add.rn.f32 	%f2600, %f2599, %f2596;
	mov.b32 	%r1258, %f2597;
	setp.eq.s32 	%p1175, %r1258, 1118925336;
	add.s32 	%r1259, %r1258, -1;
	mov.b32 	%f2601, %r1259;
	add.f32 	%f2602, %f2600, 0f37000000;
	selp.f32 	%f475, %f2602, %f2600, %p1175;
	selp.f32 	%f2603, %f2601, %f2597, %p1175;
	mul.rn.f32 	%f2604, %f2603, %f1999;
	cvt.rzi.f32.f32 	%f2605, %f2604;
	abs.f32 	%f2606, %f2605;
	setp.gt.f32 	%p1176, %f2606, 0f42FC0000;
	mov.b32 	%r1260, %f2605;
	and.b32  	%r1261, %r1260, -2147483648;
	or.b32  	%r1262, %r1261, 1123811328;
	mov.b32 	%f2607, %r1262;
	selp.f32 	%f2608, %f2607, %f2605, %p1176;
	fma.rn.f32 	%f2610, %f2608, %f2005, %f2603;
	fma.rn.f32 	%f2612, %f2608, %f2007, %f2610;
	mul.f32 	%f2613, %f2612, 0f3FB8AA3B;
	add.f32 	%f2614, %f2608, 0f4B40007F;
	mov.b32 	%r1263, %f2614;
	shl.b32 	%r1264, %r1263, 23;
	mov.b32 	%f2615, %r1264;
	ex2.approx.ftz.f32 	%f2616, %f2613;
	mul.f32 	%f476, %f2616, %f2615;
	setp.eq.f32 	%p1177, %f476, 0f7F800000;
	mov.f32 	%f3351, 0f7F800000;
	@%p1177 bra 	$L__BB6_780;

	fma.rn.f32 	%f3351, %f476, %f475, %f476;

$L__BB6_780:
	setp.lt.f32 	%p1178, %f473, 0f00000000;
	and.pred  	%p77, %p1178, %p1089;
	setp.eq.f32 	%p1180, %f473, 0f00000000;
	@%p1180 bra 	$L__BB6_784;
	bra.uni 	$L__BB6_781;

$L__BB6_784:
	add.f32 	%f2621, %f473, %f473;
	selp.f32 	%f3353, %f2621, 0f00000000, %p1089;
	bra.uni 	$L__BB6_785;

$L__BB6_781:
	mov.b32 	%r1265, %f3351;
	xor.b32  	%r1266, %r1265, -2147483648;
	mov.b32 	%f2617, %r1266;
	selp.f32 	%f3353, %f2617, %f3351, %p77;
	setp.geu.f32 	%p1181, %f473, 0f00000000;
	@%p1181 bra 	$L__BB6_785;

	cvt.rzi.f32.f32 	%f2619, %f1825;
	setp.eq.f32 	%p1182, %f2619, 0f40000000;
	@%p1182 bra 	$L__BB6_785;

	mov.f32 	%f3353, 0f7FFFFFFF;

$L__BB6_785:
	add.f32 	%f2622, %f474, 0f40000000;
	mov.b32 	%r1267, %f2622;
	setp.lt.s32 	%p1184, %r1267, 2139095040;
	@%p1184 bra 	$L__BB6_790;

	setp.gtu.f32 	%p1185, %f474, 0f7F800000;
	@%p1185 bra 	$L__BB6_789;
	bra.uni 	$L__BB6_787;

$L__BB6_789:
	add.f32 	%f3353, %f473, 0f40000000;
	bra.uni 	$L__BB6_790;

$L__BB6_787:
	setp.neu.f32 	%p1186, %f474, 0f7F800000;
	@%p1186 bra 	$L__BB6_790;

	selp.f32 	%f3353, 0fFF800000, 0f7F800000, %p77;

$L__BB6_790:
	mul.f32 	%f2624, %f3353, 0fBF000000;
	setp.eq.f32 	%p1187, %f473, 0f3F800000;
	selp.f32 	%f2625, 0fBF000000, %f2624, %p1187;
	fma.rn.f32 	%f2628, %f2625, %f2023, %f1844;
	cvt.sat.f32.f32 	%f2631, %f2628;
	fma.rm.f32 	%f2633, %f2631, %f2026, %f2028;
	add.f32 	%f2634, %f2633, 0fCB40007F;
	neg.f32 	%f2635, %f2634;
	fma.rn.f32 	%f2636, %f2625, %f1999, %f2635;
	fma.rn.f32 	%f2638, %f2625, %f2033, %f2636;
	mov.b32 	%r1268, %f2633;
	shl.b32 	%r1269, %r1268, 23;
	mov.b32 	%f2639, %r1269;
	ex2.approx.ftz.f32 	%f2640, %f2638;
	mul.f32 	%f485, %f2640, %f2639;
	div.rn.f32 	%f486, %f381, %f369;
	abs.f32 	%f487, %f486;
	setp.lt.f32 	%p1188, %f487, 0f00800000;
	mul.f32 	%f2641, %f487, 0f4B800000;
	selp.f32 	%f2642, %f2641, %f487, %p1188;
	selp.f32 	%f2643, 0fC3170000, 0fC2FE0000, %p1188;
	mov.b32 	%r1270, %f2642;
	and.b32  	%r1271, %r1270, 8388607;
	or.b32  	%r1272, %r1271, 1065353216;
	mov.b32 	%f2644, %r1272;
	shr.u32 	%r1273, %r1270, 23;
	cvt.rn.f32.u32 	%f2645, %r1273;
	add.f32 	%f2646, %f2643, %f2645;
	setp.gt.f32 	%p1189, %f2644, 0f3FB504F3;
	mul.f32 	%f2647, %f2644, 0f3F000000;
	add.f32 	%f2648, %f2646, 0f3F800000;
	selp.f32 	%f2649, %f2648, %f2646, %p1189;
	selp.f32 	%f2650, %f2647, %f2644, %p1189;
	add.f32 	%f2651, %f2650, 0fBF800000;
	add.f32 	%f2652, %f2650, 0f3F800000;
	rcp.approx.ftz.f32 	%f2653, %f2652;
	add.f32 	%f2654, %f2651, %f2651;
	mul.f32 	%f2656, %f2654, %f2653;
	mul.f32 	%f2657, %f2656, %f2656;
	fma.rn.f32 	%f2660, %f1956, %f2657, %f1955;
	fma.rn.f32 	%f2662, %f2660, %f2657, %f1958;
	mul.rn.f32 	%f2663, %f2662, %f2657;
	mul.rn.f32 	%f2664, %f2663, %f2656;
	sub.f32 	%f2665, %f2651, %f2656;
	add.f32 	%f2666, %f2665, %f2665;
	neg.f32 	%f2667, %f2656;
	fma.rn.f32 	%f2668, %f2667, %f2651, %f2666;
	mul.rn.f32 	%f2669, %f2653, %f2668;
	add.f32 	%f2670, %f2664, %f2656;
	sub.f32 	%f2671, %f2656, %f2670;
	add.f32 	%f2672, %f2664, %f2671;
	add.f32 	%f2673, %f2669, %f2672;
	add.f32 	%f2674, %f2670, %f2673;
	sub.f32 	%f2675, %f2670, %f2674;
	add.f32 	%f2676, %f2673, %f2675;
	mul.rn.f32 	%f2678, %f2649, %f1974;
	mul.rn.f32 	%f2680, %f2649, %f1976;
	add.f32 	%f2681, %f2678, %f2674;
	sub.f32 	%f2682, %f2678, %f2681;
	add.f32 	%f2683, %f2674, %f2682;
	add.f32 	%f2684, %f2676, %f2683;
	add.f32 	%f2685, %f2680, %f2684;
	add.f32 	%f2686, %f2681, %f2685;
	sub.f32 	%f2687, %f2681, %f2686;
	add.f32 	%f2688, %f2685, %f2687;
	mul.rn.f32 	%f2689, %f1825, %f2686;
	neg.f32 	%f2690, %f2689;
	fma.rn.f32 	%f2691, %f1825, %f2686, %f2690;
	fma.rn.f32 	%f2692, %f1825, %f2688, %f2691;
	fma.rn.f32 	%f2694, %f1990, %f2686, %f2692;
	add.rn.f32 	%f2695, %f2689, %f2694;
	neg.f32 	%f2696, %f2695;
	add.rn.f32 	%f2697, %f2689, %f2696;
	add.rn.f32 	%f2698, %f2697, %f2694;
	mov.b32 	%r1274, %f2695;
	setp.eq.s32 	%p1190, %r1274, 1118925336;
	add.s32 	%r1275, %r1274, -1;
	mov.b32 	%f2699, %r1275;
	add.f32 	%f2700, %f2698, 0f37000000;
	selp.f32 	%f488, %f2700, %f2698, %p1190;
	selp.f32 	%f2701, %f2699, %f2695, %p1190;
	mul.rn.f32 	%f2702, %f2701, %f1999;
	cvt.rzi.f32.f32 	%f2703, %f2702;
	abs.f32 	%f2704, %f2703;
	setp.gt.f32 	%p1191, %f2704, 0f42FC0000;
	mov.b32 	%r1276, %f2703;
	and.b32  	%r1277, %r1276, -2147483648;
	or.b32  	%r1278, %r1277, 1123811328;
	mov.b32 	%f2705, %r1278;
	selp.f32 	%f2706, %f2705, %f2703, %p1191;
	fma.rn.f32 	%f2708, %f2706, %f2005, %f2701;
	fma.rn.f32 	%f2710, %f2706, %f2007, %f2708;
	mul.f32 	%f2711, %f2710, 0f3FB8AA3B;
	add.f32 	%f2712, %f2706, 0f4B40007F;
	mov.b32 	%r1279, %f2712;
	shl.b32 	%r1280, %r1279, 23;
	mov.b32 	%f2713, %r1280;
	ex2.approx.ftz.f32 	%f2714, %f2711;
	mul.f32 	%f489, %f2714, %f2713;
	setp.eq.f32 	%p1192, %f489, 0f7F800000;
	mov.f32 	%f3354, 0f7F800000;
	@%p1192 bra 	$L__BB6_792;

	fma.rn.f32 	%f3354, %f489, %f488, %f489;

$L__BB6_792:
	setp.lt.f32 	%p1193, %f486, 0f00000000;
	and.pred  	%p78, %p1193, %p1089;
	setp.eq.f32 	%p1195, %f486, 0f00000000;
	@%p1195 bra 	$L__BB6_796;
	bra.uni 	$L__BB6_793;

$L__BB6_796:
	add.f32 	%f2719, %f486, %f486;
	selp.f32 	%f3356, %f2719, 0f00000000, %p1089;
	bra.uni 	$L__BB6_797;

$L__BB6_793:
	mov.b32 	%r1281, %f3354;
	xor.b32  	%r1282, %r1281, -2147483648;
	mov.b32 	%f2715, %r1282;
	selp.f32 	%f3356, %f2715, %f3354, %p78;
	setp.geu.f32 	%p1196, %f486, 0f00000000;
	@%p1196 bra 	$L__BB6_797;

	cvt.rzi.f32.f32 	%f2717, %f1825;
	setp.eq.f32 	%p1197, %f2717, 0f40000000;
	@%p1197 bra 	$L__BB6_797;

	mov.f32 	%f3356, 0f7FFFFFFF;

$L__BB6_797:
	add.f32 	%f2720, %f487, 0f40000000;
	mov.b32 	%r1283, %f2720;
	setp.lt.s32 	%p1199, %r1283, 2139095040;
	@%p1199 bra 	$L__BB6_802;

	setp.gtu.f32 	%p1200, %f487, 0f7F800000;
	@%p1200 bra 	$L__BB6_801;
	bra.uni 	$L__BB6_799;

$L__BB6_801:
	add.f32 	%f3356, %f486, 0f40000000;
	bra.uni 	$L__BB6_802;

$L__BB6_799:
	setp.neu.f32 	%p1201, %f487, 0f7F800000;
	@%p1201 bra 	$L__BB6_802;

	selp.f32 	%f3356, 0fFF800000, 0f7F800000, %p78;

$L__BB6_802:
	mul.f32 	%f2721, %f3356, 0fBF000000;
	setp.eq.f32 	%p1202, %f486, 0f3F800000;
	selp.f32 	%f2722, 0fBF000000, %f2721, %p1202;
	fma.rn.f32 	%f2725, %f2722, %f2023, %f1844;
	cvt.sat.f32.f32 	%f2728, %f2725;
	fma.rm.f32 	%f2730, %f2728, %f2026, %f2028;
	add.f32 	%f2731, %f2730, 0fCB40007F;
	neg.f32 	%f2732, %f2731;
	fma.rn.f32 	%f2733, %f2722, %f1999, %f2732;
	fma.rn.f32 	%f2735, %f2722, %f2033, %f2733;
	mov.b32 	%r1284, %f2730;
	shl.b32 	%r1285, %r1284, 23;
	mov.b32 	%f2736, %r1285;
	ex2.approx.ftz.f32 	%f2737, %f2735;
	mul.f32 	%f2738, %f2737, %f2736;
	add.f32 	%f2739, %f381, 0f3F800000;
	mul.f32 	%f2740, %f2739, %f485;
	mul.f32 	%f2741, %f381, %f2738;
	sub.f32 	%f2742, %f2740, %f2741;
	div.rn.f32 	%f2743, %f445, %f369;
	mul.f32 	%f498, %f2743, %f2742;
	not.pred 	%p1203, %p55;
	mov.f64 	%fd1203, %fd449;
	@%p1203 bra 	$L__BB6_804;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1286}, %fd449;
	}
	xor.b32  	%r1287, %r1286, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1288, %temp}, %fd449;
	}
	mov.b64 	%fd1203, {%r1288, %r1287};

$L__BB6_804:
	setp.eq.f32 	%p1204, %f320, 0f00000000;
	@%p1204 bra 	$L__BB6_808;
	bra.uni 	$L__BB6_805;

$L__BB6_808:
	mov.u32 	%r1289, 0;
	mov.b64 	%fd1203, {%r1289, %r153};
	bra.uni 	$L__BB6_809;

$L__BB6_805:
	setp.gt.s32 	%p1205, %r152, -1;
	@%p1205 bra 	$L__BB6_809;

	cvt.rzi.f64.f64 	%fd1002, %fd960;
	setp.eq.f64 	%p1206, %fd1002, 0d4000000000000000;
	@%p1206 bra 	$L__BB6_809;

	mov.f64 	%fd1203, 0dFFF8000000000000;

$L__BB6_809:
	selp.f64 	%fd1204, %fd1203, %fd431, %p986;
	@%p66 bra 	$L__BB6_814;

	setp.eq.s32 	%p1208, %r124, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1290, %temp}, %fd960;
	}
	setp.eq.s32 	%p1209, %r1290, 0;
	and.pred  	%p1210, %p1208, %p1209;
	@%p1210 bra 	$L__BB6_813;
	bra.uni 	$L__BB6_811;

$L__BB6_813:
	mov.u32 	%r1293, 0;
	mov.b64 	%fd1204, {%r1293, %r155};
	bra.uni 	$L__BB6_814;

$L__BB6_811:
	setp.ne.s32 	%p1211, %r156, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1291, %temp}, %fd430;
	}
	setp.ne.s32 	%p1212, %r1291, 0;
	or.pred  	%p1213, %p1211, %p1212;
	mov.f64 	%fd1204, %fd1203;
	@%p1213 bra 	$L__BB6_814;

	mov.u32 	%r1292, 0;
	mov.b64 	%fd1204, {%r1292, %r159};

$L__BB6_814:
	not.pred 	%p1214, %p56;
	mov.f64 	%fd1206, %fd450;
	@%p1214 bra 	$L__BB6_816;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1294}, %fd450;
	}
	xor.b32  	%r1295, %r1294, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1296, %temp}, %fd450;
	}
	mov.b64 	%fd1206, {%r1296, %r1295};

$L__BB6_816:
	@%p1204 bra 	$L__BB6_820;
	bra.uni 	$L__BB6_817;

$L__BB6_820:
	mov.u32 	%r1297, 0;
	mov.b64 	%fd1206, {%r1297, %r157};
	bra.uni 	$L__BB6_821;

$L__BB6_817:
	setp.gt.s32 	%p1216, %r152, -1;
	@%p1216 bra 	$L__BB6_821;

	cvt.rzi.f64.f64 	%fd1006, %fd961;
	setp.eq.f64 	%p1217, %fd1006, 0d4008000000000000;
	@%p1217 bra 	$L__BB6_821;

	mov.f64 	%fd1206, 0dFFF8000000000000;

$L__BB6_821:
	selp.f64 	%fd1207, %fd1206, %fd434, %p989;
	@%p67 bra 	$L__BB6_826;

	setp.eq.s32 	%p1219, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1298, %temp}, %fd961;
	}
	setp.eq.s32 	%p1220, %r1298, 0;
	and.pred  	%p1221, %p1219, %p1220;
	@%p1221 bra 	$L__BB6_825;
	bra.uni 	$L__BB6_823;

$L__BB6_825:
	mov.u32 	%r1301, 0;
	mov.b64 	%fd1207, {%r1301, %r161};
	bra.uni 	$L__BB6_826;

$L__BB6_823:
	setp.ne.s32 	%p1222, %r156, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1299, %temp}, %fd430;
	}
	setp.ne.s32 	%p1223, %r1299, 0;
	or.pred  	%p1224, %p1222, %p1223;
	mov.f64 	%fd1207, %fd1206;
	@%p1224 bra 	$L__BB6_826;

	mov.u32 	%r1300, 0;
	mov.b64 	%fd1207, {%r1300, %r164};

$L__BB6_826:
	not.pred 	%p1225, %p57;
	mov.f64 	%fd1209, %fd451;
	@%p1225 bra 	$L__BB6_828;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1302}, %fd451;
	}
	xor.b32  	%r1303, %r1302, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1304, %temp}, %fd451;
	}
	mov.b64 	%fd1209, {%r1304, %r1303};

$L__BB6_828:
	setp.eq.f32 	%p1226, %f553, 0f00000000;
	@%p1226 bra 	$L__BB6_832;
	bra.uni 	$L__BB6_829;

$L__BB6_832:
	mov.u32 	%r1305, 0;
	mov.b64 	%fd1209, {%r1305, %r162};
	bra.uni 	$L__BB6_833;

$L__BB6_829:
	setp.gt.s32 	%p1227, %r160, -1;
	@%p1227 bra 	$L__BB6_833;

	cvt.rzi.f64.f64 	%fd1010, %fd962;
	setp.eq.f64 	%p1228, %fd1010, 0d4010000000000000;
	@%p1228 bra 	$L__BB6_833;

	mov.f64 	%fd1209, 0dFFF8000000000000;

$L__BB6_833:
	selp.f64 	%fd1210, %fd1209, %fd436, %p992;
	@%p68 bra 	$L__BB6_838;

	setp.eq.s32 	%p1230, %r136, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1306, %temp}, %fd962;
	}
	setp.eq.s32 	%p1231, %r1306, 0;
	and.pred  	%p1232, %p1230, %p1231;
	@%p1232 bra 	$L__BB6_837;
	bra.uni 	$L__BB6_835;

$L__BB6_837:
	mov.u32 	%r1309, 0;
	mov.b64 	%fd1210, {%r1309, %r166};
	bra.uni 	$L__BB6_838;

$L__BB6_835:
	setp.ne.s32 	%p1233, %r167, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1307, %temp}, %fd435;
	}
	setp.ne.s32 	%p1234, %r1307, 0;
	or.pred  	%p1235, %p1233, %p1234;
	mov.f64 	%fd1210, %fd1209;
	@%p1235 bra 	$L__BB6_838;

	mov.u32 	%r1308, 0;
	mov.b64 	%fd1210, {%r1308, %r170};

$L__BB6_838:
	setp.eq.f32 	%p1236, %f553, 0f3F800000;
	selp.f64 	%fd1013, 0d3FF0000000000000, %fd1210, %p1236;
	setp.eq.f32 	%p1237, %f320, 0f3F800000;
	selp.f64 	%fd1014, 0d3FF0000000000000, %fd1207, %p1237;
	mul.f64 	%fd1015, %fd1014, %fd433;
	div.rn.f64 	%fd1016, %fd1015, %fd1013;
	selp.f64 	%fd1017, 0d3FF0000000000000, %fd1204, %p1237;
	mul.f64 	%fd1018, %fd1017, %fd429;
	div.rn.f64 	%fd1019, %fd1018, %fd432;
	add.f64 	%fd1020, %fd1019, %fd428;
	add.f64 	%fd1021, %fd1020, %fd1016;
	cvt.rn.f32.f64 	%f2744, %fd1021;
	div.rn.f32 	%f2745, %f325, %f366;
	mul.f32 	%f499, %f2745, %f2744;
	not.pred 	%p1238, %p58;
	mov.f64 	%fd1212, %fd452;
	@%p1238 bra 	$L__BB6_840;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1310}, %fd452;
	}
	xor.b32  	%r1311, %r1310, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1312, %temp}, %fd452;
	}
	mov.b64 	%fd1212, {%r1312, %r1311};

$L__BB6_840:
	setp.eq.f32 	%p1239, %f322, 0f00000000;
	@%p1239 bra 	$L__BB6_844;
	bra.uni 	$L__BB6_841;

$L__BB6_844:
	mov.u32 	%r1313, 0;
	mov.b64 	%fd1212, {%r1313, %r168};
	bra.uni 	$L__BB6_845;

$L__BB6_841:
	setp.gt.s32 	%p1240, %r165, -1;
	@%p1240 bra 	$L__BB6_845;

	cvt.rzi.f64.f64 	%fd1023, %fd960;
	setp.eq.f64 	%p1241, %fd1023, 0d4000000000000000;
	@%p1241 bra 	$L__BB6_845;

	mov.f64 	%fd1212, 0dFFF8000000000000;

$L__BB6_845:
	selp.f64 	%fd1213, %fd1212, %fd440, %p998;
	@%p69 bra 	$L__BB6_850;

	setp.eq.s32 	%p1243, %r124, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1314, %temp}, %fd960;
	}
	setp.eq.s32 	%p1244, %r1314, 0;
	and.pred  	%p1245, %p1243, %p1244;
	@%p1245 bra 	$L__BB6_849;
	bra.uni 	$L__BB6_847;

$L__BB6_849:
	mov.u32 	%r1317, 0;
	mov.b64 	%fd1213, {%r1317, %r171};
	bra.uni 	$L__BB6_850;

$L__BB6_847:
	setp.ne.s32 	%p1246, %r172, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1315, %temp}, %fd439;
	}
	setp.ne.s32 	%p1247, %r1315, 0;
	or.pred  	%p1248, %p1246, %p1247;
	mov.f64 	%fd1213, %fd1212;
	@%p1248 bra 	$L__BB6_850;

	mov.u32 	%r1316, 0;
	mov.b64 	%fd1213, {%r1316, %r175};

$L__BB6_850:
	not.pred 	%p1249, %p59;
	mov.f64 	%fd1215, %fd453;
	@%p1249 bra 	$L__BB6_852;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1318}, %fd453;
	}
	xor.b32  	%r1319, %r1318, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1320, %temp}, %fd453;
	}
	mov.b64 	%fd1215, {%r1320, %r1319};

$L__BB6_852:
	@%p1239 bra 	$L__BB6_856;
	bra.uni 	$L__BB6_853;

$L__BB6_856:
	mov.u32 	%r1321, 0;
	mov.b64 	%fd1215, {%r1321, %r173};
	bra.uni 	$L__BB6_857;

$L__BB6_853:
	setp.gt.s32 	%p1251, %r165, -1;
	@%p1251 bra 	$L__BB6_857;

	cvt.rzi.f64.f64 	%fd1027, %fd961;
	setp.eq.f64 	%p1252, %fd1027, 0d4008000000000000;
	@%p1252 bra 	$L__BB6_857;

	mov.f64 	%fd1215, 0dFFF8000000000000;

$L__BB6_857:
	selp.f64 	%fd1216, %fd1215, %fd442, %p1002;
	@%p70 bra 	$L__BB6_862;

	setp.eq.s32 	%p1254, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1322, %temp}, %fd961;
	}
	setp.eq.s32 	%p1255, %r1322, 0;
	and.pred  	%p1256, %p1254, %p1255;
	@%p1256 bra 	$L__BB6_861;
	bra.uni 	$L__BB6_859;

$L__BB6_861:
	mov.u32 	%r1325, 0;
	mov.b64 	%fd1216, {%r1325, %r176};
	bra.uni 	$L__BB6_862;

$L__BB6_859:
	setp.ne.s32 	%p1257, %r172, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1323, %temp}, %fd439;
	}
	setp.ne.s32 	%p1258, %r1323, 0;
	or.pred  	%p1259, %p1257, %p1258;
	mov.f64 	%fd1216, %fd1215;
	@%p1259 bra 	$L__BB6_862;

	mov.u32 	%r1324, 0;
	mov.b64 	%fd1216, {%r1324, %r177};

$L__BB6_862:
	mov.f64 	%fd1218, %fd451;
	@%p1225 bra 	$L__BB6_864;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1326}, %fd451;
	}
	xor.b32  	%r1327, %r1326, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1328, %temp}, %fd451;
	}
	mov.b64 	%fd1218, {%r1328, %r1327};

$L__BB6_864:
	@%p1226 bra 	$L__BB6_868;
	bra.uni 	$L__BB6_865;

$L__BB6_868:
	mov.u32 	%r1329, 0;
	mov.b64 	%fd1218, {%r1329, %r162};
	bra.uni 	$L__BB6_869;

$L__BB6_865:
	setp.gt.s32 	%p1262, %r160, -1;
	@%p1262 bra 	$L__BB6_869;

	cvt.rzi.f64.f64 	%fd1031, %fd962;
	setp.eq.f64 	%p1263, %fd1031, 0d4010000000000000;
	@%p1263 bra 	$L__BB6_869;

	mov.f64 	%fd1218, 0dFFF8000000000000;

$L__BB6_869:
	selp.f64 	%fd1219, %fd1218, %fd436, %p992;
	@%p68 bra 	$L__BB6_874;

	setp.eq.s32 	%p1265, %r136, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1330, %temp}, %fd962;
	}
	setp.eq.s32 	%p1266, %r1330, 0;
	and.pred  	%p1267, %p1265, %p1266;
	@%p1267 bra 	$L__BB6_873;
	bra.uni 	$L__BB6_871;

$L__BB6_873:
	mov.u32 	%r1333, 0;
	mov.b64 	%fd1219, {%r1333, %r166};
	bra.uni 	$L__BB6_874;

$L__BB6_871:
	setp.ne.s32 	%p1268, %r167, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1331, %temp}, %fd435;
	}
	setp.ne.s32 	%p1269, %r1331, 0;
	or.pred  	%p1270, %p1268, %p1269;
	mov.f64 	%fd1219, %fd1218;
	@%p1270 bra 	$L__BB6_874;

	mov.u32 	%r1332, 0;
	mov.b64 	%fd1219, {%r1332, %r170};

$L__BB6_874:
	selp.f64 	%fd1034, 0d3FF0000000000000, %fd1219, %p1236;
	setp.eq.f32 	%p1272, %f322, 0f3F800000;
	selp.f64 	%fd1035, 0d3FF0000000000000, %fd1216, %p1272;
	mul.f64 	%fd1036, %fd1035, %fd441;
	div.rn.f64 	%fd1037, %fd1036, %fd1034;
	selp.f64 	%fd1038, 0d3FF0000000000000, %fd1213, %p1272;
	mul.f64 	%fd1039, %fd1038, %fd438;
	div.rn.f64 	%fd1040, %fd1039, %fd432;
	add.f64 	%fd1041, %fd1040, %fd437;
	add.f64 	%fd1042, %fd1041, %fd1037;
	cvt.rn.f32.f64 	%f2746, %fd1042;
	div.rn.f32 	%f2747, %f326, %f368;
	mul.f32 	%f2748, %f2747, %f2746;
	mul.f32 	%f2749, %f379, %f498;
	mul.f32 	%f2750, %f2749, %f2748;
	fma.rn.f32 	%f2751, %f472, %f499, %f2750;
	mul.f32 	%f2752, %f379, %f3293;
	fma.rn.f32 	%f500, %f392, %f2752, %f3292;
	mad.lo.s32 	%r1334, %r1377, %r182, %r1376;
	add.s32 	%r1335, %r1334, %r2;
	mul.wide.s32 	%rd36, %r1335, 4;
	add.s64 	%rd37, %rd1, %rd36;
	ld.global.f32 	%f501, [%rd37];
	mul.f32 	%f2753, %f419, %f419;
	div.rn.f32 	%f2754, %f2753, %f500;
	add.f32 	%f3324, %f3324, %f2754;
	mul.f32 	%f2755, %f446, %f419;
	div.rn.f32 	%f2756, %f2755, %f500;
	add.f32 	%f3323, %f3323, %f2756;
	mul.f32 	%f2757, %f379, %f392;
	mul.f32 	%f2758, %f2757, %f419;
	div.rn.f32 	%f2759, %f2758, %f500;
	add.f32 	%f3322, %f3322, %f2759;
	div.rn.f32 	%f2760, %f419, %f500;
	add.f32 	%f3321, %f3321, %f2760;
	mul.f32 	%f2761, %f2751, %f419;
	div.rn.f32 	%f2762, %f2761, %f500;
	add.f32 	%f3320, %f3320, %f2762;
	mul.f32 	%f2763, %f446, %f446;
	div.rn.f32 	%f2764, %f2763, %f500;
	add.f32 	%f3319, %f3319, %f2764;
	mul.f32 	%f2765, %f2757, %f446;
	div.rn.f32 	%f2766, %f2765, %f500;
	add.f32 	%f3318, %f3318, %f2766;
	div.rn.f32 	%f2767, %f446, %f500;
	add.f32 	%f3317, %f3317, %f2767;
	mul.f32 	%f2768, %f2751, %f446;
	div.rn.f32 	%f2769, %f2768, %f500;
	add.f32 	%f3316, %f3316, %f2769;
	mul.f32 	%f2770, %f2757, %f2757;
	div.rn.f32 	%f2771, %f2770, %f500;
	add.f32 	%f3315, %f3315, %f2771;
	div.rn.f32 	%f2772, %f2757, %f500;
	add.f32 	%f3314, %f3314, %f2772;
	mul.f32 	%f2773, %f2751, %f2757;
	div.rn.f32 	%f2774, %f2773, %f500;
	add.f32 	%f3313, %f3313, %f2774;
	rcp.rn.f32 	%f2775, %f500;
	add.f32 	%f3325, %f3325, %f2775;
	div.rn.f32 	%f2776, %f2751, %f500;
	add.f32 	%f3326, %f3326, %f2776;
	mul.f32 	%f2777, %f2751, %f2751;
	div.rn.f32 	%f2778, %f2777, %f500;
	add.f32 	%f3327, %f3327, %f2778;
	add.f32 	%f517, %f3290, %f500;
	setp.leu.f32 	%p1273, %f517, 0f00000000;
	@%p1273 bra 	$L__BB6_882;

	add.f32 	%f518, %f3290, %f501;
	setp.gt.f32 	%p1274, %f518, 0f00000000;
	@%p1274 bra 	$L__BB6_877;
	bra.uni 	$L__BB6_876;

$L__BB6_877:
	setp.lt.f32 	%p1275, %f517, 0f00800000;
	mul.f32 	%f2781, %f517, 0f4B000000;
	selp.f32 	%f520, %f2781, %f517, %p1275;
	selp.f32 	%f2782, 0fC1B80000, 0f00000000, %p1275;
	mov.b32 	%r1336, %f520;
	add.s32 	%r1337, %r1336, -1059760811;
	and.b32  	%r1338, %r1337, -8388608;
	sub.s32 	%r1339, %r1336, %r1338;
	mov.b32 	%f2783, %r1339;
	cvt.rn.f32.s32 	%f2784, %r1338;
	mov.f32 	%f2785, 0f34000000;
	fma.rn.f32 	%f2786, %f2784, %f2785, %f2782;
	add.f32 	%f2787, %f2783, 0fBF800000;
	mov.f32 	%f2788, 0f3E1039F6;
	mov.f32 	%f2789, 0fBE055027;
	fma.rn.f32 	%f2790, %f2789, %f2787, %f2788;
	mov.f32 	%f2791, 0fBDF8CDCC;
	fma.rn.f32 	%f2792, %f2790, %f2787, %f2791;
	mov.f32 	%f2793, 0f3E0F2955;
	fma.rn.f32 	%f2794, %f2792, %f2787, %f2793;
	mov.f32 	%f2795, 0fBE2AD8B9;
	fma.rn.f32 	%f2796, %f2794, %f2787, %f2795;
	mov.f32 	%f2797, 0f3E4CED0B;
	fma.rn.f32 	%f2798, %f2796, %f2787, %f2797;
	mov.f32 	%f2799, 0fBE7FFF22;
	fma.rn.f32 	%f2800, %f2798, %f2787, %f2799;
	mov.f32 	%f2801, 0f3EAAAA78;
	fma.rn.f32 	%f2802, %f2800, %f2787, %f2801;
	mov.f32 	%f2803, 0fBF000000;
	fma.rn.f32 	%f2804, %f2802, %f2787, %f2803;
	mul.f32 	%f2805, %f2787, %f2804;
	fma.rn.f32 	%f2806, %f2805, %f2787, %f2787;
	mov.f32 	%f2807, 0f3F317218;
	fma.rn.f32 	%f3357, %f2786, %f2807, %f2806;
	setp.lt.u32 	%p1276, %r1336, 2139095040;
	@%p1276 bra 	$L__BB6_879;

	mov.f32 	%f2808, 0f7F800000;
	fma.rn.f32 	%f3357, %f520, %f2808, %f2808;

$L__BB6_879:
	setp.eq.f32 	%p1277, %f520, 0f00000000;
	selp.f32 	%f2809, 0fFF800000, %f3357, %p1277;
	mul.f32 	%f2810, %f518, %f2809;
	sub.f32 	%f524, %f2810, %f500;
	mul.f32 	%f2811, %f518, 0f4B000000;
	setp.lt.f32 	%p1278, %f518, 0f00800000;
	selp.f32 	%f525, %f2811, %f518, %p1278;
	selp.f32 	%f2812, 0fC1B80000, 0f00000000, %p1278;
	mov.b32 	%r1340, %f525;
	add.s32 	%r1341, %r1340, -1059760811;
	and.b32  	%r1342, %r1341, -8388608;
	sub.s32 	%r1343, %r1340, %r1342;
	mov.b32 	%f2813, %r1343;
	cvt.rn.f32.s32 	%f2814, %r1342;
	fma.rn.f32 	%f2816, %f2814, %f2785, %f2812;
	add.f32 	%f2817, %f2813, 0fBF800000;
	fma.rn.f32 	%f2820, %f2789, %f2817, %f2788;
	fma.rn.f32 	%f2822, %f2820, %f2817, %f2791;
	fma.rn.f32 	%f2824, %f2822, %f2817, %f2793;
	fma.rn.f32 	%f2826, %f2824, %f2817, %f2795;
	fma.rn.f32 	%f2828, %f2826, %f2817, %f2797;
	fma.rn.f32 	%f2830, %f2828, %f2817, %f2799;
	fma.rn.f32 	%f2832, %f2830, %f2817, %f2801;
	fma.rn.f32 	%f2834, %f2832, %f2817, %f2803;
	mul.f32 	%f2835, %f2817, %f2834;
	fma.rn.f32 	%f2836, %f2835, %f2817, %f2817;
	fma.rn.f32 	%f3358, %f2816, %f2807, %f2836;
	setp.lt.u32 	%p1279, %r1340, 2139095040;
	@%p1279 bra 	$L__BB6_881;

	mov.f32 	%f2838, 0f7F800000;
	fma.rn.f32 	%f3358, %f525, %f2838, %f2838;

$L__BB6_881:
	setp.eq.f32 	%p1280, %f525, 0f00000000;
	selp.f32 	%f2839, 0fFF800000, %f3358, %p1280;
	mul.f32 	%f2840, %f518, %f2839;
	sub.f32 	%f2841, %f524, %f2840;
	add.f32 	%f2842, %f501, %f2841;
	add.f32 	%f3359, %f3359, %f2842;
	bra.uni 	$L__BB6_882;

$L__BB6_876:
	neg.f32 	%f2779, %f500;
	sub.f32 	%f2780, %f2779, %f3290;
	add.f32 	%f3359, %f3359, %f2780;

$L__BB6_882:
	add.s32 	%r1377, %r1377, 1;
	setp.lt.s32 	%p1281, %r1377, %r182;
	@%p1281 bra 	$L__BB6_626;

	add.s32 	%r1376, %r1376, 1;
	setp.lt.s32 	%p1282, %r1376, %r182;
	@%p1282 bra 	$L__BB6_625;

$L__BB6_884:
	ld.param.u64 	%rd59, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_17];
	ld.param.u64 	%rd58, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_16];
	ld.param.u32 	%r1363, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_18];
	mul.wide.s32 	%rd57, %r1, 4;
	ld.param.u64 	%rd56, [_Z25kernel_MLEFit_SCMOSXYNBZ_PKfS0_S0_S0_ffffffffiiiPfS1_S1_i_param_15];
	rcp.rn.f32 	%f2843, %f3324;
	mov.f32 	%f2844, 0f3F800000;
	mul.f32 	%f2845, %f2843, %f3323;
	mul.f32 	%f2846, %f2843, %f3322;
	mul.f32 	%f2847, %f2843, %f3321;
	mul.f32 	%f2848, %f2843, %f3320;
	fma.rn.f32 	%f2849, %f2845, %f3323, 0f00000000;
	sub.f32 	%f2851, %f3319, %f2849;
	fma.rn.f32 	%f2852, %f2846, %f3323, 0f00000000;
	rcp.rn.f32 	%f2853, %f2851;
	sub.f32 	%f2854, %f3318, %f2852;
	mul.f32 	%f2855, %f2853, %f2854;
	fma.rn.f32 	%f2856, %f2847, %f3323, 0f00000000;
	sub.f32 	%f2857, %f3317, %f2856;
	mul.f32 	%f2858, %f2853, %f2857;
	fma.rn.f32 	%f2859, %f2848, %f3323, 0f00000000;
	sub.f32 	%f2860, %f3316, %f2859;
	mul.f32 	%f2861, %f2853, %f2860;
	fma.rn.f32 	%f2862, %f2845, %f3322, 0f00000000;
	sub.f32 	%f2863, %f3318, %f2862;
	fma.rn.f32 	%f2864, %f2846, %f3322, 0f00000000;
	fma.rn.f32 	%f2865, %f2855, %f2863, %f2864;
	sub.f32 	%f2866, %f3315, %f2865;
	fma.rn.f32 	%f2867, %f2847, %f3322, 0f00000000;
	fma.rn.f32 	%f2868, %f2858, %f2863, %f2867;
	rcp.rn.f32 	%f2869, %f2866;
	sub.f32 	%f2870, %f3314, %f2868;
	mul.f32 	%f2871, %f2869, %f2870;
	fma.rn.f32 	%f2872, %f2848, %f3322, 0f00000000;
	fma.rn.f32 	%f2873, %f2861, %f2863, %f2872;
	sub.f32 	%f2874, %f3313, %f2873;
	mul.f32 	%f2875, %f2869, %f2874;
	fma.rn.f32 	%f2876, %f2845, %f3321, 0f00000000;
	sub.f32 	%f2877, %f3317, %f2876;
	fma.rn.f32 	%f2878, %f2846, %f3321, 0f00000000;
	fma.rn.f32 	%f2879, %f2855, %f2877, %f2878;
	sub.f32 	%f2880, %f3314, %f2879;
	fma.rn.f32 	%f2881, %f2847, %f3321, 0f00000000;
	fma.rn.f32 	%f2882, %f2858, %f2877, %f2881;
	fma.rn.f32 	%f2883, %f2871, %f2880, %f2882;
	sub.f32 	%f2884, %f3325, %f2883;
	fma.rn.f32 	%f2885, %f2848, %f3321, 0f00000000;
	fma.rn.f32 	%f2886, %f2861, %f2877, %f2885;
	fma.rn.f32 	%f2887, %f2875, %f2880, %f2886;
	rcp.rn.f32 	%f2888, %f2884;
	sub.f32 	%f2889, %f3326, %f2887;
	mul.f32 	%f2890, %f2888, %f2889;
	fma.rn.f32 	%f2891, %f2845, %f3320, 0f00000000;
	sub.f32 	%f2892, %f3316, %f2891;
	fma.rn.f32 	%f2893, %f2846, %f3320, 0f00000000;
	fma.rn.f32 	%f2894, %f2855, %f2892, %f2893;
	sub.f32 	%f2895, %f3313, %f2894;
	fma.rn.f32 	%f2896, %f2847, %f3320, 0f00000000;
	fma.rn.f32 	%f2897, %f2858, %f2892, %f2896;
	fma.rn.f32 	%f2898, %f2871, %f2895, %f2897;
	sub.f32 	%f2899, %f3326, %f2898;
	fma.rn.f32 	%f2900, %f2848, %f3320, 0f00000000;
	fma.rn.f32 	%f2901, %f2861, %f2892, %f2900;
	fma.rn.f32 	%f2902, %f2875, %f2895, %f2901;
	fma.rn.f32 	%f2903, %f2890, %f2899, %f2902;
	sub.f32 	%f2904, %f3327, %f2903;
	add.f32 	%f2905, %f2845, 0f00000000;
	sub.f32 	%f2906, %f1807, %f2905;
	add.f32 	%f2907, %f2846, 0f00000000;
	fma.rn.f32 	%f2908, %f2855, %f2906, %f2907;
	sub.f32 	%f2909, %f1807, %f2908;
	add.f32 	%f2910, %f2847, 0f00000000;
	fma.rn.f32 	%f2911, %f2858, %f2906, %f2910;
	fma.rn.f32 	%f2912, %f2871, %f2909, %f2911;
	sub.f32 	%f2913, %f1807, %f2912;
	add.f32 	%f2914, %f2848, 0f00000000;
	fma.rn.f32 	%f2915, %f2861, %f2906, %f2914;
	fma.rn.f32 	%f2916, %f2875, %f2909, %f2915;
	fma.rn.f32 	%f2917, %f2890, %f2913, %f2916;
	sub.f32 	%f2918, %f1807, %f2917;
	div.rn.f32 	%f2919, %f2918, %f2904;
	fma.rn.f32 	%f2920, %f2899, %f2919, 0f00000000;
	sub.f32 	%f2921, %f2913, %f2920;
	mul.f32 	%f2922, %f2888, %f2921;
	fma.rn.f32 	%f2923, %f2880, %f2922, 0f00000000;
	fma.rn.f32 	%f2924, %f2895, %f2919, %f2923;
	sub.f32 	%f2925, %f2909, %f2924;
	mul.f32 	%f2926, %f2869, %f2925;
	fma.rn.f32 	%f2927, %f2863, %f2926, 0f00000000;
	fma.rn.f32 	%f2928, %f2877, %f2922, %f2927;
	fma.rn.f32 	%f2929, %f2892, %f2919, %f2928;
	sub.f32 	%f2930, %f2906, %f2929;
	mul.f32 	%f2931, %f2853, %f2930;
	fma.rn.f32 	%f2932, %f3323, %f2931, 0f00000000;
	fma.rn.f32 	%f2933, %f3322, %f2926, %f2932;
	fma.rn.f32 	%f2934, %f3321, %f2922, %f2933;
	fma.rn.f32 	%f2935, %f3320, %f2919, %f2934;
	sub.f32 	%f2936, %f2844, %f2935;
	mul.f32 	%f2937, %f2843, %f2936;
	fma.rn.f32 	%f2938, %f2845, 0f00000000, 0f00000000;
	sub.f32 	%f2939, %f2844, %f2938;
	fma.rn.f32 	%f2940, %f2846, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2941, %f2855, %f2939, %f2940;
	sub.f32 	%f2942, %f1807, %f2941;
	fma.rn.f32 	%f2943, %f2847, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2944, %f2858, %f2939, %f2943;
	fma.rn.f32 	%f2945, %f2871, %f2942, %f2944;
	sub.f32 	%f2946, %f1807, %f2945;
	fma.rn.f32 	%f2947, %f2848, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2948, %f2861, %f2939, %f2947;
	fma.rn.f32 	%f2949, %f2875, %f2942, %f2948;
	fma.rn.f32 	%f2950, %f2890, %f2946, %f2949;
	sub.f32 	%f2951, %f1807, %f2950;
	div.rn.f32 	%f2952, %f2951, %f2904;
	fma.rn.f32 	%f2953, %f2899, %f2952, 0f00000000;
	sub.f32 	%f2954, %f2946, %f2953;
	mul.f32 	%f2955, %f2888, %f2954;
	fma.rn.f32 	%f2956, %f2880, %f2955, 0f00000000;
	fma.rn.f32 	%f2957, %f2895, %f2952, %f2956;
	sub.f32 	%f2958, %f2942, %f2957;
	mul.f32 	%f2959, %f2869, %f2958;
	fma.rn.f32 	%f2960, %f2863, %f2959, 0f00000000;
	fma.rn.f32 	%f2961, %f2877, %f2955, %f2960;
	fma.rn.f32 	%f2962, %f2892, %f2952, %f2961;
	sub.f32 	%f2963, %f2939, %f2962;
	mul.f32 	%f2964, %f2853, %f2963;
	sub.f32 	%f2965, %f1807, %f2938;
	fma.rn.f32 	%f2966, %f2855, %f2965, %f2940;
	sub.f32 	%f2967, %f2844, %f2966;
	fma.rn.f32 	%f2968, %f2858, %f2965, %f2943;
	fma.rn.f32 	%f2969, %f2871, %f2967, %f2968;
	sub.f32 	%f2970, %f1807, %f2969;
	fma.rn.f32 	%f2971, %f2861, %f2965, %f2947;
	fma.rn.f32 	%f2972, %f2875, %f2967, %f2971;
	fma.rn.f32 	%f2973, %f2890, %f2970, %f2972;
	sub.f32 	%f2974, %f1807, %f2973;
	div.rn.f32 	%f2975, %f2974, %f2904;
	fma.rn.f32 	%f2976, %f2899, %f2975, 0f00000000;
	sub.f32 	%f2977, %f2970, %f2976;
	mul.f32 	%f2978, %f2888, %f2977;
	fma.rn.f32 	%f2979, %f2880, %f2978, 0f00000000;
	fma.rn.f32 	%f2980, %f2895, %f2975, %f2979;
	sub.f32 	%f2981, %f2967, %f2980;
	mul.f32 	%f2982, %f2869, %f2981;
	sub.f32 	%f2983, %f1807, %f2966;
	fma.rn.f32 	%f2984, %f2871, %f2983, %f2968;
	sub.f32 	%f2985, %f2844, %f2984;
	fma.rn.f32 	%f2986, %f2875, %f2983, %f2971;
	fma.rn.f32 	%f2987, %f2890, %f2985, %f2986;
	sub.f32 	%f2988, %f1807, %f2987;
	div.rn.f32 	%f2989, %f2988, %f2904;
	fma.rn.f32 	%f2990, %f2899, %f2989, 0f00000000;
	sub.f32 	%f2991, %f2985, %f2990;
	mul.f32 	%f2992, %f2888, %f2991;
	sub.f32 	%f2993, %f1807, %f2984;
	fma.rn.f32 	%f2994, %f2890, %f2993, %f2986;
	sub.f32 	%f2995, %f2844, %f2994;
	div.rn.f32 	%f2996, %f2995, %f2904;
	cvta.to.global.u64 	%rd38, %rd56;
	add.s64 	%rd40, %rd38, %rd57;
	st.global.f32 	[%rd40], %f3295;
	add.s32 	%r1348, %r1, %r1363;
	mul.wide.s32 	%rd41, %r1363, 4;
	add.s64 	%rd42, %rd40, %rd41;
	st.global.f32 	[%rd42], %f3294;
	add.s32 	%r1349, %r1348, %r1363;
	shl.b32 	%r1350, %r1363, 3;
	cvt.s64.s32 	%rd43, %r1350;
	add.s64 	%rd44, %rd40, %rd43;
	st.global.f32 	[%rd44], %f3293;
	add.s32 	%r1351, %r1349, %r1363;
	mul.wide.s32 	%rd45, %r1351, 4;
	add.s64 	%rd46, %rd38, %rd45;
	st.global.f32 	[%rd46], %f3292;
	add.s64 	%rd47, %rd44, %rd43;
	st.global.f32 	[%rd47], %f3291;
	cvta.to.global.u64 	%rd48, %rd58;
	add.s64 	%rd49, %rd48, %rd57;
	st.global.f32 	[%rd49], %f2937;
	add.s64 	%rd50, %rd49, %rd41;
	st.global.f32 	[%rd50], %f2964;
	add.s64 	%rd51, %rd49, %rd43;
	st.global.f32 	[%rd51], %f2982;
	add.s64 	%rd52, %rd48, %rd45;
	st.global.f32 	[%rd52], %f2992;
	add.s64 	%rd53, %rd51, %rd43;
	st.global.f32 	[%rd53], %f2996;
	cvta.to.global.u64 	%rd54, %rd59;
	add.s64 	%rd55, %rd54, %rd57;
	st.global.f32 	[%rd55], %f3359;

$L__BB6_885:
	ret;

}
	// .globl	_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i
.visible .entry _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i(
	.param .u64 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_0,
	.param .u64 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_1,
	.param .u64 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_2,
	.param .f32 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_3,
	.param .u32 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_4,
	.param .u32 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_5,
	.param .u32 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_6,
	.param .u64 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_7,
	.param .u64 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_8,
	.param .u64 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_9,
	.param .u32 _Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_10
)
{
	.reg .pred 	%p<746>;
	.reg .f32 	%f<3164>;
	.reg .b32 	%r<850>;
	.reg .f64 	%fd<627>;
	.reg .b64 	%rd<57>;


	ld.param.u64 	%rd3, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_0];
	ld.param.u64 	%rd4, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_1];
	ld.param.u64 	%rd5, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_2];
	ld.param.f32 	%f3064, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_3];
	ld.param.u32 	%r104, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_4];
	ld.param.u32 	%r105, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_5];
	ld.param.u32 	%r106, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_6];
	ld.param.u32 	%r107, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_10];
	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r108, %ntid.x;
	mov.u32 	%r109, %ctaid.x;
	mov.u32 	%r110, %tid.x;
	mad.lo.s32 	%r1, %r109, %r108, %r110;
	setp.ge.s32 	%p43, %r1, %r107;
	@%p43 bra 	$L__BB7_463;

	mul.lo.s32 	%r111, %r104, %r104;
	mul.lo.s32 	%r2, %r111, %r1;
	setp.lt.s32 	%p44, %r104, 1;
	mov.f32 	%f510, 0f00000000;
	mov.f32 	%f2978, %f510;
	mov.f32 	%f2979, %f510;
	mov.f32 	%f2980, %f510;
	@%p44 bra 	$L__BB7_11;

	add.s32 	%r3, %r104, -1;
	and.b32  	%r4, %r104, 3;
	sub.s32 	%r5, %r104, %r4;
	shl.b32 	%r6, %r104, 2;
	mov.u32 	%r112, 0;
	setp.lt.u32 	%p45, %r3, 3;
	setp.eq.s32 	%p47, %r4, 0;
	setp.eq.s32 	%p48, %r4, 1;
	setp.eq.s32 	%p49, %r4, 2;
	cvt.s64.s32 	%rd11, %r6;
	mov.u32 	%r837, %r112;

$L__BB7_3:
	cvt.rn.f32.s32 	%f4, %r837;
	mov.u32 	%r840, %r112;
	@%p45 bra 	$L__BB7_6;

	mov.u32 	%r840, %r112;
	mov.u32 	%r839, %r5;

$L__BB7_5:
	mad.lo.s32 	%r115, %r840, %r104, %r837;
	add.s32 	%r116, %r115, %r2;
	mul.wide.s32 	%rd9, %r116, 4;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.f32 	%f515, [%rd10];
	fma.rn.f32 	%f516, %f515, %f4, %f2978;
	cvt.rn.f32.s32 	%f517, %r840;
	fma.rn.f32 	%f518, %f515, %f517, %f2979;
	add.f32 	%f519, %f2980, %f515;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.f32 	%f520, [%rd12];
	fma.rn.f32 	%f521, %f520, %f4, %f516;
	add.s32 	%r117, %r840, 1;
	cvt.rn.f32.s32 	%f522, %r117;
	fma.rn.f32 	%f523, %f520, %f522, %f518;
	add.f32 	%f524, %f519, %f520;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.f32 	%f525, [%rd13];
	fma.rn.f32 	%f526, %f525, %f4, %f521;
	add.s32 	%r118, %r840, 2;
	cvt.rn.f32.s32 	%f527, %r118;
	fma.rn.f32 	%f528, %f525, %f527, %f523;
	add.f32 	%f529, %f524, %f525;
	add.s64 	%rd14, %rd13, %rd11;
	ld.global.f32 	%f530, [%rd14];
	fma.rn.f32 	%f2978, %f530, %f4, %f526;
	add.s32 	%r119, %r840, 3;
	cvt.rn.f32.s32 	%f531, %r119;
	fma.rn.f32 	%f2979, %f530, %f531, %f528;
	add.f32 	%f2980, %f529, %f530;
	add.s32 	%r840, %r840, 4;
	add.s32 	%r839, %r839, -4;
	setp.ne.s32 	%p46, %r839, 0;
	@%p46 bra 	$L__BB7_5;

$L__BB7_6:
	@%p47 bra 	$L__BB7_10;

	mad.lo.s32 	%r13, %r840, %r104, %r837;
	add.s32 	%r120, %r13, %r2;
	mul.wide.s32 	%rd15, %r120, 4;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.f32 	%f532, [%rd16];
	fma.rn.f32 	%f2978, %f532, %f4, %f2978;
	cvt.rn.f32.s32 	%f533, %r840;
	fma.rn.f32 	%f2979, %f532, %f533, %f2979;
	add.f32 	%f2980, %f2980, %f532;
	@%p48 bra 	$L__BB7_10;

	add.s32 	%r14, %r13, %r104;
	add.s32 	%r121, %r14, %r2;
	mul.wide.s32 	%rd17, %r121, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.f32 	%f534, [%rd18];
	fma.rn.f32 	%f2978, %f534, %f4, %f2978;
	add.s32 	%r122, %r840, 1;
	cvt.rn.f32.s32 	%f535, %r122;
	fma.rn.f32 	%f2979, %f534, %f535, %f2979;
	add.f32 	%f2980, %f2980, %f534;
	@%p49 bra 	$L__BB7_10;

	add.s32 	%r123, %r840, 2;
	add.s32 	%r124, %r14, %r104;
	add.s32 	%r125, %r124, %r2;
	mul.wide.s32 	%rd19, %r125, 4;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.f32 	%f536, [%rd20];
	fma.rn.f32 	%f2978, %f536, %f4, %f2978;
	cvt.rn.f32.s32 	%f537, %r123;
	fma.rn.f32 	%f2979, %f536, %f537, %f2979;
	add.f32 	%f2980, %f2980, %f536;

$L__BB7_10:
	add.s32 	%r837, %r837, 1;
	setp.lt.s32 	%p50, %r837, %r104;
	@%p50 bra 	$L__BB7_3;

$L__BB7_11:
	div.rn.f32 	%f3069, %f2978, %f2980;
	div.rn.f32 	%f3068, %f2979, %f2980;
	mov.f32 	%f3066, 0f51BA43B7;
	mov.f32 	%f2987, %f510;
	@%p44 bra 	$L__BB7_51;

	mov.f32 	%f542, 0f3F000000;
	div.rn.f32 	%f543, %f542, %f3064;
	div.rn.f32 	%f544, %f543, %f3064;
	cvt.f64.f32 	%fd1, %f544;
	mov.f64 	%fd246, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd246;
	}
	and.b32  	%r17, %r16, 2146435072;
	and.b32  	%r18, %r16, 2147483647;
	setp.gt.s32 	%p52, %r16, -1;
	selp.b32 	%r19, 2146435072, 0, %p52;
	mov.u32 	%r126, 0;
	or.b32  	%r20, %r19, -2147483648;
	setp.eq.s32 	%p54, %r17, 1062207488;
	setp.lt.s32 	%p55, %r16, 0;
	setp.ne.s32 	%p60, %r18, 1071644672;
	setp.eq.s32 	%p87, %r18, 2146435072;
	mov.u32 	%r841, %r126;
	mov.f32 	%f2987, %f510;

$L__BB7_13:
	mov.u32 	%r842, %r126;

$L__BB7_14:
	mov.f32 	%f2990, 0f00000000;
	mov.f32 	%f2991, %f2990;
	mov.u32 	%r843, %r126;

$L__BB7_15:
	sub.s32 	%r24, %r843, %r841;
	cvt.rn.f32.s32 	%f547, %r24;
	cvt.f64.f32 	%fd2, %f547;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd2;
	}
	abs.f64 	%fd247, %fd2;
	{ // callseq 154, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd247;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd246;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 154
	setp.lt.s32 	%p53, %r25, 0;
	and.pred  	%p1, %p53, %p54;
	selp.b32 	%r130, %r25, 0, %p54;
	or.b32  	%r131, %r130, 2146435072;
	selp.b32 	%r26, %r131, %r130, %p55;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r132}, %fd4;
	}
	and.b32  	%r27, %r132, 2146435072;
	setp.ne.s32 	%p56, %r27, 2146435072;
	setp.gtu.f64 	%p57, %fd247, 0d7FF0000000000000;
	setp.gt.f64 	%p58, %fd247, 0d3FF0000000000000;
	selp.b32 	%r133, 2146435072, 0, %p58;
	xor.b32  	%r134, %r133, 2146435072;
	selp.b32 	%r135, %r134, %r133, %p55;
	setp.eq.s32 	%p59, %r24, -1;
	selp.b32 	%r28, 1072693248, %r135, %p59;
	and.b32  	%r29, %r25, 2147483647;
	and.pred  	%p61, %p60, %p1;
	selp.b32 	%r30, %r20, %r19, %p61;
	mul.lo.s32 	%r31, %r843, %r104;
	or.pred  	%p2, %p56, %p57;
	mov.u32 	%r844, %r126;

$L__BB7_16:
	not.pred 	%p62, %p1;
	mov.f64 	%fd562, %fd3;
	@%p62 bra 	$L__BB7_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r136}, %fd3;
	}
	xor.b32  	%r137, %r136, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r138, %temp}, %fd3;
	}
	mov.b64 	%fd562, {%r138, %r137};

$L__BB7_18:
	setp.eq.s32 	%p63, %r24, 0;
	@%p63 bra 	$L__BB7_22;

	setp.gt.s32 	%p64, %r25, -1;
	@%p64 bra 	$L__BB7_23;

	cvt.rzi.f64.f64 	%fd250, %fd246;
	setp.eq.f64 	%p65, %fd250, 0d4000000000000000;
	@%p65 bra 	$L__BB7_23;

	mov.f64 	%fd562, 0dFFF8000000000000;
	bra.uni 	$L__BB7_23;

$L__BB7_22:
	mov.u32 	%r139, 0;
	mov.b64 	%fd562, {%r139, %r26};

$L__BB7_23:
	selp.f64 	%fd563, %fd562, %fd4, %p56;
	@%p2 bra 	$L__BB7_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd246;
	}
	setp.eq.s32 	%p68, %r140, 0;
	and.pred  	%p69, %p87, %p68;
	@%p69 bra 	$L__BB7_27;
	bra.uni 	$L__BB7_25;

$L__BB7_27:
	mov.u32 	%r143, 0;
	mov.b64 	%fd563, {%r143, %r28};
	bra.uni 	$L__BB7_28;

$L__BB7_25:
	setp.ne.s32 	%p70, %r29, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r141, %temp}, %fd2;
	}
	setp.ne.s32 	%p71, %r141, 0;
	or.pred  	%p72, %p70, %p71;
	mov.f64 	%fd563, %fd562;
	@%p72 bra 	$L__BB7_28;

	mov.u32 	%r142, 0;
	mov.b64 	%fd563, {%r142, %r30};

$L__BB7_28:
	setp.eq.s32 	%p73, %r24, 1;
	selp.f64 	%fd253, 0d3FF0000000000000, %fd563, %p73;
	mov.f64 	%fd254, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd253, %fd1;
	neg.f64 	%fd255, %fd13;
	mov.f64 	%fd256, 0d4338000000000000;
	mov.f64 	%fd257, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd258, %fd255, %fd257, %fd256;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd258;
	}
	mov.f64 	%fd259, 0dC338000000000000;
	add.rn.f64 	%fd260, %fd258, %fd259;
	mov.f64 	%fd261, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd262, %fd260, %fd261, %fd255;
	mov.f64 	%fd263, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd264, %fd260, %fd263, %fd262;
	mov.f64 	%fd265, 0d3E928AF3FCA213EA;
	mov.f64 	%fd266, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd267, %fd266, %fd264, %fd265;
	mov.f64 	%fd268, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd269, %fd267, %fd264, %fd268;
	mov.f64 	%fd270, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd271, %fd269, %fd264, %fd270;
	mov.f64 	%fd272, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd273, %fd271, %fd264, %fd272;
	mov.f64 	%fd274, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd275, %fd273, %fd264, %fd274;
	mov.f64 	%fd276, 0d3F81111111122322;
	fma.rn.f64 	%fd277, %fd275, %fd264, %fd276;
	mov.f64 	%fd278, 0d3FA55555555502A1;
	fma.rn.f64 	%fd279, %fd277, %fd264, %fd278;
	mov.f64 	%fd280, 0d3FC5555555555511;
	fma.rn.f64 	%fd281, %fd279, %fd264, %fd280;
	mov.f64 	%fd282, 0d3FE000000000000B;
	fma.rn.f64 	%fd283, %fd281, %fd264, %fd282;
	fma.rn.f64 	%fd284, %fd283, %fd264, %fd254;
	fma.rn.f64 	%fd285, %fd284, %fd264, %fd254;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd285;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd285;
	}
	shl.b32 	%r144, %r33, 20;
	add.s32 	%r145, %r35, %r144;
	mov.b64 	%fd564, {%r34, %r145};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r146}, %fd255;
	}
	mov.b32 	%f548, %r146;
	abs.f32 	%f42, %f548;
	setp.lt.f32 	%p74, %f42, 0f4086232B;
	@%p74 bra 	$L__BB7_31;

	setp.gt.f64 	%p75, %fd13, 0d8000000000000000;
	mov.f64 	%fd286, 0d7FF0000000000000;
	sub.f64 	%fd287, %fd286, %fd13;
	selp.f64 	%fd564, 0d0000000000000000, %fd287, %p75;
	setp.geu.f32 	%p76, %f42, 0f40874800;
	@%p76 bra 	$L__BB7_31;

	shr.u32 	%r147, %r33, 31;
	add.s32 	%r148, %r33, %r147;
	shr.s32 	%r149, %r148, 1;
	shl.b32 	%r150, %r149, 20;
	add.s32 	%r151, %r35, %r150;
	mov.b64 	%fd288, {%r34, %r151};
	sub.s32 	%r152, %r33, %r149;
	shl.b32 	%r153, %r152, 20;
	add.s32 	%r154, %r153, 1072693248;
	mov.u32 	%r155, 0;
	mov.b64 	%fd289, {%r155, %r154};
	mul.f64 	%fd564, %fd288, %fd289;

$L__BB7_31:
	sub.s32 	%r36, %r842, %r844;
	cvt.rn.f32.s32 	%f549, %r36;
	cvt.f64.f32 	%fd18, %f549;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 155, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd246;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd566, [retval0+0];
	} // callseq 155
	setp.lt.s32 	%p77, %r37, 0;
	and.pred  	%p3, %p77, %p54;
	not.pred 	%p79, %p3;
	@%p79 bra 	$L__BB7_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r156}, %fd566;
	}
	xor.b32  	%r157, %r156, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r158, %temp}, %fd566;
	}
	mov.b64 	%fd566, {%r158, %r157};

$L__BB7_33:
	setp.eq.s32 	%p80, %r36, 0;
	@%p80 bra 	$L__BB7_37;

	setp.gt.s32 	%p81, %r37, -1;
	@%p81 bra 	$L__BB7_38;

	cvt.rzi.f64.f64 	%fd292, %fd246;
	setp.eq.f64 	%p82, %fd292, 0d4000000000000000;
	@%p82 bra 	$L__BB7_38;

	mov.f64 	%fd566, 0dFFF8000000000000;
	bra.uni 	$L__BB7_38;

$L__BB7_37:
	mov.u32 	%r159, 0;
	selp.b32 	%r160, %r37, 0, %p54;
	or.b32  	%r161, %r160, 2146435072;
	selp.b32 	%r162, %r161, %r160, %p55;
	mov.b64 	%fd566, {%r159, %r162};

$L__BB7_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r163}, %fd25;
	}
	and.b32  	%r164, %r163, 2146435072;
	setp.ne.s32 	%p85, %r164, 2146435072;
	mov.f64 	%fd567, %fd566;
	@%p85 bra 	$L__BB7_44;

	setp.gtu.f64 	%p86, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd567, %fd25;
	@%p86 bra 	$L__BB7_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r165, %temp}, %fd246;
	}
	setp.eq.s32 	%p88, %r165, 0;
	and.pred  	%p89, %p87, %p88;
	@%p89 bra 	$L__BB7_43;
	bra.uni 	$L__BB7_41;

$L__BB7_43:
	mov.u32 	%r170, 0;
	setp.gt.f64 	%p96, %fd19, 0d3FF0000000000000;
	selp.b32 	%r171, 2146435072, 0, %p96;
	xor.b32  	%r172, %r171, 2146435072;
	selp.b32 	%r173, %r172, %r171, %p55;
	setp.eq.s32 	%p97, %r36, -1;
	selp.b32 	%r174, 1072693248, %r173, %p97;
	mov.b64 	%fd567, {%r170, %r174};
	bra.uni 	$L__BB7_44;

$L__BB7_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r166, %temp}, %fd18;
	}
	and.b32  	%r167, %r37, 2147483647;
	setp.ne.s32 	%p90, %r167, 2146435072;
	setp.ne.s32 	%p91, %r166, 0;
	or.pred  	%p92, %p90, %p91;
	mov.f64 	%fd567, %fd566;
	@%p92 bra 	$L__BB7_44;

	and.pred  	%p94, %p60, %p3;
	selp.b32 	%r168, %r20, %r19, %p94;
	mov.u32 	%r169, 0;
	mov.b64 	%fd567, {%r169, %r168};

$L__BB7_44:
	setp.eq.s32 	%p98, %r36, 1;
	selp.f64 	%fd295, 0d3FF0000000000000, %fd567, %p98;
	mul.f64 	%fd29, %fd295, %fd1;
	neg.f64 	%fd297, %fd29;
	fma.rn.f64 	%fd300, %fd297, %fd257, %fd256;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd300;
	}
	add.rn.f64 	%fd302, %fd300, %fd259;
	fma.rn.f64 	%fd304, %fd302, %fd261, %fd297;
	fma.rn.f64 	%fd306, %fd302, %fd263, %fd304;
	fma.rn.f64 	%fd309, %fd266, %fd306, %fd265;
	fma.rn.f64 	%fd311, %fd309, %fd306, %fd268;
	fma.rn.f64 	%fd313, %fd311, %fd306, %fd270;
	fma.rn.f64 	%fd315, %fd313, %fd306, %fd272;
	fma.rn.f64 	%fd317, %fd315, %fd306, %fd274;
	fma.rn.f64 	%fd319, %fd317, %fd306, %fd276;
	fma.rn.f64 	%fd321, %fd319, %fd306, %fd278;
	fma.rn.f64 	%fd323, %fd321, %fd306, %fd280;
	fma.rn.f64 	%fd325, %fd323, %fd306, %fd282;
	fma.rn.f64 	%fd326, %fd325, %fd306, %fd254;
	fma.rn.f64 	%fd327, %fd326, %fd306, %fd254;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd327;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd327;
	}
	shl.b32 	%r175, %r38, 20;
	add.s32 	%r176, %r40, %r175;
	mov.b64 	%fd568, {%r39, %r176};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r177}, %fd297;
	}
	mov.b32 	%f550, %r177;
	abs.f32 	%f43, %f550;
	setp.lt.f32 	%p99, %f43, 0f4086232B;
	@%p99 bra 	$L__BB7_47;

	setp.gt.f64 	%p100, %fd29, 0d8000000000000000;
	mov.f64 	%fd328, 0d7FF0000000000000;
	sub.f64 	%fd329, %fd328, %fd29;
	selp.f64 	%fd568, 0d0000000000000000, %fd329, %p100;
	setp.geu.f32 	%p101, %f43, 0f40874800;
	@%p101 bra 	$L__BB7_47;

	shr.u32 	%r178, %r38, 31;
	add.s32 	%r179, %r38, %r178;
	shr.s32 	%r180, %r179, 1;
	shl.b32 	%r181, %r180, 20;
	add.s32 	%r182, %r40, %r181;
	mov.b64 	%fd330, {%r39, %r182};
	sub.s32 	%r183, %r38, %r180;
	shl.b32 	%r184, %r183, 20;
	add.s32 	%r185, %r184, 1072693248;
	mov.u32 	%r186, 0;
	mov.b64 	%fd331, {%r186, %r185};
	mul.f64 	%fd568, %fd330, %fd331;

$L__BB7_47:
	add.s32 	%r187, %r844, %r31;
	add.s32 	%r188, %r187, %r2;
	mul.wide.s32 	%rd21, %r188, 4;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.f32 	%f551, [%rd22];
	cvt.f64.f32 	%fd332, %f551;
	mul.f64 	%fd333, %fd564, %fd568;
	cvt.f64.f32 	%fd334, %f2991;
	fma.rn.f64 	%fd335, %fd333, %fd332, %fd334;
	cvt.rn.f32.f64 	%f2991, %fd335;
	cvt.f64.f32 	%fd336, %f2990;
	add.f64 	%fd337, %fd333, %fd336;
	cvt.rn.f32.f64 	%f2990, %fd337;
	add.s32 	%r844, %r844, 1;
	setp.lt.s32 	%p102, %r844, %r104;
	@%p102 bra 	$L__BB7_16;

	add.s32 	%r843, %r843, 1;
	setp.lt.s32 	%p103, %r843, %r104;
	@%p103 bra 	$L__BB7_15;

	div.rn.f32 	%f552, %f2991, %f2990;
	max.f32 	%f2987, %f2987, %f552;
	min.f32 	%f3066, %f3066, %f552;
	add.s32 	%r842, %r842, 1;
	setp.lt.s32 	%p104, %r842, %r104;
	@%p104 bra 	$L__BB7_14;

	add.s32 	%r841, %r841, 1;
	setp.lt.s32 	%p105, %r841, %r104;
	@%p105 bra 	$L__BB7_13;

$L__BB7_51:
	sub.f32 	%f554, %f2987, %f3066;
	add.f32 	%f555, %f554, %f554;
	fma.rn.f32 	%f556, %f554, 0f40000000, %f555;
	mul.f32 	%f557, %f556, 0f40490FD8;
	mul.f32 	%f558, %f557, %f3064;
	mul.f32 	%f559, %f558, %f3064;
	max.f32 	%f3067, %f510, %f559;
	setp.lt.s32 	%p106, %r106, 1;
	mov.f32 	%f3065, %f3064;
	@%p106 bra 	$L__BB7_373;

	cvt.rn.f32.s32 	%f562, %r104;
	mul.f32 	%f51, %f562, 0f3F000000;
	cvt.rn.f32.s32 	%f52, %r105;
	mov.u32 	%r845, 0;
	cvta.to.global.u64 	%rd23, %rd4;
	mov.f64 	%fd339, 0d4008000000000000;
	mov.f64 	%fd345, 0d4014000000000000;
	cvta.to.global.u64 	%rd29, %rd5;
	mov.f32 	%f3065, %f3064;

$L__BB7_53:
	mov.f32 	%f3013, 0f00000000;
	mov.f32 	%f3014, %f3013;
	mov.f32 	%f3015, %f3013;
	mov.f32 	%f3016, %f3013;
	mov.f32 	%f3017, %f3013;
	mov.f32 	%f3018, %f3013;
	mov.f32 	%f3019, %f3013;
	mov.f32 	%f3020, %f3013;
	mov.f32 	%f3021, %f3013;
	mov.f32 	%f3022, %f3013;
	mov.f32 	%f3023, %f3013;
	mov.f32 	%f3024, %f3013;
	@%p44 bra 	$L__BB7_372;

	mov.f32 	%f3013, 0f00000000;
	mov.f32 	%f587, 0f3F000000;
	div.rn.f32 	%f588, %f587, %f3065;
	div.rn.f32 	%f60, %f588, %f3065;
	div.rn.f32 	%f589, %f587, %f3064;
	div.rn.f32 	%f61, %f589, %f3064;
	div.rn.f32 	%f590, %f3067, 0fC0206C98;
	div.rn.f32 	%f62, %f590, %f3065;
	cvt.f64.f32 	%fd34, %f590;
	div.rn.f32 	%f63, %f590, %f3064;
	div.rn.f32 	%f64, %f62, %f3065;
	mov.f32 	%f591, 0fC0000000;
	div.rn.f32 	%f65, %f591, %f3065;
	div.rn.f32 	%f592, %f3067, 0f40206C98;
	cvt.f64.f32 	%fd35, %f592;
	div.rn.f32 	%f66, %f63, %f3064;
	div.rn.f32 	%f67, %f591, %f3064;
	shl.b32 	%r195, %r1, 1;
	mul.wide.s32 	%rd24, %r195, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.f32 	%f68, [%rd25+4];
	ld.global.f32 	%f69, [%rd25];
	mov.u32 	%r846, 0;

$L__BB7_55:
	mov.u32 	%r847, 0;
	mov.f32 	%f2839, 0f00000000;
	cvt.rn.f32.s32 	%f82, %r846;
	sub.f32 	%f83, %f82, %f3069;
	add.f32 	%f84, %f83, 0f3F000000;
	sqrt.rn.f32 	%f593, %f60;
	mul.f32 	%f594, %f84, %f593;
	abs.f32 	%f85, %f594;
	setp.ge.f32 	%p108, %f85, 0f3F8060FE;
	mul.f32 	%f595, %f594, %f594;
	selp.f32 	%f596, %f85, %f595, %p108;
	selp.f32 	%f597, 0f3789CA3C, 0f38B1E96A, %p108;
	selp.f32 	%f598, 0fB9F560B9, 0fBA574D20, %p108;
	fma.rn.f32 	%f599, %f597, %f596, %f598;
	selp.f32 	%f600, 0f3BAC840B, 0f3BAAD5EA, %p108;
	fma.rn.f32 	%f601, %f599, %f596, %f600;
	selp.f32 	%f602, 0fBD0C8162, 0fBCDC1BE7, %p108;
	fma.rn.f32 	%f603, %f601, %f596, %f602;
	selp.f32 	%f604, 0f3E1CF906, 0f3DE718AF, %p108;
	fma.rn.f32 	%f605, %f603, %f596, %f604;
	selp.f32 	%f606, 0f3F6A937E, 0fBEC093AC, %p108;
	fma.rn.f32 	%f607, %f605, %f596, %f606;
	selp.f32 	%f608, 0f3F20D842, 0f3E0375D3, %p108;
	fma.rn.f32 	%f609, %f607, %f596, %f608;
	neg.f32 	%f610, %f85;
	selp.f32 	%f611, %f610, %f594, %p108;
	fma.rn.f32 	%f86, %f609, %f611, %f611;
	mov.b32 	%r197, %f594;
	and.b32  	%r47, %r197, -2147483648;
	add.f32 	%f87, %f83, 0fBF000000;
	mul.f32 	%f612, %f87, %f593;
	abs.f32 	%f88, %f612;
	setp.ge.f32 	%p109, %f88, 0f3F8060FE;
	mul.f32 	%f613, %f612, %f612;
	selp.f32 	%f614, %f88, %f613, %p109;
	selp.f32 	%f615, 0f3789CA3C, 0f38B1E96A, %p109;
	selp.f32 	%f616, 0fB9F560B9, 0fBA574D20, %p109;
	fma.rn.f32 	%f617, %f615, %f614, %f616;
	selp.f32 	%f618, 0f3BAC840B, 0f3BAAD5EA, %p109;
	fma.rn.f32 	%f619, %f617, %f614, %f618;
	selp.f32 	%f620, 0fBD0C8162, 0fBCDC1BE7, %p109;
	fma.rn.f32 	%f621, %f619, %f614, %f620;
	selp.f32 	%f622, 0f3E1CF906, 0f3DE718AF, %p109;
	fma.rn.f32 	%f623, %f621, %f614, %f622;
	selp.f32 	%f624, 0f3F6A937E, 0fBEC093AC, %p109;
	fma.rn.f32 	%f625, %f623, %f614, %f624;
	selp.f32 	%f626, 0f3F20D842, 0f3E0375D3, %p109;
	fma.rn.f32 	%f627, %f625, %f614, %f626;
	neg.f32 	%f628, %f88;
	selp.f32 	%f629, %f628, %f612, %p109;
	fma.rn.f32 	%f89, %f627, %f629, %f629;
	mov.b32 	%r198, %f612;
	and.b32  	%r48, %r198, -2147483648;
	sqrt.rn.f32 	%f90, %f61;
	add.f32 	%f630, %f82, 0f3F000000;
	sub.f32 	%f91, %f630, %f3069;
	div.rn.f32 	%f92, %f91, %f3065;
	mov.f32 	%f631, 0f3F800000;
	cvt.rzi.f32.f32 	%f632, %f631;
	add.f32 	%f633, %f632, %f632;
	mov.f32 	%f634, 0f40000000;
	sub.f32 	%f635, %f634, %f633;
	abs.f32 	%f93, %f635;
	setp.eq.f32 	%p110, %f93, 0f3F800000;
	abs.f32 	%f94, %f92;
	setp.lt.f32 	%p111, %f94, 0f00800000;
	mul.f32 	%f636, %f94, 0f4B800000;
	selp.f32 	%f637, %f636, %f94, %p111;
	selp.f32 	%f638, 0fC3170000, 0fC2FE0000, %p111;
	mov.b32 	%r199, %f637;
	and.b32  	%r200, %r199, 8388607;
	or.b32  	%r201, %r200, 1065353216;
	mov.b32 	%f639, %r201;
	shr.u32 	%r202, %r199, 23;
	cvt.rn.f32.u32 	%f640, %r202;
	add.f32 	%f641, %f638, %f640;
	setp.gt.f32 	%p112, %f639, 0f3FB504F3;
	mul.f32 	%f642, %f639, 0f3F000000;
	add.f32 	%f643, %f641, 0f3F800000;
	selp.f32 	%f644, %f643, %f641, %p112;
	selp.f32 	%f645, %f642, %f639, %p112;
	add.f32 	%f646, %f645, 0fBF800000;
	add.f32 	%f647, %f645, 0f3F800000;
	rcp.approx.ftz.f32 	%f648, %f647;
	add.f32 	%f649, %f646, %f646;
	mul.f32 	%f650, %f649, %f648;
	mul.f32 	%f651, %f650, %f650;
	mov.f32 	%f652, 0f3C4CAF63;
	mov.f32 	%f653, 0f3B18F0FE;
	fma.rn.f32 	%f654, %f653, %f651, %f652;
	mov.f32 	%f655, 0f3DAAAABD;
	fma.rn.f32 	%f656, %f654, %f651, %f655;
	mul.rn.f32 	%f657, %f656, %f651;
	mul.rn.f32 	%f658, %f657, %f650;
	sub.f32 	%f659, %f646, %f650;
	add.f32 	%f660, %f659, %f659;
	neg.f32 	%f661, %f650;
	fma.rn.f32 	%f662, %f661, %f646, %f660;
	mul.rn.f32 	%f663, %f648, %f662;
	add.f32 	%f664, %f658, %f650;
	sub.f32 	%f665, %f650, %f664;
	add.f32 	%f666, %f658, %f665;
	add.f32 	%f667, %f663, %f666;
	add.f32 	%f668, %f664, %f667;
	sub.f32 	%f669, %f664, %f668;
	add.f32 	%f670, %f667, %f669;
	mov.f32 	%f671, 0f3F317200;
	mul.rn.f32 	%f672, %f644, %f671;
	mov.f32 	%f673, 0f35BFBE8E;
	mul.rn.f32 	%f674, %f644, %f673;
	add.f32 	%f675, %f672, %f668;
	sub.f32 	%f676, %f672, %f675;
	add.f32 	%f677, %f668, %f676;
	add.f32 	%f678, %f670, %f677;
	add.f32 	%f679, %f674, %f678;
	add.f32 	%f680, %f675, %f679;
	sub.f32 	%f681, %f675, %f680;
	add.f32 	%f682, %f679, %f681;
	mul.rn.f32 	%f683, %f634, %f680;
	neg.f32 	%f684, %f683;
	fma.rn.f32 	%f685, %f634, %f680, %f684;
	fma.rn.f32 	%f686, %f634, %f682, %f685;
	fma.rn.f32 	%f688, %f2839, %f680, %f686;
	add.rn.f32 	%f689, %f683, %f688;
	neg.f32 	%f690, %f689;
	add.rn.f32 	%f691, %f683, %f690;
	add.rn.f32 	%f692, %f691, %f688;
	mov.b32 	%r203, %f689;
	setp.eq.s32 	%p113, %r203, 1118925336;
	add.s32 	%r204, %r203, -1;
	mov.b32 	%f693, %r204;
	add.f32 	%f694, %f692, 0f37000000;
	selp.f32 	%f95, %f694, %f692, %p113;
	selp.f32 	%f695, %f693, %f689, %p113;
	mov.f32 	%f696, 0f3FB8AA3B;
	mul.rn.f32 	%f697, %f695, %f696;
	cvt.rzi.f32.f32 	%f698, %f697;
	abs.f32 	%f699, %f698;
	setp.gt.f32 	%p114, %f699, 0f42FC0000;
	mov.b32 	%r205, %f698;
	and.b32  	%r206, %r205, -2147483648;
	or.b32  	%r207, %r206, 1123811328;
	mov.b32 	%f700, %r207;
	selp.f32 	%f701, %f700, %f698, %p114;
	mov.f32 	%f702, 0fBF317218;
	fma.rn.f32 	%f703, %f701, %f702, %f695;
	mov.f32 	%f704, 0f3102E308;
	fma.rn.f32 	%f705, %f701, %f704, %f703;
	mul.f32 	%f706, %f705, 0f3FB8AA3B;
	add.f32 	%f707, %f701, 0f4B40007F;
	mov.b32 	%r208, %f707;
	shl.b32 	%r209, %r208, 23;
	mov.b32 	%f708, %r209;
	ex2.approx.ftz.f32 	%f709, %f706;
	mul.f32 	%f96, %f709, %f708;
	setp.lt.f32 	%p115, %f92, 0f00000000;
	and.pred  	%p4, %p115, %p110;
	div.rn.f32 	%f97, %f87, %f3065;
	abs.f32 	%f98, %f97;
	setp.lt.f32 	%p116, %f98, 0f00800000;
	mul.f32 	%f710, %f98, 0f4B800000;
	selp.f32 	%f711, %f710, %f98, %p116;
	selp.f32 	%f712, 0fC3170000, 0fC2FE0000, %p116;
	mov.b32 	%r210, %f711;
	and.b32  	%r211, %r210, 8388607;
	or.b32  	%r212, %r211, 1065353216;
	mov.b32 	%f713, %r212;
	shr.u32 	%r213, %r210, 23;
	cvt.rn.f32.u32 	%f714, %r213;
	add.f32 	%f715, %f712, %f714;
	setp.gt.f32 	%p117, %f713, 0f3FB504F3;
	mul.f32 	%f716, %f713, 0f3F000000;
	add.f32 	%f717, %f715, 0f3F800000;
	selp.f32 	%f718, %f717, %f715, %p117;
	selp.f32 	%f719, %f716, %f713, %p117;
	add.f32 	%f720, %f719, 0fBF800000;
	add.f32 	%f721, %f719, 0f3F800000;
	rcp.approx.ftz.f32 	%f722, %f721;
	add.f32 	%f723, %f720, %f720;
	mul.f32 	%f724, %f723, %f722;
	mul.f32 	%f725, %f724, %f724;
	fma.rn.f32 	%f726, %f653, %f725, %f652;
	fma.rn.f32 	%f727, %f726, %f725, %f655;
	mul.rn.f32 	%f728, %f727, %f725;
	mul.rn.f32 	%f729, %f728, %f724;
	sub.f32 	%f730, %f720, %f724;
	add.f32 	%f731, %f730, %f730;
	neg.f32 	%f732, %f724;
	fma.rn.f32 	%f733, %f732, %f720, %f731;
	mul.rn.f32 	%f734, %f722, %f733;
	add.f32 	%f735, %f729, %f724;
	sub.f32 	%f736, %f724, %f735;
	add.f32 	%f737, %f729, %f736;
	add.f32 	%f738, %f734, %f737;
	add.f32 	%f739, %f735, %f738;
	sub.f32 	%f740, %f735, %f739;
	add.f32 	%f741, %f738, %f740;
	mul.rn.f32 	%f742, %f718, %f671;
	mul.rn.f32 	%f743, %f718, %f673;
	add.f32 	%f744, %f742, %f739;
	sub.f32 	%f745, %f742, %f744;
	add.f32 	%f746, %f739, %f745;
	add.f32 	%f747, %f741, %f746;
	add.f32 	%f748, %f743, %f747;
	add.f32 	%f749, %f744, %f748;
	sub.f32 	%f750, %f744, %f749;
	add.f32 	%f751, %f748, %f750;
	mul.rn.f32 	%f752, %f634, %f749;
	neg.f32 	%f753, %f752;
	fma.rn.f32 	%f754, %f634, %f749, %f753;
	fma.rn.f32 	%f755, %f634, %f751, %f754;
	fma.rn.f32 	%f756, %f2839, %f749, %f755;
	add.rn.f32 	%f757, %f752, %f756;
	neg.f32 	%f758, %f757;
	add.rn.f32 	%f759, %f752, %f758;
	add.rn.f32 	%f760, %f759, %f756;
	mov.b32 	%r214, %f757;
	setp.eq.s32 	%p118, %r214, 1118925336;
	add.s32 	%r215, %r214, -1;
	mov.b32 	%f761, %r215;
	add.f32 	%f762, %f760, 0f37000000;
	selp.f32 	%f99, %f762, %f760, %p118;
	selp.f32 	%f763, %f761, %f757, %p118;
	mul.rn.f32 	%f764, %f763, %f696;
	cvt.rzi.f32.f32 	%f765, %f764;
	abs.f32 	%f766, %f765;
	setp.gt.f32 	%p119, %f766, 0f42FC0000;
	mov.b32 	%r216, %f765;
	and.b32  	%r217, %r216, -2147483648;
	or.b32  	%r218, %r217, 1123811328;
	mov.b32 	%f767, %r218;
	selp.f32 	%f768, %f767, %f765, %p119;
	fma.rn.f32 	%f769, %f768, %f702, %f763;
	fma.rn.f32 	%f770, %f768, %f704, %f769;
	mul.f32 	%f771, %f770, 0f3FB8AA3B;
	add.f32 	%f772, %f768, 0f4B40007F;
	mov.b32 	%r219, %f772;
	shl.b32 	%r220, %r219, 23;
	mov.b32 	%f773, %r220;
	ex2.approx.ftz.f32 	%f774, %f771;
	mul.f32 	%f100, %f774, %f773;
	cvt.f64.f32 	%fd338, %f3065;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd338;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd339;
	}
	and.b32  	%r51, %r50, 2146435072;
	setp.eq.s32 	%p121, %r51, 1073741824;
	abs.f64 	%fd340, %fd338;
	{ // callseq 156, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd340;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd36, [retval0+0];
	} // callseq 156
	setp.lt.s32 	%p122, %r49, 0;
	and.pred  	%p6, %p122, %p121;
	setp.lt.s32 	%p123, %r50, 0;
	add.f64 	%fd341, %fd338, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r221}, %fd341;
	}
	and.b32  	%r52, %r221, 2146435072;
	setp.ne.s32 	%p124, %r52, 2146435072;
	setp.gtu.f64 	%p125, %fd340, 0d7FF0000000000000;
	and.b32  	%r53, %r50, 2147483647;
	setp.gt.f64 	%p126, %fd340, 0d3FF0000000000000;
	selp.b32 	%r222, 2146435072, 0, %p126;
	xor.b32  	%r223, %r222, 2146435072;
	selp.b32 	%r224, %r223, %r222, %p123;
	setp.eq.f32 	%p127, %f3065, 0fBF800000;
	selp.b32 	%r54, 1072693248, %r224, %p127;
	setp.gt.s32 	%p128, %r50, -1;
	selp.b32 	%r55, 2146435072, 0, %p128;
	cvt.f64.f32 	%fd342, %f3064;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd342;
	}
	abs.f64 	%fd343, %fd342;
	{ // callseq 157, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd37, [retval0+0];
	} // callseq 157
	setp.lt.s32 	%p129, %r56, 0;
	and.pred  	%p7, %p129, %p121;
	add.f64 	%fd344, %fd342, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r225}, %fd344;
	}
	and.b32  	%r57, %r225, 2146435072;
	setp.ne.s32 	%p130, %r57, 2146435072;
	setp.gtu.f64 	%p131, %fd343, 0d7FF0000000000000;
	add.f32 	%f775, %f82, 0f3F800000;
	sub.f32 	%f776, %f775, %f3069;
	div.rn.f32 	%f101, %f776, %f3065;
	abs.f32 	%f102, %f101;
	setp.lt.f32 	%p132, %f102, 0f00800000;
	mul.f32 	%f777, %f102, 0f4B800000;
	selp.f32 	%f778, %f777, %f102, %p132;
	selp.f32 	%f779, 0fC3170000, 0fC2FE0000, %p132;
	mov.b32 	%r226, %f778;
	and.b32  	%r227, %r226, 8388607;
	or.b32  	%r228, %r227, 1065353216;
	mov.b32 	%f780, %r228;
	shr.u32 	%r229, %r226, 23;
	cvt.rn.f32.u32 	%f781, %r229;
	add.f32 	%f782, %f779, %f781;
	setp.gt.f32 	%p133, %f780, 0f3FB504F3;
	mul.f32 	%f783, %f780, 0f3F000000;
	add.f32 	%f784, %f782, 0f3F800000;
	selp.f32 	%f785, %f784, %f782, %p133;
	selp.f32 	%f786, %f783, %f780, %p133;
	add.f32 	%f787, %f786, 0fBF800000;
	add.f32 	%f788, %f786, 0f3F800000;
	rcp.approx.ftz.f32 	%f789, %f788;
	add.f32 	%f790, %f787, %f787;
	mul.f32 	%f791, %f790, %f789;
	mul.f32 	%f792, %f791, %f791;
	fma.rn.f32 	%f793, %f653, %f792, %f652;
	fma.rn.f32 	%f794, %f793, %f792, %f655;
	mul.rn.f32 	%f795, %f794, %f792;
	mul.rn.f32 	%f796, %f795, %f791;
	sub.f32 	%f797, %f787, %f791;
	add.f32 	%f798, %f797, %f797;
	neg.f32 	%f799, %f791;
	fma.rn.f32 	%f800, %f799, %f787, %f798;
	mul.rn.f32 	%f801, %f789, %f800;
	add.f32 	%f802, %f796, %f791;
	sub.f32 	%f803, %f791, %f802;
	add.f32 	%f804, %f796, %f803;
	add.f32 	%f805, %f801, %f804;
	add.f32 	%f806, %f802, %f805;
	sub.f32 	%f807, %f802, %f806;
	add.f32 	%f808, %f805, %f807;
	mul.rn.f32 	%f809, %f785, %f671;
	mul.rn.f32 	%f810, %f785, %f673;
	add.f32 	%f811, %f809, %f806;
	sub.f32 	%f812, %f809, %f811;
	add.f32 	%f813, %f806, %f812;
	add.f32 	%f814, %f808, %f813;
	add.f32 	%f815, %f810, %f814;
	add.f32 	%f816, %f811, %f815;
	sub.f32 	%f817, %f811, %f816;
	add.f32 	%f818, %f815, %f817;
	mul.rn.f32 	%f819, %f634, %f816;
	neg.f32 	%f820, %f819;
	fma.rn.f32 	%f821, %f634, %f816, %f820;
	fma.rn.f32 	%f822, %f634, %f818, %f821;
	fma.rn.f32 	%f823, %f2839, %f816, %f822;
	add.rn.f32 	%f824, %f819, %f823;
	neg.f32 	%f825, %f824;
	add.rn.f32 	%f826, %f819, %f825;
	add.rn.f32 	%f827, %f826, %f823;
	mov.b32 	%r230, %f824;
	setp.eq.s32 	%p134, %r230, 1118925336;
	add.s32 	%r231, %r230, -1;
	mov.b32 	%f828, %r231;
	add.f32 	%f829, %f827, 0f37000000;
	selp.f32 	%f103, %f829, %f827, %p134;
	selp.f32 	%f830, %f828, %f824, %p134;
	mul.rn.f32 	%f831, %f830, %f696;
	cvt.rzi.f32.f32 	%f832, %f831;
	abs.f32 	%f833, %f832;
	setp.gt.f32 	%p135, %f833, 0f42FC0000;
	mov.b32 	%r232, %f832;
	and.b32  	%r233, %r232, -2147483648;
	or.b32  	%r234, %r233, 1123811328;
	mov.b32 	%f834, %r234;
	selp.f32 	%f835, %f834, %f832, %p135;
	fma.rn.f32 	%f836, %f835, %f702, %f830;
	fma.rn.f32 	%f837, %f835, %f704, %f836;
	mul.f32 	%f838, %f837, 0f3FB8AA3B;
	add.f32 	%f839, %f835, 0f4B40007F;
	mov.b32 	%r235, %f839;
	shl.b32 	%r236, %r235, 23;
	mov.b32 	%f840, %r236;
	ex2.approx.ftz.f32 	%f841, %f838;
	mul.f32 	%f104, %f841, %f840;
	setp.gt.f64 	%p137, %fd343, 0d3FF0000000000000;
	selp.b32 	%r237, 2146435072, 0, %p137;
	xor.b32  	%r238, %r237, 2146435072;
	selp.b32 	%r239, %r238, %r237, %p123;
	setp.eq.f32 	%p138, %f3064, 0fBF800000;
	selp.b32 	%r58, 1072693248, %r239, %p138;
	div.rn.f32 	%f105, %f83, %f3065;
	abs.f32 	%f106, %f105;
	setp.lt.f32 	%p139, %f106, 0f00800000;
	mul.f32 	%f842, %f106, 0f4B800000;
	selp.f32 	%f843, %f842, %f106, %p139;
	selp.f32 	%f844, 0fC3170000, 0fC2FE0000, %p139;
	mov.b32 	%r240, %f843;
	and.b32  	%r241, %r240, 8388607;
	or.b32  	%r242, %r241, 1065353216;
	mov.b32 	%f845, %r242;
	shr.u32 	%r243, %r240, 23;
	cvt.rn.f32.u32 	%f846, %r243;
	add.f32 	%f847, %f844, %f846;
	setp.gt.f32 	%p140, %f845, 0f3FB504F3;
	mul.f32 	%f848, %f845, 0f3F000000;
	add.f32 	%f849, %f847, 0f3F800000;
	selp.f32 	%f850, %f849, %f847, %p140;
	selp.f32 	%f851, %f848, %f845, %p140;
	add.f32 	%f852, %f851, 0fBF800000;
	add.f32 	%f853, %f851, 0f3F800000;
	rcp.approx.ftz.f32 	%f854, %f853;
	add.f32 	%f855, %f852, %f852;
	mul.f32 	%f856, %f855, %f854;
	mul.f32 	%f857, %f856, %f856;
	fma.rn.f32 	%f858, %f653, %f857, %f652;
	fma.rn.f32 	%f859, %f858, %f857, %f655;
	mul.rn.f32 	%f860, %f859, %f857;
	mul.rn.f32 	%f861, %f860, %f856;
	sub.f32 	%f862, %f852, %f856;
	add.f32 	%f863, %f862, %f862;
	neg.f32 	%f864, %f856;
	fma.rn.f32 	%f865, %f864, %f852, %f863;
	mul.rn.f32 	%f866, %f854, %f865;
	add.f32 	%f867, %f861, %f856;
	sub.f32 	%f868, %f856, %f867;
	add.f32 	%f869, %f861, %f868;
	add.f32 	%f870, %f866, %f869;
	add.f32 	%f871, %f867, %f870;
	sub.f32 	%f872, %f867, %f871;
	add.f32 	%f873, %f870, %f872;
	mul.rn.f32 	%f874, %f850, %f671;
	mul.rn.f32 	%f875, %f850, %f673;
	add.f32 	%f876, %f874, %f871;
	sub.f32 	%f877, %f874, %f876;
	add.f32 	%f878, %f871, %f877;
	add.f32 	%f879, %f873, %f878;
	add.f32 	%f880, %f875, %f879;
	add.f32 	%f881, %f876, %f880;
	sub.f32 	%f882, %f876, %f881;
	add.f32 	%f883, %f880, %f882;
	mul.rn.f32 	%f884, %f634, %f881;
	neg.f32 	%f885, %f884;
	fma.rn.f32 	%f886, %f634, %f881, %f885;
	fma.rn.f32 	%f887, %f634, %f883, %f886;
	fma.rn.f32 	%f888, %f2839, %f881, %f887;
	add.rn.f32 	%f889, %f884, %f888;
	neg.f32 	%f890, %f889;
	add.rn.f32 	%f891, %f884, %f890;
	add.rn.f32 	%f892, %f891, %f888;
	mov.b32 	%r244, %f889;
	setp.eq.s32 	%p141, %r244, 1118925336;
	add.s32 	%r245, %r244, -1;
	mov.b32 	%f893, %r245;
	add.f32 	%f894, %f892, 0f37000000;
	selp.f32 	%f107, %f894, %f892, %p141;
	selp.f32 	%f895, %f893, %f889, %p141;
	mul.rn.f32 	%f896, %f895, %f696;
	cvt.rzi.f32.f32 	%f897, %f896;
	abs.f32 	%f898, %f897;
	setp.gt.f32 	%p142, %f898, 0f42FC0000;
	mov.b32 	%r246, %f897;
	and.b32  	%r247, %r246, -2147483648;
	or.b32  	%r248, %r247, 1123811328;
	mov.b32 	%f899, %r248;
	selp.f32 	%f900, %f899, %f897, %p142;
	fma.rn.f32 	%f901, %f900, %f702, %f895;
	fma.rn.f32 	%f902, %f900, %f704, %f901;
	mul.f32 	%f903, %f902, 0f3FB8AA3B;
	add.f32 	%f904, %f900, 0f4B40007F;
	mov.b32 	%r249, %f904;
	shl.b32 	%r250, %r249, 23;
	mov.b32 	%f905, %r250;
	ex2.approx.ftz.f32 	%f906, %f903;
	mul.f32 	%f108, %f906, %f905;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r251}, %fd345;
	}
	and.b32  	%r252, %r251, 2146435072;
	setp.eq.s32 	%p144, %r252, 1074790400;
	{ // callseq 158, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd340;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd345;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd38, [retval0+0];
	} // callseq 158
	and.pred  	%p10, %p122, %p144;
	selp.b32 	%r253, %r49, 0, %p144;
	setp.lt.s32 	%p145, %r251, 0;
	or.b32  	%r254, %r253, 2146435072;
	selp.b32 	%r59, %r254, %r253, %p145;
	add.f64 	%fd346, %fd338, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r255}, %fd346;
	}
	and.b32  	%r60, %r255, 2146435072;
	setp.ne.s32 	%p146, %r60, 2146435072;
	cvt.f64.f32 	%fd39, %f84;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd39;
	}
	abs.f64 	%fd347, %fd39;
	{ // callseq 159, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd347;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd40, [retval0+0];
	} // callseq 159
	setp.lt.s32 	%p147, %r61, 0;
	and.pred  	%p11, %p147, %p121;
	and.b32  	%r62, %r251, 2147483647;
	selp.b32 	%r256, %r223, %r222, %p145;
	selp.b32 	%r63, 1072693248, %r256, %p127;
	add.f64 	%fd41, %fd39, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r257}, %fd41;
	}
	and.b32  	%r64, %r257, 2146435072;
	setp.ne.s32 	%p148, %r64, 2146435072;
	setp.gt.s32 	%p149, %r251, -1;
	selp.b32 	%r258, 2146435072, 0, %p149;
	setp.ne.s32 	%p150, %r62, 1071644672;
	and.pred  	%p151, %p150, %p10;
	or.b32  	%r259, %r258, -2147483648;
	selp.b32 	%r65, %r259, %r258, %p151;
	setp.gtu.f64 	%p152, %fd347, 0d7FF0000000000000;
	cvt.f64.f32 	%fd42, %f87;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd42;
	}
	abs.f64 	%fd348, %fd42;
	{ // callseq 160, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd348;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd43, [retval0+0];
	} // callseq 160
	setp.lt.s32 	%p153, %r66, 0;
	and.pred  	%p12, %p153, %p121;
	setp.gt.f64 	%p154, %fd347, 0d3FF0000000000000;
	selp.b32 	%r260, 2146435072, 0, %p154;
	xor.b32  	%r261, %r260, 2146435072;
	selp.b32 	%r262, %r261, %r260, %p123;
	setp.eq.f32 	%p155, %f84, 0fBF800000;
	selp.b32 	%r67, 1072693248, %r262, %p155;
	add.f64 	%fd44, %fd42, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r263}, %fd44;
	}
	and.b32  	%r68, %r263, 2146435072;
	setp.ne.s32 	%p156, %r68, 2146435072;
	setp.gtu.f64 	%p157, %fd348, 0d7FF0000000000000;
	setp.gt.f64 	%p158, %fd348, 0d3FF0000000000000;
	selp.b32 	%r264, 2146435072, 0, %p158;
	xor.b32  	%r265, %r264, 2146435072;
	selp.b32 	%r266, %r265, %r264, %p123;
	setp.eq.f32 	%p159, %f87, 0fBF800000;
	selp.b32 	%r69, 1072693248, %r266, %p159;
	{ // callseq 161, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd345;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd45, [retval0+0];
	} // callseq 161
	and.pred  	%p13, %p129, %p144;
	selp.b32 	%r267, %r56, 0, %p144;
	or.b32  	%r268, %r267, 2146435072;
	selp.b32 	%r70, %r268, %r267, %p145;
	add.f64 	%fd349, %fd342, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r269}, %fd349;
	}
	and.b32  	%r71, %r269, 2146435072;
	setp.ne.s32 	%p160, %r71, 2146435072;
	selp.b32 	%r270, %r238, %r237, %p145;
	selp.b32 	%r72, 1072693248, %r270, %p138;
	and.pred  	%p161, %p150, %p13;
	selp.b32 	%r73, %r259, %r258, %p161;
	mov.f64 	%fd350, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd350;
	}
	and.b32  	%r75, %r74, 2147483647;
	setp.gt.s32 	%p162, %r74, -1;
	selp.b32 	%r76, 2146435072, 0, %p162;
	or.pred  	%p16, %p124, %p125;
	or.pred  	%p17, %p130, %p131;
	or.pred  	%p20, %p146, %p125;
	or.pred  	%p21, %p148, %p152;
	or.pred  	%p22, %p156, %p157;
	or.pred  	%p23, %p160, %p131;
	shr.s32 	%r271, %r74, 31;
	and.b32  	%r77, %r271, 2146435072;

$L__BB7_56:
	cvt.rn.f32.s32 	%f2844, %r846;
	sub.f32 	%f2843, %f2844, %f3069;
	add.f32 	%f2842, %f2843, 0f3F000000;
	mul.f32 	%f2841, %f2842, %f593;
	abs.f32 	%f2840, %f2841;
	setp.ltu.f32 	%p163, %f2840, 0f3F8060FE;
	mov.f32 	%f3025, %f86;
	@%p163 bra 	$L__BB7_58;

	mov.f32 	%f2950, 0f3F800000;
	ex2.approx.ftz.f32 	%f907, %f86;
	sub.f32 	%f909, %f2950, %f907;
	mov.b32 	%r272, %f909;
	or.b32  	%r273, %r47, %r272;
	mov.b32 	%f3025, %r273;

$L__BB7_58:
	cvt.rn.f32.s32 	%f2849, %r846;
	sub.f32 	%f2848, %f2849, %f3069;
	add.f32 	%f2847, %f2848, 0fBF000000;
	mul.f32 	%f2846, %f2847, %f593;
	abs.f32 	%f2845, %f2846;
	setp.ltu.f32 	%p164, %f2845, 0f3F8060FE;
	mov.f32 	%f3026, %f89;
	@%p164 bra 	$L__BB7_60;

	mov.f32 	%f2949, 0f3F800000;
	ex2.approx.ftz.f32 	%f910, %f89;
	sub.f32 	%f912, %f2949, %f910;
	mov.b32 	%r274, %f912;
	or.b32  	%r275, %r48, %r274;
	mov.b32 	%f3026, %r275;

$L__BB7_60:
	sub.f32 	%f913, %f3025, %f3026;
	mul.f32 	%f125, %f913, 0f3F000000;
	cvt.rn.f32.s32 	%f126, %r847;
	sub.f32 	%f127, %f126, %f3068;
	add.f32 	%f128, %f127, 0f3F000000;
	mul.f32 	%f129, %f128, %f90;
	abs.f32 	%f914, %f129;
	setp.ltu.f32 	%p165, %f914, 0f3F8060FE;
	setp.ge.f32 	%p166, %f914, 0f3F8060FE;
	mul.f32 	%f915, %f129, %f129;
	selp.f32 	%f916, %f914, %f915, %p166;
	selp.f32 	%f917, 0f3789CA3C, 0f38B1E96A, %p166;
	selp.f32 	%f918, 0fB9F560B9, 0fBA574D20, %p166;
	fma.rn.f32 	%f919, %f917, %f916, %f918;
	selp.f32 	%f920, 0f3BAC840B, 0f3BAAD5EA, %p166;
	fma.rn.f32 	%f921, %f919, %f916, %f920;
	selp.f32 	%f922, 0fBD0C8162, 0fBCDC1BE7, %p166;
	fma.rn.f32 	%f923, %f921, %f916, %f922;
	selp.f32 	%f924, 0f3E1CF906, 0f3DE718AF, %p166;
	fma.rn.f32 	%f925, %f923, %f916, %f924;
	selp.f32 	%f926, 0f3F6A937E, 0fBEC093AC, %p166;
	fma.rn.f32 	%f927, %f925, %f916, %f926;
	selp.f32 	%f928, 0f3F20D842, 0f3E0375D3, %p166;
	fma.rn.f32 	%f929, %f927, %f916, %f928;
	neg.f32 	%f930, %f914;
	selp.f32 	%f931, %f930, %f129, %p166;
	fma.rn.f32 	%f3027, %f929, %f931, %f931;
	@%p165 bra 	$L__BB7_62;

	mov.f32 	%f2948, 0f3F800000;
	ex2.approx.ftz.f32 	%f932, %f3027;
	sub.f32 	%f934, %f2948, %f932;
	mov.b32 	%r276, %f934;
	mov.b32 	%r277, %f129;
	and.b32  	%r278, %r277, -2147483648;
	or.b32  	%r279, %r278, %r276;
	mov.b32 	%f3027, %r279;

$L__BB7_62:
	cvt.rn.f32.s32 	%f2851, %r847;
	sub.f32 	%f2850, %f2851, %f3068;
	add.f32 	%f133, %f2850, 0fBF000000;
	mul.f32 	%f134, %f133, %f90;
	abs.f32 	%f935, %f134;
	setp.ltu.f32 	%p167, %f935, 0f3F8060FE;
	setp.ge.f32 	%p168, %f935, 0f3F8060FE;
	mul.f32 	%f936, %f134, %f134;
	selp.f32 	%f937, %f935, %f936, %p168;
	selp.f32 	%f938, 0f3789CA3C, 0f38B1E96A, %p168;
	selp.f32 	%f939, 0fB9F560B9, 0fBA574D20, %p168;
	fma.rn.f32 	%f940, %f938, %f937, %f939;
	selp.f32 	%f941, 0f3BAC840B, 0f3BAAD5EA, %p168;
	fma.rn.f32 	%f942, %f940, %f937, %f941;
	selp.f32 	%f943, 0fBD0C8162, 0fBCDC1BE7, %p168;
	fma.rn.f32 	%f944, %f942, %f937, %f943;
	selp.f32 	%f945, 0f3E1CF906, 0f3DE718AF, %p168;
	fma.rn.f32 	%f946, %f944, %f937, %f945;
	selp.f32 	%f947, 0f3F6A937E, 0fBEC093AC, %p168;
	fma.rn.f32 	%f948, %f946, %f937, %f947;
	selp.f32 	%f949, 0f3F20D842, 0f3E0375D3, %p168;
	fma.rn.f32 	%f950, %f948, %f937, %f949;
	neg.f32 	%f951, %f935;
	selp.f32 	%f952, %f951, %f134, %p168;
	fma.rn.f32 	%f3028, %f950, %f952, %f952;
	@%p167 bra 	$L__BB7_64;

	mov.f32 	%f2947, 0f3F800000;
	ex2.approx.ftz.f32 	%f953, %f3028;
	sub.f32 	%f955, %f2947, %f953;
	mov.b32 	%r280, %f955;
	mov.b32 	%r281, %f134;
	and.b32  	%r282, %r281, -2147483648;
	or.b32  	%r283, %r282, %r280;
	mov.b32 	%f3028, %r283;

$L__BB7_64:
	cvt.rn.f32.s32 	%f2852, %r846;
	sub.f32 	%f957, %f3027, %f3028;
	mul.f32 	%f138, %f957, 0f3F000000;
	mul.f32 	%f958, %f125, %f3067;
	fma.rn.f32 	%f139, %f138, %f958, %f3066;
	mad.lo.s32 	%r284, %r847, %r104, %r846;
	add.s32 	%r285, %r284, %r2;
	mul.wide.s32 	%rd27, %r285, 4;
	add.s64 	%rd28, %rd1, %rd27;
	ld.global.f32 	%f140, [%rd28];
	add.f32 	%f959, %f68, %f126;
	fma.rn.f32 	%f960, %f959, %f52, %f69;
	add.f32 	%f961, %f960, %f2852;
	cvt.rzi.s32.f32 	%r286, %f961;
	mul.wide.s32 	%rd30, %r286, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.f32 	%f3063, [%rd31];
	setp.eq.f32 	%p169, %f96, 0f7F800000;
	mov.f32 	%f3029, 0f7F800000;
	@%p169 bra 	$L__BB7_66;

	fma.rn.f32 	%f3029, %f96, %f95, %f96;

$L__BB7_66:
	setp.geu.f32 	%p728, %f92, 0f00000000;
	mov.b32 	%r287, %f3029;
	xor.b32  	%r288, %r287, -2147483648;
	mov.b32 	%f962, %r288;
	selp.f32 	%f144, %f962, %f3029, %p4;
	add.f32 	%f963, %f92, %f92;
	selp.f32 	%f964, %f963, 0f00000000, %p110;
	setp.eq.f32 	%p171, %f92, 0f00000000;
	selp.f32 	%f3030, %f964, %f144, %p171;
	@%p728 bra 	$L__BB7_69;

	cvt.rzi.f32.f32 	%f966, %f634;
	setp.eq.f32 	%p172, %f966, 0f40000000;
	mov.f32 	%f3030, %f144;
	@%p172 bra 	$L__BB7_69;

	mov.f32 	%f3030, 0f7FFFFFFF;

$L__BB7_69:
	mov.f32 	%f2855, 0f3FB8AA3B;
	mov.f32 	%f2854, 0f3F000000;
	abs.f32 	%f2853, %f92;
	add.f32 	%f969, %f2853, 0f40000000;
	mov.b32 	%r289, %f969;
	setp.gt.s32 	%p173, %r289, 2139095039;
	add.f32 	%f970, %f92, 0f40000000;
	setp.gtu.f32 	%p174, %f2853, 0f7F800000;
	mov.f32 	%f3031, 0f7F800000;
	selp.f32 	%f971, %f970, %f3030, %p174;
	selp.f32 	%f972, 0fFF800000, 0f7F800000, %p4;
	setp.neu.f32 	%p175, %f2853, 0f7F800000;
	selp.f32 	%f973, %f971, %f972, %p175;
	selp.f32 	%f974, %f973, %f3030, %p173;
	mul.f32 	%f975, %f974, 0fBF000000;
	setp.eq.f32 	%p176, %f92, 0f3F800000;
	selp.f32 	%f976, 0fBF000000, %f975, %p176;
	mov.f32 	%f978, 0f3BBB989D;
	fma.rn.f32 	%f979, %f976, %f978, %f2854;
	mov.f32 	%f981, 0f437C0000;
	cvt.sat.f32.f32 	%f982, %f979;
	mov.f32 	%f983, 0f4B400001;
	fma.rm.f32 	%f984, %f982, %f981, %f983;
	add.f32 	%f985, %f984, 0fCB40007F;
	neg.f32 	%f986, %f985;
	fma.rn.f32 	%f987, %f976, %f2855, %f986;
	mov.f32 	%f988, 0f32A57060;
	fma.rn.f32 	%f989, %f976, %f988, %f987;
	mov.b32 	%r290, %f984;
	shl.b32 	%r291, %r290, 23;
	mov.b32 	%f990, %r291;
	ex2.approx.ftz.f32 	%f991, %f989;
	mul.f32 	%f147, %f991, %f990;
	setp.eq.f32 	%p177, %f100, 0f7F800000;
	@%p177 bra 	$L__BB7_71;

	fma.rn.f32 	%f3031, %f100, %f99, %f100;

$L__BB7_71:
	setp.geu.f32 	%p731, %f97, 0f00000000;
	setp.lt.f32 	%p730, %f97, 0f00000000;
	and.pred  	%p729, %p730, %p110;
	mov.b32 	%r292, %f3031;
	xor.b32  	%r293, %r292, -2147483648;
	mov.b32 	%f992, %r293;
	selp.f32 	%f150, %f992, %f3031, %p729;
	add.f32 	%f993, %f97, %f97;
	selp.f32 	%f994, %f993, 0f00000000, %p110;
	setp.eq.f32 	%p179, %f97, 0f00000000;
	selp.f32 	%f3032, %f994, %f150, %p179;
	@%p731 bra 	$L__BB7_74;

	cvt.rzi.f32.f32 	%f996, %f634;
	setp.eq.f32 	%p180, %f996, 0f40000000;
	mov.f32 	%f3032, %f150;
	@%p180 bra 	$L__BB7_74;

	mov.f32 	%f3032, 0f7FFFFFFF;

$L__BB7_74:
	mov.f32 	%f2862, 0f32A57060;
	mov.f32 	%f2861, 0f4B400001;
	mov.f32 	%f2860, 0f437C0000;
	mov.f32 	%f2859, 0f3BBB989D;
	abs.f32 	%f2858, %f97;
	setp.lt.f32 	%p733, %f97, 0f00000000;
	and.pred  	%p732, %p733, %p110;
	mov.f32 	%f2857, 0f3FB8AA3B;
	mov.f32 	%f2856, 0f3F000000;
	add.f32 	%f998, %f2858, 0f40000000;
	mov.b32 	%r294, %f998;
	setp.gt.s32 	%p181, %r294, 2139095039;
	add.f32 	%f999, %f97, 0f40000000;
	setp.gtu.f32 	%p182, %f2858, 0f7F800000;
	selp.f32 	%f1000, %f999, %f3032, %p182;
	selp.f32 	%f1001, 0fFF800000, 0f7F800000, %p732;
	setp.neu.f32 	%p183, %f2858, 0f7F800000;
	selp.f32 	%f1002, %f1000, %f1001, %p183;
	selp.f32 	%f1003, %f1002, %f3032, %p181;
	mul.f32 	%f1004, %f1003, 0fBF000000;
	setp.eq.f32 	%p184, %f97, 0f3F800000;
	selp.f32 	%f1005, 0fBF000000, %f1004, %p184;
	fma.rn.f32 	%f1008, %f1005, %f2859, %f2856;
	cvt.sat.f32.f32 	%f1011, %f1008;
	fma.rm.f32 	%f1013, %f1011, %f2860, %f2861;
	add.f32 	%f1014, %f1013, 0fCB40007F;
	neg.f32 	%f1015, %f1014;
	fma.rn.f32 	%f1016, %f1005, %f2857, %f1015;
	fma.rn.f32 	%f1018, %f1005, %f2862, %f1016;
	mov.b32 	%r295, %f1013;
	shl.b32 	%r296, %r295, 23;
	mov.b32 	%f1019, %r296;
	ex2.approx.ftz.f32 	%f1020, %f1018;
	mul.f32 	%f153, %f1020, %f1019;
	sub.f32 	%f1021, %f147, %f153;
	mul.f32 	%f1022, %f62, %f1021;
	mul.f32 	%f154, %f138, %f1022;
	not.pred 	%p185, %p6;
	mov.f64 	%fd570, %fd36;
	@%p185 bra 	$L__BB7_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r297}, %fd36;
	}
	xor.b32  	%r298, %r297, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r299, %temp}, %fd36;
	}
	mov.b64 	%fd570, {%r299, %r298};

$L__BB7_76:
	setp.eq.f32 	%p186, %f3065, 0f00000000;
	@%p186 bra 	$L__BB7_80;
	bra.uni 	$L__BB7_77;

$L__BB7_80:
	mov.u32 	%r300, 0;
	selp.b32 	%r302, %r49, 0, %p121;
	or.b32  	%r303, %r302, 2146435072;
	selp.b32 	%r304, %r303, %r302, %p123;
	mov.b64 	%fd570, {%r300, %r304};
	bra.uni 	$L__BB7_81;

$L__BB7_77:
	setp.gt.s32 	%p187, %r49, -1;
	@%p187 bra 	$L__BB7_81;

	cvt.rzi.f64.f64 	%fd352, %fd339;
	setp.eq.f64 	%p188, %fd352, 0d4008000000000000;
	@%p188 bra 	$L__BB7_81;

	mov.f64 	%fd570, 0dFFF8000000000000;

$L__BB7_81:
	cvt.f64.f32 	%fd550, %f3065;
	add.f64 	%fd549, %fd550, 0d4008000000000000;
	selp.f64 	%fd571, %fd570, %fd549, %p124;
	@%p16 bra 	$L__BB7_86;

	setp.eq.s32 	%p192, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r305, %temp}, %fd339;
	}
	setp.eq.s32 	%p193, %r305, 0;
	and.pred  	%p194, %p192, %p193;
	@%p194 bra 	$L__BB7_85;
	bra.uni 	$L__BB7_83;

$L__BB7_85:
	mov.u32 	%r312, 0;
	mov.b64 	%fd571, {%r312, %r54};
	bra.uni 	$L__BB7_86;

$L__BB7_83:
	cvt.f64.f32 	%fd551, %f3065;
	and.b32  	%r306, %r49, 2147483647;
	setp.ne.s32 	%p195, %r306, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r307, %temp}, %fd551;
	}
	setp.ne.s32 	%p196, %r307, 0;
	or.pred  	%p197, %p195, %p196;
	mov.f64 	%fd571, %fd570;
	@%p197 bra 	$L__BB7_86;

	setp.ne.s32 	%p198, %r53, 1071644672;
	and.pred  	%p199, %p198, %p6;
	or.b32  	%r309, %r55, -2147483648;
	selp.b32 	%r310, %r309, %r55, %p199;
	mov.u32 	%r311, 0;
	mov.b64 	%fd571, {%r311, %r310};

$L__BB7_86:
	mov.f32 	%f2873, 0f3102E308;
	mov.f32 	%f2872, 0fBF317218;
	mov.f32 	%f2871, 0f35BFBE8E;
	mov.f32 	%f2870, 0f3F317200;
	mov.f32 	%f2869, 0f3DAAAABD;
	mov.f32 	%f2868, 0f3C4CAF63;
	mov.f32 	%f2867, 0f3B18F0FE;
	cvt.rn.f32.s32 	%f2866, %r846;
	add.f32 	%f2865, %f2866, 0f3F000000;
	sub.f32 	%f2864, %f2865, %f3069;
	mov.f32 	%f2863, 0f3FB8AA3B;
	setp.eq.f32 	%p200, %f3065, 0f3F800000;
	selp.f64 	%fd358, 0d3FF0000000000000, %fd571, %p200;
	div.rn.f64 	%fd359, %fd34, %fd358;
	mul.f32 	%f1024, %f87, %f153;
	mul.f32 	%f1025, %f2864, %f147;
	sub.f32 	%f1026, %f1025, %f1024;
	cvt.f64.f32 	%fd360, %f1026;
	mul.f64 	%fd361, %fd359, %fd360;
	cvt.f64.f32 	%fd54, %f138;
	mul.f64 	%fd362, %fd361, %fd54;
	cvt.rn.f32.f64 	%f155, %fd362;
	add.f32 	%f1027, %f126, 0f3F000000;
	sub.f32 	%f156, %f1027, %f3068;
	div.rn.f32 	%f157, %f156, %f3064;
	abs.f32 	%f158, %f157;
	setp.lt.f32 	%p201, %f158, 0f00800000;
	mul.f32 	%f1028, %f158, 0f4B800000;
	selp.f32 	%f1029, %f1028, %f158, %p201;
	selp.f32 	%f1030, 0fC3170000, 0fC2FE0000, %p201;
	mov.b32 	%r313, %f1029;
	and.b32  	%r314, %r313, 8388607;
	or.b32  	%r315, %r314, 1065353216;
	mov.b32 	%f1031, %r315;
	shr.u32 	%r316, %r313, 23;
	cvt.rn.f32.u32 	%f1032, %r316;
	add.f32 	%f1033, %f1030, %f1032;
	setp.gt.f32 	%p202, %f1031, 0f3FB504F3;
	mul.f32 	%f1034, %f1031, 0f3F000000;
	add.f32 	%f1035, %f1033, 0f3F800000;
	selp.f32 	%f1036, %f1035, %f1033, %p202;
	selp.f32 	%f1037, %f1034, %f1031, %p202;
	add.f32 	%f1038, %f1037, 0fBF800000;
	add.f32 	%f1039, %f1037, 0f3F800000;
	rcp.approx.ftz.f32 	%f1040, %f1039;
	add.f32 	%f1041, %f1038, %f1038;
	mul.f32 	%f1043, %f1041, %f1040;
	mul.f32 	%f1044, %f1043, %f1043;
	fma.rn.f32 	%f1047, %f2867, %f1044, %f2868;
	fma.rn.f32 	%f1049, %f1047, %f1044, %f2869;
	mul.rn.f32 	%f1050, %f1049, %f1044;
	mul.rn.f32 	%f1051, %f1050, %f1043;
	sub.f32 	%f1052, %f1038, %f1043;
	add.f32 	%f1053, %f1052, %f1052;
	neg.f32 	%f1054, %f1043;
	fma.rn.f32 	%f1055, %f1054, %f1038, %f1053;
	mul.rn.f32 	%f1056, %f1040, %f1055;
	add.f32 	%f1057, %f1051, %f1043;
	sub.f32 	%f1058, %f1043, %f1057;
	add.f32 	%f1059, %f1051, %f1058;
	add.f32 	%f1060, %f1056, %f1059;
	add.f32 	%f1061, %f1057, %f1060;
	sub.f32 	%f1062, %f1057, %f1061;
	add.f32 	%f1063, %f1060, %f1062;
	mul.rn.f32 	%f1065, %f1036, %f2870;
	mul.rn.f32 	%f1067, %f1036, %f2871;
	add.f32 	%f1068, %f1065, %f1061;
	sub.f32 	%f1069, %f1065, %f1068;
	add.f32 	%f1070, %f1061, %f1069;
	add.f32 	%f1071, %f1063, %f1070;
	add.f32 	%f1072, %f1067, %f1071;
	add.f32 	%f1073, %f1068, %f1072;
	sub.f32 	%f1074, %f1068, %f1073;
	add.f32 	%f1075, %f1072, %f1074;
	mul.rn.f32 	%f1076, %f634, %f1073;
	neg.f32 	%f1077, %f1076;
	fma.rn.f32 	%f1078, %f634, %f1073, %f1077;
	fma.rn.f32 	%f1079, %f634, %f1075, %f1078;
	mov.f32 	%f1080, 0f00000000;
	fma.rn.f32 	%f1081, %f1080, %f1073, %f1079;
	add.rn.f32 	%f1082, %f1076, %f1081;
	neg.f32 	%f1083, %f1082;
	add.rn.f32 	%f1084, %f1076, %f1083;
	add.rn.f32 	%f1085, %f1084, %f1081;
	mov.b32 	%r317, %f1082;
	setp.eq.s32 	%p203, %r317, 1118925336;
	add.s32 	%r318, %r317, -1;
	mov.b32 	%f1086, %r318;
	add.f32 	%f1087, %f1085, 0f37000000;
	selp.f32 	%f159, %f1087, %f1085, %p203;
	selp.f32 	%f1088, %f1086, %f1082, %p203;
	mul.rn.f32 	%f1090, %f1088, %f2863;
	cvt.rzi.f32.f32 	%f1091, %f1090;
	abs.f32 	%f1092, %f1091;
	setp.gt.f32 	%p204, %f1092, 0f42FC0000;
	mov.b32 	%r319, %f1091;
	and.b32  	%r320, %r319, -2147483648;
	or.b32  	%r321, %r320, 1123811328;
	mov.b32 	%f1093, %r321;
	selp.f32 	%f1094, %f1093, %f1091, %p204;
	fma.rn.f32 	%f1096, %f1094, %f2872, %f1088;
	fma.rn.f32 	%f1098, %f1094, %f2873, %f1096;
	mul.f32 	%f1099, %f1098, 0f3FB8AA3B;
	add.f32 	%f1100, %f1094, 0f4B40007F;
	mov.b32 	%r322, %f1100;
	shl.b32 	%r323, %r322, 23;
	mov.b32 	%f1101, %r323;
	ex2.approx.ftz.f32 	%f1102, %f1099;
	mul.f32 	%f160, %f1102, %f1101;
	setp.eq.f32 	%p205, %f160, 0f7F800000;
	mov.f32 	%f3033, 0f7F800000;
	@%p205 bra 	$L__BB7_88;

	fma.rn.f32 	%f3033, %f160, %f159, %f160;

$L__BB7_88:
	setp.lt.f32 	%p206, %f157, 0f00000000;
	and.pred  	%p24, %p206, %p110;
	setp.eq.f32 	%p208, %f157, 0f00000000;
	@%p208 bra 	$L__BB7_92;
	bra.uni 	$L__BB7_89;

$L__BB7_92:
	add.f32 	%f1107, %f157, %f157;
	selp.f32 	%f3035, %f1107, 0f00000000, %p110;
	bra.uni 	$L__BB7_93;

$L__BB7_89:
	mov.b32 	%r324, %f3033;
	xor.b32  	%r325, %r324, -2147483648;
	mov.b32 	%f1103, %r325;
	selp.f32 	%f3035, %f1103, %f3033, %p24;
	setp.geu.f32 	%p209, %f157, 0f00000000;
	@%p209 bra 	$L__BB7_93;

	cvt.rzi.f32.f32 	%f1105, %f634;
	setp.eq.f32 	%p210, %f1105, 0f40000000;
	@%p210 bra 	$L__BB7_93;

	mov.f32 	%f3035, 0f7FFFFFFF;

$L__BB7_93:
	abs.f32 	%f2953, %f157;
	add.f32 	%f1108, %f2953, 0f40000000;
	mov.b32 	%r326, %f1108;
	setp.lt.s32 	%p212, %r326, 2139095040;
	@%p212 bra 	$L__BB7_98;

	abs.f32 	%f2958, %f157;
	setp.gtu.f32 	%p213, %f2958, 0f7F800000;
	@%p213 bra 	$L__BB7_97;
	bra.uni 	$L__BB7_95;

$L__BB7_97:
	add.f32 	%f3035, %f157, 0f40000000;
	bra.uni 	$L__BB7_98;

$L__BB7_95:
	abs.f32 	%f2959, %f157;
	setp.neu.f32 	%p214, %f2959, 0f7F800000;
	@%p214 bra 	$L__BB7_98;

	selp.f32 	%f3035, 0fFF800000, 0f7F800000, %p24;

$L__BB7_98:
	mov.f32 	%f2887, 0f00000000;
	mov.f32 	%f2886, 0f3102E308;
	mov.f32 	%f2885, 0fBF317218;
	mov.f32 	%f2884, 0f35BFBE8E;
	mov.f32 	%f2883, 0f3F317200;
	mov.f32 	%f2882, 0f3DAAAABD;
	mov.f32 	%f2881, 0f3C4CAF63;
	mov.f32 	%f2880, 0f3B18F0FE;
	mov.f32 	%f2879, 0f32A57060;
	mov.f32 	%f2878, 0f4B400001;
	mov.f32 	%f2877, 0f437C0000;
	mov.f32 	%f2876, 0f3BBB989D;
	mov.f32 	%f2875, 0f3FB8AA3B;
	mov.f32 	%f2874, 0f3F000000;
	mul.f32 	%f1110, %f3035, 0fBF000000;
	setp.eq.f32 	%p215, %f157, 0f3F800000;
	selp.f32 	%f1111, 0fBF000000, %f1110, %p215;
	fma.rn.f32 	%f1114, %f1111, %f2876, %f2874;
	cvt.sat.f32.f32 	%f1117, %f1114;
	fma.rm.f32 	%f1119, %f1117, %f2877, %f2878;
	add.f32 	%f1120, %f1119, 0fCB40007F;
	neg.f32 	%f1121, %f1120;
	fma.rn.f32 	%f1122, %f1111, %f2875, %f1121;
	fma.rn.f32 	%f1124, %f1111, %f2879, %f1122;
	mov.b32 	%r327, %f1119;
	shl.b32 	%r328, %r327, 23;
	mov.b32 	%f1125, %r328;
	ex2.approx.ftz.f32 	%f1126, %f1124;
	mul.f32 	%f169, %f1126, %f1125;
	div.rn.f32 	%f170, %f133, %f3064;
	abs.f32 	%f171, %f170;
	setp.lt.f32 	%p216, %f171, 0f00800000;
	mul.f32 	%f1127, %f171, 0f4B800000;
	selp.f32 	%f1128, %f1127, %f171, %p216;
	selp.f32 	%f1129, 0fC3170000, 0fC2FE0000, %p216;
	mov.b32 	%r329, %f1128;
	and.b32  	%r330, %r329, 8388607;
	or.b32  	%r331, %r330, 1065353216;
	mov.b32 	%f1130, %r331;
	shr.u32 	%r332, %r329, 23;
	cvt.rn.f32.u32 	%f1131, %r332;
	add.f32 	%f1132, %f1129, %f1131;
	setp.gt.f32 	%p217, %f1130, 0f3FB504F3;
	mul.f32 	%f1133, %f1130, 0f3F000000;
	add.f32 	%f1134, %f1132, 0f3F800000;
	selp.f32 	%f1135, %f1134, %f1132, %p217;
	selp.f32 	%f1136, %f1133, %f1130, %p217;
	add.f32 	%f1137, %f1136, 0fBF800000;
	add.f32 	%f1138, %f1136, 0f3F800000;
	rcp.approx.ftz.f32 	%f1139, %f1138;
	add.f32 	%f1140, %f1137, %f1137;
	mul.f32 	%f1142, %f1140, %f1139;
	mul.f32 	%f1143, %f1142, %f1142;
	fma.rn.f32 	%f1146, %f2880, %f1143, %f2881;
	fma.rn.f32 	%f1148, %f1146, %f1143, %f2882;
	mul.rn.f32 	%f1149, %f1148, %f1143;
	mul.rn.f32 	%f1150, %f1149, %f1142;
	sub.f32 	%f1151, %f1137, %f1142;
	add.f32 	%f1152, %f1151, %f1151;
	neg.f32 	%f1153, %f1142;
	fma.rn.f32 	%f1154, %f1153, %f1137, %f1152;
	mul.rn.f32 	%f1155, %f1139, %f1154;
	add.f32 	%f1156, %f1150, %f1142;
	sub.f32 	%f1157, %f1142, %f1156;
	add.f32 	%f1158, %f1150, %f1157;
	add.f32 	%f1159, %f1155, %f1158;
	add.f32 	%f1160, %f1156, %f1159;
	sub.f32 	%f1161, %f1156, %f1160;
	add.f32 	%f1162, %f1159, %f1161;
	mul.rn.f32 	%f1164, %f1135, %f2883;
	mul.rn.f32 	%f1166, %f1135, %f2884;
	add.f32 	%f1167, %f1164, %f1160;
	sub.f32 	%f1168, %f1164, %f1167;
	add.f32 	%f1169, %f1160, %f1168;
	add.f32 	%f1170, %f1162, %f1169;
	add.f32 	%f1171, %f1166, %f1170;
	add.f32 	%f1172, %f1167, %f1171;
	sub.f32 	%f1173, %f1167, %f1172;
	add.f32 	%f1174, %f1171, %f1173;
	mul.rn.f32 	%f1175, %f634, %f1172;
	neg.f32 	%f1176, %f1175;
	fma.rn.f32 	%f1177, %f634, %f1172, %f1176;
	fma.rn.f32 	%f1178, %f634, %f1174, %f1177;
	fma.rn.f32 	%f1180, %f2887, %f1172, %f1178;
	add.rn.f32 	%f1181, %f1175, %f1180;
	neg.f32 	%f1182, %f1181;
	add.rn.f32 	%f1183, %f1175, %f1182;
	add.rn.f32 	%f1184, %f1183, %f1180;
	mov.b32 	%r333, %f1181;
	setp.eq.s32 	%p218, %r333, 1118925336;
	add.s32 	%r334, %r333, -1;
	mov.b32 	%f1185, %r334;
	add.f32 	%f1186, %f1184, 0f37000000;
	selp.f32 	%f172, %f1186, %f1184, %p218;
	selp.f32 	%f1187, %f1185, %f1181, %p218;
	mul.rn.f32 	%f1188, %f1187, %f2875;
	cvt.rzi.f32.f32 	%f1189, %f1188;
	abs.f32 	%f1190, %f1189;
	setp.gt.f32 	%p219, %f1190, 0f42FC0000;
	mov.b32 	%r335, %f1189;
	and.b32  	%r336, %r335, -2147483648;
	or.b32  	%r337, %r336, 1123811328;
	mov.b32 	%f1191, %r337;
	selp.f32 	%f1192, %f1191, %f1189, %p219;
	fma.rn.f32 	%f1194, %f1192, %f2885, %f1187;
	fma.rn.f32 	%f1196, %f1192, %f2886, %f1194;
	mul.f32 	%f1197, %f1196, 0f3FB8AA3B;
	add.f32 	%f1198, %f1192, 0f4B40007F;
	mov.b32 	%r338, %f1198;
	shl.b32 	%r339, %r338, 23;
	mov.b32 	%f1199, %r339;
	ex2.approx.ftz.f32 	%f1200, %f1197;
	mul.f32 	%f173, %f1200, %f1199;
	setp.eq.f32 	%p220, %f173, 0f7F800000;
	mov.f32 	%f3036, 0f7F800000;
	@%p220 bra 	$L__BB7_100;

	fma.rn.f32 	%f3036, %f173, %f172, %f173;

$L__BB7_100:
	setp.lt.f32 	%p221, %f170, 0f00000000;
	and.pred  	%p25, %p221, %p110;
	setp.eq.f32 	%p223, %f170, 0f00000000;
	@%p223 bra 	$L__BB7_104;
	bra.uni 	$L__BB7_101;

$L__BB7_104:
	add.f32 	%f1205, %f170, %f170;
	selp.f32 	%f3038, %f1205, 0f00000000, %p110;
	bra.uni 	$L__BB7_105;

$L__BB7_101:
	mov.b32 	%r340, %f3036;
	xor.b32  	%r341, %r340, -2147483648;
	mov.b32 	%f1201, %r341;
	selp.f32 	%f3038, %f1201, %f3036, %p25;
	setp.geu.f32 	%p224, %f170, 0f00000000;
	@%p224 bra 	$L__BB7_105;

	cvt.rzi.f32.f32 	%f1203, %f634;
	setp.eq.f32 	%p225, %f1203, 0f40000000;
	@%p225 bra 	$L__BB7_105;

	mov.f32 	%f3038, 0f7FFFFFFF;

$L__BB7_105:
	abs.f32 	%f2960, %f170;
	add.f32 	%f1206, %f2960, 0f40000000;
	mov.b32 	%r342, %f1206;
	setp.lt.s32 	%p227, %r342, 2139095040;
	@%p227 bra 	$L__BB7_110;

	abs.f32 	%f2961, %f170;
	setp.gtu.f32 	%p228, %f2961, 0f7F800000;
	@%p228 bra 	$L__BB7_109;
	bra.uni 	$L__BB7_107;

$L__BB7_109:
	add.f32 	%f3038, %f170, 0f40000000;
	bra.uni 	$L__BB7_110;

$L__BB7_107:
	abs.f32 	%f2962, %f170;
	setp.neu.f32 	%p229, %f2962, 0f7F800000;
	@%p229 bra 	$L__BB7_110;

	selp.f32 	%f3038, 0fFF800000, 0f7F800000, %p25;

$L__BB7_110:
	mov.f32 	%f2893, 0f32A57060;
	mov.f32 	%f2892, 0f4B400001;
	mov.f32 	%f2891, 0f437C0000;
	mov.f32 	%f2890, 0f3BBB989D;
	mov.f32 	%f2889, 0f3FB8AA3B;
	mov.f32 	%f2888, 0f3F000000;
	mul.f32 	%f1207, %f3038, 0fBF000000;
	setp.eq.f32 	%p230, %f170, 0f3F800000;
	selp.f32 	%f1208, 0fBF000000, %f1207, %p230;
	fma.rn.f32 	%f1211, %f1208, %f2890, %f2888;
	cvt.sat.f32.f32 	%f1214, %f1211;
	fma.rm.f32 	%f1216, %f1214, %f2891, %f2892;
	add.f32 	%f1217, %f1216, 0fCB40007F;
	neg.f32 	%f1218, %f1217;
	fma.rn.f32 	%f1219, %f1208, %f2889, %f1218;
	fma.rn.f32 	%f1221, %f1208, %f2893, %f1219;
	mov.b32 	%r343, %f1216;
	shl.b32 	%r344, %r343, 23;
	mov.b32 	%f1222, %r344;
	ex2.approx.ftz.f32 	%f1223, %f1221;
	mul.f32 	%f182, %f1223, %f1222;
	sub.f32 	%f1224, %f169, %f182;
	mul.f32 	%f1225, %f63, %f1224;
	mul.f32 	%f183, %f125, %f1225;
	not.pred 	%p231, %p7;
	mov.f64 	%fd573, %fd37;
	@%p231 bra 	$L__BB7_112;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r345}, %fd37;
	}
	xor.b32  	%r346, %r345, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r347, %temp}, %fd37;
	}
	mov.b64 	%fd573, {%r347, %r346};

$L__BB7_112:
	setp.eq.f32 	%p232, %f3064, 0f00000000;
	@%p232 bra 	$L__BB7_116;
	bra.uni 	$L__BB7_113;

$L__BB7_116:
	mov.u32 	%r348, 0;
	selp.b32 	%r350, %r56, 0, %p121;
	or.b32  	%r351, %r350, 2146435072;
	selp.b32 	%r352, %r351, %r350, %p123;
	mov.b64 	%fd573, {%r348, %r352};
	bra.uni 	$L__BB7_117;

$L__BB7_113:
	setp.gt.s32 	%p233, %r56, -1;
	@%p233 bra 	$L__BB7_117;

	cvt.rzi.f64.f64 	%fd364, %fd339;
	setp.eq.f64 	%p234, %fd364, 0d4008000000000000;
	@%p234 bra 	$L__BB7_117;

	mov.f64 	%fd573, 0dFFF8000000000000;

$L__BB7_117:
	cvt.f64.f32 	%fd553, %f3064;
	add.f64 	%fd552, %fd553, 0d4008000000000000;
	selp.f64 	%fd574, %fd573, %fd552, %p130;
	@%p17 bra 	$L__BB7_122;

	setp.eq.s32 	%p238, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r353, %temp}, %fd339;
	}
	setp.eq.s32 	%p239, %r353, 0;
	and.pred  	%p240, %p238, %p239;
	@%p240 bra 	$L__BB7_121;
	bra.uni 	$L__BB7_119;

$L__BB7_121:
	mov.u32 	%r360, 0;
	mov.b64 	%fd574, {%r360, %r58};
	bra.uni 	$L__BB7_122;

$L__BB7_119:
	cvt.f64.f32 	%fd554, %f3064;
	and.b32  	%r354, %r56, 2147483647;
	setp.ne.s32 	%p241, %r354, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r355, %temp}, %fd554;
	}
	setp.ne.s32 	%p242, %r355, 0;
	or.pred  	%p243, %p241, %p242;
	mov.f64 	%fd574, %fd573;
	@%p243 bra 	$L__BB7_122;

	setp.ne.s32 	%p244, %r53, 1071644672;
	and.pred  	%p245, %p244, %p7;
	or.b32  	%r357, %r55, -2147483648;
	selp.b32 	%r358, %r357, %r55, %p245;
	mov.u32 	%r359, 0;
	mov.b64 	%fd574, {%r359, %r358};

$L__BB7_122:
	cvt.rn.f32.s32 	%f2956, %r847;
	add.f32 	%f2955, %f2956, 0f3F000000;
	sub.f32 	%f2954, %f2955, %f3068;
	setp.eq.f32 	%p246, %f3064, 0f3F800000;
	selp.f64 	%fd370, 0d3FF0000000000000, %fd574, %p246;
	div.rn.f64 	%fd371, %fd34, %fd370;
	mul.f32 	%f1227, %f133, %f182;
	mul.f32 	%f1228, %f2954, %f169;
	sub.f32 	%f1229, %f1228, %f1227;
	cvt.f64.f32 	%fd372, %f1229;
	mul.f64 	%fd373, %fd371, %fd372;
	cvt.f64.f32 	%fd374, %f125;
	mul.f64 	%fd375, %fd373, %fd374;
	cvt.rn.f32.f64 	%f184, %fd375;
	setp.eq.f32 	%p247, %f104, 0f7F800000;
	mov.f32 	%f3039, 0f7F800000;
	@%p247 bra 	$L__BB7_124;

	fma.rn.f32 	%f3039, %f104, %f103, %f104;

$L__BB7_124:
	setp.geu.f32 	%p736, %f101, 0f00000000;
	setp.lt.f32 	%p735, %f101, 0f00000000;
	and.pred  	%p734, %p735, %p110;
	mov.b32 	%r361, %f3039;
	xor.b32  	%r362, %r361, -2147483648;
	mov.b32 	%f1230, %r362;
	selp.f32 	%f187, %f1230, %f3039, %p734;
	add.f32 	%f1231, %f101, %f101;
	selp.f32 	%f1232, %f1231, 0f00000000, %p110;
	setp.eq.f32 	%p249, %f101, 0f00000000;
	selp.f32 	%f3040, %f1232, %f187, %p249;
	@%p736 bra 	$L__BB7_127;

	cvt.rzi.f32.f32 	%f1234, %f634;
	setp.eq.f32 	%p250, %f1234, 0f40000000;
	mov.f32 	%f3040, %f187;
	@%p250 bra 	$L__BB7_127;

	mov.f32 	%f3040, 0f7FFFFFFF;

$L__BB7_127:
	abs.f32 	%f2900, %f101;
	setp.lt.f32 	%p738, %f101, 0f00000000;
	and.pred  	%p737, %p738, %p110;
	mov.f32 	%f2899, 0f32A57060;
	mov.f32 	%f2898, 0f4B400001;
	mov.f32 	%f2897, 0f437C0000;
	mov.f32 	%f2896, 0f3BBB989D;
	mov.f32 	%f2895, 0f3FB8AA3B;
	mov.f32 	%f2894, 0f3F000000;
	add.f32 	%f1237, %f2900, 0f40000000;
	mov.b32 	%r363, %f1237;
	setp.gt.s32 	%p251, %r363, 2139095039;
	add.f32 	%f1238, %f101, 0f40000000;
	setp.gtu.f32 	%p252, %f2900, 0f7F800000;
	mov.f32 	%f3041, 0f7F800000;
	selp.f32 	%f1239, %f1238, %f3040, %p252;
	selp.f32 	%f1240, 0fFF800000, 0f7F800000, %p737;
	setp.neu.f32 	%p253, %f2900, 0f7F800000;
	selp.f32 	%f1241, %f1239, %f1240, %p253;
	selp.f32 	%f1242, %f1241, %f3040, %p251;
	mul.f32 	%f1243, %f1242, 0fBF000000;
	setp.eq.f32 	%p254, %f101, 0f3F800000;
	selp.f32 	%f1244, 0fBF000000, %f1243, %p254;
	fma.rn.f32 	%f1247, %f1244, %f2896, %f2894;
	cvt.sat.f32.f32 	%f1250, %f1247;
	fma.rm.f32 	%f1252, %f1250, %f2897, %f2898;
	add.f32 	%f1253, %f1252, 0fCB40007F;
	neg.f32 	%f1254, %f1253;
	fma.rn.f32 	%f1255, %f1244, %f2895, %f1254;
	fma.rn.f32 	%f1257, %f1244, %f2899, %f1255;
	mov.b32 	%r364, %f1252;
	shl.b32 	%r365, %r364, 23;
	mov.b32 	%f1258, %r365;
	ex2.approx.ftz.f32 	%f1259, %f1257;
	mul.f32 	%f190, %f1259, %f1258;
	setp.eq.f32 	%p255, %f108, 0f7F800000;
	@%p255 bra 	$L__BB7_129;

	fma.rn.f32 	%f3041, %f108, %f107, %f108;

$L__BB7_129:
	setp.geu.f32 	%p741, %f105, 0f00000000;
	setp.lt.f32 	%p740, %f105, 0f00000000;
	and.pred  	%p739, %p740, %p110;
	mov.b32 	%r366, %f3041;
	xor.b32  	%r367, %r366, -2147483648;
	mov.b32 	%f1260, %r367;
	selp.f32 	%f193, %f1260, %f3041, %p739;
	add.f32 	%f1261, %f105, %f105;
	selp.f32 	%f1262, %f1261, 0f00000000, %p110;
	setp.eq.f32 	%p257, %f105, 0f00000000;
	selp.f32 	%f3042, %f1262, %f193, %p257;
	@%p741 bra 	$L__BB7_132;

	cvt.rzi.f32.f32 	%f1264, %f634;
	setp.eq.f32 	%p258, %f1264, 0f40000000;
	mov.f32 	%f3042, %f193;
	@%p258 bra 	$L__BB7_132;

	mov.f32 	%f3042, 0f7FFFFFFF;

$L__BB7_132:
	cvt.rn.f32.s32 	%f2909, %r846;
	sub.f32 	%f2908, %f2909, %f3069;
	abs.f32 	%f2907, %f105;
	setp.lt.f32 	%p743, %f105, 0f00000000;
	and.pred  	%p742, %p743, %p110;
	mov.f32 	%f2906, 0f32A57060;
	mov.f32 	%f2905, 0f4B400001;
	mov.f32 	%f2904, 0f437C0000;
	mov.f32 	%f2903, 0f3BBB989D;
	mov.f32 	%f2902, 0f3FB8AA3B;
	mov.f32 	%f2901, 0f3F000000;
	add.f32 	%f1266, %f2907, 0f40000000;
	mov.b32 	%r368, %f1266;
	setp.gt.s32 	%p259, %r368, 2139095039;
	add.f32 	%f1267, %f105, 0f40000000;
	setp.gtu.f32 	%p260, %f2907, 0f7F800000;
	selp.f32 	%f1268, %f1267, %f3042, %p260;
	selp.f32 	%f1269, 0fFF800000, 0f7F800000, %p742;
	setp.neu.f32 	%p261, %f2907, 0f7F800000;
	selp.f32 	%f1270, %f1268, %f1269, %p261;
	selp.f32 	%f1271, %f1270, %f3042, %p259;
	mul.f32 	%f1272, %f1271, 0fBF000000;
	setp.eq.f32 	%p262, %f105, 0f3F800000;
	selp.f32 	%f1273, 0fBF000000, %f1272, %p262;
	fma.rn.f32 	%f1276, %f1273, %f2903, %f2901;
	cvt.sat.f32.f32 	%f1279, %f1276;
	fma.rm.f32 	%f1281, %f1279, %f2904, %f2905;
	add.f32 	%f1282, %f1281, 0fCB40007F;
	neg.f32 	%f1283, %f1282;
	fma.rn.f32 	%f1284, %f1273, %f2902, %f1283;
	fma.rn.f32 	%f1286, %f1273, %f2906, %f1284;
	mov.b32 	%r369, %f1281;
	shl.b32 	%r370, %r369, 23;
	mov.b32 	%f1287, %r370;
	ex2.approx.ftz.f32 	%f1288, %f1286;
	mul.f32 	%f196, %f1288, %f1287;
	add.f32 	%f1289, %f2908, 0f3F800000;
	mul.f32 	%f1290, %f1289, %f190;
	mul.f32 	%f1291, %f2908, %f196;
	sub.f32 	%f1292, %f1290, %f1291;
	mul.f32 	%f1293, %f64, %f1292;
	mul.f32 	%f197, %f138, %f1293;
	not.pred 	%p263, %p10;
	mov.f64 	%fd576, %fd38;
	@%p263 bra 	$L__BB7_134;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r371}, %fd38;
	}
	xor.b32  	%r372, %r371, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r373, %temp}, %fd38;
	}
	mov.b64 	%fd576, {%r373, %r372};

$L__BB7_134:
	setp.eq.f32 	%p744, %f3065, 0f00000000;
	@%p744 bra 	$L__BB7_138;
	bra.uni 	$L__BB7_135;

$L__BB7_138:
	mov.u32 	%r374, 0;
	mov.b64 	%fd576, {%r374, %r59};
	bra.uni 	$L__BB7_139;

$L__BB7_135:
	setp.gt.s32 	%p265, %r49, -1;
	@%p265 bra 	$L__BB7_139;

	cvt.rzi.f64.f64 	%fd377, %fd345;
	setp.eq.f64 	%p266, %fd377, 0d4014000000000000;
	@%p266 bra 	$L__BB7_139;

	mov.f64 	%fd576, 0dFFF8000000000000;

$L__BB7_139:
	cvt.f64.f32 	%fd556, %f3065;
	add.f64 	%fd555, %fd556, 0d4014000000000000;
	selp.f64 	%fd577, %fd576, %fd555, %p146;
	@%p20 bra 	$L__BB7_144;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r836}, %fd345;
	}
	and.b32  	%r835, %r836, 2147483647;
	setp.eq.s32 	%p268, %r835, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r375, %temp}, %fd345;
	}
	setp.eq.s32 	%p269, %r375, 0;
	and.pred  	%p270, %p268, %p269;
	@%p270 bra 	$L__BB7_143;
	bra.uni 	$L__BB7_141;

$L__BB7_143:
	mov.u32 	%r379, 0;
	mov.b64 	%fd577, {%r379, %r63};
	bra.uni 	$L__BB7_144;

$L__BB7_141:
	cvt.f64.f32 	%fd557, %f3065;
	and.b32  	%r376, %r49, 2147483647;
	setp.ne.s32 	%p271, %r376, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r377, %temp}, %fd557;
	}
	setp.ne.s32 	%p272, %r377, 0;
	or.pred  	%p273, %p271, %p272;
	mov.f64 	%fd577, %fd576;
	@%p273 bra 	$L__BB7_144;

	mov.u32 	%r378, 0;
	mov.b64 	%fd577, {%r378, %r65};

$L__BB7_144:
	not.pred 	%p274, %p11;
	mov.f64 	%fd579, %fd40;
	@%p274 bra 	$L__BB7_146;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r380}, %fd40;
	}
	xor.b32  	%r381, %r380, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r382, %temp}, %fd40;
	}
	mov.b64 	%fd579, {%r382, %r381};

$L__BB7_146:
	cvt.rn.f32.s32 	%f2912, %r846;
	sub.f32 	%f2911, %f2912, %f3069;
	add.f32 	%f2910, %f2911, 0f3F000000;
	setp.eq.f32 	%p275, %f2910, 0f00000000;
	@%p275 bra 	$L__BB7_150;
	bra.uni 	$L__BB7_147;

$L__BB7_150:
	mov.u32 	%r383, 0;
	selp.b32 	%r385, %r61, 0, %p121;
	or.b32  	%r386, %r385, 2146435072;
	selp.b32 	%r387, %r386, %r385, %p123;
	mov.b64 	%fd579, {%r383, %r387};
	bra.uni 	$L__BB7_151;

$L__BB7_147:
	setp.gt.s32 	%p276, %r61, -1;
	@%p276 bra 	$L__BB7_151;

	cvt.rzi.f64.f64 	%fd384, %fd339;
	setp.eq.f64 	%p277, %fd384, 0d4008000000000000;
	@%p277 bra 	$L__BB7_151;

	mov.f64 	%fd579, 0dFFF8000000000000;

$L__BB7_151:
	selp.f64 	%fd580, %fd579, %fd41, %p148;
	@%p21 bra 	$L__BB7_156;

	setp.eq.s32 	%p281, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r388, %temp}, %fd339;
	}
	setp.eq.s32 	%p282, %r388, 0;
	and.pred  	%p283, %p281, %p282;
	@%p283 bra 	$L__BB7_155;
	bra.uni 	$L__BB7_153;

$L__BB7_155:
	mov.u32 	%r395, 0;
	mov.b64 	%fd580, {%r395, %r67};
	bra.uni 	$L__BB7_156;

$L__BB7_153:
	cvt.rn.f32.s32 	%f2915, %r846;
	sub.f32 	%f2914, %f2915, %f3069;
	add.f32 	%f2913, %f2914, 0f3F000000;
	cvt.f64.f32 	%fd558, %f2913;
	and.b32  	%r389, %r61, 2147483647;
	setp.ne.s32 	%p284, %r389, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r390, %temp}, %fd558;
	}
	setp.ne.s32 	%p285, %r390, 0;
	or.pred  	%p286, %p284, %p285;
	mov.f64 	%fd580, %fd579;
	@%p286 bra 	$L__BB7_156;

	setp.ne.s32 	%p287, %r53, 1071644672;
	and.pred  	%p288, %p287, %p11;
	or.b32  	%r392, %r55, -2147483648;
	selp.b32 	%r393, %r392, %r55, %p288;
	mov.u32 	%r394, 0;
	mov.b64 	%fd580, {%r394, %r393};

$L__BB7_156:
	cvt.rn.f32.s32 	%f2918, %r846;
	sub.f32 	%f2917, %f2918, %f3069;
	add.f32 	%f2916, %f2917, 0f3F000000;
	setp.eq.f32 	%p289, %f2916, 0f3F800000;
	selp.f64 	%fd387, 0d3FF0000000000000, %fd580, %p289;
	cvt.f64.f32 	%fd388, %f190;
	mul.f64 	%fd79, %fd387, %fd388;
	not.pred 	%p290, %p12;
	mov.f64 	%fd582, %fd43;
	@%p290 bra 	$L__BB7_158;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r396}, %fd43;
	}
	xor.b32  	%r397, %r396, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r398, %temp}, %fd43;
	}
	mov.b64 	%fd582, {%r398, %r397};

$L__BB7_158:
	setp.eq.f32 	%p291, %f87, 0f00000000;
	@%p291 bra 	$L__BB7_162;
	bra.uni 	$L__BB7_159;

$L__BB7_162:
	mov.u32 	%r399, 0;
	selp.b32 	%r401, %r66, 0, %p121;
	or.b32  	%r402, %r401, 2146435072;
	selp.b32 	%r403, %r402, %r401, %p123;
	mov.b64 	%fd582, {%r399, %r403};
	bra.uni 	$L__BB7_163;

$L__BB7_159:
	setp.gt.s32 	%p292, %r66, -1;
	@%p292 bra 	$L__BB7_163;

	cvt.rzi.f64.f64 	%fd390, %fd339;
	setp.eq.f64 	%p293, %fd390, 0d4008000000000000;
	@%p293 bra 	$L__BB7_163;

	mov.f64 	%fd582, 0dFFF8000000000000;

$L__BB7_163:
	selp.f64 	%fd583, %fd582, %fd44, %p156;
	@%p22 bra 	$L__BB7_168;

	setp.eq.s32 	%p297, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r404, %temp}, %fd339;
	}
	setp.eq.s32 	%p298, %r404, 0;
	and.pred  	%p299, %p297, %p298;
	@%p299 bra 	$L__BB7_167;
	bra.uni 	$L__BB7_165;

$L__BB7_167:
	mov.u32 	%r411, 0;
	mov.b64 	%fd583, {%r411, %r69};
	bra.uni 	$L__BB7_168;

$L__BB7_165:
	cvt.rn.f32.s32 	%f2921, %r846;
	sub.f32 	%f2920, %f2921, %f3069;
	add.f32 	%f2919, %f2920, 0fBF000000;
	cvt.f64.f32 	%fd559, %f2919;
	and.b32  	%r405, %r66, 2147483647;
	setp.ne.s32 	%p300, %r405, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r406, %temp}, %fd559;
	}
	setp.ne.s32 	%p301, %r406, 0;
	or.pred  	%p302, %p300, %p301;
	mov.f64 	%fd583, %fd582;
	@%p302 bra 	$L__BB7_168;

	setp.ne.s32 	%p303, %r53, 1071644672;
	and.pred  	%p304, %p303, %p12;
	or.b32  	%r408, %r55, -2147483648;
	selp.b32 	%r409, %r408, %r55, %p304;
	mov.u32 	%r410, 0;
	mov.b64 	%fd583, {%r410, %r409};

$L__BB7_168:
	cvt.f64.f32 	%fd560, %f138;
	setp.eq.f32 	%p745, %f3065, 0f3F800000;
	cvt.rn.f32.s32 	%f2957, %r847;
	mov.f32 	%f2930, 0f00000000;
	mov.f32 	%f2929, 0f3102E308;
	mov.f32 	%f2928, 0fBF317218;
	mov.f32 	%f2927, 0f35BFBE8E;
	mov.f32 	%f2926, 0f3F317200;
	mov.f32 	%f2925, 0f3DAAAABD;
	mov.f32 	%f2924, 0f3C4CAF63;
	mov.f32 	%f2923, 0f3B18F0FE;
	mov.f32 	%f2922, 0f3FB8AA3B;
	setp.eq.f32 	%p305, %f87, 0f3F800000;
	selp.f64 	%fd393, 0d3FF0000000000000, %fd583, %p305;
	cvt.f64.f32 	%fd394, %f196;
	mul.f64 	%fd395, %fd393, %fd394;
	sub.f64 	%fd396, %fd79, %fd395;
	selp.f64 	%fd397, 0d3FF0000000000000, %fd577, %p745;
	div.rn.f64 	%fd398, %fd35, %fd397;
	mul.f64 	%fd399, %fd398, %fd396;
	mul.f64 	%fd400, %fd399, %fd560;
	mul.f32 	%f1295, %f65, %f197;
	cvt.f64.f32 	%fd401, %f1295;
	sub.f64 	%fd402, %fd401, %fd400;
	cvt.rn.f32.f64 	%f198, %fd402;
	add.f32 	%f1296, %f2957, 0f3F800000;
	sub.f32 	%f1297, %f1296, %f3068;
	div.rn.f32 	%f199, %f1297, %f3064;
	abs.f32 	%f200, %f199;
	setp.lt.f32 	%p307, %f200, 0f00800000;
	mul.f32 	%f1298, %f200, 0f4B800000;
	selp.f32 	%f1299, %f1298, %f200, %p307;
	selp.f32 	%f1300, 0fC3170000, 0fC2FE0000, %p307;
	mov.b32 	%r412, %f1299;
	and.b32  	%r413, %r412, 8388607;
	or.b32  	%r414, %r413, 1065353216;
	mov.b32 	%f1301, %r414;
	shr.u32 	%r415, %r412, 23;
	cvt.rn.f32.u32 	%f1302, %r415;
	add.f32 	%f1303, %f1300, %f1302;
	setp.gt.f32 	%p308, %f1301, 0f3FB504F3;
	mul.f32 	%f1304, %f1301, 0f3F000000;
	add.f32 	%f1305, %f1303, 0f3F800000;
	selp.f32 	%f1306, %f1305, %f1303, %p308;
	selp.f32 	%f1307, %f1304, %f1301, %p308;
	add.f32 	%f1308, %f1307, 0fBF800000;
	add.f32 	%f1309, %f1307, 0f3F800000;
	rcp.approx.ftz.f32 	%f1310, %f1309;
	add.f32 	%f1311, %f1308, %f1308;
	mul.f32 	%f1313, %f1311, %f1310;
	mul.f32 	%f1314, %f1313, %f1313;
	fma.rn.f32 	%f1317, %f2923, %f1314, %f2924;
	fma.rn.f32 	%f1319, %f1317, %f1314, %f2925;
	mul.rn.f32 	%f1320, %f1319, %f1314;
	mul.rn.f32 	%f1321, %f1320, %f1313;
	sub.f32 	%f1322, %f1308, %f1313;
	add.f32 	%f1323, %f1322, %f1322;
	neg.f32 	%f1324, %f1313;
	fma.rn.f32 	%f1325, %f1324, %f1308, %f1323;
	mul.rn.f32 	%f1326, %f1310, %f1325;
	add.f32 	%f1327, %f1321, %f1313;
	sub.f32 	%f1328, %f1313, %f1327;
	add.f32 	%f1329, %f1321, %f1328;
	add.f32 	%f1330, %f1326, %f1329;
	add.f32 	%f1331, %f1327, %f1330;
	sub.f32 	%f1332, %f1327, %f1331;
	add.f32 	%f1333, %f1330, %f1332;
	mul.rn.f32 	%f1335, %f1306, %f2926;
	mul.rn.f32 	%f1337, %f1306, %f2927;
	add.f32 	%f1338, %f1335, %f1331;
	sub.f32 	%f1339, %f1335, %f1338;
	add.f32 	%f1340, %f1331, %f1339;
	add.f32 	%f1341, %f1333, %f1340;
	add.f32 	%f1342, %f1337, %f1341;
	add.f32 	%f1343, %f1338, %f1342;
	sub.f32 	%f1344, %f1338, %f1343;
	add.f32 	%f1345, %f1342, %f1344;
	mul.rn.f32 	%f1346, %f634, %f1343;
	neg.f32 	%f1347, %f1346;
	fma.rn.f32 	%f1348, %f634, %f1343, %f1347;
	fma.rn.f32 	%f1349, %f634, %f1345, %f1348;
	fma.rn.f32 	%f1351, %f2930, %f1343, %f1349;
	add.rn.f32 	%f1352, %f1346, %f1351;
	neg.f32 	%f1353, %f1352;
	add.rn.f32 	%f1354, %f1346, %f1353;
	add.rn.f32 	%f1355, %f1354, %f1351;
	mov.b32 	%r416, %f1352;
	setp.eq.s32 	%p309, %r416, 1118925336;
	add.s32 	%r417, %r416, -1;
	mov.b32 	%f1356, %r417;
	add.f32 	%f1357, %f1355, 0f37000000;
	selp.f32 	%f201, %f1357, %f1355, %p309;
	selp.f32 	%f1358, %f1356, %f1352, %p309;
	mul.rn.f32 	%f1360, %f1358, %f2922;
	cvt.rzi.f32.f32 	%f1361, %f1360;
	abs.f32 	%f1362, %f1361;
	setp.gt.f32 	%p310, %f1362, 0f42FC0000;
	mov.b32 	%r418, %f1361;
	and.b32  	%r419, %r418, -2147483648;
	or.b32  	%r420, %r419, 1123811328;
	mov.b32 	%f1363, %r420;
	selp.f32 	%f1364, %f1363, %f1361, %p310;
	fma.rn.f32 	%f1366, %f1364, %f2928, %f1358;
	fma.rn.f32 	%f1368, %f1364, %f2929, %f1366;
	mul.f32 	%f1369, %f1368, 0f3FB8AA3B;
	add.f32 	%f1370, %f1364, 0f4B40007F;
	mov.b32 	%r421, %f1370;
	shl.b32 	%r422, %r421, 23;
	mov.b32 	%f1371, %r422;
	ex2.approx.ftz.f32 	%f1372, %f1369;
	mul.f32 	%f202, %f1372, %f1371;
	setp.eq.f32 	%p311, %f202, 0f7F800000;
	mov.f32 	%f3043, 0f7F800000;
	@%p311 bra 	$L__BB7_170;

	fma.rn.f32 	%f3043, %f202, %f201, %f202;

$L__BB7_170:
	setp.lt.f32 	%p312, %f199, 0f00000000;
	and.pred  	%p26, %p312, %p110;
	setp.eq.f32 	%p314, %f199, 0f00000000;
	@%p314 bra 	$L__BB7_174;
	bra.uni 	$L__BB7_171;

$L__BB7_174:
	add.f32 	%f1377, %f199, %f199;
	selp.f32 	%f3045, %f1377, 0f00000000, %p110;
	bra.uni 	$L__BB7_175;

$L__BB7_171:
	mov.b32 	%r423, %f3043;
	xor.b32  	%r424, %r423, -2147483648;
	mov.b32 	%f1373, %r424;
	selp.f32 	%f3045, %f1373, %f3043, %p26;
	setp.geu.f32 	%p315, %f199, 0f00000000;
	@%p315 bra 	$L__BB7_175;

	cvt.rzi.f32.f32 	%f1375, %f634;
	setp.eq.f32 	%p316, %f1375, 0f40000000;
	@%p316 bra 	$L__BB7_175;

	mov.f32 	%f3045, 0f7FFFFFFF;

$L__BB7_175:
	abs.f32 	%f2963, %f199;
	add.f32 	%f1378, %f2963, 0f40000000;
	mov.b32 	%r425, %f1378;
	setp.lt.s32 	%p318, %r425, 2139095040;
	@%p318 bra 	$L__BB7_180;

	abs.f32 	%f2964, %f199;
	setp.gtu.f32 	%p319, %f2964, 0f7F800000;
	@%p319 bra 	$L__BB7_179;
	bra.uni 	$L__BB7_177;

$L__BB7_179:
	add.f32 	%f3045, %f199, 0f40000000;
	bra.uni 	$L__BB7_180;

$L__BB7_177:
	abs.f32 	%f2965, %f199;
	setp.neu.f32 	%p320, %f2965, 0f7F800000;
	@%p320 bra 	$L__BB7_180;

	selp.f32 	%f3045, 0fFF800000, 0f7F800000, %p26;

$L__BB7_180:
	mov.f32 	%f2946, 0f00000000;
	mov.f32 	%f2945, 0f3102E308;
	mov.f32 	%f2944, 0fBF317218;
	mov.f32 	%f2943, 0f35BFBE8E;
	mov.f32 	%f2942, 0f3F317200;
	mov.f32 	%f2941, 0f3DAAAABD;
	mov.f32 	%f2940, 0f3C4CAF63;
	mov.f32 	%f2939, 0f3B18F0FE;
	mov.f32 	%f2938, 0f32A57060;
	mov.f32 	%f2937, 0f4B400001;
	mov.f32 	%f2936, 0f437C0000;
	mov.f32 	%f2935, 0f3BBB989D;
	mov.f32 	%f2934, 0f3FB8AA3B;
	mov.f32 	%f2933, 0f3F000000;
	cvt.rn.f32.s32 	%f2932, %r847;
	sub.f32 	%f2931, %f2932, %f3068;
	mul.f32 	%f1380, %f3045, 0fBF000000;
	setp.eq.f32 	%p321, %f199, 0f3F800000;
	selp.f32 	%f1381, 0fBF000000, %f1380, %p321;
	fma.rn.f32 	%f1384, %f1381, %f2935, %f2933;
	cvt.sat.f32.f32 	%f1387, %f1384;
	fma.rm.f32 	%f1389, %f1387, %f2936, %f2937;
	add.f32 	%f1390, %f1389, 0fCB40007F;
	neg.f32 	%f1391, %f1390;
	fma.rn.f32 	%f1392, %f1381, %f2934, %f1391;
	fma.rn.f32 	%f1394, %f1381, %f2938, %f1392;
	mov.b32 	%r426, %f1389;
	shl.b32 	%r427, %r426, 23;
	mov.b32 	%f1395, %r427;
	ex2.approx.ftz.f32 	%f1396, %f1394;
	mul.f32 	%f211, %f1396, %f1395;
	div.rn.f32 	%f212, %f2931, %f3064;
	abs.f32 	%f213, %f212;
	setp.lt.f32 	%p322, %f213, 0f00800000;
	mul.f32 	%f1397, %f213, 0f4B800000;
	selp.f32 	%f1398, %f1397, %f213, %p322;
	selp.f32 	%f1399, 0fC3170000, 0fC2FE0000, %p322;
	mov.b32 	%r428, %f1398;
	and.b32  	%r429, %r428, 8388607;
	or.b32  	%r430, %r429, 1065353216;
	mov.b32 	%f1400, %r430;
	shr.u32 	%r431, %r428, 23;
	cvt.rn.f32.u32 	%f1401, %r431;
	add.f32 	%f1402, %f1399, %f1401;
	setp.gt.f32 	%p323, %f1400, 0f3FB504F3;
	mul.f32 	%f1403, %f1400, 0f3F000000;
	add.f32 	%f1404, %f1402, 0f3F800000;
	selp.f32 	%f1405, %f1404, %f1402, %p323;
	selp.f32 	%f1406, %f1403, %f1400, %p323;
	add.f32 	%f1407, %f1406, 0fBF800000;
	add.f32 	%f1408, %f1406, 0f3F800000;
	rcp.approx.ftz.f32 	%f1409, %f1408;
	add.f32 	%f1410, %f1407, %f1407;
	mul.f32 	%f1412, %f1410, %f1409;
	mul.f32 	%f1413, %f1412, %f1412;
	fma.rn.f32 	%f1416, %f2939, %f1413, %f2940;
	fma.rn.f32 	%f1418, %f1416, %f1413, %f2941;
	mul.rn.f32 	%f1419, %f1418, %f1413;
	mul.rn.f32 	%f1420, %f1419, %f1412;
	sub.f32 	%f1421, %f1407, %f1412;
	add.f32 	%f1422, %f1421, %f1421;
	neg.f32 	%f1423, %f1412;
	fma.rn.f32 	%f1424, %f1423, %f1407, %f1422;
	mul.rn.f32 	%f1425, %f1409, %f1424;
	add.f32 	%f1426, %f1420, %f1412;
	sub.f32 	%f1427, %f1412, %f1426;
	add.f32 	%f1428, %f1420, %f1427;
	add.f32 	%f1429, %f1425, %f1428;
	add.f32 	%f1430, %f1426, %f1429;
	sub.f32 	%f1431, %f1426, %f1430;
	add.f32 	%f1432, %f1429, %f1431;
	mul.rn.f32 	%f1434, %f1405, %f2942;
	mul.rn.f32 	%f1436, %f1405, %f2943;
	add.f32 	%f1437, %f1434, %f1430;
	sub.f32 	%f1438, %f1434, %f1437;
	add.f32 	%f1439, %f1430, %f1438;
	add.f32 	%f1440, %f1432, %f1439;
	add.f32 	%f1441, %f1436, %f1440;
	add.f32 	%f1442, %f1437, %f1441;
	sub.f32 	%f1443, %f1437, %f1442;
	add.f32 	%f1444, %f1441, %f1443;
	mul.rn.f32 	%f1445, %f634, %f1442;
	neg.f32 	%f1446, %f1445;
	fma.rn.f32 	%f1447, %f634, %f1442, %f1446;
	fma.rn.f32 	%f1448, %f634, %f1444, %f1447;
	fma.rn.f32 	%f1450, %f2946, %f1442, %f1448;
	add.rn.f32 	%f1451, %f1445, %f1450;
	neg.f32 	%f1452, %f1451;
	add.rn.f32 	%f1453, %f1445, %f1452;
	add.rn.f32 	%f1454, %f1453, %f1450;
	mov.b32 	%r432, %f1451;
	setp.eq.s32 	%p324, %r432, 1118925336;
	add.s32 	%r433, %r432, -1;
	mov.b32 	%f1455, %r433;
	add.f32 	%f1456, %f1454, 0f37000000;
	selp.f32 	%f214, %f1456, %f1454, %p324;
	selp.f32 	%f1457, %f1455, %f1451, %p324;
	mul.rn.f32 	%f1458, %f1457, %f2934;
	cvt.rzi.f32.f32 	%f1459, %f1458;
	abs.f32 	%f1460, %f1459;
	setp.gt.f32 	%p325, %f1460, 0f42FC0000;
	mov.b32 	%r434, %f1459;
	and.b32  	%r435, %r434, -2147483648;
	or.b32  	%r436, %r435, 1123811328;
	mov.b32 	%f1461, %r436;
	selp.f32 	%f1462, %f1461, %f1459, %p325;
	fma.rn.f32 	%f1464, %f1462, %f2944, %f1457;
	fma.rn.f32 	%f1466, %f1462, %f2945, %f1464;
	mul.f32 	%f1467, %f1466, 0f3FB8AA3B;
	add.f32 	%f1468, %f1462, 0f4B40007F;
	mov.b32 	%r437, %f1468;
	shl.b32 	%r438, %r437, 23;
	mov.b32 	%f1469, %r438;
	ex2.approx.ftz.f32 	%f1470, %f1467;
	mul.f32 	%f215, %f1470, %f1469;
	setp.eq.f32 	%p326, %f215, 0f7F800000;
	mov.f32 	%f3046, 0f7F800000;
	@%p326 bra 	$L__BB7_182;

	fma.rn.f32 	%f3046, %f215, %f214, %f215;

$L__BB7_182:
	setp.lt.f32 	%p327, %f212, 0f00000000;
	and.pred  	%p27, %p327, %p110;
	setp.eq.f32 	%p329, %f212, 0f00000000;
	@%p329 bra 	$L__BB7_186;
	bra.uni 	$L__BB7_183;

$L__BB7_186:
	add.f32 	%f1475, %f212, %f212;
	selp.f32 	%f3048, %f1475, 0f00000000, %p110;
	bra.uni 	$L__BB7_187;

$L__BB7_183:
	mov.b32 	%r439, %f3046;
	xor.b32  	%r440, %r439, -2147483648;
	mov.b32 	%f1471, %r440;
	selp.f32 	%f3048, %f1471, %f3046, %p27;
	setp.geu.f32 	%p330, %f212, 0f00000000;
	@%p330 bra 	$L__BB7_187;

	cvt.rzi.f32.f32 	%f1473, %f634;
	setp.eq.f32 	%p331, %f1473, 0f40000000;
	@%p331 bra 	$L__BB7_187;

	mov.f32 	%f3048, 0f7FFFFFFF;

$L__BB7_187:
	abs.f32 	%f2827, %f212;
	add.f32 	%f1476, %f2827, 0f40000000;
	mov.b32 	%r441, %f1476;
	setp.lt.s32 	%p333, %r441, 2139095040;
	@%p333 bra 	$L__BB7_192;

	abs.f32 	%f2951, %f212;
	setp.gtu.f32 	%p334, %f2951, 0f7F800000;
	@%p334 bra 	$L__BB7_191;
	bra.uni 	$L__BB7_189;

$L__BB7_191:
	add.f32 	%f3048, %f212, 0f40000000;
	bra.uni 	$L__BB7_192;

$L__BB7_189:
	abs.f32 	%f2952, %f212;
	setp.neu.f32 	%p335, %f2952, 0f7F800000;
	@%p335 bra 	$L__BB7_192;

	selp.f32 	%f3048, 0fFF800000, 0f7F800000, %p27;

$L__BB7_192:
	mov.f32 	%f2835, 0f32A57060;
	mov.f32 	%f2834, 0f4B400001;
	mov.f32 	%f2833, 0f437C0000;
	mov.f32 	%f2832, 0f3BBB989D;
	mov.f32 	%f2831, 0f3FB8AA3B;
	mov.f32 	%f2830, 0f3F000000;
	cvt.rn.f32.s32 	%f2829, %r847;
	sub.f32 	%f2828, %f2829, %f3068;
	mul.f32 	%f1477, %f3048, 0fBF000000;
	setp.eq.f32 	%p336, %f212, 0f3F800000;
	selp.f32 	%f1478, 0fBF000000, %f1477, %p336;
	fma.rn.f32 	%f1481, %f1478, %f2832, %f2830;
	cvt.sat.f32.f32 	%f1484, %f1481;
	fma.rm.f32 	%f1486, %f1484, %f2833, %f2834;
	add.f32 	%f1487, %f1486, 0fCB40007F;
	neg.f32 	%f1488, %f1487;
	fma.rn.f32 	%f1489, %f1478, %f2831, %f1488;
	fma.rn.f32 	%f1491, %f1478, %f2835, %f1489;
	mov.b32 	%r442, %f1486;
	shl.b32 	%r443, %r442, 23;
	mov.b32 	%f1492, %r443;
	ex2.approx.ftz.f32 	%f1493, %f1491;
	mul.f32 	%f224, %f1493, %f1492;
	add.f32 	%f1494, %f2828, 0f3F800000;
	mul.f32 	%f1495, %f1494, %f211;
	mul.f32 	%f1496, %f2828, %f224;
	sub.f32 	%f1497, %f1495, %f1496;
	mul.f32 	%f1498, %f66, %f1497;
	mul.f32 	%f225, %f125, %f1498;
	not.pred 	%p337, %p13;
	mov.f64 	%fd585, %fd45;
	@%p337 bra 	$L__BB7_194;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r444}, %fd45;
	}
	xor.b32  	%r445, %r444, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r446, %temp}, %fd45;
	}
	mov.b64 	%fd585, {%r446, %r445};

$L__BB7_194:
	setp.eq.f32 	%p726, %f3064, 0f00000000;
	@%p726 bra 	$L__BB7_198;
	bra.uni 	$L__BB7_195;

$L__BB7_198:
	mov.u32 	%r447, 0;
	mov.b64 	%fd585, {%r447, %r70};
	bra.uni 	$L__BB7_199;

$L__BB7_195:
	setp.gt.s32 	%p339, %r56, -1;
	@%p339 bra 	$L__BB7_199;

	cvt.rzi.f64.f64 	%fd404, %fd345;
	setp.eq.f64 	%p340, %fd404, 0d4014000000000000;
	@%p340 bra 	$L__BB7_199;

	mov.f64 	%fd585, 0dFFF8000000000000;

$L__BB7_199:
	cvt.f64.f32 	%fd546, %f3064;
	add.f64 	%fd545, %fd546, 0d4014000000000000;
	selp.f64 	%fd586, %fd585, %fd545, %p160;
	@%p23 bra 	$L__BB7_204;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r831}, %fd345;
	}
	and.b32  	%r830, %r831, 2147483647;
	setp.eq.s32 	%p342, %r830, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r448, %temp}, %fd345;
	}
	setp.eq.s32 	%p343, %r448, 0;
	and.pred  	%p344, %p342, %p343;
	@%p344 bra 	$L__BB7_203;
	bra.uni 	$L__BB7_201;

$L__BB7_203:
	mov.u32 	%r452, 0;
	mov.b64 	%fd586, {%r452, %r72};
	bra.uni 	$L__BB7_204;

$L__BB7_201:
	cvt.f64.f32 	%fd547, %f3064;
	and.b32  	%r449, %r56, 2147483647;
	setp.ne.s32 	%p345, %r449, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r450, %temp}, %fd547;
	}
	setp.ne.s32 	%p346, %r450, 0;
	or.pred  	%p347, %p345, %p346;
	mov.f64 	%fd586, %fd585;
	@%p347 bra 	$L__BB7_204;

	mov.u32 	%r451, 0;
	mov.b64 	%fd586, {%r451, %r73};

$L__BB7_204:
	cvt.f64.f32 	%fd410, %f128;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd410;
	}
	abs.f64 	%fd96, %fd410;
	{ // callseq 162, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd588, [retval0+0];
	} // callseq 162
	setp.lt.s32 	%p348, %r79, 0;
	and.pred  	%p28, %p348, %p121;
	not.pred 	%p350, %p28;
	@%p350 bra 	$L__BB7_206;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r453}, %fd588;
	}
	xor.b32  	%r454, %r453, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r455, %temp}, %fd588;
	}
	mov.b64 	%fd588, {%r455, %r454};

$L__BB7_206:
	setp.eq.f32 	%p351, %f128, 0f00000000;
	@%p351 bra 	$L__BB7_210;
	bra.uni 	$L__BB7_207;

$L__BB7_210:
	mov.u32 	%r456, 0;
	selp.b32 	%r457, %r79, 0, %p121;
	or.b32  	%r458, %r457, 2146435072;
	selp.b32 	%r459, %r458, %r457, %p123;
	mov.b64 	%fd588, {%r456, %r459};
	bra.uni 	$L__BB7_211;

$L__BB7_207:
	setp.gt.s32 	%p352, %r79, -1;
	@%p352 bra 	$L__BB7_211;

	cvt.rzi.f64.f64 	%fd413, %fd339;
	setp.eq.f64 	%p353, %fd413, 0d4008000000000000;
	@%p353 bra 	$L__BB7_211;

	mov.f64 	%fd588, 0dFFF8000000000000;

$L__BB7_211:
	add.f64 	%fd102, %fd410, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r460}, %fd102;
	}
	and.b32  	%r461, %r460, 2146435072;
	setp.ne.s32 	%p356, %r461, 2146435072;
	mov.f64 	%fd589, %fd588;
	@%p356 bra 	$L__BB7_217;

	setp.gtu.f64 	%p357, %fd96, 0d7FF0000000000000;
	mov.f64 	%fd589, %fd102;
	@%p357 bra 	$L__BB7_217;

	setp.eq.s32 	%p358, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r462, %temp}, %fd339;
	}
	setp.eq.s32 	%p359, %r462, 0;
	and.pred  	%p360, %p358, %p359;
	@%p360 bra 	$L__BB7_216;
	bra.uni 	$L__BB7_214;

$L__BB7_216:
	mov.u32 	%r469, 0;
	setp.gt.f64 	%p368, %fd96, 0d3FF0000000000000;
	selp.b32 	%r470, 2146435072, 0, %p368;
	xor.b32  	%r471, %r470, 2146435072;
	selp.b32 	%r472, %r471, %r470, %p123;
	setp.eq.f32 	%p369, %f128, 0fBF800000;
	selp.b32 	%r473, 1072693248, %r472, %p369;
	mov.b64 	%fd589, {%r469, %r473};
	bra.uni 	$L__BB7_217;

$L__BB7_214:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r463, %temp}, %fd410;
	}
	and.b32  	%r464, %r79, 2147483647;
	setp.ne.s32 	%p361, %r464, 2146435072;
	setp.ne.s32 	%p362, %r463, 0;
	or.pred  	%p363, %p361, %p362;
	mov.f64 	%fd589, %fd588;
	@%p363 bra 	$L__BB7_217;

	setp.ne.s32 	%p364, %r53, 1071644672;
	and.pred  	%p365, %p364, %p28;
	mov.u32 	%r466, 0;
	or.b32  	%r467, %r55, -2147483648;
	selp.b32 	%r468, %r467, %r55, %p365;
	mov.b64 	%fd589, {%r466, %r468};

$L__BB7_217:
	setp.eq.f32 	%p370, %f128, 0f3F800000;
	selp.f64 	%fd418, 0d3FF0000000000000, %fd589, %p370;
	cvt.f64.f32 	%fd419, %f211;
	mul.f64 	%fd106, %fd418, %fd419;
	cvt.f64.f32 	%fd107, %f133;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd107;
	}
	abs.f64 	%fd108, %fd107;
	{ // callseq 163, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd339;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd591, [retval0+0];
	} // callseq 163
	setp.lt.s32 	%p371, %r80, 0;
	and.pred  	%p29, %p371, %p121;
	not.pred 	%p373, %p29;
	@%p373 bra 	$L__BB7_219;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r474}, %fd591;
	}
	xor.b32  	%r475, %r474, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r476, %temp}, %fd591;
	}
	mov.b64 	%fd591, {%r476, %r475};

$L__BB7_219:
	setp.eq.f32 	%p374, %f133, 0f00000000;
	@%p374 bra 	$L__BB7_223;
	bra.uni 	$L__BB7_220;

$L__BB7_223:
	mov.u32 	%r477, 0;
	selp.b32 	%r478, %r80, 0, %p121;
	or.b32  	%r479, %r478, 2146435072;
	selp.b32 	%r480, %r479, %r478, %p123;
	mov.b64 	%fd591, {%r477, %r480};
	bra.uni 	$L__BB7_224;

$L__BB7_220:
	setp.gt.s32 	%p375, %r80, -1;
	@%p375 bra 	$L__BB7_224;

	cvt.rzi.f64.f64 	%fd422, %fd339;
	setp.eq.f64 	%p376, %fd422, 0d4008000000000000;
	@%p376 bra 	$L__BB7_224;

	mov.f64 	%fd591, 0dFFF8000000000000;

$L__BB7_224:
	add.f64 	%fd114, %fd107, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r481}, %fd114;
	}
	and.b32  	%r482, %r481, 2146435072;
	setp.ne.s32 	%p379, %r482, 2146435072;
	mov.f64 	%fd592, %fd591;
	@%p379 bra 	$L__BB7_230;

	setp.gtu.f64 	%p380, %fd108, 0d7FF0000000000000;
	mov.f64 	%fd592, %fd114;
	@%p380 bra 	$L__BB7_230;

	setp.eq.s32 	%p381, %r53, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r483, %temp}, %fd339;
	}
	setp.eq.s32 	%p382, %r483, 0;
	and.pred  	%p383, %p381, %p382;
	@%p383 bra 	$L__BB7_229;
	bra.uni 	$L__BB7_227;

$L__BB7_229:
	mov.u32 	%r490, 0;
	setp.gt.f64 	%p391, %fd108, 0d3FF0000000000000;
	selp.b32 	%r491, 2146435072, 0, %p391;
	xor.b32  	%r492, %r491, 2146435072;
	selp.b32 	%r493, %r492, %r491, %p123;
	setp.eq.f32 	%p392, %f133, 0fBF800000;
	selp.b32 	%r494, 1072693248, %r493, %p392;
	mov.b64 	%fd592, {%r490, %r494};
	bra.uni 	$L__BB7_230;

$L__BB7_227:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r484, %temp}, %fd107;
	}
	and.b32  	%r485, %r80, 2147483647;
	setp.ne.s32 	%p384, %r485, 2146435072;
	setp.ne.s32 	%p385, %r484, 0;
	or.pred  	%p386, %p384, %p385;
	mov.f64 	%fd592, %fd591;
	@%p386 bra 	$L__BB7_230;

	setp.ne.s32 	%p387, %r53, 1071644672;
	and.pred  	%p388, %p387, %p29;
	mov.u32 	%r487, 0;
	or.b32  	%r488, %r55, -2147483648;
	selp.b32 	%r489, %r488, %r55, %p388;
	mov.b64 	%fd592, {%r487, %r489};

$L__BB7_230:
	cvt.f64.f32 	%fd548, %f125;
	setp.eq.f32 	%p727, %f3064, 0f3F800000;
	mov.f32 	%f3049, 0f00000000;
	setp.eq.f32 	%p393, %f133, 0f3F800000;
	selp.f64 	%fd425, 0d3FF0000000000000, %fd592, %p393;
	cvt.f64.f32 	%fd426, %f224;
	mul.f64 	%fd427, %fd425, %fd426;
	sub.f64 	%fd428, %fd106, %fd427;
	selp.f64 	%fd429, 0d3FF0000000000000, %fd586, %p727;
	div.rn.f64 	%fd430, %fd35, %fd429;
	mul.f64 	%fd431, %fd430, %fd428;
	mul.f64 	%fd433, %fd431, %fd548;
	mul.f32 	%f1500, %f67, %f225;
	cvt.f64.f32 	%fd434, %f1500;
	sub.f64 	%fd435, %fd434, %fd433;
	cvt.rn.f32.f64 	%f226, %fd435;
	mul.f32 	%f227, %f125, %f138;
	setp.leu.f32 	%p395, %f139, 0f3C23D70A;
	@%p395 bra 	$L__BB7_232;

	sub.f32 	%f1501, %f140, %f139;
	add.f32 	%f1502, %f139, %f3063;
	div.rn.f32 	%f3049, %f1501, %f1502;

$L__BB7_232:
	mov.f32 	%f3050, 0f00000000;
	@%p395 bra 	$L__BB7_247;

	and.b32  	%r495, %r74, 2146435072;
	setp.eq.s32 	%p397, %r495, 1062207488;
	add.f32 	%f230, %f139, %f3063;
	cvt.f64.f32 	%fd118, %f230;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r81}, %fd118;
	}
	abs.f64 	%fd119, %fd118;
	{ // callseq 164, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd119;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd594, [retval0+0];
	} // callseq 164
	setp.lt.s32 	%p398, %r81, 0;
	and.pred  	%p30, %p398, %p397;
	not.pred 	%p399, %p30;
	@%p399 bra 	$L__BB7_235;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r496}, %fd594;
	}
	xor.b32  	%r497, %r496, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r498, %temp}, %fd594;
	}
	mov.b64 	%fd594, {%r498, %r497};

$L__BB7_235:
	setp.eq.f32 	%p400, %f230, 0f00000000;
	@%p400 bra 	$L__BB7_239;
	bra.uni 	$L__BB7_236;

$L__BB7_239:
	setp.lt.s32 	%p403, %r74, 0;
	mov.u32 	%r499, 0;
	selp.b32 	%r501, %r81, 0, %p397;
	or.b32  	%r502, %r501, 2146435072;
	selp.b32 	%r503, %r502, %r501, %p403;
	mov.b64 	%fd594, {%r499, %r503};
	bra.uni 	$L__BB7_240;

$L__BB7_236:
	setp.gt.s32 	%p401, %r81, -1;
	@%p401 bra 	$L__BB7_240;

	cvt.rzi.f64.f64 	%fd438, %fd350;
	setp.eq.f64 	%p402, %fd438, 0d4000000000000000;
	@%p402 bra 	$L__BB7_240;

	mov.f64 	%fd594, 0dFFF8000000000000;

$L__BB7_240:
	add.f64 	%fd125, %fd118, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r504}, %fd125;
	}
	and.b32  	%r505, %r504, 2146435072;
	setp.ne.s32 	%p405, %r505, 2146435072;
	mov.f64 	%fd595, %fd594;
	@%p405 bra 	$L__BB7_246;

	setp.gtu.f64 	%p406, %fd119, 0d7FF0000000000000;
	mov.f64 	%fd595, %fd125;
	@%p406 bra 	$L__BB7_246;

	setp.eq.s32 	%p407, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r506, %temp}, %fd350;
	}
	setp.eq.s32 	%p408, %r506, 0;
	and.pred  	%p409, %p407, %p408;
	@%p409 bra 	$L__BB7_245;
	bra.uni 	$L__BB7_243;

$L__BB7_245:
	setp.lt.s32 	%p415, %r74, 0;
	mov.u32 	%r512, 0;
	setp.gt.f64 	%p416, %fd119, 0d3FF0000000000000;
	selp.b32 	%r513, 2146435072, 0, %p416;
	xor.b32  	%r514, %r513, 2146435072;
	selp.b32 	%r515, %r514, %r513, %p415;
	setp.eq.f32 	%p417, %f230, 0fBF800000;
	selp.b32 	%r516, 1072693248, %r515, %p417;
	mov.b64 	%fd595, {%r512, %r516};
	bra.uni 	$L__BB7_246;

$L__BB7_243:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r507, %temp}, %fd118;
	}
	and.b32  	%r508, %r81, 2147483647;
	setp.ne.s32 	%p410, %r508, 2146435072;
	setp.ne.s32 	%p411, %r507, 0;
	or.pred  	%p412, %p410, %p411;
	mov.f64 	%fd595, %fd594;
	@%p412 bra 	$L__BB7_246;

	setp.ne.s32 	%p413, %r75, 1071644672;
	and.pred  	%p414, %p413, %p30;
	or.b32  	%r509, %r76, -2147483648;
	selp.b32 	%r510, %r509, %r76, %p414;
	mov.u32 	%r511, 0;
	mov.b64 	%fd595, {%r511, %r510};

$L__BB7_246:
	setp.eq.f32 	%p418, %f230, 0f3F800000;
	selp.f64 	%fd441, 0d3FF0000000000000, %fd595, %p418;
	add.f32 	%f1504, %f140, %f3063;
	cvt.f64.f32 	%fd442, %f1504;
	div.rn.f64 	%fd443, %fd442, %fd441;
	cvt.rn.f32.f64 	%f3050, %fd443;

$L__BB7_247:
	and.b32  	%r517, %r74, 2146435072;
	setp.eq.s32 	%p419, %r517, 1062207488;
	mov.f32 	%f1505, 0f47C35000;
	min.f32 	%f1506, %f3050, %f1505;
	cvt.f64.f32 	%fd129, %f1506;
	min.f32 	%f233, %f3049, %f1505;
	fma.rn.f32 	%f3018, %f233, %f154, %f3018;
	mul.f32 	%f1507, %f233, %f155;
	cvt.f64.f32 	%fd130, %f1507;
	cvt.f64.f32 	%fd131, %f154;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd131;
	}
	abs.f64 	%fd132, %fd131;
	{ // callseq 165, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd132;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd596, [retval0+0];
	} // callseq 165
	@%p419 bra 	$L__BB7_304;
	bra.uni 	$L__BB7_248;

$L__BB7_304:
	setp.gt.s32 	%p495, %r82, -1;
	@%p495 bra 	$L__BB7_306;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r578}, %fd596;
	}
	xor.b32  	%r579, %r578, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r580, %temp}, %fd596;
	}
	mov.b64 	%fd596, {%r580, %r579};

$L__BB7_306:
	setp.eq.f32 	%p496, %f154, 0f00000000;
	@%p496 bra 	$L__BB7_310;
	bra.uni 	$L__BB7_307;

$L__BB7_310:
	setp.lt.s32 	%p499, %r74, 0;
	mov.u32 	%r581, 0;
	or.b32  	%r582, %r82, 2146435072;
	selp.b32 	%r583, %r582, %r82, %p499;
	mov.b64 	%fd596, {%r581, %r583};
	bra.uni 	$L__BB7_311;

$L__BB7_248:
	setp.eq.f32 	%p420, %f154, 0f00000000;
	@%p420 bra 	$L__BB7_252;
	bra.uni 	$L__BB7_249;

$L__BB7_252:
	mov.u32 	%r518, 0;
	mov.b64 	%fd596, {%r518, %r77};
	bra.uni 	$L__BB7_253;

$L__BB7_307:
	@%p495 bra 	$L__BB7_311;

	cvt.rzi.f64.f64 	%fd496, %fd350;
	setp.eq.f64 	%p498, %fd496, 0d4000000000000000;
	@%p498 bra 	$L__BB7_311;

	mov.f64 	%fd596, 0dFFF8000000000000;

$L__BB7_311:
	add.f64 	%fd186, %fd131, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r584}, %fd186;
	}
	and.b32  	%r585, %r584, 2146435072;
	setp.ne.s32 	%p500, %r585, 2146435072;
	mov.f64 	%fd608, %fd596;
	@%p500 bra 	$L__BB7_317;

	setp.gtu.f64 	%p501, %fd132, 0d7FF0000000000000;
	mov.f64 	%fd608, %fd186;
	@%p501 bra 	$L__BB7_317;

	setp.eq.s32 	%p502, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r586, %temp}, %fd350;
	}
	setp.eq.s32 	%p503, %r586, 0;
	and.pred  	%p504, %p502, %p503;
	@%p504 bra 	$L__BB7_316;
	bra.uni 	$L__BB7_314;

$L__BB7_316:
	setp.lt.s32 	%p511, %r74, 0;
	mov.u32 	%r592, 0;
	setp.gt.f64 	%p512, %fd132, 0d3FF0000000000000;
	selp.b32 	%r593, 2146435072, 0, %p512;
	xor.b32  	%r594, %r593, 2146435072;
	selp.b32 	%r595, %r594, %r593, %p511;
	setp.eq.f32 	%p513, %f154, 0fBF800000;
	selp.b32 	%r596, 1072693248, %r595, %p513;
	mov.b64 	%fd608, {%r592, %r596};
	bra.uni 	$L__BB7_317;

$L__BB7_249:
	setp.gt.s32 	%p421, %r82, -1;
	@%p421 bra 	$L__BB7_253;

	cvt.rzi.f64.f64 	%fd446, %fd350;
	setp.eq.f64 	%p422, %fd446, 0d4000000000000000;
	@%p422 bra 	$L__BB7_253;

	mov.f64 	%fd596, 0dFFF8000000000000;

$L__BB7_253:
	add.f64 	%fd136, %fd131, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r519}, %fd136;
	}
	and.b32  	%r520, %r519, 2146435072;
	setp.ne.s32 	%p423, %r520, 2146435072;
	mov.f64 	%fd597, %fd596;
	@%p423 bra 	$L__BB7_259;

	setp.gtu.f64 	%p424, %fd132, 0d7FF0000000000000;
	mov.f64 	%fd597, %fd136;
	@%p424 bra 	$L__BB7_259;

	setp.eq.s32 	%p425, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r521, %temp}, %fd350;
	}
	setp.eq.s32 	%p426, %r521, 0;
	and.pred  	%p427, %p425, %p426;
	@%p427 bra 	$L__BB7_258;
	bra.uni 	$L__BB7_256;

$L__BB7_258:
	setp.lt.s32 	%p431, %r74, 0;
	mov.u32 	%r525, 0;
	setp.gt.f64 	%p432, %fd132, 0d3FF0000000000000;
	selp.b32 	%r526, 2146435072, 0, %p432;
	xor.b32  	%r527, %r526, 2146435072;
	selp.b32 	%r528, %r527, %r526, %p431;
	setp.eq.f32 	%p433, %f154, 0fBF800000;
	selp.b32 	%r529, 1072693248, %r528, %p433;
	mov.b64 	%fd597, {%r525, %r529};
	bra.uni 	$L__BB7_259;

$L__BB7_314:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r587, %temp}, %fd131;
	}
	and.b32  	%r588, %r82, 2147483647;
	setp.ne.s32 	%p505, %r588, 2146435072;
	setp.ne.s32 	%p506, %r587, 0;
	or.pred  	%p507, %p505, %p506;
	mov.f64 	%fd608, %fd596;
	@%p507 bra 	$L__BB7_317;

	setp.lt.s32 	%p508, %r82, 0;
	mov.u32 	%r589, 0;
	setp.ne.s32 	%p509, %r75, 1071644672;
	and.pred  	%p510, %p509, %p508;
	or.b32  	%r590, %r76, -2147483648;
	selp.b32 	%r591, %r590, %r76, %p510;
	mov.b64 	%fd608, {%r589, %r591};

$L__BB7_317:
	setp.eq.f32 	%p514, %f154, 0f3F800000;
	selp.f64 	%fd499, 0d3FF0000000000000, %fd608, %p514;
	mul.f64 	%fd500, %fd499, %fd129;
	sub.f64 	%fd501, %fd130, %fd500;
	cvt.f64.f32 	%fd502, %f3024;
	add.f64 	%fd626, %fd501, %fd502;
	cvt.f64.f32 	%fd191, %f183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd191;
	}
	abs.f64 	%fd192, %fd191;
	{ // callseq 170, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd192;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd610, [retval0+0];
	} // callseq 170
	setp.gt.s32 	%p515, %r87, -1;
	@%p515 bra 	$L__BB7_319;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r597}, %fd610;
	}
	xor.b32  	%r598, %r597, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r599, %temp}, %fd610;
	}
	mov.b64 	%fd610, {%r599, %r598};

$L__BB7_319:
	setp.eq.f32 	%p516, %f183, 0f00000000;
	@%p516 bra 	$L__BB7_323;
	bra.uni 	$L__BB7_320;

$L__BB7_323:
	setp.lt.s32 	%p519, %r74, 0;
	mov.u32 	%r600, 0;
	or.b32  	%r601, %r87, 2146435072;
	selp.b32 	%r602, %r601, %r87, %p519;
	mov.b64 	%fd610, {%r600, %r602};
	bra.uni 	$L__BB7_324;

$L__BB7_320:
	@%p515 bra 	$L__BB7_324;

	cvt.rzi.f64.f64 	%fd505, %fd350;
	setp.eq.f64 	%p518, %fd505, 0d4000000000000000;
	@%p518 bra 	$L__BB7_324;

	mov.f64 	%fd610, 0dFFF8000000000000;

$L__BB7_324:
	add.f64 	%fd198, %fd191, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r603}, %fd198;
	}
	and.b32  	%r604, %r603, 2146435072;
	setp.ne.s32 	%p520, %r604, 2146435072;
	mov.f64 	%fd611, %fd610;
	@%p520 bra 	$L__BB7_330;

	setp.gtu.f64 	%p521, %fd192, 0d7FF0000000000000;
	mov.f64 	%fd611, %fd198;
	@%p521 bra 	$L__BB7_330;

	setp.eq.s32 	%p522, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r605, %temp}, %fd350;
	}
	setp.eq.s32 	%p523, %r605, 0;
	and.pred  	%p524, %p522, %p523;
	@%p524 bra 	$L__BB7_329;
	bra.uni 	$L__BB7_327;

$L__BB7_329:
	setp.lt.s32 	%p531, %r74, 0;
	mov.u32 	%r611, 0;
	setp.gt.f64 	%p532, %fd192, 0d3FF0000000000000;
	selp.b32 	%r612, 2146435072, 0, %p532;
	xor.b32  	%r613, %r612, 2146435072;
	selp.b32 	%r614, %r613, %r612, %p531;
	setp.eq.f32 	%p533, %f183, 0fBF800000;
	selp.b32 	%r615, 1072693248, %r614, %p533;
	mov.b64 	%fd611, {%r611, %r615};
	bra.uni 	$L__BB7_330;

$L__BB7_256:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r522, %temp}, %fd131;
	}
	and.b32  	%r523, %r82, 2147483647;
	setp.ne.s32 	%p428, %r523, 2146435072;
	setp.ne.s32 	%p429, %r522, 0;
	or.pred  	%p430, %p428, %p429;
	mov.f64 	%fd597, %fd596;
	@%p430 bra 	$L__BB7_259;

	mov.u32 	%r524, 0;
	mov.b64 	%fd597, {%r524, %r76};

$L__BB7_259:
	setp.eq.f32 	%p434, %f154, 0f3F800000;
	selp.f64 	%fd449, 0d3FF0000000000000, %fd597, %p434;
	mul.f64 	%fd450, %fd449, %fd129;
	sub.f64 	%fd451, %fd130, %fd450;
	cvt.f64.f32 	%fd452, %f3024;
	add.f64 	%fd626, %fd451, %fd452;
	cvt.f64.f32 	%fd141, %f183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd141;
	}
	abs.f64 	%fd142, %fd141;
	setp.eq.f32 	%p435, %f183, 0f00000000;
	@%p435 bra 	$L__BB7_263;
	bra.uni 	$L__BB7_260;

$L__BB7_263:
	mov.u32 	%r530, 0;
	mov.b64 	%fd598, {%r530, %r77};
	bra.uni 	$L__BB7_264;

$L__BB7_260:
	{ // callseq 166, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd142;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd598, [retval0+0];
	} // callseq 166
	setp.gt.s32 	%p436, %r83, -1;
	@%p436 bra 	$L__BB7_264;

	cvt.rzi.f64.f64 	%fd455, %fd350;
	setp.eq.f64 	%p437, %fd455, 0d4000000000000000;
	@%p437 bra 	$L__BB7_264;

	mov.f64 	%fd598, 0dFFF8000000000000;

$L__BB7_264:
	add.f64 	%fd146, %fd141, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r531}, %fd146;
	}
	and.b32  	%r532, %r531, 2146435072;
	setp.ne.s32 	%p438, %r532, 2146435072;
	mov.f64 	%fd599, %fd598;
	@%p438 bra 	$L__BB7_270;

	setp.gtu.f64 	%p439, %fd142, 0d7FF0000000000000;
	mov.f64 	%fd599, %fd146;
	@%p439 bra 	$L__BB7_270;

	setp.eq.s32 	%p440, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r533, %temp}, %fd350;
	}
	setp.eq.s32 	%p441, %r533, 0;
	and.pred  	%p442, %p440, %p441;
	@%p442 bra 	$L__BB7_269;
	bra.uni 	$L__BB7_267;

$L__BB7_269:
	setp.lt.s32 	%p446, %r74, 0;
	mov.u32 	%r537, 0;
	setp.gt.f64 	%p447, %fd142, 0d3FF0000000000000;
	selp.b32 	%r538, 2146435072, 0, %p447;
	xor.b32  	%r539, %r538, 2146435072;
	selp.b32 	%r540, %r539, %r538, %p446;
	setp.eq.f32 	%p448, %f183, 0fBF800000;
	selp.b32 	%r541, 1072693248, %r540, %p448;
	mov.b64 	%fd599, {%r537, %r541};
	bra.uni 	$L__BB7_270;

$L__BB7_327:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r606, %temp}, %fd191;
	}
	and.b32  	%r607, %r87, 2147483647;
	setp.ne.s32 	%p525, %r607, 2146435072;
	setp.ne.s32 	%p526, %r606, 0;
	or.pred  	%p527, %p525, %p526;
	mov.f64 	%fd611, %fd610;
	@%p527 bra 	$L__BB7_330;

	setp.lt.s32 	%p528, %r87, 0;
	mov.u32 	%r608, 0;
	setp.ne.s32 	%p529, %r75, 1071644672;
	and.pred  	%p530, %p529, %p528;
	or.b32  	%r609, %r76, -2147483648;
	selp.b32 	%r610, %r609, %r76, %p530;
	mov.b64 	%fd611, {%r608, %r610};

$L__BB7_330:
	setp.eq.f32 	%p534, %f183, 0f3F800000;
	selp.f64 	%fd508, 0d3FF0000000000000, %fd611, %p534;
	mul.f64 	%fd509, %fd508, %fd129;
	mul.f32 	%f1512, %f233, %f184;
	cvt.f64.f32 	%fd510, %f1512;
	sub.f64 	%fd511, %fd510, %fd509;
	cvt.f64.f32 	%fd512, %f3023;
	add.f64 	%fd625, %fd511, %fd512;
	cvt.f64.f32 	%fd203, %f227;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd203;
	}
	abs.f64 	%fd204, %fd203;
	{ // callseq 171, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd204;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd613, [retval0+0];
	} // callseq 171
	setp.gt.s32 	%p535, %r88, -1;
	@%p535 bra 	$L__BB7_332;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r616}, %fd613;
	}
	xor.b32  	%r617, %r616, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r618, %temp}, %fd613;
	}
	mov.b64 	%fd613, {%r618, %r617};

$L__BB7_332:
	setp.eq.f32 	%p536, %f227, 0f00000000;
	@%p536 bra 	$L__BB7_336;
	bra.uni 	$L__BB7_333;

$L__BB7_336:
	setp.lt.s32 	%p539, %r74, 0;
	mov.u32 	%r619, 0;
	or.b32  	%r620, %r88, 2146435072;
	selp.b32 	%r621, %r620, %r88, %p539;
	mov.b64 	%fd613, {%r619, %r621};
	bra.uni 	$L__BB7_337;

$L__BB7_333:
	@%p535 bra 	$L__BB7_337;

	cvt.rzi.f64.f64 	%fd515, %fd350;
	setp.eq.f64 	%p538, %fd515, 0d4000000000000000;
	@%p538 bra 	$L__BB7_337;

	mov.f64 	%fd613, 0dFFF8000000000000;

$L__BB7_337:
	add.f64 	%fd210, %fd203, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r622}, %fd210;
	}
	and.b32  	%r623, %r622, 2146435072;
	setp.ne.s32 	%p540, %r623, 2146435072;
	mov.f64 	%fd614, %fd613;
	@%p540 bra 	$L__BB7_343;

	setp.gtu.f64 	%p541, %fd204, 0d7FF0000000000000;
	mov.f64 	%fd614, %fd210;
	@%p541 bra 	$L__BB7_343;

	setp.eq.s32 	%p542, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r624, %temp}, %fd350;
	}
	setp.eq.s32 	%p543, %r624, 0;
	and.pred  	%p544, %p542, %p543;
	@%p544 bra 	$L__BB7_342;
	bra.uni 	$L__BB7_340;

$L__BB7_342:
	setp.lt.s32 	%p551, %r74, 0;
	mov.u32 	%r630, 0;
	setp.gt.f64 	%p552, %fd204, 0d3FF0000000000000;
	selp.b32 	%r631, 2146435072, 0, %p552;
	xor.b32  	%r632, %r631, 2146435072;
	selp.b32 	%r633, %r632, %r631, %p551;
	setp.eq.f32 	%p553, %f227, 0fBF800000;
	selp.b32 	%r634, 1072693248, %r633, %p553;
	mov.b64 	%fd614, {%r630, %r634};
	bra.uni 	$L__BB7_343;

$L__BB7_267:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r534, %temp}, %fd141;
	}
	and.b32  	%r535, %r83, 2147483647;
	setp.ne.s32 	%p443, %r535, 2146435072;
	setp.ne.s32 	%p444, %r534, 0;
	or.pred  	%p445, %p443, %p444;
	mov.f64 	%fd599, %fd598;
	@%p445 bra 	$L__BB7_270;

	mov.u32 	%r536, 0;
	mov.b64 	%fd599, {%r536, %r76};

$L__BB7_270:
	setp.eq.f32 	%p449, %f183, 0f3F800000;
	selp.f64 	%fd458, 0d3FF0000000000000, %fd599, %p449;
	mul.f64 	%fd459, %fd458, %fd129;
	mul.f32 	%f1508, %f233, %f184;
	cvt.f64.f32 	%fd460, %f1508;
	sub.f64 	%fd461, %fd460, %fd459;
	cvt.f64.f32 	%fd462, %f3023;
	add.f64 	%fd625, %fd461, %fd462;
	cvt.f64.f32 	%fd151, %f227;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd151;
	}
	abs.f64 	%fd152, %fd151;
	setp.eq.f32 	%p450, %f227, 0f00000000;
	@%p450 bra 	$L__BB7_274;
	bra.uni 	$L__BB7_271;

$L__BB7_274:
	mov.u32 	%r542, 0;
	mov.b64 	%fd600, {%r542, %r77};
	bra.uni 	$L__BB7_275;

$L__BB7_271:
	{ // callseq 167, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd152;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd600, [retval0+0];
	} // callseq 167
	setp.gt.s32 	%p451, %r84, -1;
	@%p451 bra 	$L__BB7_275;

	cvt.rzi.f64.f64 	%fd465, %fd350;
	setp.eq.f64 	%p452, %fd465, 0d4000000000000000;
	@%p452 bra 	$L__BB7_275;

	mov.f64 	%fd600, 0dFFF8000000000000;

$L__BB7_275:
	add.f64 	%fd156, %fd151, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r543}, %fd156;
	}
	and.b32  	%r544, %r543, 2146435072;
	setp.ne.s32 	%p453, %r544, 2146435072;
	mov.f64 	%fd601, %fd600;
	@%p453 bra 	$L__BB7_281;

	setp.gtu.f64 	%p454, %fd152, 0d7FF0000000000000;
	mov.f64 	%fd601, %fd156;
	@%p454 bra 	$L__BB7_281;

	setp.eq.s32 	%p455, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r545, %temp}, %fd350;
	}
	setp.eq.s32 	%p456, %r545, 0;
	and.pred  	%p457, %p455, %p456;
	@%p457 bra 	$L__BB7_280;
	bra.uni 	$L__BB7_278;

$L__BB7_280:
	setp.lt.s32 	%p461, %r74, 0;
	mov.u32 	%r549, 0;
	setp.gt.f64 	%p462, %fd152, 0d3FF0000000000000;
	selp.b32 	%r550, 2146435072, 0, %p462;
	xor.b32  	%r551, %r550, 2146435072;
	selp.b32 	%r552, %r551, %r550, %p461;
	setp.eq.f32 	%p463, %f227, 0fBF800000;
	selp.b32 	%r553, 1072693248, %r552, %p463;
	mov.b64 	%fd601, {%r549, %r553};
	bra.uni 	$L__BB7_281;

$L__BB7_340:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r625, %temp}, %fd203;
	}
	and.b32  	%r626, %r88, 2147483647;
	setp.ne.s32 	%p545, %r626, 2146435072;
	setp.ne.s32 	%p546, %r625, 0;
	or.pred  	%p547, %p545, %p546;
	mov.f64 	%fd614, %fd613;
	@%p547 bra 	$L__BB7_343;

	setp.lt.s32 	%p548, %r88, 0;
	mov.u32 	%r627, 0;
	setp.ne.s32 	%p549, %r75, 1071644672;
	and.pred  	%p550, %p549, %p548;
	or.b32  	%r628, %r76, -2147483648;
	selp.b32 	%r629, %r628, %r76, %p550;
	mov.b64 	%fd614, {%r627, %r629};

$L__BB7_343:
	mul.f32 	%f1513, %f233, 0f00000000;
	cvt.f64.f32 	%fd518, %f1513;
	setp.eq.f32 	%p554, %f227, 0f3F800000;
	selp.f64 	%fd519, 0d3FF0000000000000, %fd614, %p554;
	mul.f64 	%fd520, %fd519, %fd129;
	sub.f64 	%fd521, %fd518, %fd520;
	cvt.f64.f32 	%fd522, %f3022;
	add.f64 	%fd624, %fd521, %fd522;
	cvt.f64.f32 	%fd523, %f3021;
	sub.f64 	%fd524, %fd518, %fd129;
	add.f64 	%fd623, %fd524, %fd523;
	cvt.f64.f32 	%fd216, %f197;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r89}, %fd216;
	}
	abs.f64 	%fd217, %fd216;
	{ // callseq 172, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd217;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd616, [retval0+0];
	} // callseq 172
	setp.gt.s32 	%p555, %r89, -1;
	@%p555 bra 	$L__BB7_345;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r635}, %fd616;
	}
	xor.b32  	%r636, %r635, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r637, %temp}, %fd616;
	}
	mov.b64 	%fd616, {%r637, %r636};

$L__BB7_345:
	setp.eq.f32 	%p556, %f197, 0f00000000;
	@%p556 bra 	$L__BB7_349;
	bra.uni 	$L__BB7_346;

$L__BB7_349:
	setp.lt.s32 	%p559, %r74, 0;
	mov.u32 	%r638, 0;
	or.b32  	%r639, %r89, 2146435072;
	selp.b32 	%r640, %r639, %r89, %p559;
	mov.b64 	%fd616, {%r638, %r640};
	bra.uni 	$L__BB7_350;

$L__BB7_346:
	@%p555 bra 	$L__BB7_350;

	cvt.rzi.f64.f64 	%fd527, %fd350;
	setp.eq.f64 	%p558, %fd527, 0d4000000000000000;
	@%p558 bra 	$L__BB7_350;

	mov.f64 	%fd616, 0dFFF8000000000000;

$L__BB7_350:
	add.f64 	%fd223, %fd216, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r641}, %fd223;
	}
	and.b32  	%r642, %r641, 2146435072;
	setp.ne.s32 	%p560, %r642, 2146435072;
	mov.f64 	%fd617, %fd616;
	@%p560 bra 	$L__BB7_356;

	setp.gtu.f64 	%p561, %fd217, 0d7FF0000000000000;
	mov.f64 	%fd617, %fd223;
	@%p561 bra 	$L__BB7_356;

	setp.eq.s32 	%p562, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r643, %temp}, %fd350;
	}
	setp.eq.s32 	%p563, %r643, 0;
	and.pred  	%p564, %p562, %p563;
	@%p564 bra 	$L__BB7_355;
	bra.uni 	$L__BB7_353;

$L__BB7_355:
	setp.lt.s32 	%p571, %r74, 0;
	mov.u32 	%r649, 0;
	setp.gt.f64 	%p572, %fd217, 0d3FF0000000000000;
	selp.b32 	%r650, 2146435072, 0, %p572;
	xor.b32  	%r651, %r650, 2146435072;
	selp.b32 	%r652, %r651, %r650, %p571;
	setp.eq.f32 	%p573, %f197, 0fBF800000;
	selp.b32 	%r653, 1072693248, %r652, %p573;
	mov.b64 	%fd617, {%r649, %r653};
	bra.uni 	$L__BB7_356;

$L__BB7_278:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r546, %temp}, %fd151;
	}
	and.b32  	%r547, %r84, 2147483647;
	setp.ne.s32 	%p458, %r547, 2146435072;
	setp.ne.s32 	%p459, %r546, 0;
	or.pred  	%p460, %p458, %p459;
	mov.f64 	%fd601, %fd600;
	@%p460 bra 	$L__BB7_281;

	mov.u32 	%r548, 0;
	mov.b64 	%fd601, {%r548, %r76};

$L__BB7_281:
	mul.f32 	%f1509, %f233, 0f00000000;
	cvt.f64.f32 	%fd468, %f1509;
	setp.eq.f32 	%p464, %f227, 0f3F800000;
	selp.f64 	%fd469, 0d3FF0000000000000, %fd601, %p464;
	mul.f64 	%fd470, %fd469, %fd129;
	sub.f64 	%fd471, %fd468, %fd470;
	cvt.f64.f32 	%fd472, %f3022;
	add.f64 	%fd624, %fd471, %fd472;
	cvt.f64.f32 	%fd473, %f3021;
	sub.f64 	%fd474, %fd468, %fd129;
	add.f64 	%fd623, %fd474, %fd473;
	cvt.f64.f32 	%fd162, %f197;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd162;
	}
	abs.f64 	%fd163, %fd162;
	setp.eq.f32 	%p465, %f197, 0f00000000;
	@%p465 bra 	$L__BB7_285;
	bra.uni 	$L__BB7_282;

$L__BB7_285:
	mov.u32 	%r554, 0;
	mov.b64 	%fd602, {%r554, %r77};
	bra.uni 	$L__BB7_286;

$L__BB7_282:
	{ // callseq 168, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd163;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd602, [retval0+0];
	} // callseq 168
	setp.gt.s32 	%p466, %r85, -1;
	@%p466 bra 	$L__BB7_286;

	cvt.rzi.f64.f64 	%fd477, %fd350;
	setp.eq.f64 	%p467, %fd477, 0d4000000000000000;
	@%p467 bra 	$L__BB7_286;

	mov.f64 	%fd602, 0dFFF8000000000000;

$L__BB7_286:
	add.f64 	%fd167, %fd162, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r555}, %fd167;
	}
	and.b32  	%r556, %r555, 2146435072;
	setp.ne.s32 	%p468, %r556, 2146435072;
	mov.f64 	%fd603, %fd602;
	@%p468 bra 	$L__BB7_292;

	setp.gtu.f64 	%p469, %fd163, 0d7FF0000000000000;
	mov.f64 	%fd603, %fd167;
	@%p469 bra 	$L__BB7_292;

	setp.eq.s32 	%p470, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r557, %temp}, %fd350;
	}
	setp.eq.s32 	%p471, %r557, 0;
	and.pred  	%p472, %p470, %p471;
	@%p472 bra 	$L__BB7_291;
	bra.uni 	$L__BB7_289;

$L__BB7_291:
	setp.lt.s32 	%p476, %r74, 0;
	mov.u32 	%r561, 0;
	setp.gt.f64 	%p477, %fd163, 0d3FF0000000000000;
	selp.b32 	%r562, 2146435072, 0, %p477;
	xor.b32  	%r563, %r562, 2146435072;
	selp.b32 	%r564, %r563, %r562, %p476;
	setp.eq.f32 	%p478, %f197, 0fBF800000;
	selp.b32 	%r565, 1072693248, %r564, %p478;
	mov.b64 	%fd603, {%r561, %r565};
	bra.uni 	$L__BB7_292;

$L__BB7_353:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r644, %temp}, %fd216;
	}
	and.b32  	%r645, %r89, 2147483647;
	setp.ne.s32 	%p565, %r645, 2146435072;
	setp.ne.s32 	%p566, %r644, 0;
	or.pred  	%p567, %p565, %p566;
	mov.f64 	%fd617, %fd616;
	@%p567 bra 	$L__BB7_356;

	setp.lt.s32 	%p568, %r89, 0;
	mov.u32 	%r646, 0;
	setp.ne.s32 	%p569, %r75, 1071644672;
	and.pred  	%p570, %p569, %p568;
	or.b32  	%r647, %r76, -2147483648;
	selp.b32 	%r648, %r647, %r76, %p570;
	mov.b64 	%fd617, {%r646, %r648};

$L__BB7_356:
	setp.eq.f32 	%p574, %f197, 0f3F800000;
	selp.f64 	%fd530, 0d3FF0000000000000, %fd617, %p574;
	mul.f64 	%fd531, %fd530, %fd129;
	mul.f32 	%f1514, %f233, %f198;
	cvt.f64.f32 	%fd532, %f1514;
	sub.f64 	%fd533, %fd532, %fd531;
	cvt.f64.f32 	%fd534, %f3020;
	add.f64 	%fd622, %fd533, %fd534;
	cvt.f64.f32 	%fd228, %f225;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd228;
	}
	abs.f64 	%fd229, %fd228;
	{ // callseq 173, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd229;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd619, [retval0+0];
	} // callseq 173
	setp.gt.s32 	%p575, %r90, -1;
	@%p575 bra 	$L__BB7_358;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r654}, %fd619;
	}
	xor.b32  	%r655, %r654, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r656, %temp}, %fd619;
	}
	mov.b64 	%fd619, {%r656, %r655};

$L__BB7_358:
	setp.eq.f32 	%p576, %f225, 0f00000000;
	@%p576 bra 	$L__BB7_362;
	bra.uni 	$L__BB7_359;

$L__BB7_362:
	setp.lt.s32 	%p579, %r74, 0;
	mov.u32 	%r657, 0;
	or.b32  	%r658, %r90, 2146435072;
	selp.b32 	%r659, %r658, %r90, %p579;
	mov.b64 	%fd619, {%r657, %r659};
	bra.uni 	$L__BB7_363;

$L__BB7_359:
	@%p575 bra 	$L__BB7_363;

	cvt.rzi.f64.f64 	%fd537, %fd350;
	setp.eq.f64 	%p578, %fd537, 0d4000000000000000;
	@%p578 bra 	$L__BB7_363;

	mov.f64 	%fd619, 0dFFF8000000000000;

$L__BB7_363:
	add.f64 	%fd235, %fd228, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r660}, %fd235;
	}
	and.b32  	%r661, %r660, 2146435072;
	setp.ne.s32 	%p580, %r661, 2146435072;
	mov.f64 	%fd620, %fd619;
	@%p580 bra 	$L__BB7_369;

	setp.gtu.f64 	%p581, %fd229, 0d7FF0000000000000;
	mov.f64 	%fd620, %fd235;
	@%p581 bra 	$L__BB7_369;

	setp.eq.s32 	%p582, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r662, %temp}, %fd350;
	}
	setp.eq.s32 	%p583, %r662, 0;
	and.pred  	%p584, %p582, %p583;
	@%p584 bra 	$L__BB7_368;
	bra.uni 	$L__BB7_366;

$L__BB7_368:
	setp.lt.s32 	%p591, %r74, 0;
	mov.u32 	%r668, 0;
	setp.gt.f64 	%p592, %fd229, 0d3FF0000000000000;
	selp.b32 	%r669, 2146435072, 0, %p592;
	xor.b32  	%r670, %r669, 2146435072;
	selp.b32 	%r671, %r670, %r669, %p591;
	setp.eq.f32 	%p593, %f225, 0fBF800000;
	selp.b32 	%r672, 1072693248, %r671, %p593;
	mov.b64 	%fd620, {%r668, %r672};
	bra.uni 	$L__BB7_369;

$L__BB7_289:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r558, %temp}, %fd162;
	}
	and.b32  	%r559, %r85, 2147483647;
	setp.ne.s32 	%p473, %r559, 2146435072;
	setp.ne.s32 	%p474, %r558, 0;
	or.pred  	%p475, %p473, %p474;
	mov.f64 	%fd603, %fd602;
	@%p475 bra 	$L__BB7_292;

	mov.u32 	%r560, 0;
	mov.b64 	%fd603, {%r560, %r76};

$L__BB7_292:
	setp.eq.f32 	%p479, %f197, 0f3F800000;
	selp.f64 	%fd480, 0d3FF0000000000000, %fd603, %p479;
	mul.f64 	%fd481, %fd480, %fd129;
	mul.f32 	%f1510, %f233, %f198;
	cvt.f64.f32 	%fd482, %f1510;
	sub.f64 	%fd483, %fd482, %fd481;
	cvt.f64.f32 	%fd484, %f3020;
	add.f64 	%fd622, %fd483, %fd484;
	cvt.f64.f32 	%fd172, %f225;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd172;
	}
	abs.f64 	%fd173, %fd172;
	setp.eq.f32 	%p480, %f225, 0f00000000;
	@%p480 bra 	$L__BB7_296;
	bra.uni 	$L__BB7_293;

$L__BB7_296:
	mov.u32 	%r566, 0;
	mov.b64 	%fd604, {%r566, %r77};
	bra.uni 	$L__BB7_297;

$L__BB7_293:
	{ // callseq 169, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd173;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd350;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd604, [retval0+0];
	} // callseq 169
	setp.gt.s32 	%p481, %r86, -1;
	@%p481 bra 	$L__BB7_297;

	cvt.rzi.f64.f64 	%fd487, %fd350;
	setp.eq.f64 	%p482, %fd487, 0d4000000000000000;
	@%p482 bra 	$L__BB7_297;

	mov.f64 	%fd604, 0dFFF8000000000000;

$L__BB7_297:
	add.f64 	%fd177, %fd172, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r567}, %fd177;
	}
	and.b32  	%r568, %r567, 2146435072;
	setp.ne.s32 	%p483, %r568, 2146435072;
	mov.f64 	%fd605, %fd604;
	@%p483 bra 	$L__BB7_303;

	setp.gtu.f64 	%p484, %fd173, 0d7FF0000000000000;
	mov.f64 	%fd605, %fd177;
	@%p484 bra 	$L__BB7_303;

	setp.eq.s32 	%p485, %r75, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r569, %temp}, %fd350;
	}
	setp.eq.s32 	%p486, %r569, 0;
	and.pred  	%p487, %p485, %p486;
	@%p487 bra 	$L__BB7_302;
	bra.uni 	$L__BB7_300;

$L__BB7_302:
	setp.lt.s32 	%p491, %r74, 0;
	mov.u32 	%r573, 0;
	setp.gt.f64 	%p492, %fd173, 0d3FF0000000000000;
	selp.b32 	%r574, 2146435072, 0, %p492;
	xor.b32  	%r575, %r574, 2146435072;
	selp.b32 	%r576, %r575, %r574, %p491;
	setp.eq.f32 	%p493, %f225, 0fBF800000;
	selp.b32 	%r577, 1072693248, %r576, %p493;
	mov.b64 	%fd605, {%r573, %r577};
	bra.uni 	$L__BB7_303;

$L__BB7_366:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r663, %temp}, %fd228;
	}
	and.b32  	%r664, %r90, 2147483647;
	setp.ne.s32 	%p585, %r664, 2146435072;
	setp.ne.s32 	%p586, %r663, 0;
	or.pred  	%p587, %p585, %p586;
	mov.f64 	%fd620, %fd619;
	@%p587 bra 	$L__BB7_369;

	setp.lt.s32 	%p588, %r90, 0;
	mov.u32 	%r665, 0;
	setp.ne.s32 	%p589, %r75, 1071644672;
	and.pred  	%p590, %p589, %p588;
	or.b32  	%r666, %r76, -2147483648;
	selp.b32 	%r667, %r666, %r76, %p590;
	mov.b64 	%fd620, {%r665, %r667};

$L__BB7_369:
	setp.eq.f32 	%p594, %f225, 0f3F800000;
	selp.f64 	%fd540, 0d3FF0000000000000, %fd620, %p594;
	mul.f64 	%fd541, %fd540, %fd129;
	mul.f32 	%f1515, %f233, %f226;
	cvt.f64.f32 	%fd542, %f1515;
	sub.f64 	%fd543, %fd542, %fd541;
	cvt.f64.f32 	%fd544, %f3019;
	add.f64 	%fd621, %fd543, %fd544;
	bra.uni 	$L__BB7_370;

$L__BB7_300:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r570, %temp}, %fd172;
	}
	and.b32  	%r571, %r86, 2147483647;
	setp.ne.s32 	%p488, %r571, 2146435072;
	setp.ne.s32 	%p489, %r570, 0;
	or.pred  	%p490, %p488, %p489;
	mov.f64 	%fd605, %fd604;
	@%p490 bra 	$L__BB7_303;

	mov.u32 	%r572, 0;
	mov.b64 	%fd605, {%r572, %r76};

$L__BB7_303:
	setp.eq.f32 	%p494, %f225, 0f3F800000;
	selp.f64 	%fd490, 0d3FF0000000000000, %fd605, %p494;
	mul.f64 	%fd491, %fd490, %fd129;
	mul.f32 	%f1511, %f233, %f226;
	cvt.f64.f32 	%fd492, %f1511;
	sub.f64 	%fd493, %fd492, %fd491;
	cvt.f64.f32 	%fd494, %f3019;
	add.f64 	%fd621, %fd493, %fd494;

$L__BB7_370:
	cvt.rn.f32.f64 	%f3024, %fd626;
	cvt.rn.f32.f64 	%f3023, %fd625;
	cvt.rn.f32.f64 	%f3022, %fd624;
	cvt.rn.f32.f64 	%f3021, %fd623;
	cvt.rn.f32.f64 	%f3020, %fd622;
	cvt.rn.f32.f64 	%f3019, %fd621;
	fma.rn.f32 	%f3017, %f233, %f183, %f3017;
	fma.rn.f32 	%f3016, %f233, %f227, %f3016;
	add.f32 	%f3015, %f3015, %f233;
	fma.rn.f32 	%f3014, %f233, %f197, %f3014;
	fma.rn.f32 	%f3013, %f233, %f225, %f3013;
	add.s32 	%r847, %r847, 1;
	setp.lt.s32 	%p595, %r847, %r104;
	@%p595 bra 	$L__BB7_56;

	add.s32 	%r846, %r846, 1;
	setp.lt.s32 	%p596, %r846, %r104;
	@%p596 bra 	$L__BB7_55;

$L__BB7_372:
	ld.param.u32 	%r832, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_6];
	div.rn.f32 	%f1516, %f3018, %f3024;
	mov.f32 	%f1517, 0fBF800000;
	max.f32 	%f1518, %f1516, %f1517;
	mov.f32 	%f1519, 0f3F800000;
	min.f32 	%f1520, %f1518, %f1519;
	sub.f32 	%f3069, %f3069, %f1520;
	div.rn.f32 	%f1521, %f3017, %f3023;
	max.f32 	%f1522, %f1521, %f1517;
	min.f32 	%f1523, %f1522, %f1519;
	sub.f32 	%f3068, %f3068, %f1523;
	neg.f32 	%f1524, %f3067;
	div.rn.f32 	%f1525, %f3016, %f3022;
	max.f32 	%f1526, %f1525, %f1524;
	min.f32 	%f1527, %f1526, %f3067;
	sub.f32 	%f1528, %f3067, %f1527;
	neg.f32 	%f1529, %f3066;
	div.rn.f32 	%f1530, %f3015, %f3021;
	max.f32 	%f1531, %f1530, %f1529;
	min.f32 	%f1532, %f1531, %f3066;
	sub.f32 	%f1533, %f3066, %f1532;
	neg.f32 	%f1534, %f3065;
	div.rn.f32 	%f1535, %f3014, %f3020;
	max.f32 	%f1536, %f1535, %f1534;
	min.f32 	%f1537, %f1536, %f3065;
	sub.f32 	%f1538, %f3065, %f1537;
	neg.f32 	%f1539, %f3064;
	div.rn.f32 	%f1540, %f3013, %f3019;
	max.f32 	%f1541, %f1540, %f1539;
	min.f32 	%f1542, %f1541, %f3064;
	sub.f32 	%f1543, %f3064, %f1542;
	max.f32 	%f3067, %f1528, %f1519;
	mov.f32 	%f1544, 0f3C23D70A;
	max.f32 	%f3066, %f1533, %f1544;
	mov.f32 	%f1545, 0f3F000000;
	max.f32 	%f1546, %f1538, %f1545;
	min.f32 	%f3065, %f1546, %f51;
	max.f32 	%f1547, %f1543, %f1545;
	min.f32 	%f3064, %f1547, %f51;
	add.s32 	%r845, %r845, 1;
	setp.lt.s32 	%p597, %r845, %r832;
	@%p597 bra 	$L__BB7_53;

$L__BB7_373:
	mov.f32 	%f1569, 0f00000000;
	mov.f32 	%f3093, %f1569;
	mov.f32 	%f3094, %f1569;
	mov.f32 	%f3095, %f1569;
	mov.f32 	%f3098, %f1569;
	mov.f32 	%f3102, %f1569;
	mov.f32 	%f3107, %f1569;
	mov.f32 	%f3096, %f1569;
	mov.f32 	%f3097, %f1569;
	mov.f32 	%f3099, %f1569;
	mov.f32 	%f3103, %f1569;
	mov.f32 	%f3108, %f1569;
	mov.f32 	%f3100, %f1569;
	mov.f32 	%f3101, %f1569;
	mov.f32 	%f3104, %f1569;
	mov.f32 	%f3109, %f1569;
	mov.f32 	%f3105, %f1569;
	mov.f32 	%f3106, %f1569;
	mov.f32 	%f3110, %f1569;
	mov.f32 	%f3111, %f1569;
	mov.f32 	%f3112, %f1569;
	mov.f32 	%f3113, %f1569;
	mov.f32 	%f3141, %f1569;
	@%p44 bra 	$L__BB7_462;

	mov.f32 	%f1592, 0f3F000000;
	div.rn.f32 	%f1593, %f1592, %f3065;
	div.rn.f32 	%f1594, %f1593, %f3065;
	div.rn.f32 	%f1595, %f1592, %f3064;
	div.rn.f32 	%f1596, %f1595, %f3064;
	div.rn.f32 	%f1597, %f3067, 0fC0206C98;
	div.rn.f32 	%f272, %f1597, %f3065;
	div.rn.f32 	%f273, %f1597, %f3064;
	div.rn.f32 	%f274, %f272, %f3065;
	div.rn.f32 	%f275, %f273, %f3064;
	sqrt.rn.f32 	%f276, %f1594;
	sqrt.rn.f32 	%f277, %f1596;
	mov.f32 	%f1598, 0f3F800000;
	cvt.rzi.f32.f32 	%f1599, %f1598;
	add.f32 	%f1600, %f1599, %f1599;
	mov.f32 	%f1601, 0f40000000;
	sub.f32 	%f1602, %f1601, %f1600;
	abs.f32 	%f278, %f1602;
	mov.u32 	%r673, 0;
	setp.eq.f32 	%p606, %f278, 0f3F800000;
	mov.u32 	%r848, %r673;

$L__BB7_375:
	cvt.rn.f32.s32 	%f1603, %r848;
	sub.f32 	%f301, %f1603, %f3069;
	add.f32 	%f1604, %f301, 0f3F000000;
	mul.f32 	%f1605, %f1604, %f276;
	abs.f32 	%f302, %f1605;
	setp.ge.f32 	%p599, %f302, 0f3F8060FE;
	mul.f32 	%f1606, %f1605, %f1605;
	selp.f32 	%f1607, %f302, %f1606, %p599;
	selp.f32 	%f1608, 0f3789CA3C, 0f38B1E96A, %p599;
	selp.f32 	%f1609, 0fB9F560B9, 0fBA574D20, %p599;
	fma.rn.f32 	%f1610, %f1608, %f1607, %f1609;
	selp.f32 	%f1611, 0f3BAC840B, 0f3BAAD5EA, %p599;
	fma.rn.f32 	%f1612, %f1610, %f1607, %f1611;
	selp.f32 	%f1613, 0fBD0C8162, 0fBCDC1BE7, %p599;
	fma.rn.f32 	%f1614, %f1612, %f1607, %f1613;
	selp.f32 	%f1615, 0f3E1CF906, 0f3DE718AF, %p599;
	fma.rn.f32 	%f1616, %f1614, %f1607, %f1615;
	selp.f32 	%f1617, 0f3F6A937E, 0fBEC093AC, %p599;
	fma.rn.f32 	%f1618, %f1616, %f1607, %f1617;
	selp.f32 	%f1619, 0f3F20D842, 0f3E0375D3, %p599;
	fma.rn.f32 	%f1620, %f1618, %f1607, %f1619;
	neg.f32 	%f1621, %f302;
	selp.f32 	%f1622, %f1621, %f1605, %p599;
	fma.rn.f32 	%f303, %f1620, %f1622, %f1622;
	mov.b32 	%r675, %f1605;
	and.b32  	%r95, %r675, -2147483648;
	add.f32 	%f1623, %f301, 0fBF000000;
	mul.f32 	%f1624, %f1623, %f276;
	abs.f32 	%f304, %f1624;
	setp.ge.f32 	%p600, %f304, 0f3F8060FE;
	mul.f32 	%f1625, %f1624, %f1624;
	selp.f32 	%f1626, %f304, %f1625, %p600;
	selp.f32 	%f1627, 0f3789CA3C, 0f38B1E96A, %p600;
	selp.f32 	%f1628, 0fB9F560B9, 0fBA574D20, %p600;
	fma.rn.f32 	%f1629, %f1627, %f1626, %f1628;
	selp.f32 	%f1630, 0f3BAC840B, 0f3BAAD5EA, %p600;
	fma.rn.f32 	%f1631, %f1629, %f1626, %f1630;
	selp.f32 	%f1632, 0fBD0C8162, 0fBCDC1BE7, %p600;
	fma.rn.f32 	%f1633, %f1631, %f1626, %f1632;
	selp.f32 	%f1634, 0f3E1CF906, 0f3DE718AF, %p600;
	fma.rn.f32 	%f1635, %f1633, %f1626, %f1634;
	selp.f32 	%f1636, 0f3F6A937E, 0fBEC093AC, %p600;
	fma.rn.f32 	%f1637, %f1635, %f1626, %f1636;
	selp.f32 	%f1638, 0f3F20D842, 0f3E0375D3, %p600;
	fma.rn.f32 	%f1639, %f1637, %f1626, %f1638;
	neg.f32 	%f1640, %f304;
	selp.f32 	%f1641, %f1640, %f1624, %p600;
	fma.rn.f32 	%f305, %f1639, %f1641, %f1641;
	mov.b32 	%r676, %f1624;
	and.b32  	%r96, %r676, -2147483648;
	add.f32 	%f1642, %f1603, 0f3F000000;
	sub.f32 	%f1643, %f1642, %f3069;
	div.rn.f32 	%f306, %f1643, %f3065;
	abs.f32 	%f307, %f306;
	setp.lt.f32 	%p601, %f307, 0f00800000;
	mul.f32 	%f1644, %f307, 0f4B800000;
	selp.f32 	%f1645, %f1644, %f307, %p601;
	selp.f32 	%f1646, 0fC3170000, 0fC2FE0000, %p601;
	mov.b32 	%r677, %f1645;
	and.b32  	%r678, %r677, 8388607;
	or.b32  	%r679, %r678, 1065353216;
	mov.b32 	%f1647, %r679;
	shr.u32 	%r680, %r677, 23;
	cvt.rn.f32.u32 	%f1648, %r680;
	add.f32 	%f1649, %f1646, %f1648;
	setp.gt.f32 	%p602, %f1647, 0f3FB504F3;
	mul.f32 	%f1650, %f1647, 0f3F000000;
	add.f32 	%f1651, %f1649, 0f3F800000;
	selp.f32 	%f1652, %f1651, %f1649, %p602;
	selp.f32 	%f1653, %f1650, %f1647, %p602;
	add.f32 	%f1654, %f1653, 0fBF800000;
	add.f32 	%f1655, %f1653, 0f3F800000;
	rcp.approx.ftz.f32 	%f1656, %f1655;
	add.f32 	%f1657, %f1654, %f1654;
	mul.f32 	%f1659, %f1657, %f1656;
	mul.f32 	%f1660, %f1659, %f1659;
	mov.f32 	%f1661, 0f3C4CAF63;
	mov.f32 	%f1662, 0f3B18F0FE;
	fma.rn.f32 	%f1663, %f1662, %f1660, %f1661;
	mov.f32 	%f1664, 0f3DAAAABD;
	fma.rn.f32 	%f1665, %f1663, %f1660, %f1664;
	mul.rn.f32 	%f1666, %f1665, %f1660;
	mul.rn.f32 	%f1667, %f1666, %f1659;
	sub.f32 	%f1668, %f1654, %f1659;
	add.f32 	%f1669, %f1668, %f1668;
	neg.f32 	%f1670, %f1659;
	fma.rn.f32 	%f1671, %f1670, %f1654, %f1669;
	mul.rn.f32 	%f1672, %f1656, %f1671;
	add.f32 	%f1673, %f1667, %f1659;
	sub.f32 	%f1674, %f1659, %f1673;
	add.f32 	%f1675, %f1667, %f1674;
	add.f32 	%f1676, %f1672, %f1675;
	add.f32 	%f1677, %f1673, %f1676;
	sub.f32 	%f1678, %f1673, %f1677;
	add.f32 	%f1679, %f1676, %f1678;
	mov.f32 	%f1680, 0f3F317200;
	mul.rn.f32 	%f1681, %f1652, %f1680;
	mov.f32 	%f1682, 0f35BFBE8E;
	mul.rn.f32 	%f1683, %f1652, %f1682;
	add.f32 	%f1684, %f1681, %f1677;
	sub.f32 	%f1685, %f1681, %f1684;
	add.f32 	%f1686, %f1677, %f1685;
	add.f32 	%f1687, %f1679, %f1686;
	add.f32 	%f1688, %f1683, %f1687;
	add.f32 	%f1689, %f1684, %f1688;
	sub.f32 	%f1690, %f1684, %f1689;
	add.f32 	%f1691, %f1688, %f1690;
	mul.rn.f32 	%f1692, %f1601, %f1689;
	neg.f32 	%f1693, %f1692;
	fma.rn.f32 	%f1694, %f1601, %f1689, %f1693;
	fma.rn.f32 	%f1695, %f1601, %f1691, %f1694;
	fma.rn.f32 	%f1697, %f1569, %f1689, %f1695;
	add.rn.f32 	%f1698, %f1692, %f1697;
	neg.f32 	%f1699, %f1698;
	add.rn.f32 	%f1700, %f1692, %f1699;
	add.rn.f32 	%f1701, %f1700, %f1697;
	mov.b32 	%r681, %f1698;
	setp.eq.s32 	%p603, %r681, 1118925336;
	add.s32 	%r682, %r681, -1;
	mov.b32 	%f1702, %r682;
	add.f32 	%f1703, %f1701, 0f37000000;
	selp.f32 	%f308, %f1703, %f1701, %p603;
	selp.f32 	%f1704, %f1702, %f1698, %p603;
	mov.f32 	%f1705, 0f3FB8AA3B;
	mul.rn.f32 	%f1706, %f1704, %f1705;
	cvt.rzi.f32.f32 	%f1707, %f1706;
	abs.f32 	%f1708, %f1707;
	setp.gt.f32 	%p604, %f1708, 0f42FC0000;
	mov.b32 	%r683, %f1707;
	and.b32  	%r684, %r683, -2147483648;
	or.b32  	%r685, %r684, 1123811328;
	mov.b32 	%f1709, %r685;
	selp.f32 	%f1710, %f1709, %f1707, %p604;
	mov.f32 	%f1711, 0fBF317218;
	fma.rn.f32 	%f1712, %f1710, %f1711, %f1704;
	mov.f32 	%f1713, 0f3102E308;
	fma.rn.f32 	%f1714, %f1710, %f1713, %f1712;
	mul.f32 	%f1715, %f1714, 0f3FB8AA3B;
	add.f32 	%f1716, %f1710, 0f4B40007F;
	mov.b32 	%r686, %f1716;
	shl.b32 	%r687, %r686, 23;
	mov.b32 	%f1717, %r687;
	ex2.approx.ftz.f32 	%f1718, %f1715;
	mul.f32 	%f309, %f1718, %f1717;
	setp.lt.f32 	%p605, %f306, 0f00000000;
	and.pred  	%p31, %p605, %p606;
	add.f32 	%f1719, %f306, %f306;
	selp.f32 	%f310, %f1719, 0f00000000, %p606;
	add.f32 	%f1720, %f307, 0f40000000;
	mov.b32 	%r97, %f1720;
	div.rn.f32 	%f311, %f1623, %f3065;
	abs.f32 	%f312, %f311;
	setp.lt.f32 	%p607, %f312, 0f00800000;
	mul.f32 	%f1721, %f312, 0f4B800000;
	selp.f32 	%f1722, %f1721, %f312, %p607;
	selp.f32 	%f1723, 0fC3170000, 0fC2FE0000, %p607;
	mov.b32 	%r688, %f1722;
	and.b32  	%r689, %r688, 8388607;
	or.b32  	%r690, %r689, 1065353216;
	mov.b32 	%f1724, %r690;
	shr.u32 	%r691, %r688, 23;
	cvt.rn.f32.u32 	%f1725, %r691;
	add.f32 	%f1726, %f1723, %f1725;
	setp.gt.f32 	%p608, %f1724, 0f3FB504F3;
	mul.f32 	%f1727, %f1724, 0f3F000000;
	add.f32 	%f1728, %f1726, 0f3F800000;
	selp.f32 	%f1729, %f1728, %f1726, %p608;
	selp.f32 	%f1730, %f1727, %f1724, %p608;
	add.f32 	%f1731, %f1730, 0fBF800000;
	add.f32 	%f1732, %f1730, 0f3F800000;
	rcp.approx.ftz.f32 	%f1733, %f1732;
	add.f32 	%f1734, %f1731, %f1731;
	mul.f32 	%f1735, %f1734, %f1733;
	mul.f32 	%f1736, %f1735, %f1735;
	fma.rn.f32 	%f1737, %f1662, %f1736, %f1661;
	fma.rn.f32 	%f1738, %f1737, %f1736, %f1664;
	mul.rn.f32 	%f1739, %f1738, %f1736;
	mul.rn.f32 	%f1740, %f1739, %f1735;
	sub.f32 	%f1741, %f1731, %f1735;
	add.f32 	%f1742, %f1741, %f1741;
	neg.f32 	%f1743, %f1735;
	fma.rn.f32 	%f1744, %f1743, %f1731, %f1742;
	mul.rn.f32 	%f1745, %f1733, %f1744;
	add.f32 	%f1746, %f1740, %f1735;
	sub.f32 	%f1747, %f1735, %f1746;
	add.f32 	%f1748, %f1740, %f1747;
	add.f32 	%f1749, %f1745, %f1748;
	add.f32 	%f1750, %f1746, %f1749;
	sub.f32 	%f1751, %f1746, %f1750;
	add.f32 	%f1752, %f1749, %f1751;
	mul.rn.f32 	%f1753, %f1729, %f1680;
	mul.rn.f32 	%f1754, %f1729, %f1682;
	add.f32 	%f1755, %f1753, %f1750;
	sub.f32 	%f1756, %f1753, %f1755;
	add.f32 	%f1757, %f1750, %f1756;
	add.f32 	%f1758, %f1752, %f1757;
	add.f32 	%f1759, %f1754, %f1758;
	add.f32 	%f1760, %f1755, %f1759;
	sub.f32 	%f1761, %f1755, %f1760;
	add.f32 	%f1762, %f1759, %f1761;
	mul.rn.f32 	%f1763, %f1601, %f1760;
	neg.f32 	%f1764, %f1763;
	fma.rn.f32 	%f1765, %f1601, %f1760, %f1764;
	fma.rn.f32 	%f1766, %f1601, %f1762, %f1765;
	fma.rn.f32 	%f1767, %f1569, %f1760, %f1766;
	add.rn.f32 	%f1768, %f1763, %f1767;
	neg.f32 	%f1769, %f1768;
	add.rn.f32 	%f1770, %f1763, %f1769;
	add.rn.f32 	%f1771, %f1770, %f1767;
	mov.b32 	%r692, %f1768;
	setp.eq.s32 	%p609, %r692, 1118925336;
	add.s32 	%r693, %r692, -1;
	mov.b32 	%f1772, %r693;
	add.f32 	%f1773, %f1771, 0f37000000;
	selp.f32 	%f313, %f1773, %f1771, %p609;
	selp.f32 	%f1774, %f1772, %f1768, %p609;
	mul.rn.f32 	%f1775, %f1774, %f1705;
	cvt.rzi.f32.f32 	%f1776, %f1775;
	abs.f32 	%f1777, %f1776;
	setp.gt.f32 	%p610, %f1777, 0f42FC0000;
	mov.b32 	%r694, %f1776;
	and.b32  	%r695, %r694, -2147483648;
	or.b32  	%r696, %r695, 1123811328;
	mov.b32 	%f1778, %r696;
	selp.f32 	%f1779, %f1778, %f1776, %p610;
	fma.rn.f32 	%f1780, %f1779, %f1711, %f1774;
	fma.rn.f32 	%f1781, %f1779, %f1713, %f1780;
	mul.f32 	%f1782, %f1781, 0f3FB8AA3B;
	add.f32 	%f1783, %f1779, 0f4B40007F;
	mov.b32 	%r697, %f1783;
	shl.b32 	%r698, %r697, 23;
	mov.b32 	%f1784, %r698;
	ex2.approx.ftz.f32 	%f1785, %f1782;
	mul.f32 	%f314, %f1785, %f1784;
	add.f32 	%f315, %f306, 0f40000000;
	setp.lt.f32 	%p611, %f311, 0f00000000;
	and.pred  	%p32, %p611, %p606;
	selp.f32 	%f316, 0fFF800000, 0f7F800000, %p31;
	add.f32 	%f1786, %f311, %f311;
	selp.f32 	%f317, %f1786, 0f00000000, %p606;
	add.f32 	%f1787, %f312, 0f40000000;
	mov.b32 	%r98, %f1787;
	add.f32 	%f318, %f311, 0f40000000;
	selp.f32 	%f319, 0fFF800000, 0f7F800000, %p32;
	add.f32 	%f1788, %f1603, 0f3F800000;
	sub.f32 	%f1789, %f1788, %f3069;
	div.rn.f32 	%f320, %f1789, %f3065;
	abs.f32 	%f321, %f320;
	setp.lt.f32 	%p612, %f321, 0f00800000;
	mul.f32 	%f1790, %f321, 0f4B800000;
	selp.f32 	%f1791, %f1790, %f321, %p612;
	selp.f32 	%f1792, 0fC3170000, 0fC2FE0000, %p612;
	mov.b32 	%r699, %f1791;
	and.b32  	%r700, %r699, 8388607;
	or.b32  	%r701, %r700, 1065353216;
	mov.b32 	%f1793, %r701;
	shr.u32 	%r702, %r699, 23;
	cvt.rn.f32.u32 	%f1794, %r702;
	add.f32 	%f1795, %f1792, %f1794;
	setp.gt.f32 	%p613, %f1793, 0f3FB504F3;
	mul.f32 	%f1796, %f1793, 0f3F000000;
	add.f32 	%f1797, %f1795, 0f3F800000;
	selp.f32 	%f1798, %f1797, %f1795, %p613;
	selp.f32 	%f1799, %f1796, %f1793, %p613;
	add.f32 	%f1800, %f1799, 0fBF800000;
	add.f32 	%f1801, %f1799, 0f3F800000;
	rcp.approx.ftz.f32 	%f1802, %f1801;
	add.f32 	%f1803, %f1800, %f1800;
	mul.f32 	%f1804, %f1803, %f1802;
	mul.f32 	%f1805, %f1804, %f1804;
	fma.rn.f32 	%f1806, %f1662, %f1805, %f1661;
	fma.rn.f32 	%f1807, %f1806, %f1805, %f1664;
	mul.rn.f32 	%f1808, %f1807, %f1805;
	mul.rn.f32 	%f1809, %f1808, %f1804;
	sub.f32 	%f1810, %f1800, %f1804;
	add.f32 	%f1811, %f1810, %f1810;
	neg.f32 	%f1812, %f1804;
	fma.rn.f32 	%f1813, %f1812, %f1800, %f1811;
	mul.rn.f32 	%f1814, %f1802, %f1813;
	add.f32 	%f1815, %f1809, %f1804;
	sub.f32 	%f1816, %f1804, %f1815;
	add.f32 	%f1817, %f1809, %f1816;
	add.f32 	%f1818, %f1814, %f1817;
	add.f32 	%f1819, %f1815, %f1818;
	sub.f32 	%f1820, %f1815, %f1819;
	add.f32 	%f1821, %f1818, %f1820;
	mul.rn.f32 	%f1822, %f1798, %f1680;
	mul.rn.f32 	%f1823, %f1798, %f1682;
	add.f32 	%f1824, %f1822, %f1819;
	sub.f32 	%f1825, %f1822, %f1824;
	add.f32 	%f1826, %f1819, %f1825;
	add.f32 	%f1827, %f1821, %f1826;
	add.f32 	%f1828, %f1823, %f1827;
	add.f32 	%f1829, %f1824, %f1828;
	sub.f32 	%f1830, %f1824, %f1829;
	add.f32 	%f1831, %f1828, %f1830;
	mul.rn.f32 	%f1832, %f1601, %f1829;
	neg.f32 	%f1833, %f1832;
	fma.rn.f32 	%f1834, %f1601, %f1829, %f1833;
	fma.rn.f32 	%f1835, %f1601, %f1831, %f1834;
	fma.rn.f32 	%f1836, %f1569, %f1829, %f1835;
	add.rn.f32 	%f1837, %f1832, %f1836;
	neg.f32 	%f1838, %f1837;
	add.rn.f32 	%f1839, %f1832, %f1838;
	add.rn.f32 	%f1840, %f1839, %f1836;
	mov.b32 	%r703, %f1837;
	setp.eq.s32 	%p614, %r703, 1118925336;
	add.s32 	%r704, %r703, -1;
	mov.b32 	%f1841, %r704;
	add.f32 	%f1842, %f1840, 0f37000000;
	selp.f32 	%f322, %f1842, %f1840, %p614;
	selp.f32 	%f1843, %f1841, %f1837, %p614;
	mul.rn.f32 	%f1844, %f1843, %f1705;
	cvt.rzi.f32.f32 	%f1845, %f1844;
	abs.f32 	%f1846, %f1845;
	setp.gt.f32 	%p615, %f1846, 0f42FC0000;
	mov.b32 	%r705, %f1845;
	and.b32  	%r706, %r705, -2147483648;
	or.b32  	%r707, %r706, 1123811328;
	mov.b32 	%f1847, %r707;
	selp.f32 	%f1848, %f1847, %f1845, %p615;
	fma.rn.f32 	%f1849, %f1848, %f1711, %f1843;
	fma.rn.f32 	%f1850, %f1848, %f1713, %f1849;
	mul.f32 	%f1851, %f1850, 0f3FB8AA3B;
	add.f32 	%f1852, %f1848, 0f4B40007F;
	mov.b32 	%r708, %f1852;
	shl.b32 	%r709, %r708, 23;
	mov.b32 	%f1853, %r709;
	ex2.approx.ftz.f32 	%f1854, %f1851;
	mul.f32 	%f323, %f1854, %f1853;
	setp.lt.f32 	%p616, %f320, 0f00000000;
	and.pred  	%p33, %p616, %p606;
	add.f32 	%f1855, %f320, %f320;
	selp.f32 	%f324, %f1855, 0f00000000, %p606;
	add.f32 	%f1856, %f321, 0f40000000;
	mov.b32 	%r99, %f1856;
	div.rn.f32 	%f325, %f301, %f3065;
	abs.f32 	%f326, %f325;
	setp.lt.f32 	%p617, %f326, 0f00800000;
	mul.f32 	%f1857, %f326, 0f4B800000;
	selp.f32 	%f1858, %f1857, %f326, %p617;
	selp.f32 	%f1859, 0fC3170000, 0fC2FE0000, %p617;
	mov.b32 	%r710, %f1858;
	and.b32  	%r711, %r710, 8388607;
	or.b32  	%r712, %r711, 1065353216;
	mov.b32 	%f1860, %r712;
	shr.u32 	%r713, %r710, 23;
	cvt.rn.f32.u32 	%f1861, %r713;
	add.f32 	%f1862, %f1859, %f1861;
	setp.gt.f32 	%p618, %f1860, 0f3FB504F3;
	mul.f32 	%f1863, %f1860, 0f3F000000;
	add.f32 	%f1864, %f1862, 0f3F800000;
	selp.f32 	%f1865, %f1864, %f1862, %p618;
	selp.f32 	%f1866, %f1863, %f1860, %p618;
	add.f32 	%f1867, %f1866, 0fBF800000;
	add.f32 	%f1868, %f1866, 0f3F800000;
	rcp.approx.ftz.f32 	%f1869, %f1868;
	add.f32 	%f1870, %f1867, %f1867;
	mul.f32 	%f1871, %f1870, %f1869;
	mul.f32 	%f1872, %f1871, %f1871;
	fma.rn.f32 	%f1873, %f1662, %f1872, %f1661;
	fma.rn.f32 	%f1874, %f1873, %f1872, %f1664;
	mul.rn.f32 	%f1875, %f1874, %f1872;
	mul.rn.f32 	%f1876, %f1875, %f1871;
	sub.f32 	%f1877, %f1867, %f1871;
	add.f32 	%f1878, %f1877, %f1877;
	neg.f32 	%f1879, %f1871;
	fma.rn.f32 	%f1880, %f1879, %f1867, %f1878;
	mul.rn.f32 	%f1881, %f1869, %f1880;
	add.f32 	%f1882, %f1876, %f1871;
	sub.f32 	%f1883, %f1871, %f1882;
	add.f32 	%f1884, %f1876, %f1883;
	add.f32 	%f1885, %f1881, %f1884;
	add.f32 	%f1886, %f1882, %f1885;
	sub.f32 	%f1887, %f1882, %f1886;
	add.f32 	%f1888, %f1885, %f1887;
	mul.rn.f32 	%f1889, %f1865, %f1680;
	mul.rn.f32 	%f1890, %f1865, %f1682;
	add.f32 	%f1891, %f1889, %f1886;
	sub.f32 	%f1892, %f1889, %f1891;
	add.f32 	%f1893, %f1886, %f1892;
	add.f32 	%f1894, %f1888, %f1893;
	add.f32 	%f1895, %f1890, %f1894;
	add.f32 	%f1896, %f1891, %f1895;
	sub.f32 	%f1897, %f1891, %f1896;
	add.f32 	%f1898, %f1895, %f1897;
	mul.rn.f32 	%f1899, %f1601, %f1896;
	neg.f32 	%f1900, %f1899;
	fma.rn.f32 	%f1901, %f1601, %f1896, %f1900;
	fma.rn.f32 	%f1902, %f1601, %f1898, %f1901;
	fma.rn.f32 	%f1903, %f1569, %f1896, %f1902;
	add.rn.f32 	%f1904, %f1899, %f1903;
	neg.f32 	%f1905, %f1904;
	add.rn.f32 	%f1906, %f1899, %f1905;
	add.rn.f32 	%f1907, %f1906, %f1903;
	mov.b32 	%r714, %f1904;
	setp.eq.s32 	%p619, %r714, 1118925336;
	add.s32 	%r715, %r714, -1;
	mov.b32 	%f1908, %r715;
	add.f32 	%f1909, %f1907, 0f37000000;
	selp.f32 	%f327, %f1909, %f1907, %p619;
	selp.f32 	%f1910, %f1908, %f1904, %p619;
	mul.rn.f32 	%f1911, %f1910, %f1705;
	cvt.rzi.f32.f32 	%f1912, %f1911;
	abs.f32 	%f1913, %f1912;
	setp.gt.f32 	%p620, %f1913, 0f42FC0000;
	mov.b32 	%r716, %f1912;
	and.b32  	%r717, %r716, -2147483648;
	or.b32  	%r718, %r717, 1123811328;
	mov.b32 	%f1914, %r718;
	selp.f32 	%f1915, %f1914, %f1912, %p620;
	fma.rn.f32 	%f1916, %f1915, %f1711, %f1910;
	fma.rn.f32 	%f1917, %f1915, %f1713, %f1916;
	mul.f32 	%f1918, %f1917, 0f3FB8AA3B;
	add.f32 	%f1919, %f1915, 0f4B40007F;
	mov.b32 	%r719, %f1919;
	shl.b32 	%r720, %r719, 23;
	mov.b32 	%f1920, %r720;
	ex2.approx.ftz.f32 	%f1921, %f1918;
	mul.f32 	%f328, %f1921, %f1920;
	add.f32 	%f329, %f320, 0f40000000;
	setp.lt.f32 	%p621, %f325, 0f00000000;
	and.pred  	%p34, %p621, %p606;
	selp.f32 	%f330, 0fFF800000, 0f7F800000, %p33;
	add.f32 	%f1922, %f325, %f325;
	selp.f32 	%f331, %f1922, 0f00000000, %p606;
	add.f32 	%f1923, %f326, 0f40000000;
	mov.b32 	%r100, %f1923;
	add.f32 	%f332, %f301, 0f3F800000;
	add.f32 	%f333, %f325, 0f40000000;
	selp.f32 	%f334, 0fFF800000, 0f7F800000, %p34;
	setp.geu.f32 	%p35, %f306, 0f00000000;
	setp.geu.f32 	%p36, %f311, 0f00000000;
	setp.geu.f32 	%p37, %f320, 0f00000000;
	setp.geu.f32 	%p38, %f325, 0f00000000;
	mov.u32 	%r849, %r673;

$L__BB7_376:
	setp.ltu.f32 	%p622, %f302, 0f3F8060FE;
	mov.f32 	%f3115, %f303;
	@%p622 bra 	$L__BB7_378;

	ex2.approx.ftz.f32 	%f1924, %f303;
	sub.f32 	%f1926, %f1598, %f1924;
	mov.b32 	%r721, %f1926;
	or.b32  	%r722, %r95, %r721;
	mov.b32 	%f3115, %r722;

$L__BB7_378:
	setp.ltu.f32 	%p623, %f304, 0f3F8060FE;
	mov.f32 	%f3116, %f305;
	@%p623 bra 	$L__BB7_380;

	ex2.approx.ftz.f32 	%f1927, %f305;
	sub.f32 	%f1929, %f1598, %f1927;
	mov.b32 	%r723, %f1929;
	or.b32  	%r724, %r96, %r723;
	mov.b32 	%f3116, %r724;

$L__BB7_380:
	sub.f32 	%f1930, %f3115, %f3116;
	mul.f32 	%f361, %f1930, 0f3F000000;
	cvt.rn.f32.s32 	%f362, %r849;
	sub.f32 	%f363, %f362, %f3068;
	add.f32 	%f1931, %f363, 0f3F000000;
	mul.f32 	%f364, %f1931, %f277;
	abs.f32 	%f1932, %f364;
	setp.ltu.f32 	%p624, %f1932, 0f3F8060FE;
	setp.ge.f32 	%p625, %f1932, 0f3F8060FE;
	mul.f32 	%f1933, %f364, %f364;
	selp.f32 	%f1934, %f1932, %f1933, %p625;
	selp.f32 	%f1935, 0f3789CA3C, 0f38B1E96A, %p625;
	selp.f32 	%f1936, 0fB9F560B9, 0fBA574D20, %p625;
	fma.rn.f32 	%f1937, %f1935, %f1934, %f1936;
	selp.f32 	%f1938, 0f3BAC840B, 0f3BAAD5EA, %p625;
	fma.rn.f32 	%f1939, %f1937, %f1934, %f1938;
	selp.f32 	%f1940, 0fBD0C8162, 0fBCDC1BE7, %p625;
	fma.rn.f32 	%f1941, %f1939, %f1934, %f1940;
	selp.f32 	%f1942, 0f3E1CF906, 0f3DE718AF, %p625;
	fma.rn.f32 	%f1943, %f1941, %f1934, %f1942;
	selp.f32 	%f1944, 0f3F6A937E, 0fBEC093AC, %p625;
	fma.rn.f32 	%f1945, %f1943, %f1934, %f1944;
	selp.f32 	%f1946, 0f3F20D842, 0f3E0375D3, %p625;
	fma.rn.f32 	%f1947, %f1945, %f1934, %f1946;
	neg.f32 	%f1948, %f1932;
	selp.f32 	%f1949, %f1948, %f364, %p625;
	fma.rn.f32 	%f3117, %f1947, %f1949, %f1949;
	@%p624 bra 	$L__BB7_382;

	ex2.approx.ftz.f32 	%f1950, %f3117;
	sub.f32 	%f1952, %f1598, %f1950;
	mov.b32 	%r725, %f1952;
	mov.b32 	%r726, %f364;
	and.b32  	%r727, %r726, -2147483648;
	or.b32  	%r728, %r727, %r725;
	mov.b32 	%f3117, %r728;

$L__BB7_382:
	add.f32 	%f368, %f363, 0fBF000000;
	mul.f32 	%f369, %f368, %f277;
	abs.f32 	%f1953, %f369;
	setp.ltu.f32 	%p626, %f1953, 0f3F8060FE;
	setp.ge.f32 	%p627, %f1953, 0f3F8060FE;
	mul.f32 	%f1954, %f369, %f369;
	selp.f32 	%f1955, %f1953, %f1954, %p627;
	selp.f32 	%f1956, 0f3789CA3C, 0f38B1E96A, %p627;
	selp.f32 	%f1957, 0fB9F560B9, 0fBA574D20, %p627;
	fma.rn.f32 	%f1958, %f1956, %f1955, %f1957;
	selp.f32 	%f1959, 0f3BAC840B, 0f3BAAD5EA, %p627;
	fma.rn.f32 	%f1960, %f1958, %f1955, %f1959;
	selp.f32 	%f1961, 0fBD0C8162, 0fBCDC1BE7, %p627;
	fma.rn.f32 	%f1962, %f1960, %f1955, %f1961;
	selp.f32 	%f1963, 0f3E1CF906, 0f3DE718AF, %p627;
	fma.rn.f32 	%f1964, %f1962, %f1955, %f1963;
	selp.f32 	%f1965, 0f3F6A937E, 0fBEC093AC, %p627;
	fma.rn.f32 	%f1966, %f1964, %f1955, %f1965;
	selp.f32 	%f1967, 0f3F20D842, 0f3E0375D3, %p627;
	fma.rn.f32 	%f1968, %f1966, %f1955, %f1967;
	neg.f32 	%f1969, %f1953;
	selp.f32 	%f1970, %f1969, %f369, %p627;
	fma.rn.f32 	%f3118, %f1968, %f1970, %f1970;
	@%p626 bra 	$L__BB7_384;

	ex2.approx.ftz.f32 	%f1971, %f3118;
	sub.f32 	%f1973, %f1598, %f1971;
	mov.b32 	%r729, %f1973;
	mov.b32 	%r730, %f369;
	and.b32  	%r731, %r730, -2147483648;
	or.b32  	%r732, %r731, %r729;
	mov.b32 	%f3118, %r732;

$L__BB7_384:
	sub.f32 	%f1975, %f3117, %f3118;
	mul.f32 	%f373, %f1975, 0f3F000000;
	mul.f32 	%f1976, %f361, %f3067;
	fma.rn.f32 	%f374, %f373, %f1976, %f3066;
	mad.lo.s32 	%r733, %r849, %r104, %r848;
	add.s32 	%r734, %r733, %r2;
	mul.wide.s32 	%rd32, %r734, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f32 	%f375, [%rd33];
	setp.eq.f32 	%p628, %f309, 0f7F800000;
	mov.f32 	%f3119, 0f7F800000;
	@%p628 bra 	$L__BB7_386;

	fma.rn.f32 	%f3119, %f309, %f308, %f309;

$L__BB7_386:
	mov.b32 	%r735, %f3119;
	xor.b32  	%r736, %r735, -2147483648;
	mov.b32 	%f1977, %r736;
	selp.f32 	%f378, %f1977, %f3119, %p31;
	setp.eq.f32 	%p629, %f306, 0f00000000;
	selp.f32 	%f3120, %f310, %f378, %p629;
	@%p35 bra 	$L__BB7_389;

	cvt.rzi.f32.f32 	%f1979, %f1601;
	setp.eq.f32 	%p630, %f1979, 0f40000000;
	mov.f32 	%f3120, %f378;
	@%p630 bra 	$L__BB7_389;

	mov.f32 	%f3120, 0f7FFFFFFF;

$L__BB7_389:
	setp.eq.f32 	%p631, %f314, 0f7F800000;
	mov.f32 	%f3121, 0f7F800000;
	@%p631 bra 	$L__BB7_391;

	fma.rn.f32 	%f3121, %f314, %f313, %f314;

$L__BB7_391:
	mov.b32 	%r737, %f3121;
	xor.b32  	%r738, %r737, -2147483648;
	mov.b32 	%f1982, %r738;
	selp.f32 	%f383, %f1982, %f3121, %p32;
	setp.eq.f32 	%p632, %f311, 0f00000000;
	selp.f32 	%f3122, %f317, %f383, %p632;
	@%p36 bra 	$L__BB7_394;

	cvt.rzi.f32.f32 	%f1984, %f1601;
	setp.eq.f32 	%p633, %f1984, 0f40000000;
	mov.f32 	%f3122, %f383;
	@%p633 bra 	$L__BB7_394;

	mov.f32 	%f3122, 0f7FFFFFFF;

$L__BB7_394:
	setp.gtu.f32 	%p634, %f307, 0f7F800000;
	mov.f32 	%f3123, 0f7F800000;
	selp.f32 	%f1987, %f315, %f3120, %p634;
	setp.neu.f32 	%p635, %f307, 0f7F800000;
	selp.f32 	%f1988, %f1987, %f316, %p635;
	setp.gt.s32 	%p636, %r97, 2139095039;
	selp.f32 	%f1989, %f1988, %f3120, %p636;
	mul.f32 	%f1990, %f1989, 0fBF000000;
	setp.eq.f32 	%p637, %f306, 0f3F800000;
	selp.f32 	%f1991, 0fBF000000, %f1990, %p637;
	mov.f32 	%f1993, 0f3BBB989D;
	fma.rn.f32 	%f1994, %f1991, %f1993, %f1592;
	mov.f32 	%f1996, 0f437C0000;
	cvt.sat.f32.f32 	%f1997, %f1994;
	mov.f32 	%f1998, 0f4B400001;
	fma.rm.f32 	%f1999, %f1997, %f1996, %f1998;
	setp.gtu.f32 	%p638, %f312, 0f7F800000;
	selp.f32 	%f2000, %f318, %f3122, %p638;
	setp.neu.f32 	%p639, %f312, 0f7F800000;
	selp.f32 	%f2001, %f2000, %f319, %p639;
	setp.gt.s32 	%p640, %r98, 2139095039;
	selp.f32 	%f2002, %f2001, %f3122, %p640;
	mul.f32 	%f2003, %f2002, 0fBF000000;
	setp.eq.f32 	%p641, %f311, 0f3F800000;
	selp.f32 	%f2004, 0fBF000000, %f2003, %p641;
	fma.rn.f32 	%f2005, %f2004, %f1993, %f1592;
	cvt.sat.f32.f32 	%f2006, %f2005;
	fma.rm.f32 	%f2007, %f2006, %f1996, %f1998;
	add.f32 	%f2008, %f2007, 0fCB40007F;
	neg.f32 	%f2009, %f2008;
	fma.rn.f32 	%f2010, %f2004, %f1705, %f2009;
	mov.f32 	%f2011, 0f32A57060;
	fma.rn.f32 	%f2012, %f2004, %f2011, %f2010;
	mov.b32 	%r739, %f2007;
	shl.b32 	%r740, %r739, 23;
	mov.b32 	%f2013, %r740;
	ex2.approx.ftz.f32 	%f2014, %f2012;
	mul.f32 	%f2015, %f2014, %f2013;
	mov.b32 	%r741, %f1999;
	shl.b32 	%r742, %r741, 23;
	mov.b32 	%f2016, %r742;
	add.f32 	%f2017, %f1999, 0fCB40007F;
	neg.f32 	%f2018, %f2017;
	fma.rn.f32 	%f2019, %f1991, %f1705, %f2018;
	fma.rn.f32 	%f2020, %f1991, %f2011, %f2019;
	ex2.approx.ftz.f32 	%f2021, %f2020;
	mul.f32 	%f2022, %f2021, %f2016;
	sub.f32 	%f2023, %f2022, %f2015;
	mul.f32 	%f2024, %f272, %f2023;
	mul.f32 	%f386, %f373, %f2024;
	add.f32 	%f2025, %f362, 0f3F000000;
	sub.f32 	%f2026, %f2025, %f3068;
	div.rn.f32 	%f387, %f2026, %f3064;
	abs.f32 	%f388, %f387;
	setp.lt.f32 	%p642, %f388, 0f00800000;
	mul.f32 	%f2027, %f388, 0f4B800000;
	selp.f32 	%f2028, %f2027, %f388, %p642;
	selp.f32 	%f2029, 0fC3170000, 0fC2FE0000, %p642;
	mov.b32 	%r743, %f2028;
	and.b32  	%r744, %r743, 8388607;
	or.b32  	%r745, %r744, 1065353216;
	mov.b32 	%f2030, %r745;
	shr.u32 	%r746, %r743, 23;
	cvt.rn.f32.u32 	%f2031, %r746;
	add.f32 	%f2032, %f2029, %f2031;
	setp.gt.f32 	%p643, %f2030, 0f3FB504F3;
	mul.f32 	%f2033, %f2030, 0f3F000000;
	add.f32 	%f2034, %f2032, 0f3F800000;
	selp.f32 	%f2035, %f2034, %f2032, %p643;
	selp.f32 	%f2036, %f2033, %f2030, %p643;
	add.f32 	%f2037, %f2036, 0fBF800000;
	add.f32 	%f2038, %f2036, 0f3F800000;
	rcp.approx.ftz.f32 	%f2039, %f2038;
	add.f32 	%f2040, %f2037, %f2037;
	mul.f32 	%f2042, %f2040, %f2039;
	mul.f32 	%f2043, %f2042, %f2042;
	fma.rn.f32 	%f2046, %f1662, %f2043, %f1661;
	fma.rn.f32 	%f2048, %f2046, %f2043, %f1664;
	mul.rn.f32 	%f2049, %f2048, %f2043;
	mul.rn.f32 	%f2050, %f2049, %f2042;
	sub.f32 	%f2051, %f2037, %f2042;
	add.f32 	%f2052, %f2051, %f2051;
	neg.f32 	%f2053, %f2042;
	fma.rn.f32 	%f2054, %f2053, %f2037, %f2052;
	mul.rn.f32 	%f2055, %f2039, %f2054;
	add.f32 	%f2056, %f2050, %f2042;
	sub.f32 	%f2057, %f2042, %f2056;
	add.f32 	%f2058, %f2050, %f2057;
	add.f32 	%f2059, %f2055, %f2058;
	add.f32 	%f2060, %f2056, %f2059;
	sub.f32 	%f2061, %f2056, %f2060;
	add.f32 	%f2062, %f2059, %f2061;
	mul.rn.f32 	%f2064, %f2035, %f1680;
	mul.rn.f32 	%f2066, %f2035, %f1682;
	add.f32 	%f2067, %f2064, %f2060;
	sub.f32 	%f2068, %f2064, %f2067;
	add.f32 	%f2069, %f2060, %f2068;
	add.f32 	%f2070, %f2062, %f2069;
	add.f32 	%f2071, %f2066, %f2070;
	add.f32 	%f2072, %f2067, %f2071;
	sub.f32 	%f2073, %f2067, %f2072;
	add.f32 	%f2074, %f2071, %f2073;
	mul.rn.f32 	%f2075, %f1601, %f2072;
	neg.f32 	%f2076, %f2075;
	fma.rn.f32 	%f2077, %f1601, %f2072, %f2076;
	fma.rn.f32 	%f2078, %f1601, %f2074, %f2077;
	mov.f32 	%f2079, 0f00000000;
	fma.rn.f32 	%f2080, %f2079, %f2072, %f2078;
	add.rn.f32 	%f2081, %f2075, %f2080;
	neg.f32 	%f2082, %f2081;
	add.rn.f32 	%f2083, %f2075, %f2082;
	add.rn.f32 	%f2084, %f2083, %f2080;
	mov.b32 	%r747, %f2081;
	setp.eq.s32 	%p644, %r747, 1118925336;
	add.s32 	%r748, %r747, -1;
	mov.b32 	%f2085, %r748;
	add.f32 	%f2086, %f2084, 0f37000000;
	selp.f32 	%f389, %f2086, %f2084, %p644;
	selp.f32 	%f2087, %f2085, %f2081, %p644;
	mul.rn.f32 	%f2088, %f2087, %f1705;
	cvt.rzi.f32.f32 	%f2089, %f2088;
	abs.f32 	%f2090, %f2089;
	setp.gt.f32 	%p645, %f2090, 0f42FC0000;
	mov.b32 	%r749, %f2089;
	and.b32  	%r750, %r749, -2147483648;
	or.b32  	%r751, %r750, 1123811328;
	mov.b32 	%f2091, %r751;
	selp.f32 	%f2092, %f2091, %f2089, %p645;
	fma.rn.f32 	%f2094, %f2092, %f1711, %f2087;
	fma.rn.f32 	%f2096, %f2092, %f1713, %f2094;
	mul.f32 	%f2097, %f2096, 0f3FB8AA3B;
	add.f32 	%f2098, %f2092, 0f4B40007F;
	mov.b32 	%r752, %f2098;
	shl.b32 	%r753, %r752, 23;
	mov.b32 	%f2099, %r753;
	ex2.approx.ftz.f32 	%f2100, %f2097;
	mul.f32 	%f390, %f2100, %f2099;
	setp.eq.f32 	%p646, %f390, 0f7F800000;
	@%p646 bra 	$L__BB7_396;

	fma.rn.f32 	%f3123, %f390, %f389, %f390;

$L__BB7_396:
	setp.lt.f32 	%p647, %f387, 0f00000000;
	and.pred  	%p39, %p647, %p606;
	setp.eq.f32 	%p649, %f387, 0f00000000;
	@%p649 bra 	$L__BB7_400;
	bra.uni 	$L__BB7_397;

$L__BB7_400:
	add.f32 	%f2105, %f387, %f387;
	selp.f32 	%f3125, %f2105, 0f00000000, %p606;
	bra.uni 	$L__BB7_401;

$L__BB7_397:
	mov.b32 	%r754, %f3123;
	xor.b32  	%r755, %r754, -2147483648;
	mov.b32 	%f2101, %r755;
	selp.f32 	%f3125, %f2101, %f3123, %p39;
	setp.geu.f32 	%p650, %f387, 0f00000000;
	@%p650 bra 	$L__BB7_401;

	cvt.rzi.f32.f32 	%f2103, %f1601;
	setp.eq.f32 	%p651, %f2103, 0f40000000;
	@%p651 bra 	$L__BB7_401;

	mov.f32 	%f3125, 0f7FFFFFFF;

$L__BB7_401:
	add.f32 	%f2106, %f388, 0f40000000;
	mov.b32 	%r756, %f2106;
	setp.lt.s32 	%p653, %r756, 2139095040;
	@%p653 bra 	$L__BB7_406;

	setp.gtu.f32 	%p654, %f388, 0f7F800000;
	@%p654 bra 	$L__BB7_405;
	bra.uni 	$L__BB7_403;

$L__BB7_405:
	add.f32 	%f3125, %f387, 0f40000000;
	bra.uni 	$L__BB7_406;

$L__BB7_403:
	setp.neu.f32 	%p655, %f388, 0f7F800000;
	@%p655 bra 	$L__BB7_406;

	selp.f32 	%f3125, 0fFF800000, 0f7F800000, %p39;

$L__BB7_406:
	mul.f32 	%f2108, %f3125, 0fBF000000;
	setp.eq.f32 	%p656, %f387, 0f3F800000;
	selp.f32 	%f2109, 0fBF000000, %f2108, %p656;
	fma.rn.f32 	%f2112, %f2109, %f1993, %f1592;
	cvt.sat.f32.f32 	%f2115, %f2112;
	fma.rm.f32 	%f2117, %f2115, %f1996, %f1998;
	add.f32 	%f2118, %f2117, 0fCB40007F;
	neg.f32 	%f2119, %f2118;
	fma.rn.f32 	%f2120, %f2109, %f1705, %f2119;
	fma.rn.f32 	%f2122, %f2109, %f2011, %f2120;
	mov.b32 	%r757, %f2117;
	shl.b32 	%r758, %r757, 23;
	mov.b32 	%f2123, %r758;
	ex2.approx.ftz.f32 	%f2124, %f2122;
	mul.f32 	%f399, %f2124, %f2123;
	div.rn.f32 	%f400, %f368, %f3064;
	abs.f32 	%f401, %f400;
	setp.lt.f32 	%p657, %f401, 0f00800000;
	mul.f32 	%f2125, %f401, 0f4B800000;
	selp.f32 	%f2126, %f2125, %f401, %p657;
	selp.f32 	%f2127, 0fC3170000, 0fC2FE0000, %p657;
	mov.b32 	%r759, %f2126;
	and.b32  	%r760, %r759, 8388607;
	or.b32  	%r761, %r760, 1065353216;
	mov.b32 	%f2128, %r761;
	shr.u32 	%r762, %r759, 23;
	cvt.rn.f32.u32 	%f2129, %r762;
	add.f32 	%f2130, %f2127, %f2129;
	setp.gt.f32 	%p658, %f2128, 0f3FB504F3;
	mul.f32 	%f2131, %f2128, 0f3F000000;
	add.f32 	%f2132, %f2130, 0f3F800000;
	selp.f32 	%f2133, %f2132, %f2130, %p658;
	selp.f32 	%f2134, %f2131, %f2128, %p658;
	add.f32 	%f2135, %f2134, 0fBF800000;
	add.f32 	%f2136, %f2134, 0f3F800000;
	rcp.approx.ftz.f32 	%f2137, %f2136;
	add.f32 	%f2138, %f2135, %f2135;
	mul.f32 	%f2140, %f2138, %f2137;
	mul.f32 	%f2141, %f2140, %f2140;
	fma.rn.f32 	%f2144, %f1662, %f2141, %f1661;
	fma.rn.f32 	%f2146, %f2144, %f2141, %f1664;
	mul.rn.f32 	%f2147, %f2146, %f2141;
	mul.rn.f32 	%f2148, %f2147, %f2140;
	sub.f32 	%f2149, %f2135, %f2140;
	add.f32 	%f2150, %f2149, %f2149;
	neg.f32 	%f2151, %f2140;
	fma.rn.f32 	%f2152, %f2151, %f2135, %f2150;
	mul.rn.f32 	%f2153, %f2137, %f2152;
	add.f32 	%f2154, %f2148, %f2140;
	sub.f32 	%f2155, %f2140, %f2154;
	add.f32 	%f2156, %f2148, %f2155;
	add.f32 	%f2157, %f2153, %f2156;
	add.f32 	%f2158, %f2154, %f2157;
	sub.f32 	%f2159, %f2154, %f2158;
	add.f32 	%f2160, %f2157, %f2159;
	mul.rn.f32 	%f2162, %f2133, %f1680;
	mul.rn.f32 	%f2164, %f2133, %f1682;
	add.f32 	%f2165, %f2162, %f2158;
	sub.f32 	%f2166, %f2162, %f2165;
	add.f32 	%f2167, %f2158, %f2166;
	add.f32 	%f2168, %f2160, %f2167;
	add.f32 	%f2169, %f2164, %f2168;
	add.f32 	%f2170, %f2165, %f2169;
	sub.f32 	%f2171, %f2165, %f2170;
	add.f32 	%f2172, %f2169, %f2171;
	mul.rn.f32 	%f2173, %f1601, %f2170;
	neg.f32 	%f2174, %f2173;
	fma.rn.f32 	%f2175, %f1601, %f2170, %f2174;
	fma.rn.f32 	%f2176, %f1601, %f2172, %f2175;
	fma.rn.f32 	%f2178, %f2079, %f2170, %f2176;
	add.rn.f32 	%f2179, %f2173, %f2178;
	neg.f32 	%f2180, %f2179;
	add.rn.f32 	%f2181, %f2173, %f2180;
	add.rn.f32 	%f2182, %f2181, %f2178;
	mov.b32 	%r763, %f2179;
	setp.eq.s32 	%p659, %r763, 1118925336;
	add.s32 	%r764, %r763, -1;
	mov.b32 	%f2183, %r764;
	add.f32 	%f2184, %f2182, 0f37000000;
	selp.f32 	%f402, %f2184, %f2182, %p659;
	selp.f32 	%f2185, %f2183, %f2179, %p659;
	mul.rn.f32 	%f2186, %f2185, %f1705;
	cvt.rzi.f32.f32 	%f2187, %f2186;
	abs.f32 	%f2188, %f2187;
	setp.gt.f32 	%p660, %f2188, 0f42FC0000;
	mov.b32 	%r765, %f2187;
	and.b32  	%r766, %r765, -2147483648;
	or.b32  	%r767, %r766, 1123811328;
	mov.b32 	%f2189, %r767;
	selp.f32 	%f2190, %f2189, %f2187, %p660;
	fma.rn.f32 	%f2192, %f2190, %f1711, %f2185;
	fma.rn.f32 	%f2194, %f2190, %f1713, %f2192;
	mul.f32 	%f2195, %f2194, 0f3FB8AA3B;
	add.f32 	%f2196, %f2190, 0f4B40007F;
	mov.b32 	%r768, %f2196;
	shl.b32 	%r769, %r768, 23;
	mov.b32 	%f2197, %r769;
	ex2.approx.ftz.f32 	%f2198, %f2195;
	mul.f32 	%f403, %f2198, %f2197;
	setp.eq.f32 	%p661, %f403, 0f7F800000;
	mov.f32 	%f3126, 0f7F800000;
	@%p661 bra 	$L__BB7_408;

	fma.rn.f32 	%f3126, %f403, %f402, %f403;

$L__BB7_408:
	setp.lt.f32 	%p662, %f400, 0f00000000;
	and.pred  	%p40, %p662, %p606;
	setp.eq.f32 	%p664, %f400, 0f00000000;
	@%p664 bra 	$L__BB7_412;
	bra.uni 	$L__BB7_409;

$L__BB7_412:
	add.f32 	%f2203, %f400, %f400;
	selp.f32 	%f3128, %f2203, 0f00000000, %p606;
	bra.uni 	$L__BB7_413;

$L__BB7_409:
	mov.b32 	%r770, %f3126;
	xor.b32  	%r771, %r770, -2147483648;
	mov.b32 	%f2199, %r771;
	selp.f32 	%f3128, %f2199, %f3126, %p40;
	setp.geu.f32 	%p665, %f400, 0f00000000;
	@%p665 bra 	$L__BB7_413;

	cvt.rzi.f32.f32 	%f2201, %f1601;
	setp.eq.f32 	%p666, %f2201, 0f40000000;
	@%p666 bra 	$L__BB7_413;

	mov.f32 	%f3128, 0f7FFFFFFF;

$L__BB7_413:
	add.f32 	%f2204, %f401, 0f40000000;
	mov.b32 	%r772, %f2204;
	setp.lt.s32 	%p668, %r772, 2139095040;
	@%p668 bra 	$L__BB7_418;

	setp.gtu.f32 	%p669, %f401, 0f7F800000;
	@%p669 bra 	$L__BB7_417;
	bra.uni 	$L__BB7_415;

$L__BB7_417:
	add.f32 	%f3128, %f400, 0f40000000;
	bra.uni 	$L__BB7_418;

$L__BB7_415:
	setp.neu.f32 	%p670, %f401, 0f7F800000;
	@%p670 bra 	$L__BB7_418;

	selp.f32 	%f3128, 0fFF800000, 0f7F800000, %p40;

$L__BB7_418:
	mul.f32 	%f2206, %f3128, 0fBF000000;
	setp.eq.f32 	%p671, %f400, 0f3F800000;
	selp.f32 	%f2207, 0fBF000000, %f2206, %p671;
	fma.rn.f32 	%f2210, %f2207, %f1993, %f1592;
	cvt.sat.f32.f32 	%f2213, %f2210;
	fma.rm.f32 	%f2215, %f2213, %f1996, %f1998;
	add.f32 	%f2216, %f2215, 0fCB40007F;
	neg.f32 	%f2217, %f2216;
	fma.rn.f32 	%f2218, %f2207, %f1705, %f2217;
	fma.rn.f32 	%f2220, %f2207, %f2011, %f2218;
	mov.b32 	%r773, %f2215;
	shl.b32 	%r774, %r773, 23;
	mov.b32 	%f2221, %r774;
	ex2.approx.ftz.f32 	%f2222, %f2220;
	mul.f32 	%f2223, %f2222, %f2221;
	sub.f32 	%f412, %f399, %f2223;
	setp.eq.f32 	%p672, %f323, 0f7F800000;
	mov.f32 	%f3129, 0f7F800000;
	@%p672 bra 	$L__BB7_420;

	fma.rn.f32 	%f3129, %f323, %f322, %f323;

$L__BB7_420:
	mov.b32 	%r775, %f3129;
	xor.b32  	%r776, %r775, -2147483648;
	mov.b32 	%f2224, %r776;
	selp.f32 	%f415, %f2224, %f3129, %p33;
	setp.eq.f32 	%p673, %f320, 0f00000000;
	selp.f32 	%f3130, %f324, %f415, %p673;
	@%p37 bra 	$L__BB7_423;

	cvt.rzi.f32.f32 	%f2226, %f1601;
	setp.eq.f32 	%p674, %f2226, 0f40000000;
	mov.f32 	%f3130, %f415;
	@%p674 bra 	$L__BB7_423;

	mov.f32 	%f3130, 0f7FFFFFFF;

$L__BB7_423:
	setp.eq.f32 	%p675, %f328, 0f7F800000;
	mov.f32 	%f3131, 0f7F800000;
	@%p675 bra 	$L__BB7_425;

	fma.rn.f32 	%f3131, %f328, %f327, %f328;

$L__BB7_425:
	mov.b32 	%r777, %f3131;
	xor.b32  	%r778, %r777, -2147483648;
	mov.b32 	%f2229, %r778;
	selp.f32 	%f420, %f2229, %f3131, %p34;
	setp.eq.f32 	%p676, %f325, 0f00000000;
	selp.f32 	%f3132, %f331, %f420, %p676;
	@%p38 bra 	$L__BB7_428;

	cvt.rzi.f32.f32 	%f2231, %f1601;
	setp.eq.f32 	%p677, %f2231, 0f40000000;
	mov.f32 	%f3132, %f420;
	@%p677 bra 	$L__BB7_428;

	mov.f32 	%f3132, 0f7FFFFFFF;

$L__BB7_428:
	mul.f32 	%f2234, %f273, %f412;
	mul.f32 	%f423, %f361, %f2234;
	setp.gtu.f32 	%p678, %f321, 0f7F800000;
	mov.f32 	%f3133, 0f7F800000;
	selp.f32 	%f2235, %f329, %f3130, %p678;
	setp.neu.f32 	%p679, %f321, 0f7F800000;
	selp.f32 	%f2236, %f2235, %f330, %p679;
	setp.gt.s32 	%p680, %r99, 2139095039;
	selp.f32 	%f2237, %f2236, %f3130, %p680;
	mul.f32 	%f2238, %f2237, 0fBF000000;
	setp.eq.f32 	%p681, %f320, 0f3F800000;
	selp.f32 	%f2239, 0fBF000000, %f2238, %p681;
	fma.rn.f32 	%f2242, %f2239, %f1993, %f1592;
	cvt.sat.f32.f32 	%f2245, %f2242;
	fma.rm.f32 	%f2247, %f2245, %f1996, %f1998;
	setp.gtu.f32 	%p682, %f326, 0f7F800000;
	selp.f32 	%f2248, %f333, %f3132, %p682;
	setp.neu.f32 	%p683, %f326, 0f7F800000;
	selp.f32 	%f2249, %f2248, %f334, %p683;
	setp.gt.s32 	%p684, %r100, 2139095039;
	selp.f32 	%f2250, %f2249, %f3132, %p684;
	mul.f32 	%f2251, %f2250, 0fBF000000;
	setp.eq.f32 	%p685, %f325, 0f3F800000;
	selp.f32 	%f2252, 0fBF000000, %f2251, %p685;
	fma.rn.f32 	%f2253, %f2252, %f1993, %f1592;
	cvt.sat.f32.f32 	%f2254, %f2253;
	fma.rm.f32 	%f2255, %f2254, %f1996, %f1998;
	add.f32 	%f2256, %f2255, 0fCB40007F;
	neg.f32 	%f2257, %f2256;
	fma.rn.f32 	%f2258, %f2252, %f1705, %f2257;
	fma.rn.f32 	%f2260, %f2252, %f2011, %f2258;
	mov.b32 	%r779, %f2255;
	shl.b32 	%r780, %r779, 23;
	mov.b32 	%f2261, %r780;
	ex2.approx.ftz.f32 	%f2262, %f2260;
	mul.f32 	%f2263, %f2262, %f2261;
	mul.f32 	%f2264, %f301, %f2263;
	mov.b32 	%r781, %f2247;
	shl.b32 	%r782, %r781, 23;
	mov.b32 	%f2265, %r782;
	add.f32 	%f2266, %f2247, 0fCB40007F;
	neg.f32 	%f2267, %f2266;
	fma.rn.f32 	%f2268, %f2239, %f1705, %f2267;
	fma.rn.f32 	%f2269, %f2239, %f2011, %f2268;
	ex2.approx.ftz.f32 	%f2270, %f2269;
	mul.f32 	%f2271, %f2270, %f2265;
	mul.f32 	%f2272, %f332, %f2271;
	sub.f32 	%f2273, %f2272, %f2264;
	mul.f32 	%f2274, %f274, %f2273;
	mul.f32 	%f424, %f373, %f2274;
	add.f32 	%f2275, %f362, 0f3F800000;
	sub.f32 	%f2276, %f2275, %f3068;
	div.rn.f32 	%f425, %f2276, %f3064;
	abs.f32 	%f426, %f425;
	setp.lt.f32 	%p686, %f426, 0f00800000;
	mul.f32 	%f2277, %f426, 0f4B800000;
	selp.f32 	%f2278, %f2277, %f426, %p686;
	selp.f32 	%f2279, 0fC3170000, 0fC2FE0000, %p686;
	mov.b32 	%r783, %f2278;
	and.b32  	%r784, %r783, 8388607;
	or.b32  	%r785, %r784, 1065353216;
	mov.b32 	%f2280, %r785;
	shr.u32 	%r786, %r783, 23;
	cvt.rn.f32.u32 	%f2281, %r786;
	add.f32 	%f2282, %f2279, %f2281;
	setp.gt.f32 	%p687, %f2280, 0f3FB504F3;
	mul.f32 	%f2283, %f2280, 0f3F000000;
	add.f32 	%f2284, %f2282, 0f3F800000;
	selp.f32 	%f2285, %f2284, %f2282, %p687;
	selp.f32 	%f2286, %f2283, %f2280, %p687;
	add.f32 	%f2287, %f2286, 0fBF800000;
	add.f32 	%f2288, %f2286, 0f3F800000;
	rcp.approx.ftz.f32 	%f2289, %f2288;
	add.f32 	%f2290, %f2287, %f2287;
	mul.f32 	%f2292, %f2290, %f2289;
	mul.f32 	%f2293, %f2292, %f2292;
	fma.rn.f32 	%f2296, %f1662, %f2293, %f1661;
	fma.rn.f32 	%f2298, %f2296, %f2293, %f1664;
	mul.rn.f32 	%f2299, %f2298, %f2293;
	mul.rn.f32 	%f2300, %f2299, %f2292;
	sub.f32 	%f2301, %f2287, %f2292;
	add.f32 	%f2302, %f2301, %f2301;
	neg.f32 	%f2303, %f2292;
	fma.rn.f32 	%f2304, %f2303, %f2287, %f2302;
	mul.rn.f32 	%f2305, %f2289, %f2304;
	add.f32 	%f2306, %f2300, %f2292;
	sub.f32 	%f2307, %f2292, %f2306;
	add.f32 	%f2308, %f2300, %f2307;
	add.f32 	%f2309, %f2305, %f2308;
	add.f32 	%f2310, %f2306, %f2309;
	sub.f32 	%f2311, %f2306, %f2310;
	add.f32 	%f2312, %f2309, %f2311;
	mul.rn.f32 	%f2314, %f2285, %f1680;
	mul.rn.f32 	%f2316, %f2285, %f1682;
	add.f32 	%f2317, %f2314, %f2310;
	sub.f32 	%f2318, %f2314, %f2317;
	add.f32 	%f2319, %f2310, %f2318;
	add.f32 	%f2320, %f2312, %f2319;
	add.f32 	%f2321, %f2316, %f2320;
	add.f32 	%f2322, %f2317, %f2321;
	sub.f32 	%f2323, %f2317, %f2322;
	add.f32 	%f2324, %f2321, %f2323;
	mul.rn.f32 	%f2325, %f1601, %f2322;
	neg.f32 	%f2326, %f2325;
	fma.rn.f32 	%f2327, %f1601, %f2322, %f2326;
	fma.rn.f32 	%f2328, %f1601, %f2324, %f2327;
	fma.rn.f32 	%f2330, %f2079, %f2322, %f2328;
	add.rn.f32 	%f2331, %f2325, %f2330;
	neg.f32 	%f2332, %f2331;
	add.rn.f32 	%f2333, %f2325, %f2332;
	add.rn.f32 	%f2334, %f2333, %f2330;
	mov.b32 	%r787, %f2331;
	setp.eq.s32 	%p688, %r787, 1118925336;
	add.s32 	%r788, %r787, -1;
	mov.b32 	%f2335, %r788;
	add.f32 	%f2336, %f2334, 0f37000000;
	selp.f32 	%f427, %f2336, %f2334, %p688;
	selp.f32 	%f2337, %f2335, %f2331, %p688;
	mul.rn.f32 	%f2338, %f2337, %f1705;
	cvt.rzi.f32.f32 	%f2339, %f2338;
	abs.f32 	%f2340, %f2339;
	setp.gt.f32 	%p689, %f2340, 0f42FC0000;
	mov.b32 	%r789, %f2339;
	and.b32  	%r790, %r789, -2147483648;
	or.b32  	%r791, %r790, 1123811328;
	mov.b32 	%f2341, %r791;
	selp.f32 	%f2342, %f2341, %f2339, %p689;
	fma.rn.f32 	%f2344, %f2342, %f1711, %f2337;
	fma.rn.f32 	%f2346, %f2342, %f1713, %f2344;
	mul.f32 	%f2347, %f2346, 0f3FB8AA3B;
	add.f32 	%f2348, %f2342, 0f4B40007F;
	mov.b32 	%r792, %f2348;
	shl.b32 	%r793, %r792, 23;
	mov.b32 	%f2349, %r793;
	ex2.approx.ftz.f32 	%f2350, %f2347;
	mul.f32 	%f428, %f2350, %f2349;
	setp.eq.f32 	%p690, %f428, 0f7F800000;
	@%p690 bra 	$L__BB7_430;

	fma.rn.f32 	%f3133, %f428, %f427, %f428;

$L__BB7_430:
	setp.lt.f32 	%p691, %f425, 0f00000000;
	and.pred  	%p41, %p691, %p606;
	setp.eq.f32 	%p693, %f425, 0f00000000;
	@%p693 bra 	$L__BB7_434;
	bra.uni 	$L__BB7_431;

$L__BB7_434:
	add.f32 	%f2355, %f425, %f425;
	selp.f32 	%f3135, %f2355, 0f00000000, %p606;
	bra.uni 	$L__BB7_435;

$L__BB7_431:
	mov.b32 	%r794, %f3133;
	xor.b32  	%r795, %r794, -2147483648;
	mov.b32 	%f2351, %r795;
	selp.f32 	%f3135, %f2351, %f3133, %p41;
	setp.geu.f32 	%p694, %f425, 0f00000000;
	@%p694 bra 	$L__BB7_435;

	cvt.rzi.f32.f32 	%f2353, %f1601;
	setp.eq.f32 	%p695, %f2353, 0f40000000;
	@%p695 bra 	$L__BB7_435;

	mov.f32 	%f3135, 0f7FFFFFFF;

$L__BB7_435:
	add.f32 	%f2356, %f426, 0f40000000;
	mov.b32 	%r796, %f2356;
	setp.lt.s32 	%p697, %r796, 2139095040;
	@%p697 bra 	$L__BB7_440;

	setp.gtu.f32 	%p698, %f426, 0f7F800000;
	@%p698 bra 	$L__BB7_439;
	bra.uni 	$L__BB7_437;

$L__BB7_439:
	add.f32 	%f3135, %f425, 0f40000000;
	bra.uni 	$L__BB7_440;

$L__BB7_437:
	setp.neu.f32 	%p699, %f426, 0f7F800000;
	@%p699 bra 	$L__BB7_440;

	selp.f32 	%f3135, 0fFF800000, 0f7F800000, %p41;

$L__BB7_440:
	mul.f32 	%f2358, %f3135, 0fBF000000;
	setp.eq.f32 	%p700, %f425, 0f3F800000;
	selp.f32 	%f2359, 0fBF000000, %f2358, %p700;
	fma.rn.f32 	%f2362, %f2359, %f1993, %f1592;
	cvt.sat.f32.f32 	%f2365, %f2362;
	fma.rm.f32 	%f2367, %f2365, %f1996, %f1998;
	add.f32 	%f2368, %f2367, 0fCB40007F;
	neg.f32 	%f2369, %f2368;
	fma.rn.f32 	%f2370, %f2359, %f1705, %f2369;
	fma.rn.f32 	%f2372, %f2359, %f2011, %f2370;
	mov.b32 	%r797, %f2367;
	shl.b32 	%r798, %r797, 23;
	mov.b32 	%f2373, %r798;
	ex2.approx.ftz.f32 	%f2374, %f2372;
	mul.f32 	%f437, %f2374, %f2373;
	div.rn.f32 	%f438, %f363, %f3064;
	abs.f32 	%f439, %f438;
	setp.lt.f32 	%p701, %f439, 0f00800000;
	mul.f32 	%f2375, %f439, 0f4B800000;
	selp.f32 	%f2376, %f2375, %f439, %p701;
	selp.f32 	%f2377, 0fC3170000, 0fC2FE0000, %p701;
	mov.b32 	%r799, %f2376;
	and.b32  	%r800, %r799, 8388607;
	or.b32  	%r801, %r800, 1065353216;
	mov.b32 	%f2378, %r801;
	shr.u32 	%r802, %r799, 23;
	cvt.rn.f32.u32 	%f2379, %r802;
	add.f32 	%f2380, %f2377, %f2379;
	setp.gt.f32 	%p702, %f2378, 0f3FB504F3;
	mul.f32 	%f2381, %f2378, 0f3F000000;
	add.f32 	%f2382, %f2380, 0f3F800000;
	selp.f32 	%f2383, %f2382, %f2380, %p702;
	selp.f32 	%f2384, %f2381, %f2378, %p702;
	add.f32 	%f2385, %f2384, 0fBF800000;
	add.f32 	%f2386, %f2384, 0f3F800000;
	rcp.approx.ftz.f32 	%f2387, %f2386;
	add.f32 	%f2388, %f2385, %f2385;
	mul.f32 	%f2390, %f2388, %f2387;
	mul.f32 	%f2391, %f2390, %f2390;
	fma.rn.f32 	%f2394, %f1662, %f2391, %f1661;
	fma.rn.f32 	%f2396, %f2394, %f2391, %f1664;
	mul.rn.f32 	%f2397, %f2396, %f2391;
	mul.rn.f32 	%f2398, %f2397, %f2390;
	sub.f32 	%f2399, %f2385, %f2390;
	add.f32 	%f2400, %f2399, %f2399;
	neg.f32 	%f2401, %f2390;
	fma.rn.f32 	%f2402, %f2401, %f2385, %f2400;
	mul.rn.f32 	%f2403, %f2387, %f2402;
	add.f32 	%f2404, %f2398, %f2390;
	sub.f32 	%f2405, %f2390, %f2404;
	add.f32 	%f2406, %f2398, %f2405;
	add.f32 	%f2407, %f2403, %f2406;
	add.f32 	%f2408, %f2404, %f2407;
	sub.f32 	%f2409, %f2404, %f2408;
	add.f32 	%f2410, %f2407, %f2409;
	mul.rn.f32 	%f2412, %f2383, %f1680;
	mul.rn.f32 	%f2414, %f2383, %f1682;
	add.f32 	%f2415, %f2412, %f2408;
	sub.f32 	%f2416, %f2412, %f2415;
	add.f32 	%f2417, %f2408, %f2416;
	add.f32 	%f2418, %f2410, %f2417;
	add.f32 	%f2419, %f2414, %f2418;
	add.f32 	%f2420, %f2415, %f2419;
	sub.f32 	%f2421, %f2415, %f2420;
	add.f32 	%f2422, %f2419, %f2421;
	mul.rn.f32 	%f2423, %f1601, %f2420;
	neg.f32 	%f2424, %f2423;
	fma.rn.f32 	%f2425, %f1601, %f2420, %f2424;
	fma.rn.f32 	%f2426, %f1601, %f2422, %f2425;
	fma.rn.f32 	%f2428, %f2079, %f2420, %f2426;
	add.rn.f32 	%f2429, %f2423, %f2428;
	neg.f32 	%f2430, %f2429;
	add.rn.f32 	%f2431, %f2423, %f2430;
	add.rn.f32 	%f2432, %f2431, %f2428;
	mov.b32 	%r803, %f2429;
	setp.eq.s32 	%p703, %r803, 1118925336;
	add.s32 	%r804, %r803, -1;
	mov.b32 	%f2433, %r804;
	add.f32 	%f2434, %f2432, 0f37000000;
	selp.f32 	%f440, %f2434, %f2432, %p703;
	selp.f32 	%f2435, %f2433, %f2429, %p703;
	mul.rn.f32 	%f2436, %f2435, %f1705;
	cvt.rzi.f32.f32 	%f2437, %f2436;
	abs.f32 	%f2438, %f2437;
	setp.gt.f32 	%p704, %f2438, 0f42FC0000;
	mov.b32 	%r805, %f2437;
	and.b32  	%r806, %r805, -2147483648;
	or.b32  	%r807, %r806, 1123811328;
	mov.b32 	%f2439, %r807;
	selp.f32 	%f2440, %f2439, %f2437, %p704;
	fma.rn.f32 	%f2442, %f2440, %f1711, %f2435;
	fma.rn.f32 	%f2444, %f2440, %f1713, %f2442;
	mul.f32 	%f2445, %f2444, 0f3FB8AA3B;
	add.f32 	%f2446, %f2440, 0f4B40007F;
	mov.b32 	%r808, %f2446;
	shl.b32 	%r809, %r808, 23;
	mov.b32 	%f2447, %r809;
	ex2.approx.ftz.f32 	%f2448, %f2445;
	mul.f32 	%f441, %f2448, %f2447;
	setp.eq.f32 	%p705, %f441, 0f7F800000;
	mov.f32 	%f3136, 0f7F800000;
	@%p705 bra 	$L__BB7_442;

	fma.rn.f32 	%f3136, %f441, %f440, %f441;

$L__BB7_442:
	setp.lt.f32 	%p706, %f438, 0f00000000;
	and.pred  	%p42, %p706, %p606;
	setp.eq.f32 	%p708, %f438, 0f00000000;
	@%p708 bra 	$L__BB7_446;
	bra.uni 	$L__BB7_443;

$L__BB7_446:
	add.f32 	%f2453, %f438, %f438;
	selp.f32 	%f3138, %f2453, 0f00000000, %p606;
	bra.uni 	$L__BB7_447;

$L__BB7_443:
	mov.b32 	%r810, %f3136;
	xor.b32  	%r811, %r810, -2147483648;
	mov.b32 	%f2449, %r811;
	selp.f32 	%f3138, %f2449, %f3136, %p42;
	setp.geu.f32 	%p709, %f438, 0f00000000;
	@%p709 bra 	$L__BB7_447;

	cvt.rzi.f32.f32 	%f2451, %f1601;
	setp.eq.f32 	%p710, %f2451, 0f40000000;
	@%p710 bra 	$L__BB7_447;

	mov.f32 	%f3138, 0f7FFFFFFF;

$L__BB7_447:
	add.f32 	%f2454, %f439, 0f40000000;
	mov.b32 	%r812, %f2454;
	setp.lt.s32 	%p712, %r812, 2139095040;
	@%p712 bra 	$L__BB7_452;

	setp.gtu.f32 	%p713, %f439, 0f7F800000;
	@%p713 bra 	$L__BB7_451;
	bra.uni 	$L__BB7_449;

$L__BB7_451:
	add.f32 	%f3138, %f438, 0f40000000;
	bra.uni 	$L__BB7_452;

$L__BB7_449:
	setp.neu.f32 	%p714, %f439, 0f7F800000;
	@%p714 bra 	$L__BB7_452;

	selp.f32 	%f3138, 0fFF800000, 0f7F800000, %p42;

$L__BB7_452:
	mul.f32 	%f2455, %f3138, 0fBF000000;
	setp.eq.f32 	%p715, %f438, 0f3F800000;
	selp.f32 	%f2456, 0fBF000000, %f2455, %p715;
	fma.rn.f32 	%f2459, %f2456, %f1993, %f1592;
	cvt.sat.f32.f32 	%f2462, %f2459;
	fma.rm.f32 	%f2464, %f2462, %f1996, %f1998;
	add.f32 	%f2465, %f2464, 0fCB40007F;
	neg.f32 	%f2466, %f2465;
	fma.rn.f32 	%f2467, %f2456, %f1705, %f2466;
	fma.rn.f32 	%f2469, %f2456, %f2011, %f2467;
	mov.b32 	%r813, %f2464;
	shl.b32 	%r814, %r813, 23;
	mov.b32 	%f2470, %r814;
	ex2.approx.ftz.f32 	%f2471, %f2469;
	mul.f32 	%f2472, %f2471, %f2470;
	add.f32 	%f2473, %f363, 0f3F800000;
	mul.f32 	%f2474, %f2473, %f437;
	mul.f32 	%f2475, %f363, %f2472;
	sub.f32 	%f2476, %f2474, %f2475;
	mul.f32 	%f2477, %f275, %f2476;
	mul.f32 	%f2478, %f361, %f2477;
	mul.f32 	%f2479, %f386, %f386;
	div.rn.f32 	%f2480, %f2479, %f374;
	add.f32 	%f3110, %f3110, %f2480;
	mul.f32 	%f2481, %f423, %f386;
	div.rn.f32 	%f2482, %f2481, %f374;
	add.f32 	%f3109, %f3109, %f2482;
	mul.f32 	%f2483, %f361, %f373;
	mul.f32 	%f2484, %f2483, %f386;
	div.rn.f32 	%f2485, %f2484, %f374;
	add.f32 	%f3108, %f3108, %f2485;
	div.rn.f32 	%f2486, %f386, %f374;
	add.f32 	%f3107, %f3107, %f2486;
	mul.f32 	%f2487, %f424, %f386;
	div.rn.f32 	%f2488, %f2487, %f374;
	add.f32 	%f3106, %f3106, %f2488;
	mul.f32 	%f2489, %f2478, %f386;
	div.rn.f32 	%f2490, %f2489, %f374;
	add.f32 	%f3105, %f3105, %f2490;
	mul.f32 	%f2491, %f423, %f423;
	div.rn.f32 	%f2492, %f2491, %f374;
	add.f32 	%f3104, %f3104, %f2492;
	mul.f32 	%f2493, %f2483, %f423;
	div.rn.f32 	%f2494, %f2493, %f374;
	add.f32 	%f3103, %f3103, %f2494;
	div.rn.f32 	%f2495, %f423, %f374;
	add.f32 	%f3102, %f3102, %f2495;
	mul.f32 	%f2496, %f424, %f423;
	div.rn.f32 	%f2497, %f2496, %f374;
	add.f32 	%f3101, %f3101, %f2497;
	mul.f32 	%f2498, %f2478, %f423;
	div.rn.f32 	%f2499, %f2498, %f374;
	add.f32 	%f3100, %f3100, %f2499;
	mul.f32 	%f2500, %f2483, %f2483;
	div.rn.f32 	%f2501, %f2500, %f374;
	add.f32 	%f3099, %f3099, %f2501;
	div.rn.f32 	%f2502, %f2483, %f374;
	add.f32 	%f3098, %f3098, %f2502;
	mul.f32 	%f2503, %f424, %f2483;
	div.rn.f32 	%f2504, %f2503, %f374;
	add.f32 	%f3097, %f3097, %f2504;
	mul.f32 	%f2505, %f2478, %f2483;
	div.rn.f32 	%f2506, %f2505, %f374;
	add.f32 	%f3096, %f3096, %f2506;
	rcp.rn.f32 	%f2507, %f374;
	add.f32 	%f3095, %f3095, %f2507;
	div.rn.f32 	%f2508, %f424, %f374;
	add.f32 	%f3094, %f3094, %f2508;
	div.rn.f32 	%f2509, %f2478, %f374;
	add.f32 	%f3093, %f3093, %f2509;
	mul.f32 	%f2510, %f424, %f424;
	div.rn.f32 	%f2511, %f2510, %f374;
	add.f32 	%f3111, %f3111, %f2511;
	mul.f32 	%f2512, %f2478, %f424;
	div.rn.f32 	%f2513, %f2512, %f374;
	add.f32 	%f3112, %f3112, %f2513;
	mul.f32 	%f2514, %f2478, %f2478;
	div.rn.f32 	%f2515, %f2514, %f374;
	add.f32 	%f3113, %f3113, %f2515;
	add.f32 	%f471, %f3063, %f374;
	setp.leu.f32 	%p716, %f471, 0f00000000;
	@%p716 bra 	$L__BB7_460;

	add.f32 	%f472, %f3063, %f375;
	setp.gt.f32 	%p717, %f472, 0f00000000;
	@%p717 bra 	$L__BB7_455;
	bra.uni 	$L__BB7_454;

$L__BB7_455:
	setp.lt.f32 	%p718, %f471, 0f00800000;
	mul.f32 	%f2518, %f471, 0f4B000000;
	selp.f32 	%f474, %f2518, %f471, %p718;
	selp.f32 	%f2519, 0fC1B80000, 0f00000000, %p718;
	mov.b32 	%r815, %f474;
	add.s32 	%r816, %r815, -1059760811;
	and.b32  	%r817, %r816, -8388608;
	sub.s32 	%r818, %r815, %r817;
	mov.b32 	%f2520, %r818;
	cvt.rn.f32.s32 	%f2521, %r817;
	mov.f32 	%f2522, 0f34000000;
	fma.rn.f32 	%f2523, %f2521, %f2522, %f2519;
	add.f32 	%f2524, %f2520, 0fBF800000;
	mov.f32 	%f2525, 0f3E1039F6;
	mov.f32 	%f2526, 0fBE055027;
	fma.rn.f32 	%f2527, %f2526, %f2524, %f2525;
	mov.f32 	%f2528, 0fBDF8CDCC;
	fma.rn.f32 	%f2529, %f2527, %f2524, %f2528;
	mov.f32 	%f2530, 0f3E0F2955;
	fma.rn.f32 	%f2531, %f2529, %f2524, %f2530;
	mov.f32 	%f2532, 0fBE2AD8B9;
	fma.rn.f32 	%f2533, %f2531, %f2524, %f2532;
	mov.f32 	%f2534, 0f3E4CED0B;
	fma.rn.f32 	%f2535, %f2533, %f2524, %f2534;
	mov.f32 	%f2536, 0fBE7FFF22;
	fma.rn.f32 	%f2537, %f2535, %f2524, %f2536;
	mov.f32 	%f2538, 0f3EAAAA78;
	fma.rn.f32 	%f2539, %f2537, %f2524, %f2538;
	mov.f32 	%f2540, 0fBF000000;
	fma.rn.f32 	%f2541, %f2539, %f2524, %f2540;
	mul.f32 	%f2542, %f2524, %f2541;
	fma.rn.f32 	%f2543, %f2542, %f2524, %f2524;
	mov.f32 	%f2544, 0f3F317218;
	fma.rn.f32 	%f3139, %f2523, %f2544, %f2543;
	setp.lt.u32 	%p719, %r815, 2139095040;
	@%p719 bra 	$L__BB7_457;

	mov.f32 	%f2545, 0f7F800000;
	fma.rn.f32 	%f3139, %f474, %f2545, %f2545;

$L__BB7_457:
	setp.eq.f32 	%p720, %f474, 0f00000000;
	selp.f32 	%f2546, 0fFF800000, %f3139, %p720;
	mul.f32 	%f2547, %f472, %f2546;
	sub.f32 	%f478, %f2547, %f374;
	mul.f32 	%f2548, %f472, 0f4B000000;
	setp.lt.f32 	%p721, %f472, 0f00800000;
	selp.f32 	%f479, %f2548, %f472, %p721;
	selp.f32 	%f2549, 0fC1B80000, 0f00000000, %p721;
	mov.b32 	%r819, %f479;
	add.s32 	%r820, %r819, -1059760811;
	and.b32  	%r821, %r820, -8388608;
	sub.s32 	%r822, %r819, %r821;
	mov.b32 	%f2550, %r822;
	cvt.rn.f32.s32 	%f2551, %r821;
	fma.rn.f32 	%f2553, %f2551, %f2522, %f2549;
	add.f32 	%f2554, %f2550, 0fBF800000;
	fma.rn.f32 	%f2557, %f2526, %f2554, %f2525;
	fma.rn.f32 	%f2559, %f2557, %f2554, %f2528;
	fma.rn.f32 	%f2561, %f2559, %f2554, %f2530;
	fma.rn.f32 	%f2563, %f2561, %f2554, %f2532;
	fma.rn.f32 	%f2565, %f2563, %f2554, %f2534;
	fma.rn.f32 	%f2567, %f2565, %f2554, %f2536;
	fma.rn.f32 	%f2569, %f2567, %f2554, %f2538;
	fma.rn.f32 	%f2571, %f2569, %f2554, %f2540;
	mul.f32 	%f2572, %f2554, %f2571;
	fma.rn.f32 	%f2573, %f2572, %f2554, %f2554;
	fma.rn.f32 	%f3140, %f2553, %f2544, %f2573;
	setp.lt.u32 	%p722, %r819, 2139095040;
	@%p722 bra 	$L__BB7_459;

	mov.f32 	%f2575, 0f7F800000;
	fma.rn.f32 	%f3140, %f479, %f2575, %f2575;

$L__BB7_459:
	setp.eq.f32 	%p723, %f479, 0f00000000;
	selp.f32 	%f2576, 0fFF800000, %f3140, %p723;
	mul.f32 	%f2577, %f472, %f2576;
	sub.f32 	%f2578, %f478, %f2577;
	add.f32 	%f2579, %f375, %f2578;
	add.f32 	%f3141, %f3141, %f2579;
	bra.uni 	$L__BB7_460;

$L__BB7_454:
	neg.f32 	%f2516, %f374;
	sub.f32 	%f2517, %f2516, %f3063;
	add.f32 	%f3141, %f3141, %f2517;

$L__BB7_460:
	add.s32 	%r849, %r849, 1;
	setp.lt.s32 	%p724, %r849, %r104;
	@%p724 bra 	$L__BB7_376;

	add.s32 	%r848, %r848, 1;
	setp.lt.s32 	%p725, %r848, %r104;
	@%p725 bra 	$L__BB7_375;

$L__BB7_462:
	ld.param.u64 	%rd56, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_9];
	ld.param.u64 	%rd55, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_8];
	ld.param.u32 	%r833, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_10];
	ld.param.u64 	%rd54, [_Z28kernel_MLEFit_SCMOSXYNBSXSY_PKfS0_S0_fiiiPfS1_S1_i_param_7];
	rcp.rn.f32 	%f2580, %f3110;
	mov.f32 	%f2581, 0f3F800000;
	mul.f32 	%f2582, %f2580, %f3109;
	mul.f32 	%f2583, %f2580, %f3108;
	mul.f32 	%f2584, %f2580, %f3107;
	mul.f32 	%f2585, %f2580, %f3106;
	mul.f32 	%f2586, %f2580, %f3105;
	fma.rn.f32 	%f2587, %f2582, %f3109, 0f00000000;
	sub.f32 	%f2589, %f3104, %f2587;
	fma.rn.f32 	%f2590, %f2583, %f3109, 0f00000000;
	rcp.rn.f32 	%f2591, %f2589;
	sub.f32 	%f2592, %f3103, %f2590;
	mul.f32 	%f2593, %f2591, %f2592;
	fma.rn.f32 	%f2594, %f2584, %f3109, 0f00000000;
	sub.f32 	%f2595, %f3102, %f2594;
	mul.f32 	%f2596, %f2591, %f2595;
	fma.rn.f32 	%f2597, %f2585, %f3109, 0f00000000;
	sub.f32 	%f2598, %f3101, %f2597;
	mul.f32 	%f2599, %f2591, %f2598;
	fma.rn.f32 	%f2600, %f2586, %f3109, 0f00000000;
	sub.f32 	%f2601, %f3100, %f2600;
	mul.f32 	%f2602, %f2591, %f2601;
	fma.rn.f32 	%f2603, %f2582, %f3108, 0f00000000;
	sub.f32 	%f2604, %f3103, %f2603;
	fma.rn.f32 	%f2605, %f2583, %f3108, 0f00000000;
	fma.rn.f32 	%f2606, %f2593, %f2604, %f2605;
	sub.f32 	%f2607, %f3099, %f2606;
	fma.rn.f32 	%f2608, %f2584, %f3108, 0f00000000;
	fma.rn.f32 	%f2609, %f2596, %f2604, %f2608;
	rcp.rn.f32 	%f2610, %f2607;
	sub.f32 	%f2611, %f3098, %f2609;
	mul.f32 	%f2612, %f2610, %f2611;
	fma.rn.f32 	%f2613, %f2585, %f3108, 0f00000000;
	fma.rn.f32 	%f2614, %f2599, %f2604, %f2613;
	sub.f32 	%f2615, %f3097, %f2614;
	mul.f32 	%f2616, %f2610, %f2615;
	fma.rn.f32 	%f2617, %f2586, %f3108, 0f00000000;
	fma.rn.f32 	%f2618, %f2602, %f2604, %f2617;
	sub.f32 	%f2619, %f3096, %f2618;
	mul.f32 	%f2620, %f2610, %f2619;
	fma.rn.f32 	%f2621, %f2582, %f3107, 0f00000000;
	sub.f32 	%f2622, %f3102, %f2621;
	fma.rn.f32 	%f2623, %f2583, %f3107, 0f00000000;
	fma.rn.f32 	%f2624, %f2593, %f2622, %f2623;
	sub.f32 	%f2625, %f3098, %f2624;
	fma.rn.f32 	%f2626, %f2584, %f3107, 0f00000000;
	fma.rn.f32 	%f2627, %f2596, %f2622, %f2626;
	fma.rn.f32 	%f2628, %f2612, %f2625, %f2627;
	sub.f32 	%f2629, %f3095, %f2628;
	fma.rn.f32 	%f2630, %f2585, %f3107, 0f00000000;
	fma.rn.f32 	%f2631, %f2599, %f2622, %f2630;
	fma.rn.f32 	%f2632, %f2616, %f2625, %f2631;
	rcp.rn.f32 	%f2633, %f2629;
	sub.f32 	%f2634, %f3094, %f2632;
	mul.f32 	%f2635, %f2633, %f2634;
	fma.rn.f32 	%f2636, %f2586, %f3107, 0f00000000;
	fma.rn.f32 	%f2637, %f2602, %f2622, %f2636;
	fma.rn.f32 	%f2638, %f2620, %f2625, %f2637;
	sub.f32 	%f2639, %f3093, %f2638;
	mul.f32 	%f2640, %f2633, %f2639;
	fma.rn.f32 	%f2641, %f2582, %f3106, 0f00000000;
	sub.f32 	%f2642, %f3101, %f2641;
	fma.rn.f32 	%f2643, %f2583, %f3106, 0f00000000;
	fma.rn.f32 	%f2644, %f2593, %f2642, %f2643;
	sub.f32 	%f2645, %f3097, %f2644;
	fma.rn.f32 	%f2646, %f2584, %f3106, 0f00000000;
	fma.rn.f32 	%f2647, %f2596, %f2642, %f2646;
	fma.rn.f32 	%f2648, %f2612, %f2645, %f2647;
	sub.f32 	%f2649, %f3094, %f2648;
	fma.rn.f32 	%f2650, %f2585, %f3106, 0f00000000;
	fma.rn.f32 	%f2651, %f2599, %f2642, %f2650;
	fma.rn.f32 	%f2652, %f2616, %f2645, %f2651;
	fma.rn.f32 	%f2653, %f2635, %f2649, %f2652;
	sub.f32 	%f2654, %f3111, %f2653;
	fma.rn.f32 	%f2655, %f2586, %f3106, 0f00000000;
	fma.rn.f32 	%f2656, %f2602, %f2642, %f2655;
	fma.rn.f32 	%f2657, %f2620, %f2645, %f2656;
	fma.rn.f32 	%f2658, %f2640, %f2649, %f2657;
	rcp.rn.f32 	%f2659, %f2654;
	sub.f32 	%f2660, %f3112, %f2658;
	mul.f32 	%f2661, %f2659, %f2660;
	fma.rn.f32 	%f2662, %f2582, %f3105, 0f00000000;
	sub.f32 	%f2663, %f3100, %f2662;
	fma.rn.f32 	%f2664, %f2583, %f3105, 0f00000000;
	fma.rn.f32 	%f2665, %f2593, %f2663, %f2664;
	sub.f32 	%f2666, %f3096, %f2665;
	fma.rn.f32 	%f2667, %f2584, %f3105, 0f00000000;
	fma.rn.f32 	%f2668, %f2596, %f2663, %f2667;
	fma.rn.f32 	%f2669, %f2612, %f2666, %f2668;
	sub.f32 	%f2670, %f3093, %f2669;
	fma.rn.f32 	%f2671, %f2585, %f3105, 0f00000000;
	fma.rn.f32 	%f2672, %f2599, %f2663, %f2671;
	fma.rn.f32 	%f2673, %f2616, %f2666, %f2672;
	fma.rn.f32 	%f2674, %f2635, %f2670, %f2673;
	sub.f32 	%f2675, %f3112, %f2674;
	fma.rn.f32 	%f2676, %f2586, %f3105, 0f00000000;
	fma.rn.f32 	%f2677, %f2602, %f2663, %f2676;
	fma.rn.f32 	%f2678, %f2620, %f2666, %f2677;
	fma.rn.f32 	%f2679, %f2640, %f2670, %f2678;
	fma.rn.f32 	%f2680, %f2661, %f2675, %f2679;
	sub.f32 	%f2681, %f3113, %f2680;
	add.f32 	%f2682, %f2582, 0f00000000;
	sub.f32 	%f2683, %f1569, %f2682;
	add.f32 	%f2684, %f2583, 0f00000000;
	fma.rn.f32 	%f2685, %f2593, %f2683, %f2684;
	sub.f32 	%f2686, %f1569, %f2685;
	add.f32 	%f2687, %f2584, 0f00000000;
	fma.rn.f32 	%f2688, %f2596, %f2683, %f2687;
	fma.rn.f32 	%f2689, %f2612, %f2686, %f2688;
	sub.f32 	%f2690, %f1569, %f2689;
	add.f32 	%f2691, %f2585, 0f00000000;
	fma.rn.f32 	%f2692, %f2599, %f2683, %f2691;
	fma.rn.f32 	%f2693, %f2616, %f2686, %f2692;
	fma.rn.f32 	%f2694, %f2635, %f2690, %f2693;
	sub.f32 	%f2695, %f1569, %f2694;
	add.f32 	%f2696, %f2586, 0f00000000;
	fma.rn.f32 	%f2697, %f2602, %f2683, %f2696;
	fma.rn.f32 	%f2698, %f2620, %f2686, %f2697;
	fma.rn.f32 	%f2699, %f2640, %f2690, %f2698;
	fma.rn.f32 	%f2700, %f2661, %f2695, %f2699;
	sub.f32 	%f2701, %f1569, %f2700;
	div.rn.f32 	%f2702, %f2701, %f2681;
	fma.rn.f32 	%f2703, %f2675, %f2702, 0f00000000;
	sub.f32 	%f2704, %f2695, %f2703;
	mul.f32 	%f2705, %f2659, %f2704;
	fma.rn.f32 	%f2706, %f2649, %f2705, 0f00000000;
	fma.rn.f32 	%f2707, %f2670, %f2702, %f2706;
	sub.f32 	%f2708, %f2690, %f2707;
	mul.f32 	%f2709, %f2633, %f2708;
	fma.rn.f32 	%f2710, %f2625, %f2709, 0f00000000;
	fma.rn.f32 	%f2711, %f2645, %f2705, %f2710;
	fma.rn.f32 	%f2712, %f2666, %f2702, %f2711;
	sub.f32 	%f2713, %f2686, %f2712;
	mul.f32 	%f2714, %f2610, %f2713;
	fma.rn.f32 	%f2715, %f2604, %f2714, 0f00000000;
	fma.rn.f32 	%f2716, %f2622, %f2709, %f2715;
	fma.rn.f32 	%f2717, %f2642, %f2705, %f2716;
	fma.rn.f32 	%f2718, %f2663, %f2702, %f2717;
	sub.f32 	%f2719, %f2683, %f2718;
	mul.f32 	%f2720, %f2591, %f2719;
	fma.rn.f32 	%f2721, %f3109, %f2720, 0f00000000;
	fma.rn.f32 	%f2722, %f3108, %f2714, %f2721;
	fma.rn.f32 	%f2723, %f3107, %f2709, %f2722;
	fma.rn.f32 	%f2724, %f3106, %f2705, %f2723;
	fma.rn.f32 	%f2725, %f3105, %f2702, %f2724;
	sub.f32 	%f2726, %f2581, %f2725;
	mul.f32 	%f2727, %f2580, %f2726;
	fma.rn.f32 	%f2728, %f2582, 0f00000000, 0f00000000;
	sub.f32 	%f2729, %f2581, %f2728;
	fma.rn.f32 	%f2730, %f2583, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2731, %f2593, %f2729, %f2730;
	sub.f32 	%f2732, %f1569, %f2731;
	fma.rn.f32 	%f2733, %f2584, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2734, %f2596, %f2729, %f2733;
	fma.rn.f32 	%f2735, %f2612, %f2732, %f2734;
	sub.f32 	%f2736, %f1569, %f2735;
	fma.rn.f32 	%f2737, %f2585, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2738, %f2599, %f2729, %f2737;
	fma.rn.f32 	%f2739, %f2616, %f2732, %f2738;
	fma.rn.f32 	%f2740, %f2635, %f2736, %f2739;
	sub.f32 	%f2741, %f1569, %f2740;
	fma.rn.f32 	%f2742, %f2586, 0f00000000, 0f00000000;
	fma.rn.f32 	%f2743, %f2602, %f2729, %f2742;
	fma.rn.f32 	%f2744, %f2620, %f2732, %f2743;
	fma.rn.f32 	%f2745, %f2640, %f2736, %f2744;
	fma.rn.f32 	%f2746, %f2661, %f2741, %f2745;
	sub.f32 	%f2747, %f1569, %f2746;
	div.rn.f32 	%f2748, %f2747, %f2681;
	fma.rn.f32 	%f2749, %f2675, %f2748, 0f00000000;
	sub.f32 	%f2750, %f2741, %f2749;
	mul.f32 	%f2751, %f2659, %f2750;
	fma.rn.f32 	%f2752, %f2649, %f2751, 0f00000000;
	fma.rn.f32 	%f2753, %f2670, %f2748, %f2752;
	sub.f32 	%f2754, %f2736, %f2753;
	mul.f32 	%f2755, %f2633, %f2754;
	fma.rn.f32 	%f2756, %f2625, %f2755, 0f00000000;
	fma.rn.f32 	%f2757, %f2645, %f2751, %f2756;
	fma.rn.f32 	%f2758, %f2666, %f2748, %f2757;
	sub.f32 	%f2759, %f2732, %f2758;
	mul.f32 	%f2760, %f2610, %f2759;
	fma.rn.f32 	%f2761, %f2604, %f2760, 0f00000000;
	fma.rn.f32 	%f2762, %f2622, %f2755, %f2761;
	fma.rn.f32 	%f2763, %f2642, %f2751, %f2762;
	fma.rn.f32 	%f2764, %f2663, %f2748, %f2763;
	sub.f32 	%f2765, %f2729, %f2764;
	mul.f32 	%f2766, %f2591, %f2765;
	sub.f32 	%f2767, %f1569, %f2728;
	fma.rn.f32 	%f2768, %f2593, %f2767, %f2730;
	sub.f32 	%f2769, %f2581, %f2768;
	fma.rn.f32 	%f2770, %f2596, %f2767, %f2733;
	fma.rn.f32 	%f2771, %f2612, %f2769, %f2770;
	sub.f32 	%f2772, %f1569, %f2771;
	fma.rn.f32 	%f2773, %f2599, %f2767, %f2737;
	fma.rn.f32 	%f2774, %f2616, %f2769, %f2773;
	fma.rn.f32 	%f2775, %f2635, %f2772, %f2774;
	sub.f32 	%f2776, %f1569, %f2775;
	fma.rn.f32 	%f2777, %f2602, %f2767, %f2742;
	fma.rn.f32 	%f2778, %f2620, %f2769, %f2777;
	fma.rn.f32 	%f2779, %f2640, %f2772, %f2778;
	fma.rn.f32 	%f2780, %f2661, %f2776, %f2779;
	sub.f32 	%f2781, %f1569, %f2780;
	div.rn.f32 	%f2782, %f2781, %f2681;
	fma.rn.f32 	%f2783, %f2675, %f2782, 0f00000000;
	sub.f32 	%f2784, %f2776, %f2783;
	mul.f32 	%f2785, %f2659, %f2784;
	fma.rn.f32 	%f2786, %f2649, %f2785, 0f00000000;
	fma.rn.f32 	%f2787, %f2670, %f2782, %f2786;
	sub.f32 	%f2788, %f2772, %f2787;
	mul.f32 	%f2789, %f2633, %f2788;
	fma.rn.f32 	%f2790, %f2625, %f2789, 0f00000000;
	fma.rn.f32 	%f2791, %f2645, %f2785, %f2790;
	fma.rn.f32 	%f2792, %f2666, %f2782, %f2791;
	sub.f32 	%f2793, %f2769, %f2792;
	mul.f32 	%f2794, %f2610, %f2793;
	sub.f32 	%f2795, %f1569, %f2768;
	fma.rn.f32 	%f2796, %f2612, %f2795, %f2770;
	sub.f32 	%f2797, %f2581, %f2796;
	fma.rn.f32 	%f2798, %f2616, %f2795, %f2773;
	fma.rn.f32 	%f2799, %f2635, %f2797, %f2798;
	sub.f32 	%f2800, %f1569, %f2799;
	fma.rn.f32 	%f2801, %f2620, %f2795, %f2777;
	fma.rn.f32 	%f2802, %f2640, %f2797, %f2801;
	fma.rn.f32 	%f2803, %f2661, %f2800, %f2802;
	sub.f32 	%f2804, %f1569, %f2803;
	div.rn.f32 	%f2805, %f2804, %f2681;
	fma.rn.f32 	%f2806, %f2675, %f2805, 0f00000000;
	sub.f32 	%f2807, %f2800, %f2806;
	mul.f32 	%f2808, %f2659, %f2807;
	fma.rn.f32 	%f2809, %f2649, %f2808, 0f00000000;
	fma.rn.f32 	%f2810, %f2670, %f2805, %f2809;
	sub.f32 	%f2811, %f2797, %f2810;
	mul.f32 	%f2812, %f2633, %f2811;
	sub.f32 	%f2813, %f1569, %f2796;
	fma.rn.f32 	%f2814, %f2635, %f2813, %f2798;
	sub.f32 	%f2815, %f2581, %f2814;
	fma.rn.f32 	%f2816, %f2640, %f2813, %f2801;
	fma.rn.f32 	%f2817, %f2661, %f2815, %f2816;
	sub.f32 	%f2818, %f1569, %f2817;
	div.rn.f32 	%f2819, %f2818, %f2681;
	fma.rn.f32 	%f2820, %f2675, %f2819, 0f00000000;
	sub.f32 	%f2821, %f2815, %f2820;
	mul.f32 	%f2822, %f2659, %f2821;
	sub.f32 	%f2823, %f1569, %f2814;
	fma.rn.f32 	%f2824, %f2661, %f2823, %f2816;
	sub.f32 	%f2825, %f2581, %f2824;
	div.rn.f32 	%f2826, %f2825, %f2681;
	cvta.to.global.u64 	%rd34, %rd54;
	mul.wide.s32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	st.global.f32 	[%rd36], %f3069;
	add.s32 	%r827, %r1, %r833;
	mul.wide.s32 	%rd37, %r833, 4;
	add.s64 	%rd38, %rd36, %rd37;
	st.global.f32 	[%rd38], %f3068;
	add.s32 	%r828, %r827, %r833;
	mul.wide.s32 	%rd39, %r828, 4;
	add.s64 	%rd40, %rd34, %rd39;
	st.global.f32 	[%rd40], %f3067;
	shl.b32 	%r829, %r833, 2;
	cvt.s64.s32 	%rd41, %r829;
	add.s64 	%rd42, %rd40, %rd41;
	st.global.f32 	[%rd42], %f3066;
	add.s64 	%rd43, %rd42, %rd41;
	st.global.f32 	[%rd43], %f3065;
	add.s64 	%rd44, %rd43, %rd41;
	st.global.f32 	[%rd44], %f3064;
	cvta.to.global.u64 	%rd45, %rd55;
	add.s64 	%rd46, %rd45, %rd35;
	st.global.f32 	[%rd46], %f2727;
	add.s64 	%rd47, %rd46, %rd37;
	st.global.f32 	[%rd47], %f2766;
	add.s64 	%rd48, %rd45, %rd39;
	st.global.f32 	[%rd48], %f2794;
	add.s64 	%rd49, %rd48, %rd41;
	st.global.f32 	[%rd49], %f2812;
	add.s64 	%rd50, %rd49, %rd41;
	st.global.f32 	[%rd50], %f2822;
	add.s64 	%rd51, %rd50, %rd41;
	st.global.f32 	[%rd51], %f2826;
	cvta.to.global.u64 	%rd52, %rd56;
	add.s64 	%rd53, %rd52, %rd35;
	st.global.f32 	[%rd53], %f3141;

$L__BB7_463:
	ret;

}
	// .globl	_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i
.visible .entry _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i(
	.param .u64 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_0,
	.param .f32 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_1,
	.param .u32 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_2,
	.param .u32 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_3,
	.param .u32 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_4,
	.param .f32 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_5,
	.param .f32 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_6,
	.param .u64 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_7,
	.param .u64 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_8,
	.param .u64 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_9,
	.param .u64 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_10,
	.param .u32 _Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_11
)
{
	.local .align 16 .b8 	__local_depot8[192];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<408>;
	.reg .f32 	%f<1819>;
	.reg .b32 	%r<662>;
	.reg .f64 	%fd<399>;
	.reg .b64 	%rd<144>;


	mov.u64 	%SPL, __local_depot8;
	ld.param.u64 	%rd51, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_0];
	ld.param.f32 	%f378, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_1];
	ld.param.u32 	%r151, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_2];
	ld.param.u32 	%r153, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_4];
	ld.param.f32 	%f379, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_5];
	ld.param.u32 	%r154, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_11];
	cvta.to.global.u64 	%rd1, %rd51;
	add.u64 	%rd2, %SPL, 0;
	add.u64 	%rd3, %SPL, 32;
	add.u64 	%rd4, %SPL, 64;
	add.u64 	%rd5, %SPL, 96;
	add.u64 	%rd6, %SPL, 128;
	add.u64 	%rd7, %SPL, 160;
	mov.f32 	%f1683, 0f00000000;
	st.local.v4.f32 	[%rd2], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd2+16], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd3], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd3+16], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd4], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd4+16], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd5], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd5+16], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd6], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd6+16], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd7], {%f1683, %f1683, %f1683, %f1683};
	st.local.v4.f32 	[%rd7+16], {%f1683, %f1683, %f1683, %f1683};
	mov.u32 	%r155, %ntid.x;
	mov.u32 	%r156, %ctaid.x;
	mov.u32 	%r157, %tid.x;
	mad.lo.s32 	%r158, %r155, %r156, %r157;
	mul.lo.s32 	%r159, %r151, %r151;
	mul.lo.s32 	%r1, %r158, %r159;
	setp.ge.s32 	%p17, %r158, %r154;
	@%p17 bra 	$L__BB8_303;

	setp.lt.s32 	%p18, %r151, 1;
	mov.f32 	%f1684, %f1683;
	mov.f32 	%f1685, %f1683;
	@%p18 bra 	$L__BB8_11;

	add.s32 	%r2, %r151, -1;
	and.b32  	%r3, %r151, 3;
	sub.s32 	%r4, %r151, %r3;
	shl.b32 	%r5, %r151, 2;
	mov.u32 	%r160, 0;
	setp.lt.u32 	%p19, %r2, 3;
	setp.eq.s32 	%p21, %r3, 0;
	setp.eq.s32 	%p22, %r3, 1;
	setp.eq.s32 	%p23, %r3, 2;
	cvt.s64.s32 	%rd60, %r5;
	mov.u32 	%r618, %r160;
	mov.f32 	%f1685, %f1683;
	mov.f32 	%f1684, %f1683;

$L__BB8_3:
	cvt.rn.f32.s32 	%f4, %r618;
	mov.u32 	%r621, %r160;
	@%p19 bra 	$L__BB8_6;

	mov.u32 	%r621, %r160;
	mov.u32 	%r620, %r4;

$L__BB8_5:
	mad.lo.s32 	%r163, %r621, %r151, %r618;
	add.s32 	%r164, %r163, %r1;
	mul.wide.s32 	%rd58, %r164, 4;
	add.s64 	%rd59, %rd1, %rd58;
	ld.global.f32 	%f389, [%rd59];
	fma.rn.f32 	%f390, %f389, %f4, %f1683;
	cvt.rn.f32.s32 	%f391, %r621;
	fma.rn.f32 	%f392, %f389, %f391, %f1684;
	add.f32 	%f393, %f1685, %f389;
	add.s64 	%rd61, %rd59, %rd60;
	ld.global.f32 	%f394, [%rd61];
	fma.rn.f32 	%f395, %f394, %f4, %f390;
	add.s32 	%r165, %r621, 1;
	cvt.rn.f32.s32 	%f396, %r165;
	fma.rn.f32 	%f397, %f394, %f396, %f392;
	add.f32 	%f398, %f393, %f394;
	add.s64 	%rd62, %rd61, %rd60;
	ld.global.f32 	%f399, [%rd62];
	fma.rn.f32 	%f400, %f399, %f4, %f395;
	add.s32 	%r166, %r621, 2;
	cvt.rn.f32.s32 	%f401, %r166;
	fma.rn.f32 	%f402, %f399, %f401, %f397;
	add.f32 	%f403, %f398, %f399;
	add.s64 	%rd63, %rd62, %rd60;
	ld.global.f32 	%f404, [%rd63];
	fma.rn.f32 	%f1683, %f404, %f4, %f400;
	add.s32 	%r167, %r621, 3;
	cvt.rn.f32.s32 	%f405, %r167;
	fma.rn.f32 	%f1684, %f404, %f405, %f402;
	add.f32 	%f1685, %f403, %f404;
	add.s32 	%r621, %r621, 4;
	add.s32 	%r620, %r620, -4;
	setp.ne.s32 	%p20, %r620, 0;
	@%p20 bra 	$L__BB8_5;

$L__BB8_6:
	@%p21 bra 	$L__BB8_10;

	mad.lo.s32 	%r12, %r621, %r151, %r618;
	add.s32 	%r168, %r12, %r1;
	mul.wide.s32 	%rd64, %r168, 4;
	add.s64 	%rd65, %rd1, %rd64;
	ld.global.f32 	%f406, [%rd65];
	fma.rn.f32 	%f1683, %f406, %f4, %f1683;
	cvt.rn.f32.s32 	%f407, %r621;
	fma.rn.f32 	%f1684, %f406, %f407, %f1684;
	add.f32 	%f1685, %f1685, %f406;
	@%p22 bra 	$L__BB8_10;

	add.s32 	%r13, %r12, %r151;
	add.s32 	%r169, %r13, %r1;
	mul.wide.s32 	%rd66, %r169, 4;
	add.s64 	%rd67, %rd1, %rd66;
	ld.global.f32 	%f408, [%rd67];
	fma.rn.f32 	%f1683, %f408, %f4, %f1683;
	add.s32 	%r170, %r621, 1;
	cvt.rn.f32.s32 	%f409, %r170;
	fma.rn.f32 	%f1684, %f408, %f409, %f1684;
	add.f32 	%f1685, %f1685, %f408;
	@%p23 bra 	$L__BB8_10;

	add.s32 	%r171, %r621, 2;
	add.s32 	%r172, %r13, %r151;
	add.s32 	%r173, %r172, %r1;
	mul.wide.s32 	%rd68, %r173, 4;
	add.s64 	%rd69, %rd1, %rd68;
	ld.global.f32 	%f410, [%rd69];
	fma.rn.f32 	%f1683, %f410, %f4, %f1683;
	cvt.rn.f32.s32 	%f411, %r171;
	fma.rn.f32 	%f1684, %f410, %f411, %f1684;
	add.f32 	%f1685, %f1685, %f410;

$L__BB8_10:
	add.s32 	%r618, %r618, 1;
	setp.lt.s32 	%p24, %r618, %r151;
	@%p24 bra 	$L__BB8_3;

$L__BB8_11:
	div.rn.f32 	%f1774, %f1683, %f1685;
	div.rn.f32 	%f1773, %f1684, %f1685;
	mov.f32 	%f413, 0f3F000000;
	div.rn.f32 	%f414, %f413, %f378;
	div.rn.f32 	%f34, %f414, %f378;
	mov.f32 	%f1690, 0f51BA43B7;
	@%p18 bra 	$L__BB8_51;

	cvt.f64.f32 	%fd1, %f34;
	mov.f64 	%fd115, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd115;
	}
	and.b32  	%r16, %r15, 2146435072;
	and.b32  	%r17, %r15, 2147483647;
	setp.gt.s32 	%p26, %r15, -1;
	selp.b32 	%r18, 2146435072, 0, %p26;
	mov.u32 	%r174, 0;
	or.b32  	%r19, %r18, -2147483648;
	setp.eq.s32 	%p28, %r16, 1062207488;
	setp.lt.s32 	%p29, %r15, 0;
	setp.ne.s32 	%p34, %r17, 1071644672;
	setp.eq.s32 	%p61, %r17, 2146435072;
	mov.u32 	%r622, %r174;

$L__BB8_13:
	mov.u32 	%r623, %r174;

$L__BB8_14:
	mov.f32 	%f1693, 0f00000000;
	mov.f32 	%f1694, %f1693;
	mov.u32 	%r624, %r174;

$L__BB8_15:
	sub.s32 	%r23, %r624, %r622;
	cvt.rn.f32.s32 	%f418, %r23;
	cvt.f64.f32 	%fd2, %f418;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r24}, %fd2;
	}
	abs.f64 	%fd116, %fd2;
	{ // callseq 174, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd116;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 174
	setp.lt.s32 	%p27, %r24, 0;
	and.pred  	%p1, %p27, %p28;
	selp.b32 	%r178, %r24, 0, %p28;
	or.b32  	%r179, %r178, 2146435072;
	selp.b32 	%r25, %r179, %r178, %p29;
	add.f64 	%fd4, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r180}, %fd4;
	}
	and.b32  	%r26, %r180, 2146435072;
	setp.ne.s32 	%p30, %r26, 2146435072;
	setp.gtu.f64 	%p31, %fd116, 0d7FF0000000000000;
	setp.gt.f64 	%p32, %fd116, 0d3FF0000000000000;
	selp.b32 	%r181, 2146435072, 0, %p32;
	xor.b32  	%r182, %r181, 2146435072;
	selp.b32 	%r183, %r182, %r181, %p29;
	setp.eq.s32 	%p33, %r23, -1;
	selp.b32 	%r27, 1072693248, %r183, %p33;
	and.b32  	%r28, %r24, 2147483647;
	and.pred  	%p35, %p34, %p1;
	selp.b32 	%r29, %r19, %r18, %p35;
	mul.lo.s32 	%r30, %r624, %r151;
	or.pred  	%p2, %p30, %p31;
	mov.u32 	%r625, %r174;

$L__BB8_16:
	not.pred 	%p36, %p1;
	mov.f64 	%fd372, %fd3;
	@%p36 bra 	$L__BB8_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r184}, %fd3;
	}
	xor.b32  	%r185, %r184, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r186, %temp}, %fd3;
	}
	mov.b64 	%fd372, {%r186, %r185};

$L__BB8_18:
	setp.eq.s32 	%p37, %r23, 0;
	@%p37 bra 	$L__BB8_22;

	setp.gt.s32 	%p38, %r24, -1;
	@%p38 bra 	$L__BB8_23;

	cvt.rzi.f64.f64 	%fd119, %fd115;
	setp.eq.f64 	%p39, %fd119, 0d4000000000000000;
	@%p39 bra 	$L__BB8_23;

	mov.f64 	%fd372, 0dFFF8000000000000;
	bra.uni 	$L__BB8_23;

$L__BB8_22:
	mov.u32 	%r187, 0;
	mov.b64 	%fd372, {%r187, %r25};

$L__BB8_23:
	selp.f64 	%fd373, %fd372, %fd4, %p30;
	@%p2 bra 	$L__BB8_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r188, %temp}, %fd115;
	}
	setp.eq.s32 	%p42, %r188, 0;
	and.pred  	%p43, %p61, %p42;
	@%p43 bra 	$L__BB8_27;
	bra.uni 	$L__BB8_25;

$L__BB8_27:
	mov.u32 	%r191, 0;
	mov.b64 	%fd373, {%r191, %r27};
	bra.uni 	$L__BB8_28;

$L__BB8_25:
	setp.ne.s32 	%p44, %r28, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r189, %temp}, %fd2;
	}
	setp.ne.s32 	%p45, %r189, 0;
	or.pred  	%p46, %p44, %p45;
	mov.f64 	%fd373, %fd372;
	@%p46 bra 	$L__BB8_28;

	mov.u32 	%r190, 0;
	mov.b64 	%fd373, {%r190, %r29};

$L__BB8_28:
	setp.eq.s32 	%p47, %r23, 1;
	selp.f64 	%fd122, 0d3FF0000000000000, %fd373, %p47;
	mov.f64 	%fd123, 0d3FF0000000000000;
	mul.f64 	%fd13, %fd122, %fd1;
	neg.f64 	%fd124, %fd13;
	mov.f64 	%fd125, 0d4338000000000000;
	mov.f64 	%fd126, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd127, %fd124, %fd126, %fd125;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd127;
	}
	mov.f64 	%fd128, 0dC338000000000000;
	add.rn.f64 	%fd129, %fd127, %fd128;
	mov.f64 	%fd130, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd131, %fd129, %fd130, %fd124;
	mov.f64 	%fd132, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd133, %fd129, %fd132, %fd131;
	mov.f64 	%fd134, 0d3E928AF3FCA213EA;
	mov.f64 	%fd135, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd136, %fd135, %fd133, %fd134;
	mov.f64 	%fd137, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd138, %fd136, %fd133, %fd137;
	mov.f64 	%fd139, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd140, %fd138, %fd133, %fd139;
	mov.f64 	%fd141, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd142, %fd140, %fd133, %fd141;
	mov.f64 	%fd143, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd144, %fd142, %fd133, %fd143;
	mov.f64 	%fd145, 0d3F81111111122322;
	fma.rn.f64 	%fd146, %fd144, %fd133, %fd145;
	mov.f64 	%fd147, 0d3FA55555555502A1;
	fma.rn.f64 	%fd148, %fd146, %fd133, %fd147;
	mov.f64 	%fd149, 0d3FC5555555555511;
	fma.rn.f64 	%fd150, %fd148, %fd133, %fd149;
	mov.f64 	%fd151, 0d3FE000000000000B;
	fma.rn.f64 	%fd152, %fd150, %fd133, %fd151;
	fma.rn.f64 	%fd153, %fd152, %fd133, %fd123;
	fma.rn.f64 	%fd154, %fd153, %fd133, %fd123;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd154;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd154;
	}
	shl.b32 	%r192, %r32, 20;
	add.s32 	%r193, %r34, %r192;
	mov.b64 	%fd374, {%r33, %r193};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd124;
	}
	mov.b32 	%f419, %r194;
	abs.f32 	%f41, %f419;
	setp.lt.f32 	%p48, %f41, 0f4086232B;
	@%p48 bra 	$L__BB8_31;

	setp.gt.f64 	%p49, %fd13, 0d8000000000000000;
	mov.f64 	%fd155, 0d7FF0000000000000;
	sub.f64 	%fd156, %fd155, %fd13;
	selp.f64 	%fd374, 0d0000000000000000, %fd156, %p49;
	setp.geu.f32 	%p50, %f41, 0f40874800;
	@%p50 bra 	$L__BB8_31;

	shr.u32 	%r195, %r32, 31;
	add.s32 	%r196, %r32, %r195;
	shr.s32 	%r197, %r196, 1;
	shl.b32 	%r198, %r197, 20;
	add.s32 	%r199, %r34, %r198;
	mov.b64 	%fd157, {%r33, %r199};
	sub.s32 	%r200, %r32, %r197;
	shl.b32 	%r201, %r200, 20;
	add.s32 	%r202, %r201, 1072693248;
	mov.u32 	%r203, 0;
	mov.b64 	%fd158, {%r203, %r202};
	mul.f64 	%fd374, %fd157, %fd158;

$L__BB8_31:
	sub.s32 	%r35, %r623, %r625;
	cvt.rn.f32.s32 	%f420, %r35;
	cvt.f64.f32 	%fd18, %f420;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd18;
	}
	abs.f64 	%fd19, %fd18;
	{ // callseq 175, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd19;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd376, [retval0+0];
	} // callseq 175
	setp.lt.s32 	%p51, %r36, 0;
	and.pred  	%p3, %p51, %p28;
	not.pred 	%p53, %p3;
	@%p53 bra 	$L__BB8_33;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r204}, %fd376;
	}
	xor.b32  	%r205, %r204, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r206, %temp}, %fd376;
	}
	mov.b64 	%fd376, {%r206, %r205};

$L__BB8_33:
	setp.eq.s32 	%p54, %r35, 0;
	@%p54 bra 	$L__BB8_37;

	setp.gt.s32 	%p55, %r36, -1;
	@%p55 bra 	$L__BB8_38;

	cvt.rzi.f64.f64 	%fd161, %fd115;
	setp.eq.f64 	%p56, %fd161, 0d4000000000000000;
	@%p56 bra 	$L__BB8_38;

	mov.f64 	%fd376, 0dFFF8000000000000;
	bra.uni 	$L__BB8_38;

$L__BB8_37:
	mov.u32 	%r207, 0;
	selp.b32 	%r208, %r36, 0, %p28;
	or.b32  	%r209, %r208, 2146435072;
	selp.b32 	%r210, %r209, %r208, %p29;
	mov.b64 	%fd376, {%r207, %r210};

$L__BB8_38:
	add.f64 	%fd25, %fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r211}, %fd25;
	}
	and.b32  	%r212, %r211, 2146435072;
	setp.ne.s32 	%p59, %r212, 2146435072;
	mov.f64 	%fd377, %fd376;
	@%p59 bra 	$L__BB8_44;

	setp.gtu.f64 	%p60, %fd19, 0d7FF0000000000000;
	mov.f64 	%fd377, %fd25;
	@%p60 bra 	$L__BB8_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r213, %temp}, %fd115;
	}
	setp.eq.s32 	%p62, %r213, 0;
	and.pred  	%p63, %p61, %p62;
	@%p63 bra 	$L__BB8_43;
	bra.uni 	$L__BB8_41;

$L__BB8_43:
	mov.u32 	%r218, 0;
	setp.gt.f64 	%p70, %fd19, 0d3FF0000000000000;
	selp.b32 	%r219, 2146435072, 0, %p70;
	xor.b32  	%r220, %r219, 2146435072;
	selp.b32 	%r221, %r220, %r219, %p29;
	setp.eq.s32 	%p71, %r35, -1;
	selp.b32 	%r222, 1072693248, %r221, %p71;
	mov.b64 	%fd377, {%r218, %r222};
	bra.uni 	$L__BB8_44;

$L__BB8_41:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r214, %temp}, %fd18;
	}
	and.b32  	%r215, %r36, 2147483647;
	setp.ne.s32 	%p64, %r215, 2146435072;
	setp.ne.s32 	%p65, %r214, 0;
	or.pred  	%p66, %p64, %p65;
	mov.f64 	%fd377, %fd376;
	@%p66 bra 	$L__BB8_44;

	and.pred  	%p68, %p34, %p3;
	selp.b32 	%r216, %r19, %r18, %p68;
	mov.u32 	%r217, 0;
	mov.b64 	%fd377, {%r217, %r216};

$L__BB8_44:
	mov.f64 	%fd363, 0d3FF0000000000000;
	mov.f64 	%fd362, 0d3FE000000000000B;
	mov.f64 	%fd361, 0d3FC5555555555511;
	mov.f64 	%fd360, 0d3FA55555555502A1;
	mov.f64 	%fd359, 0d3F81111111122322;
	mov.f64 	%fd358, 0d3F56C16C1852B7AF;
	mov.f64 	%fd357, 0d3F2A01A014761F65;
	mov.f64 	%fd356, 0d3EFA01997C89EB71;
	mov.f64 	%fd355, 0d3EC71DEE62401315;
	mov.f64 	%fd354, 0d3E928AF3FCA213EA;
	mov.f64 	%fd353, 0d3E5ADE1569CE2BDF;
	mov.f64 	%fd352, 0dBC7ABC9E3B39803F;
	mov.f64 	%fd351, 0dBFE62E42FEFA39EF;
	mov.f64 	%fd350, 0dC338000000000000;
	mov.f64 	%fd349, 0d4338000000000000;
	mov.f64 	%fd348, 0d3FF71547652B82FE;
	setp.eq.s32 	%p72, %r35, 1;
	selp.f64 	%fd164, 0d3FF0000000000000, %fd377, %p72;
	mul.f64 	%fd29, %fd164, %fd1;
	neg.f64 	%fd166, %fd29;
	fma.rn.f64 	%fd169, %fd166, %fd348, %fd349;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd169;
	}
	add.rn.f64 	%fd171, %fd169, %fd350;
	fma.rn.f64 	%fd173, %fd171, %fd351, %fd166;
	fma.rn.f64 	%fd175, %fd171, %fd352, %fd173;
	fma.rn.f64 	%fd178, %fd353, %fd175, %fd354;
	fma.rn.f64 	%fd180, %fd178, %fd175, %fd355;
	fma.rn.f64 	%fd182, %fd180, %fd175, %fd356;
	fma.rn.f64 	%fd184, %fd182, %fd175, %fd357;
	fma.rn.f64 	%fd186, %fd184, %fd175, %fd358;
	fma.rn.f64 	%fd188, %fd186, %fd175, %fd359;
	fma.rn.f64 	%fd190, %fd188, %fd175, %fd360;
	fma.rn.f64 	%fd192, %fd190, %fd175, %fd361;
	fma.rn.f64 	%fd194, %fd192, %fd175, %fd362;
	fma.rn.f64 	%fd195, %fd194, %fd175, %fd363;
	fma.rn.f64 	%fd196, %fd195, %fd175, %fd363;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd196;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd196;
	}
	shl.b32 	%r223, %r37, 20;
	add.s32 	%r224, %r39, %r223;
	mov.b64 	%fd378, {%r38, %r224};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r225}, %fd166;
	}
	mov.b32 	%f421, %r225;
	abs.f32 	%f42, %f421;
	setp.lt.f32 	%p73, %f42, 0f4086232B;
	@%p73 bra 	$L__BB8_47;

	setp.gt.f64 	%p74, %fd29, 0d8000000000000000;
	mov.f64 	%fd197, 0d7FF0000000000000;
	sub.f64 	%fd198, %fd197, %fd29;
	selp.f64 	%fd378, 0d0000000000000000, %fd198, %p74;
	setp.geu.f32 	%p75, %f42, 0f40874800;
	@%p75 bra 	$L__BB8_47;

	shr.u32 	%r226, %r37, 31;
	add.s32 	%r227, %r37, %r226;
	shr.s32 	%r228, %r227, 1;
	shl.b32 	%r229, %r228, 20;
	add.s32 	%r230, %r39, %r229;
	mov.b64 	%fd199, {%r38, %r230};
	sub.s32 	%r231, %r37, %r228;
	shl.b32 	%r232, %r231, 20;
	add.s32 	%r233, %r232, 1072693248;
	mov.u32 	%r234, 0;
	mov.b64 	%fd200, {%r234, %r233};
	mul.f64 	%fd378, %fd199, %fd200;

$L__BB8_47:
	add.s32 	%r235, %r625, %r30;
	add.s32 	%r236, %r235, %r1;
	mul.wide.s32 	%rd70, %r236, 4;
	add.s64 	%rd71, %rd1, %rd70;
	ld.global.f32 	%f422, [%rd71];
	cvt.f64.f32 	%fd201, %f422;
	mul.f64 	%fd202, %fd374, %fd378;
	cvt.f64.f32 	%fd203, %f1694;
	fma.rn.f64 	%fd204, %fd202, %fd201, %fd203;
	cvt.rn.f32.f64 	%f1694, %fd204;
	cvt.f64.f32 	%fd205, %f1693;
	add.f64 	%fd206, %fd202, %fd205;
	cvt.rn.f32.f64 	%f1693, %fd206;
	add.s32 	%r625, %r625, 1;
	setp.lt.s32 	%p76, %r625, %r151;
	@%p76 bra 	$L__BB8_16;

	add.s32 	%r624, %r624, 1;
	setp.lt.s32 	%p77, %r624, %r151;
	@%p77 bra 	$L__BB8_15;

	div.rn.f32 	%f423, %f1694, %f1693;
	min.f32 	%f1690, %f1690, %f423;
	add.s32 	%r623, %r623, 1;
	setp.lt.s32 	%p78, %r623, %r151;
	@%p78 bra 	$L__BB8_14;

	add.s32 	%r622, %r622, 1;
	setp.lt.s32 	%p79, %r622, %r151;
	@%p79 bra 	$L__BB8_13;

$L__BB8_51:
	mov.f32 	%f426, 0f38D1B717;
	max.f32 	%f47, %f1690, %f426;
	setp.lt.s32 	%p80, %r153, 1;
	mov.f32 	%f1814, 0fBF800000;
	mov.f32 	%f1813, 0f00000000;
	mov.u32 	%r648, 0;
	@%p80 bra 	$L__BB8_280;

	ld.param.u32 	%r616, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_3];
	mul.f32 	%f429, %f379, 0f3F000000;
	div.rn.f32 	%f430, %f429, 0f40490FD8;
	div.rn.f32 	%f431, %f430, %f378;
	div.rn.f32 	%f432, %f431, %f378;
	div.rn.f32 	%f48, %f432, 0f41200000;
	div.rn.f32 	%f433, %f379, 0fC0206C98;
	div.rn.f32 	%f49, %f433, %f378;
	cvt.f64.f32 	%fd34, %f433;
	cvt.f64.f32 	%fd35, %f378;
	add.f64 	%fd36, %fd35, 0d4008000000000000;
	mul.f32 	%f50, %f378, 0f3FC00000;
	add.s32 	%r241, %r151, -1;
	mov.u32 	%r626, 1;
	setp.lt.s32 	%p106, %r616, 1;
	mov.f64 	%fd207, 0d4000000000000000;
	mov.u32 	%r628, %r648;

$L__BB8_53:
	mov.u32 	%r44, %r628;
	mov.u32 	%r628, %r626;
	setp.eq.s32 	%p81, %r628, 1;
	@%p81 bra 	$L__BB8_73;
	bra.uni 	$L__BB8_54;

$L__BB8_73:
	st.local.f32 	[%rd2], %f1774;
	st.local.f32 	[%rd3], %f1773;
	mov.u32 	%r633, 0;
	bra.uni 	$L__BB8_74;

$L__BB8_54:
	mov.f32 	%f1718, %f48;
	@%p18 bra 	$L__BB8_72;

	add.s32 	%r47, %r628, -1;
	mul.wide.s32 	%rd72, %r47, 4;
	add.s64 	%rd8, %rd2, %rd72;
	add.s64 	%rd9, %rd3, %rd72;
	mov.u32 	%r242, 0;
	mov.u32 	%r629, %r242;
	mov.f32 	%f1718, %f48;

$L__BB8_56:
	cvt.rn.f32.s32 	%f59, %r629;
	setp.eq.s32 	%p83, %r629, %r241;
	setp.eq.s32 	%p84, %r629, 0;
	or.pred  	%p85, %p83, %p84;
	selp.f32 	%f60, 0fBF800000, 0f3F800000, %p85;
	mov.u32 	%r630, %r242;

$L__BB8_57:
	setp.lt.u32 	%p86, %r628, 2;
	mov.f32 	%f1715, 0f00000000;
	mov.f32 	%f1716, %f1715;
	mov.u32 	%r632, %r242;
	mov.f32 	%f1717, %f47;
	@%p86 bra 	$L__BB8_68;

	sqrt.rn.f32 	%f64, %f34;
	cvt.rn.f32.s32 	%f65, %r630;
	mov.u64 	%rd134, %rd2;
	mov.u64 	%rd135, %rd3;
	mov.f32 	%f1717, %f47;
	mov.u32 	%r632, %r242;

$L__BB8_59:
	ld.local.f32 	%f1774, [%rd134];
	add.f32 	%f1716, %f1716, %f1774;
	ld.local.f32 	%f1773, [%rd135];
	add.f32 	%f1715, %f1715, %f1773;
	sub.f32 	%f73, %f59, %f1774;
	add.f32 	%f438, %f73, 0f3F000000;
	mul.f32 	%f74, %f438, %f64;
	abs.f32 	%f439, %f74;
	setp.ltu.f32 	%p87, %f439, 0f3F8060FE;
	setp.ge.f32 	%p88, %f439, 0f3F8060FE;
	mul.f32 	%f440, %f74, %f74;
	selp.f32 	%f441, %f439, %f440, %p88;
	selp.f32 	%f442, 0f3789CA3C, 0f38B1E96A, %p88;
	selp.f32 	%f443, 0fB9F560B9, 0fBA574D20, %p88;
	fma.rn.f32 	%f444, %f442, %f441, %f443;
	selp.f32 	%f445, 0f3BAC840B, 0f3BAAD5EA, %p88;
	fma.rn.f32 	%f446, %f444, %f441, %f445;
	selp.f32 	%f447, 0fBD0C8162, 0fBCDC1BE7, %p88;
	fma.rn.f32 	%f448, %f446, %f441, %f447;
	selp.f32 	%f449, 0f3E1CF906, 0f3DE718AF, %p88;
	fma.rn.f32 	%f450, %f448, %f441, %f449;
	selp.f32 	%f451, 0f3F6A937E, 0fBEC093AC, %p88;
	fma.rn.f32 	%f452, %f450, %f441, %f451;
	selp.f32 	%f453, 0f3F20D842, 0f3E0375D3, %p88;
	fma.rn.f32 	%f454, %f452, %f441, %f453;
	neg.f32 	%f455, %f439;
	selp.f32 	%f456, %f455, %f74, %p88;
	fma.rn.f32 	%f1709, %f454, %f456, %f456;
	@%p87 bra 	$L__BB8_61;

	ex2.approx.ftz.f32 	%f457, %f1709;
	mov.f32 	%f458, 0f3F800000;
	sub.f32 	%f459, %f458, %f457;
	mov.b32 	%r246, %f459;
	mov.b32 	%r247, %f74;
	and.b32  	%r248, %r247, -2147483648;
	or.b32  	%r249, %r248, %r246;
	mov.b32 	%f1709, %r249;

$L__BB8_61:
	add.f32 	%f460, %f73, 0fBF000000;
	mul.f32 	%f78, %f460, %f64;
	abs.f32 	%f461, %f78;
	setp.ltu.f32 	%p89, %f461, 0f3F8060FE;
	setp.ge.f32 	%p90, %f461, 0f3F8060FE;
	mul.f32 	%f462, %f78, %f78;
	selp.f32 	%f463, %f461, %f462, %p90;
	selp.f32 	%f464, 0f3789CA3C, 0f38B1E96A, %p90;
	selp.f32 	%f465, 0fB9F560B9, 0fBA574D20, %p90;
	fma.rn.f32 	%f466, %f464, %f463, %f465;
	selp.f32 	%f467, 0f3BAC840B, 0f3BAAD5EA, %p90;
	fma.rn.f32 	%f468, %f466, %f463, %f467;
	selp.f32 	%f469, 0fBD0C8162, 0fBCDC1BE7, %p90;
	fma.rn.f32 	%f470, %f468, %f463, %f469;
	selp.f32 	%f471, 0f3E1CF906, 0f3DE718AF, %p90;
	fma.rn.f32 	%f472, %f470, %f463, %f471;
	selp.f32 	%f473, 0f3F6A937E, 0fBEC093AC, %p90;
	fma.rn.f32 	%f474, %f472, %f463, %f473;
	selp.f32 	%f475, 0f3F20D842, 0f3E0375D3, %p90;
	fma.rn.f32 	%f476, %f474, %f463, %f475;
	neg.f32 	%f477, %f461;
	selp.f32 	%f478, %f477, %f78, %p90;
	fma.rn.f32 	%f1710, %f476, %f478, %f478;
	@%p89 bra 	$L__BB8_63;

	ex2.approx.ftz.f32 	%f479, %f1710;
	mov.f32 	%f480, 0f3F800000;
	sub.f32 	%f481, %f480, %f479;
	mov.b32 	%r250, %f481;
	mov.b32 	%r251, %f78;
	and.b32  	%r252, %r251, -2147483648;
	or.b32  	%r253, %r252, %r250;
	mov.b32 	%f1710, %r253;

$L__BB8_63:
	sub.f32 	%f82, %f1709, %f1710;
	sub.f32 	%f83, %f65, %f1773;
	add.f32 	%f482, %f83, 0f3F000000;
	mul.f32 	%f84, %f482, %f64;
	abs.f32 	%f483, %f84;
	setp.ltu.f32 	%p91, %f483, 0f3F8060FE;
	setp.ge.f32 	%p92, %f483, 0f3F8060FE;
	mul.f32 	%f484, %f84, %f84;
	selp.f32 	%f485, %f483, %f484, %p92;
	selp.f32 	%f486, 0f3789CA3C, 0f38B1E96A, %p92;
	selp.f32 	%f487, 0fB9F560B9, 0fBA574D20, %p92;
	fma.rn.f32 	%f488, %f486, %f485, %f487;
	selp.f32 	%f489, 0f3BAC840B, 0f3BAAD5EA, %p92;
	fma.rn.f32 	%f490, %f488, %f485, %f489;
	selp.f32 	%f491, 0fBD0C8162, 0fBCDC1BE7, %p92;
	fma.rn.f32 	%f492, %f490, %f485, %f491;
	selp.f32 	%f493, 0f3E1CF906, 0f3DE718AF, %p92;
	fma.rn.f32 	%f494, %f492, %f485, %f493;
	selp.f32 	%f495, 0f3F6A937E, 0fBEC093AC, %p92;
	fma.rn.f32 	%f496, %f494, %f485, %f495;
	selp.f32 	%f497, 0f3F20D842, 0f3E0375D3, %p92;
	fma.rn.f32 	%f498, %f496, %f485, %f497;
	neg.f32 	%f499, %f483;
	selp.f32 	%f500, %f499, %f84, %p92;
	fma.rn.f32 	%f1711, %f498, %f500, %f500;
	@%p91 bra 	$L__BB8_65;

	ex2.approx.ftz.f32 	%f501, %f1711;
	mov.f32 	%f502, 0f3F800000;
	sub.f32 	%f503, %f502, %f501;
	mov.b32 	%r254, %f503;
	mov.b32 	%r255, %f84;
	and.b32  	%r256, %r255, -2147483648;
	or.b32  	%r257, %r256, %r254;
	mov.b32 	%f1711, %r257;

$L__BB8_65:
	add.f32 	%f504, %f83, 0fBF000000;
	mul.f32 	%f88, %f504, %f64;
	abs.f32 	%f505, %f88;
	setp.ltu.f32 	%p93, %f505, 0f3F8060FE;
	setp.ge.f32 	%p94, %f505, 0f3F8060FE;
	mul.f32 	%f506, %f88, %f88;
	selp.f32 	%f507, %f505, %f506, %p94;
	selp.f32 	%f508, 0f3789CA3C, 0f38B1E96A, %p94;
	selp.f32 	%f509, 0fB9F560B9, 0fBA574D20, %p94;
	fma.rn.f32 	%f510, %f508, %f507, %f509;
	selp.f32 	%f511, 0f3BAC840B, 0f3BAAD5EA, %p94;
	fma.rn.f32 	%f512, %f510, %f507, %f511;
	selp.f32 	%f513, 0fBD0C8162, 0fBCDC1BE7, %p94;
	fma.rn.f32 	%f514, %f512, %f507, %f513;
	selp.f32 	%f515, 0f3E1CF906, 0f3DE718AF, %p94;
	fma.rn.f32 	%f516, %f514, %f507, %f515;
	selp.f32 	%f517, 0f3F6A937E, 0fBEC093AC, %p94;
	fma.rn.f32 	%f518, %f516, %f507, %f517;
	selp.f32 	%f519, 0f3F20D842, 0f3E0375D3, %p94;
	fma.rn.f32 	%f520, %f518, %f507, %f519;
	neg.f32 	%f521, %f505;
	selp.f32 	%f522, %f521, %f88, %p94;
	fma.rn.f32 	%f1712, %f520, %f522, %f522;
	@%p93 bra 	$L__BB8_67;

	ex2.approx.ftz.f32 	%f523, %f1712;
	mov.f32 	%f524, 0f3F800000;
	sub.f32 	%f525, %f524, %f523;
	mov.b32 	%r258, %f525;
	mov.b32 	%r259, %f88;
	and.b32  	%r260, %r259, -2147483648;
	or.b32  	%r261, %r260, %r258;
	mov.b32 	%f1712, %r261;

$L__BB8_67:
	sub.f32 	%f526, %f1711, %f1712;
	mul.f32 	%f527, %f526, 0f3F000000;
	mul.f32 	%f528, %f82, 0f3F000000;
	mul.f32 	%f529, %f528, %f379;
	fma.rn.f32 	%f1717, %f529, %f527, %f1717;
	add.s64 	%rd135, %rd135, 4;
	add.s64 	%rd134, %rd134, 4;
	add.s32 	%r632, %r632, 1;
	setp.lt.s32 	%p95, %r632, %r47;
	@%p95 bra 	$L__BB8_59;

$L__BB8_68:
	mad.lo.s32 	%r262, %r630, %r151, %r629;
	add.s32 	%r263, %r262, %r1;
	mul.wide.s32 	%rd73, %r263, 4;
	add.s64 	%rd74, %rd1, %rd73;
	ld.global.f32 	%f530, [%rd74];
	sub.f32 	%f98, %f530, %f1717;
	setp.leu.f32 	%p96, %f98, %f1718;
	@%p96 bra 	$L__BB8_70;

	setp.eq.s32 	%p97, %r630, 0;
	setp.eq.s32 	%p98, %r630, %r241;
	or.pred  	%p99, %p98, %p97;
	cvt.rn.f32.s32 	%f531, %r632;
	div.rn.f32 	%f532, %f1716, %f531;
	sub.f32 	%f533, %f59, %f532;
	setp.gt.f32 	%p100, %f533, 0f00000000;
	div.rn.f32 	%f534, %f1715, %f531;
	cvt.rn.f32.s32 	%f535, %r630;
	sub.f32 	%f536, %f535, %f534;
	setp.gt.f32 	%p101, %f536, 0f00000000;
	selp.f32 	%f537, 0f3F000000, 0fBF000000, %p100;
	mul.f32 	%f538, %f60, %f537;
	sub.f32 	%f539, %f59, %f538;
	st.local.f32 	[%rd8], %f539;
	selp.f32 	%f540, 0f3F000000, 0fBF000000, %p101;
	selp.f32 	%f541, 0fBF800000, 0f3F800000, %p99;
	mul.f32 	%f542, %f541, %f540;
	sub.f32 	%f543, %f535, %f542;
	st.local.f32 	[%rd9], %f543;
	mov.f32 	%f1718, %f98;

$L__BB8_70:
	add.s32 	%r630, %r630, 1;
	setp.lt.s32 	%p102, %r630, %r151;
	@%p102 bra 	$L__BB8_57;

	add.s32 	%r629, %r629, 1;
	setp.lt.s32 	%p103, %r629, %r151;
	@%p103 bra 	$L__BB8_56;

$L__BB8_72:
	setp.eq.f32 	%p104, %f1718, %f48;
	selp.u32 	%r633, 1, 0, %p104;

$L__BB8_74:
	setp.ne.s32 	%p105, %r633, 0;
	@%p105 bra 	$L__BB8_280;

	mov.f32 	%f1781, %f47;
	@%p106 bra 	$L__BB8_224;

	mov.u32 	%r634, 0;
	mov.f32 	%f1781, %f47;

$L__BB8_77:
	mov.f32 	%f1730, 0f00000000;
	mov.f32 	%f1729, %f1730;
	@%p18 bra 	$L__BB8_109;

	mov.u32 	%r267, 0;
	mov.u32 	%r635, %r267;

$L__BB8_79:
	cvt.rn.f32.s32 	%f111, %r635;
	sqrt.rn.f32 	%f112, %f34;
	mov.u32 	%r636, %r267;

$L__BB8_80:
	cvt.rn.f32.s32 	%f115, %r636;
	mov.f32 	%f1731, %f1781;
	mov.u32 	%r637, %r267;

$L__BB8_81:
	mul.wide.s32 	%rd75, %r637, 4;
	add.s64 	%rd76, %rd2, %rd75;
	ld.local.f32 	%f1774, [%rd76];
	add.s64 	%rd77, %rd6, %rd75;
	st.local.f32 	[%rd77], %f1774;
	add.s64 	%rd78, %rd3, %rd75;
	ld.local.f32 	%f1773, [%rd78];
	add.s64 	%rd79, %rd7, %rd75;
	st.local.f32 	[%rd79], %f1773;
	sub.f32 	%f119, %f111, %f1774;
	add.f32 	%f548, %f119, 0f3F000000;
	mul.f32 	%f120, %f112, %f548;
	abs.f32 	%f549, %f120;
	setp.ltu.f32 	%p108, %f549, 0f3F8060FE;
	setp.ge.f32 	%p109, %f549, 0f3F8060FE;
	mul.f32 	%f550, %f120, %f120;
	selp.f32 	%f551, %f549, %f550, %p109;
	selp.f32 	%f552, 0f3789CA3C, 0f38B1E96A, %p109;
	selp.f32 	%f553, 0fB9F560B9, 0fBA574D20, %p109;
	fma.rn.f32 	%f554, %f552, %f551, %f553;
	selp.f32 	%f555, 0f3BAC840B, 0f3BAAD5EA, %p109;
	fma.rn.f32 	%f556, %f554, %f551, %f555;
	selp.f32 	%f557, 0fBD0C8162, 0fBCDC1BE7, %p109;
	fma.rn.f32 	%f558, %f556, %f551, %f557;
	selp.f32 	%f559, 0f3E1CF906, 0f3DE718AF, %p109;
	fma.rn.f32 	%f560, %f558, %f551, %f559;
	selp.f32 	%f561, 0f3F6A937E, 0fBEC093AC, %p109;
	fma.rn.f32 	%f562, %f560, %f551, %f561;
	selp.f32 	%f563, 0f3F20D842, 0f3E0375D3, %p109;
	fma.rn.f32 	%f564, %f562, %f551, %f563;
	neg.f32 	%f565, %f549;
	selp.f32 	%f566, %f565, %f120, %p109;
	fma.rn.f32 	%f1732, %f564, %f566, %f566;
	@%p108 bra 	$L__BB8_83;

	ex2.approx.ftz.f32 	%f567, %f1732;
	mov.f32 	%f568, 0f3F800000;
	sub.f32 	%f569, %f568, %f567;
	mov.b32 	%r270, %f569;
	mov.b32 	%r271, %f120;
	and.b32  	%r272, %r271, -2147483648;
	or.b32  	%r273, %r272, %r270;
	mov.b32 	%f1732, %r273;

$L__BB8_83:
	add.f32 	%f570, %f119, 0fBF000000;
	mul.f32 	%f124, %f112, %f570;
	abs.f32 	%f571, %f124;
	setp.ltu.f32 	%p110, %f571, 0f3F8060FE;
	setp.ge.f32 	%p111, %f571, 0f3F8060FE;
	mul.f32 	%f572, %f124, %f124;
	selp.f32 	%f573, %f571, %f572, %p111;
	selp.f32 	%f574, 0f3789CA3C, 0f38B1E96A, %p111;
	selp.f32 	%f575, 0fB9F560B9, 0fBA574D20, %p111;
	fma.rn.f32 	%f576, %f574, %f573, %f575;
	selp.f32 	%f577, 0f3BAC840B, 0f3BAAD5EA, %p111;
	fma.rn.f32 	%f578, %f576, %f573, %f577;
	selp.f32 	%f579, 0fBD0C8162, 0fBCDC1BE7, %p111;
	fma.rn.f32 	%f580, %f578, %f573, %f579;
	selp.f32 	%f581, 0f3E1CF906, 0f3DE718AF, %p111;
	fma.rn.f32 	%f582, %f580, %f573, %f581;
	selp.f32 	%f583, 0f3F6A937E, 0fBEC093AC, %p111;
	fma.rn.f32 	%f584, %f582, %f573, %f583;
	selp.f32 	%f585, 0f3F20D842, 0f3E0375D3, %p111;
	fma.rn.f32 	%f586, %f584, %f573, %f585;
	neg.f32 	%f587, %f571;
	selp.f32 	%f588, %f587, %f124, %p111;
	fma.rn.f32 	%f1733, %f586, %f588, %f588;
	@%p110 bra 	$L__BB8_85;

	ex2.approx.ftz.f32 	%f589, %f1733;
	mov.f32 	%f590, 0f3F800000;
	sub.f32 	%f591, %f590, %f589;
	mov.b32 	%r274, %f591;
	mov.b32 	%r275, %f124;
	and.b32  	%r276, %r275, -2147483648;
	or.b32  	%r277, %r276, %r274;
	mov.b32 	%f1733, %r277;

$L__BB8_85:
	sub.f32 	%f128, %f1732, %f1733;
	sub.f32 	%f129, %f115, %f1773;
	add.f32 	%f592, %f129, 0f3F000000;
	mul.f32 	%f130, %f592, %f112;
	abs.f32 	%f593, %f130;
	setp.ltu.f32 	%p112, %f593, 0f3F8060FE;
	setp.ge.f32 	%p113, %f593, 0f3F8060FE;
	mul.f32 	%f594, %f130, %f130;
	selp.f32 	%f595, %f593, %f594, %p113;
	selp.f32 	%f596, 0f3789CA3C, 0f38B1E96A, %p113;
	selp.f32 	%f597, 0fB9F560B9, 0fBA574D20, %p113;
	fma.rn.f32 	%f598, %f596, %f595, %f597;
	selp.f32 	%f599, 0f3BAC840B, 0f3BAAD5EA, %p113;
	fma.rn.f32 	%f600, %f598, %f595, %f599;
	selp.f32 	%f601, 0fBD0C8162, 0fBCDC1BE7, %p113;
	fma.rn.f32 	%f602, %f600, %f595, %f601;
	selp.f32 	%f603, 0f3E1CF906, 0f3DE718AF, %p113;
	fma.rn.f32 	%f604, %f602, %f595, %f603;
	selp.f32 	%f605, 0f3F6A937E, 0fBEC093AC, %p113;
	fma.rn.f32 	%f606, %f604, %f595, %f605;
	selp.f32 	%f607, 0f3F20D842, 0f3E0375D3, %p113;
	fma.rn.f32 	%f608, %f606, %f595, %f607;
	neg.f32 	%f609, %f593;
	selp.f32 	%f610, %f609, %f130, %p113;
	fma.rn.f32 	%f1734, %f608, %f610, %f610;
	@%p112 bra 	$L__BB8_87;

	ex2.approx.ftz.f32 	%f611, %f1734;
	mov.f32 	%f612, 0f3F800000;
	sub.f32 	%f613, %f612, %f611;
	mov.b32 	%r278, %f613;
	mov.b32 	%r279, %f130;
	and.b32  	%r280, %r279, -2147483648;
	or.b32  	%r281, %r280, %r278;
	mov.b32 	%f1734, %r281;

$L__BB8_87:
	add.f32 	%f614, %f129, 0fBF000000;
	mul.f32 	%f134, %f614, %f112;
	abs.f32 	%f615, %f134;
	setp.ltu.f32 	%p114, %f615, 0f3F8060FE;
	setp.ge.f32 	%p115, %f615, 0f3F8060FE;
	mul.f32 	%f616, %f134, %f134;
	selp.f32 	%f617, %f615, %f616, %p115;
	selp.f32 	%f618, 0f3789CA3C, 0f38B1E96A, %p115;
	selp.f32 	%f619, 0fB9F560B9, 0fBA574D20, %p115;
	fma.rn.f32 	%f620, %f618, %f617, %f619;
	selp.f32 	%f621, 0f3BAC840B, 0f3BAAD5EA, %p115;
	fma.rn.f32 	%f622, %f620, %f617, %f621;
	selp.f32 	%f623, 0fBD0C8162, 0fBCDC1BE7, %p115;
	fma.rn.f32 	%f624, %f622, %f617, %f623;
	selp.f32 	%f625, 0f3E1CF906, 0f3DE718AF, %p115;
	fma.rn.f32 	%f626, %f624, %f617, %f625;
	selp.f32 	%f627, 0f3F6A937E, 0fBEC093AC, %p115;
	fma.rn.f32 	%f628, %f626, %f617, %f627;
	selp.f32 	%f629, 0f3F20D842, 0f3E0375D3, %p115;
	fma.rn.f32 	%f630, %f628, %f617, %f629;
	neg.f32 	%f631, %f615;
	selp.f32 	%f632, %f631, %f134, %p115;
	fma.rn.f32 	%f1735, %f630, %f632, %f632;
	@%p114 bra 	$L__BB8_89;

	ex2.approx.ftz.f32 	%f633, %f1735;
	mov.f32 	%f634, 0f3F800000;
	sub.f32 	%f635, %f634, %f633;
	mov.b32 	%r282, %f635;
	mov.b32 	%r283, %f134;
	and.b32  	%r284, %r283, -2147483648;
	or.b32  	%r285, %r284, %r282;
	mov.b32 	%f1735, %r285;

$L__BB8_89:
	sub.f32 	%f636, %f1734, %f1735;
	mul.f32 	%f637, %f636, 0f3F000000;
	mul.f32 	%f638, %f128, 0f3F000000;
	mul.f32 	%f639, %f638, %f379;
	fma.rn.f32 	%f1731, %f639, %f637, %f1731;
	add.s32 	%r637, %r637, 1;
	setp.lt.u32 	%p116, %r637, %r628;
	@%p116 bra 	$L__BB8_81;

	mad.lo.s32 	%r286, %r636, %r151, %r635;
	add.s32 	%r287, %r286, %r1;
	mul.wide.s32 	%rd80, %r287, 4;
	add.s64 	%rd81, %rd1, %rd80;
	ld.global.f32 	%f139, [%rd81];
	setp.leu.f32 	%p117, %f1731, 0f3C23D70A;
	mov.f32 	%f1737, 0f00000000;
	mov.f32 	%f1736, %f1737;
	@%p117 bra 	$L__BB8_92;

	div.rn.f32 	%f641, %f139, %f1731;
	add.f32 	%f1736, %f641, 0fBF800000;

$L__BB8_92:
	@%p117 bra 	$L__BB8_107;

	cvt.f64.f32 	%fd37, %f1731;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r63}, %fd37;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd207;
	}
	and.b32  	%r65, %r64, 2146435072;
	setp.eq.s32 	%p119, %r65, 1062207488;
	abs.f64 	%fd38, %fd37;
	{ // callseq 176, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd38;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd207;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd380, [retval0+0];
	} // callseq 176
	setp.lt.s32 	%p120, %r63, 0;
	and.pred  	%p4, %p120, %p119;
	not.pred 	%p121, %p4;
	@%p121 bra 	$L__BB8_95;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r288}, %fd380;
	}
	xor.b32  	%r289, %r288, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r290, %temp}, %fd380;
	}
	mov.b64 	%fd380, {%r290, %r289};

$L__BB8_95:
	setp.eq.f32 	%p122, %f1731, 0f00000000;
	@%p122 bra 	$L__BB8_99;
	bra.uni 	$L__BB8_96;

$L__BB8_99:
	selp.b32 	%r291, %r63, 0, %p119;
	mov.u32 	%r292, 0;
	or.b32  	%r293, %r291, 2146435072;
	setp.lt.s32 	%p126, %r64, 0;
	selp.b32 	%r294, %r293, %r291, %p126;
	mov.b64 	%fd380, {%r292, %r294};
	bra.uni 	$L__BB8_100;

$L__BB8_96:
	setp.gt.s32 	%p123, %r63, -1;
	@%p123 bra 	$L__BB8_100;

	cvt.rzi.f64.f64 	%fd209, %fd207;
	setp.eq.f64 	%p124, %fd209, 0d4000000000000000;
	@%p124 bra 	$L__BB8_100;

	mov.f64 	%fd380, 0dFFF8000000000000;

$L__BB8_100:
	add.f64 	%fd44, %fd37, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r295}, %fd44;
	}
	and.b32  	%r296, %r295, 2146435072;
	setp.ne.s32 	%p127, %r296, 2146435072;
	mov.f64 	%fd381, %fd380;
	@%p127 bra 	$L__BB8_106;

	setp.gtu.f64 	%p128, %fd38, 0d7FF0000000000000;
	mov.f64 	%fd381, %fd44;
	@%p128 bra 	$L__BB8_106;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r297, %temp}, %fd207;
	}
	and.b32  	%r66, %r64, 2147483647;
	setp.eq.s32 	%p129, %r66, 2146435072;
	setp.eq.s32 	%p130, %r297, 0;
	and.pred  	%p131, %p129, %p130;
	@%p131 bra 	$L__BB8_105;
	bra.uni 	$L__BB8_103;

$L__BB8_105:
	setp.gt.f64 	%p138, %fd38, 0d3FF0000000000000;
	selp.b32 	%r304, 2146435072, 0, %p138;
	mov.u32 	%r305, 0;
	xor.b32  	%r306, %r304, 2146435072;
	setp.lt.s32 	%p139, %r64, 0;
	selp.b32 	%r307, %r306, %r304, %p139;
	setp.eq.f32 	%p140, %f1731, 0fBF800000;
	selp.b32 	%r308, 1072693248, %r307, %p140;
	mov.b64 	%fd381, {%r305, %r308};
	bra.uni 	$L__BB8_106;

$L__BB8_103:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r298, %temp}, %fd37;
	}
	and.b32  	%r299, %r63, 2147483647;
	setp.ne.s32 	%p132, %r299, 2146435072;
	setp.ne.s32 	%p133, %r298, 0;
	or.pred  	%p134, %p132, %p133;
	mov.f64 	%fd381, %fd380;
	@%p134 bra 	$L__BB8_106;

	setp.gt.s32 	%p135, %r64, -1;
	selp.b32 	%r300, 2146435072, 0, %p135;
	mov.u32 	%r301, 0;
	setp.ne.s32 	%p136, %r66, 1071644672;
	and.pred  	%p137, %p136, %p4;
	or.b32  	%r302, %r300, -2147483648;
	selp.b32 	%r303, %r302, %r300, %p137;
	mov.b64 	%fd381, {%r301, %r303};

$L__BB8_106:
	setp.eq.f32 	%p141, %f1731, 0f3F800000;
	selp.f64 	%fd212, 0d3FF0000000000000, %fd381, %p141;
	cvt.f64.f32 	%fd213, %f139;
	div.rn.f64 	%fd214, %fd213, %fd212;
	cvt.rn.f32.f64 	%f1737, %fd214;

$L__BB8_107:
	mov.f32 	%f643, 0f47C35000;
	min.f32 	%f644, %f1737, %f643;
	sub.f32 	%f1729, %f1729, %f644;
	min.f32 	%f645, %f1736, %f643;
	add.f32 	%f1730, %f1730, %f645;
	add.s32 	%r636, %r636, 1;
	setp.lt.s32 	%p142, %r636, %r151;
	@%p142 bra 	$L__BB8_80;

	add.s32 	%r635, %r635, 1;
	setp.lt.s32 	%p143, %r635, %r151;
	@%p143 bra 	$L__BB8_79;

$L__BB8_109:
	cvt.rn.f32.s32 	%f1608, %r628;
	div.rn.f32 	%f646, %f1730, %f1729;
	mov.f32 	%f647, 0fBF800000;
	max.f32 	%f648, %f646, %f647;
	mov.f32 	%f649, 0f3F800000;
	min.f32 	%f650, %f648, %f649;
	div.rn.f32 	%f651, %f650, %f1608;
	fma.rn.f32 	%f652, %f651, 0fBF000000, %f1781;
	mov.f32 	%f653, 0f3A83126F;
	max.f32 	%f1781, %f652, %f653;
	mov.u32 	%r638, 0;

$L__BB8_110:
	cvt.s64.s32 	%rd14, %r638;
	mov.f32 	%f1751, 0f00000000;
	mov.f32 	%f1750, %f1751;
	mov.f32 	%f1749, %f1751;
	mov.f32 	%f1748, %f1751;
	@%p18 bra 	$L__BB8_222;

	mov.f32 	%f1748, 0f00000000;
	shl.b64 	%rd82, %rd14, 2;
	add.s64 	%rd83, %rd6, %rd82;
	ld.local.f32 	%f1774, [%rd83];
	add.s64 	%rd84, %rd7, %rd82;
	ld.local.f32 	%f1773, [%rd84];
	mov.u32 	%r639, 0;
	mov.f32 	%f1749, %f1748;
	mov.f32 	%f1750, %f1748;
	mov.f32 	%f1751, %f1748;

$L__BB8_112:
	mov.u32 	%r640, 0;
	mov.f32 	%f1611, 0f3F800000;
	mov.f32 	%f1610, 0f00000000;
	cvt.rn.f32.s32 	%f159, %r639;
	sub.f32 	%f662, %f159, %f1774;
	add.f32 	%f663, %f662, 0f3F000000;
	sqrt.rn.f32 	%f160, %f34;
	mul.f32 	%f664, %f663, %f160;
	abs.f32 	%f161, %f664;
	setp.ge.f32 	%p145, %f161, 0f3F8060FE;
	mul.f32 	%f665, %f664, %f664;
	selp.f32 	%f666, %f161, %f665, %p145;
	selp.f32 	%f667, 0f3789CA3C, 0f38B1E96A, %p145;
	selp.f32 	%f668, 0fB9F560B9, 0fBA574D20, %p145;
	fma.rn.f32 	%f669, %f667, %f666, %f668;
	selp.f32 	%f670, 0f3BAC840B, 0f3BAAD5EA, %p145;
	fma.rn.f32 	%f671, %f669, %f666, %f670;
	selp.f32 	%f672, 0fBD0C8162, 0fBCDC1BE7, %p145;
	fma.rn.f32 	%f673, %f671, %f666, %f672;
	selp.f32 	%f674, 0f3E1CF906, 0f3DE718AF, %p145;
	fma.rn.f32 	%f675, %f673, %f666, %f674;
	selp.f32 	%f676, 0f3F6A937E, 0fBEC093AC, %p145;
	fma.rn.f32 	%f677, %f675, %f666, %f676;
	selp.f32 	%f678, 0f3F20D842, 0f3E0375D3, %p145;
	fma.rn.f32 	%f679, %f677, %f666, %f678;
	neg.f32 	%f680, %f161;
	selp.f32 	%f681, %f680, %f664, %p145;
	fma.rn.f32 	%f162, %f679, %f681, %f681;
	mov.b32 	%r312, %f664;
	and.b32  	%r71, %r312, -2147483648;
	add.f32 	%f163, %f662, 0fBF000000;
	mul.f32 	%f682, %f163, %f160;
	abs.f32 	%f164, %f682;
	setp.ge.f32 	%p146, %f164, 0f3F8060FE;
	mul.f32 	%f683, %f682, %f682;
	selp.f32 	%f684, %f164, %f683, %p146;
	selp.f32 	%f685, 0f3789CA3C, 0f38B1E96A, %p146;
	selp.f32 	%f686, 0fB9F560B9, 0fBA574D20, %p146;
	fma.rn.f32 	%f687, %f685, %f684, %f686;
	selp.f32 	%f688, 0f3BAC840B, 0f3BAAD5EA, %p146;
	fma.rn.f32 	%f689, %f687, %f684, %f688;
	selp.f32 	%f690, 0fBD0C8162, 0fBCDC1BE7, %p146;
	fma.rn.f32 	%f691, %f689, %f684, %f690;
	selp.f32 	%f692, 0f3E1CF906, 0f3DE718AF, %p146;
	fma.rn.f32 	%f693, %f691, %f684, %f692;
	selp.f32 	%f694, 0f3F6A937E, 0fBEC093AC, %p146;
	fma.rn.f32 	%f695, %f693, %f684, %f694;
	selp.f32 	%f696, 0f3F20D842, 0f3E0375D3, %p146;
	fma.rn.f32 	%f697, %f695, %f684, %f696;
	neg.f32 	%f698, %f164;
	selp.f32 	%f699, %f698, %f682, %p146;
	fma.rn.f32 	%f165, %f697, %f699, %f699;
	mov.b32 	%r313, %f682;
	and.b32  	%r72, %r313, -2147483648;
	add.f32 	%f700, %f159, 0f3F000000;
	sub.f32 	%f166, %f700, %f1774;
	div.rn.f32 	%f167, %f166, %f378;
	cvt.rzi.f32.f32 	%f702, %f1611;
	add.f32 	%f703, %f702, %f702;
	mov.f32 	%f704, 0f40000000;
	sub.f32 	%f705, %f704, %f703;
	abs.f32 	%f168, %f705;
	setp.eq.f32 	%p147, %f168, 0f3F800000;
	abs.f32 	%f169, %f167;
	setp.lt.f32 	%p148, %f169, 0f00800000;
	mul.f32 	%f706, %f169, 0f4B800000;
	selp.f32 	%f707, %f706, %f169, %p148;
	selp.f32 	%f708, 0fC3170000, 0fC2FE0000, %p148;
	mov.b32 	%r314, %f707;
	and.b32  	%r315, %r314, 8388607;
	or.b32  	%r316, %r315, 1065353216;
	mov.b32 	%f709, %r316;
	shr.u32 	%r317, %r314, 23;
	cvt.rn.f32.u32 	%f710, %r317;
	add.f32 	%f711, %f708, %f710;
	setp.gt.f32 	%p149, %f709, 0f3FB504F3;
	mul.f32 	%f712, %f709, 0f3F000000;
	add.f32 	%f713, %f711, 0f3F800000;
	selp.f32 	%f714, %f713, %f711, %p149;
	selp.f32 	%f715, %f712, %f709, %p149;
	add.f32 	%f716, %f715, 0fBF800000;
	add.f32 	%f717, %f715, 0f3F800000;
	rcp.approx.ftz.f32 	%f718, %f717;
	add.f32 	%f719, %f716, %f716;
	mul.f32 	%f720, %f719, %f718;
	mul.f32 	%f721, %f720, %f720;
	mov.f32 	%f722, 0f3C4CAF63;
	mov.f32 	%f723, 0f3B18F0FE;
	fma.rn.f32 	%f724, %f723, %f721, %f722;
	mov.f32 	%f725, 0f3DAAAABD;
	fma.rn.f32 	%f726, %f724, %f721, %f725;
	mul.rn.f32 	%f727, %f726, %f721;
	mul.rn.f32 	%f728, %f727, %f720;
	sub.f32 	%f729, %f716, %f720;
	add.f32 	%f730, %f729, %f729;
	neg.f32 	%f731, %f720;
	fma.rn.f32 	%f732, %f731, %f716, %f730;
	mul.rn.f32 	%f733, %f718, %f732;
	add.f32 	%f734, %f728, %f720;
	sub.f32 	%f735, %f720, %f734;
	add.f32 	%f736, %f728, %f735;
	add.f32 	%f737, %f733, %f736;
	add.f32 	%f738, %f734, %f737;
	sub.f32 	%f739, %f734, %f738;
	add.f32 	%f740, %f737, %f739;
	mov.f32 	%f741, 0f3F317200;
	mul.rn.f32 	%f742, %f714, %f741;
	mov.f32 	%f743, 0f35BFBE8E;
	mul.rn.f32 	%f744, %f714, %f743;
	add.f32 	%f745, %f742, %f738;
	sub.f32 	%f746, %f742, %f745;
	add.f32 	%f747, %f738, %f746;
	add.f32 	%f748, %f740, %f747;
	add.f32 	%f749, %f744, %f748;
	add.f32 	%f750, %f745, %f749;
	sub.f32 	%f751, %f745, %f750;
	add.f32 	%f752, %f749, %f751;
	mul.rn.f32 	%f753, %f704, %f750;
	neg.f32 	%f754, %f753;
	fma.rn.f32 	%f755, %f704, %f750, %f754;
	fma.rn.f32 	%f756, %f704, %f752, %f755;
	fma.rn.f32 	%f758, %f1610, %f750, %f756;
	add.rn.f32 	%f759, %f753, %f758;
	neg.f32 	%f760, %f759;
	add.rn.f32 	%f761, %f753, %f760;
	add.rn.f32 	%f762, %f761, %f758;
	mov.b32 	%r318, %f759;
	setp.eq.s32 	%p150, %r318, 1118925336;
	add.s32 	%r319, %r318, -1;
	mov.b32 	%f763, %r319;
	add.f32 	%f764, %f762, 0f37000000;
	selp.f32 	%f170, %f764, %f762, %p150;
	selp.f32 	%f765, %f763, %f759, %p150;
	mov.f32 	%f766, 0f3FB8AA3B;
	mul.rn.f32 	%f767, %f765, %f766;
	cvt.rzi.f32.f32 	%f768, %f767;
	abs.f32 	%f769, %f768;
	setp.gt.f32 	%p151, %f769, 0f42FC0000;
	mov.b32 	%r320, %f768;
	and.b32  	%r321, %r320, -2147483648;
	or.b32  	%r322, %r321, 1123811328;
	mov.b32 	%f770, %r322;
	selp.f32 	%f771, %f770, %f768, %p151;
	mov.f32 	%f772, 0fBF317218;
	fma.rn.f32 	%f773, %f771, %f772, %f765;
	mov.f32 	%f774, 0f3102E308;
	fma.rn.f32 	%f775, %f771, %f774, %f773;
	mul.f32 	%f776, %f775, 0f3FB8AA3B;
	add.f32 	%f777, %f771, 0f4B40007F;
	mov.b32 	%r323, %f777;
	shl.b32 	%r324, %r323, 23;
	mov.b32 	%f778, %r324;
	ex2.approx.ftz.f32 	%f779, %f776;
	mul.f32 	%f171, %f779, %f778;
	setp.lt.f32 	%p152, %f167, 0f00000000;
	and.pred  	%p5, %p152, %p147;
	add.f32 	%f780, %f167, %f167;
	selp.f32 	%f172, %f780, 0f00000000, %p147;
	div.rn.f32 	%f173, %f163, %f378;
	abs.f32 	%f174, %f173;
	setp.lt.f32 	%p153, %f174, 0f00800000;
	mul.f32 	%f782, %f174, 0f4B800000;
	selp.f32 	%f783, %f782, %f174, %p153;
	selp.f32 	%f784, 0fC3170000, 0fC2FE0000, %p153;
	mov.b32 	%r325, %f783;
	and.b32  	%r326, %r325, 8388607;
	or.b32  	%r327, %r326, 1065353216;
	mov.b32 	%f785, %r327;
	shr.u32 	%r328, %r325, 23;
	cvt.rn.f32.u32 	%f786, %r328;
	add.f32 	%f787, %f784, %f786;
	setp.gt.f32 	%p154, %f785, 0f3FB504F3;
	mul.f32 	%f788, %f785, 0f3F000000;
	add.f32 	%f789, %f787, 0f3F800000;
	selp.f32 	%f790, %f789, %f787, %p154;
	selp.f32 	%f791, %f788, %f785, %p154;
	add.f32 	%f792, %f791, 0fBF800000;
	add.f32 	%f793, %f791, 0f3F800000;
	rcp.approx.ftz.f32 	%f794, %f793;
	add.f32 	%f795, %f792, %f792;
	mul.f32 	%f796, %f795, %f794;
	mul.f32 	%f797, %f796, %f796;
	fma.rn.f32 	%f798, %f723, %f797, %f722;
	fma.rn.f32 	%f799, %f798, %f797, %f725;
	mul.rn.f32 	%f800, %f799, %f797;
	mul.rn.f32 	%f801, %f800, %f796;
	sub.f32 	%f802, %f792, %f796;
	add.f32 	%f803, %f802, %f802;
	neg.f32 	%f804, %f796;
	fma.rn.f32 	%f805, %f804, %f792, %f803;
	mul.rn.f32 	%f806, %f794, %f805;
	add.f32 	%f807, %f801, %f796;
	sub.f32 	%f808, %f796, %f807;
	add.f32 	%f809, %f801, %f808;
	add.f32 	%f810, %f806, %f809;
	add.f32 	%f811, %f807, %f810;
	sub.f32 	%f812, %f807, %f811;
	add.f32 	%f813, %f810, %f812;
	mul.rn.f32 	%f814, %f790, %f741;
	mul.rn.f32 	%f815, %f790, %f743;
	add.f32 	%f816, %f814, %f811;
	sub.f32 	%f817, %f814, %f816;
	add.f32 	%f818, %f811, %f817;
	add.f32 	%f819, %f813, %f818;
	add.f32 	%f820, %f815, %f819;
	add.f32 	%f821, %f816, %f820;
	sub.f32 	%f822, %f816, %f821;
	add.f32 	%f823, %f820, %f822;
	mul.rn.f32 	%f824, %f704, %f821;
	neg.f32 	%f825, %f824;
	fma.rn.f32 	%f826, %f704, %f821, %f825;
	fma.rn.f32 	%f827, %f704, %f823, %f826;
	fma.rn.f32 	%f828, %f1610, %f821, %f827;
	add.rn.f32 	%f829, %f824, %f828;
	neg.f32 	%f830, %f829;
	add.rn.f32 	%f831, %f824, %f830;
	add.rn.f32 	%f832, %f831, %f828;
	mov.b32 	%r329, %f829;
	setp.eq.s32 	%p155, %r329, 1118925336;
	add.s32 	%r330, %r329, -1;
	mov.b32 	%f833, %r330;
	add.f32 	%f834, %f832, 0f37000000;
	selp.f32 	%f175, %f834, %f832, %p155;
	selp.f32 	%f835, %f833, %f829, %p155;
	mul.rn.f32 	%f836, %f835, %f766;
	cvt.rzi.f32.f32 	%f837, %f836;
	abs.f32 	%f838, %f837;
	setp.gt.f32 	%p156, %f838, 0f42FC0000;
	mov.b32 	%r331, %f837;
	and.b32  	%r332, %r331, -2147483648;
	or.b32  	%r333, %r332, 1123811328;
	mov.b32 	%f839, %r333;
	selp.f32 	%f840, %f839, %f837, %p156;
	fma.rn.f32 	%f841, %f840, %f772, %f835;
	fma.rn.f32 	%f842, %f840, %f774, %f841;
	mul.f32 	%f843, %f842, 0f3FB8AA3B;
	add.f32 	%f844, %f840, 0f4B40007F;
	mov.b32 	%r334, %f844;
	shl.b32 	%r335, %r334, 23;
	mov.b32 	%f845, %r335;
	ex2.approx.ftz.f32 	%f846, %f843;
	mul.f32 	%f176, %f846, %f845;
	setp.lt.f32 	%p157, %f173, 0f00000000;
	and.pred  	%p6, %p157, %p147;
	add.f32 	%f847, %f173, %f173;
	selp.f32 	%f179, %f847, 0f00000000, %p147;
	mov.f64 	%fd215, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r336}, %fd215;
	}
	and.b32  	%r337, %r336, 2146435072;
	setp.eq.s32 	%p158, %r337, 1073741824;
	abs.f64 	%fd216, %fd35;
	{ // callseq 177, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd216;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd215;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd48, [retval0+0];
	} // callseq 177
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r75}, %fd35;
	}
	setp.lt.s32 	%p159, %r75, 0;
	and.pred  	%p7, %p159, %p158;
	selp.b32 	%r338, %r75, 0, %p158;
	setp.lt.s32 	%p160, %r336, 0;
	or.b32  	%r339, %r338, 2146435072;
	selp.b32 	%r76, %r339, %r338, %p160;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r340}, %fd36;
	}
	and.b32  	%r77, %r340, 2146435072;
	setp.ne.s32 	%p161, %r77, 2146435072;
	setp.gtu.f64 	%p162, %fd216, 0d7FF0000000000000;
	and.b32  	%r78, %r336, 2147483647;
	setp.gt.f64 	%p163, %fd216, 0d3FF0000000000000;
	selp.b32 	%r341, 2146435072, 0, %p163;
	xor.b32  	%r342, %r341, 2146435072;
	selp.b32 	%r343, %r342, %r341, %p160;
	setp.eq.f32 	%p164, %f378, 0fBF800000;
	selp.b32 	%r79, 1072693248, %r343, %p164;
	setp.gt.s32 	%p165, %r336, -1;
	selp.b32 	%r344, 2146435072, 0, %p165;
	setp.ne.s32 	%p166, %r78, 1071644672;
	and.pred  	%p167, %p166, %p7;
	or.b32  	%r345, %r344, -2147483648;
	selp.b32 	%r81, %r345, %r344, %p167;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd207;
	}
	and.b32  	%r84, %r82, 2147483647;
	setp.gt.s32 	%p168, %r82, -1;
	selp.b32 	%r85, 2146435072, 0, %p168;
	or.b32  	%r86, %r85, -2147483648;
	or.pred  	%p10, %p161, %p162;

$L__BB8_113:
	mov.u32 	%r641, 0;
	mad.lo.s32 	%r347, %r640, %r151, %r639;
	add.s32 	%r348, %r347, %r1;
	mul.wide.s32 	%rd85, %r348, 4;
	add.s64 	%rd86, %rd1, %rd85;
	ld.global.f32 	%f186, [%rd86];
	cvt.rn.f32.s32 	%f187, %r640;
	mov.f32 	%f1752, %f1781;

$L__BB8_114:
	cvt.rn.f32.s32 	%f1612, %r639;
	mul.wide.s32 	%rd87, %r641, 4;
	add.s64 	%rd88, %rd6, %rd87;
	add.s64 	%rd89, %rd7, %rd87;
	ld.local.f32 	%f189, [%rd89];
	ld.local.f32 	%f849, [%rd88];
	sub.f32 	%f190, %f1612, %f849;
	add.f32 	%f850, %f190, 0f3F000000;
	mul.f32 	%f191, %f850, %f160;
	abs.f32 	%f851, %f191;
	setp.ltu.f32 	%p169, %f851, 0f3F8060FE;
	setp.ge.f32 	%p170, %f851, 0f3F8060FE;
	mul.f32 	%f852, %f191, %f191;
	selp.f32 	%f853, %f851, %f852, %p170;
	selp.f32 	%f854, 0f3789CA3C, 0f38B1E96A, %p170;
	selp.f32 	%f855, 0fB9F560B9, 0fBA574D20, %p170;
	fma.rn.f32 	%f856, %f854, %f853, %f855;
	selp.f32 	%f857, 0f3BAC840B, 0f3BAAD5EA, %p170;
	fma.rn.f32 	%f858, %f856, %f853, %f857;
	selp.f32 	%f859, 0fBD0C8162, 0fBCDC1BE7, %p170;
	fma.rn.f32 	%f860, %f858, %f853, %f859;
	selp.f32 	%f861, 0f3E1CF906, 0f3DE718AF, %p170;
	fma.rn.f32 	%f862, %f860, %f853, %f861;
	selp.f32 	%f863, 0f3F6A937E, 0fBEC093AC, %p170;
	fma.rn.f32 	%f864, %f862, %f853, %f863;
	selp.f32 	%f865, 0f3F20D842, 0f3E0375D3, %p170;
	fma.rn.f32 	%f866, %f864, %f853, %f865;
	neg.f32 	%f867, %f851;
	selp.f32 	%f868, %f867, %f191, %p170;
	fma.rn.f32 	%f1753, %f866, %f868, %f868;
	@%p169 bra 	$L__BB8_116;

	mov.f32 	%f1663, 0f3F800000;
	ex2.approx.ftz.f32 	%f869, %f1753;
	sub.f32 	%f871, %f1663, %f869;
	mov.b32 	%r349, %f871;
	mov.b32 	%r350, %f191;
	and.b32  	%r351, %r350, -2147483648;
	or.b32  	%r352, %r351, %r349;
	mov.b32 	%f1753, %r352;

$L__BB8_116:
	add.f32 	%f872, %f190, 0fBF000000;
	mul.f32 	%f195, %f872, %f160;
	abs.f32 	%f873, %f195;
	setp.ltu.f32 	%p171, %f873, 0f3F8060FE;
	setp.ge.f32 	%p172, %f873, 0f3F8060FE;
	mul.f32 	%f874, %f195, %f195;
	selp.f32 	%f875, %f873, %f874, %p172;
	selp.f32 	%f876, 0f3789CA3C, 0f38B1E96A, %p172;
	selp.f32 	%f877, 0fB9F560B9, 0fBA574D20, %p172;
	fma.rn.f32 	%f878, %f876, %f875, %f877;
	selp.f32 	%f879, 0f3BAC840B, 0f3BAAD5EA, %p172;
	fma.rn.f32 	%f880, %f878, %f875, %f879;
	selp.f32 	%f881, 0fBD0C8162, 0fBCDC1BE7, %p172;
	fma.rn.f32 	%f882, %f880, %f875, %f881;
	selp.f32 	%f883, 0f3E1CF906, 0f3DE718AF, %p172;
	fma.rn.f32 	%f884, %f882, %f875, %f883;
	selp.f32 	%f885, 0f3F6A937E, 0fBEC093AC, %p172;
	fma.rn.f32 	%f886, %f884, %f875, %f885;
	selp.f32 	%f887, 0f3F20D842, 0f3E0375D3, %p172;
	fma.rn.f32 	%f888, %f886, %f875, %f887;
	neg.f32 	%f889, %f873;
	selp.f32 	%f890, %f889, %f195, %p172;
	fma.rn.f32 	%f1754, %f888, %f890, %f890;
	@%p171 bra 	$L__BB8_118;

	mov.f32 	%f1662, 0f3F800000;
	ex2.approx.ftz.f32 	%f891, %f1754;
	sub.f32 	%f893, %f1662, %f891;
	mov.b32 	%r353, %f893;
	mov.b32 	%r354, %f195;
	and.b32  	%r355, %r354, -2147483648;
	or.b32  	%r356, %r355, %r353;
	mov.b32 	%f1754, %r356;

$L__BB8_118:
	sub.f32 	%f199, %f1753, %f1754;
	sub.f32 	%f200, %f187, %f189;
	add.f32 	%f894, %f200, 0f3F000000;
	mul.f32 	%f201, %f894, %f160;
	abs.f32 	%f895, %f201;
	setp.ltu.f32 	%p173, %f895, 0f3F8060FE;
	setp.ge.f32 	%p174, %f895, 0f3F8060FE;
	mul.f32 	%f896, %f201, %f201;
	selp.f32 	%f897, %f895, %f896, %p174;
	selp.f32 	%f898, 0f3789CA3C, 0f38B1E96A, %p174;
	selp.f32 	%f899, 0fB9F560B9, 0fBA574D20, %p174;
	fma.rn.f32 	%f900, %f898, %f897, %f899;
	selp.f32 	%f901, 0f3BAC840B, 0f3BAAD5EA, %p174;
	fma.rn.f32 	%f902, %f900, %f897, %f901;
	selp.f32 	%f903, 0fBD0C8162, 0fBCDC1BE7, %p174;
	fma.rn.f32 	%f904, %f902, %f897, %f903;
	selp.f32 	%f905, 0f3E1CF906, 0f3DE718AF, %p174;
	fma.rn.f32 	%f906, %f904, %f897, %f905;
	selp.f32 	%f907, 0f3F6A937E, 0fBEC093AC, %p174;
	fma.rn.f32 	%f908, %f906, %f897, %f907;
	selp.f32 	%f909, 0f3F20D842, 0f3E0375D3, %p174;
	fma.rn.f32 	%f910, %f908, %f897, %f909;
	neg.f32 	%f911, %f895;
	selp.f32 	%f912, %f911, %f201, %p174;
	fma.rn.f32 	%f1755, %f910, %f912, %f912;
	@%p173 bra 	$L__BB8_120;

	mov.f32 	%f1661, 0f3F800000;
	ex2.approx.ftz.f32 	%f913, %f1755;
	sub.f32 	%f915, %f1661, %f913;
	mov.b32 	%r357, %f915;
	mov.b32 	%r358, %f201;
	and.b32  	%r359, %r358, -2147483648;
	or.b32  	%r360, %r359, %r357;
	mov.b32 	%f1755, %r360;

$L__BB8_120:
	add.f32 	%f916, %f200, 0fBF000000;
	mul.f32 	%f205, %f916, %f160;
	abs.f32 	%f917, %f205;
	setp.ltu.f32 	%p175, %f917, 0f3F8060FE;
	setp.ge.f32 	%p176, %f917, 0f3F8060FE;
	mul.f32 	%f918, %f205, %f205;
	selp.f32 	%f919, %f917, %f918, %p176;
	selp.f32 	%f920, 0f3789CA3C, 0f38B1E96A, %p176;
	selp.f32 	%f921, 0fB9F560B9, 0fBA574D20, %p176;
	fma.rn.f32 	%f922, %f920, %f919, %f921;
	selp.f32 	%f923, 0f3BAC840B, 0f3BAAD5EA, %p176;
	fma.rn.f32 	%f924, %f922, %f919, %f923;
	selp.f32 	%f925, 0fBD0C8162, 0fBCDC1BE7, %p176;
	fma.rn.f32 	%f926, %f924, %f919, %f925;
	selp.f32 	%f927, 0f3E1CF906, 0f3DE718AF, %p176;
	fma.rn.f32 	%f928, %f926, %f919, %f927;
	selp.f32 	%f929, 0f3F6A937E, 0fBEC093AC, %p176;
	fma.rn.f32 	%f930, %f928, %f919, %f929;
	selp.f32 	%f931, 0f3F20D842, 0f3E0375D3, %p176;
	fma.rn.f32 	%f932, %f930, %f919, %f931;
	neg.f32 	%f933, %f917;
	selp.f32 	%f934, %f933, %f205, %p176;
	fma.rn.f32 	%f1756, %f932, %f934, %f934;
	@%p175 bra 	$L__BB8_122;

	mov.f32 	%f1660, 0f3F800000;
	ex2.approx.ftz.f32 	%f935, %f1756;
	sub.f32 	%f937, %f1660, %f935;
	mov.b32 	%r361, %f937;
	mov.b32 	%r362, %f205;
	and.b32  	%r363, %r362, -2147483648;
	or.b32  	%r364, %r363, %r361;
	mov.b32 	%f1756, %r364;

$L__BB8_122:
	sub.f32 	%f938, %f1755, %f1756;
	mul.f32 	%f939, %f938, 0f3F000000;
	mul.f32 	%f940, %f199, 0f3F000000;
	mul.f32 	%f941, %f940, %f379;
	fma.rn.f32 	%f1752, %f941, %f939, %f1752;
	add.s32 	%r641, %r641, 1;
	setp.lt.u32 	%p177, %r641, %r628;
	@%p177 bra 	$L__BB8_114;

	setp.leu.f32 	%p178, %f1752, 0f3C23D70A;
	mov.f32 	%f1758, 0f00000000;
	mov.f32 	%f1757, %f1758;
	@%p178 bra 	$L__BB8_125;

	div.rn.f32 	%f943, %f186, %f1752;
	add.f32 	%f1757, %f943, 0fBF800000;

$L__BB8_125:
	@%p178 bra 	$L__BB8_140;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r609}, %fd207;
	}
	and.b32  	%r608, %r609, 2146435072;
	setp.eq.s32 	%p180, %r608, 1062207488;
	cvt.f64.f32 	%fd49, %f1752;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd49;
	}
	abs.f64 	%fd50, %fd49;
	{ // callseq 178, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd50;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd207;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd383, [retval0+0];
	} // callseq 178
	setp.lt.s32 	%p181, %r90, 0;
	and.pred  	%p11, %p181, %p180;
	not.pred 	%p182, %p11;
	@%p182 bra 	$L__BB8_128;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r365}, %fd383;
	}
	xor.b32  	%r366, %r365, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r367, %temp}, %fd383;
	}
	mov.b64 	%fd383, {%r367, %r366};

$L__BB8_128:
	setp.eq.f32 	%p183, %f1752, 0f00000000;
	@%p183 bra 	$L__BB8_132;
	bra.uni 	$L__BB8_129;

$L__BB8_132:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r611}, %fd207;
	}
	setp.lt.s32 	%p186, %r611, 0;
	mov.u32 	%r368, 0;
	selp.b32 	%r369, %r90, 0, %p180;
	or.b32  	%r370, %r369, 2146435072;
	selp.b32 	%r371, %r370, %r369, %p186;
	mov.b64 	%fd383, {%r368, %r371};
	bra.uni 	$L__BB8_133;

$L__BB8_129:
	setp.gt.s32 	%p184, %r90, -1;
	@%p184 bra 	$L__BB8_133;

	cvt.rzi.f64.f64 	%fd220, %fd207;
	setp.eq.f64 	%p185, %fd220, 0d4000000000000000;
	@%p185 bra 	$L__BB8_133;

	mov.f64 	%fd383, 0dFFF8000000000000;

$L__BB8_133:
	add.f64 	%fd56, %fd49, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r372}, %fd56;
	}
	and.b32  	%r373, %r372, 2146435072;
	setp.ne.s32 	%p188, %r373, 2146435072;
	mov.f64 	%fd384, %fd383;
	@%p188 bra 	$L__BB8_139;

	setp.gtu.f64 	%p189, %fd50, 0d7FF0000000000000;
	mov.f64 	%fd384, %fd56;
	@%p189 bra 	$L__BB8_139;

	setp.eq.s32 	%p190, %r84, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r374, %temp}, %fd207;
	}
	setp.eq.s32 	%p191, %r374, 0;
	and.pred  	%p192, %p190, %p191;
	@%p192 bra 	$L__BB8_138;
	bra.uni 	$L__BB8_136;

$L__BB8_138:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r610}, %fd207;
	}
	setp.lt.s32 	%p198, %r610, 0;
	mov.u32 	%r379, 0;
	setp.gt.f64 	%p199, %fd50, 0d3FF0000000000000;
	selp.b32 	%r380, 2146435072, 0, %p199;
	xor.b32  	%r381, %r380, 2146435072;
	selp.b32 	%r382, %r381, %r380, %p198;
	setp.eq.f32 	%p200, %f1752, 0fBF800000;
	selp.b32 	%r383, 1072693248, %r382, %p200;
	mov.b64 	%fd384, {%r379, %r383};
	bra.uni 	$L__BB8_139;

$L__BB8_136:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r375, %temp}, %fd49;
	}
	and.b32  	%r376, %r90, 2147483647;
	setp.ne.s32 	%p193, %r376, 2146435072;
	setp.ne.s32 	%p194, %r375, 0;
	or.pred  	%p195, %p193, %p194;
	mov.f64 	%fd384, %fd383;
	@%p195 bra 	$L__BB8_139;

	setp.ne.s32 	%p196, %r84, 1071644672;
	and.pred  	%p197, %p196, %p11;
	selp.b32 	%r377, %r86, %r85, %p197;
	mov.u32 	%r378, 0;
	mov.b64 	%fd384, {%r378, %r377};

$L__BB8_139:
	setp.eq.f32 	%p201, %f1752, 0f3F800000;
	selp.f64 	%fd223, 0d3FF0000000000000, %fd384, %p201;
	cvt.f64.f32 	%fd224, %f186;
	div.rn.f64 	%fd225, %fd224, %fd223;
	cvt.rn.f32.f64 	%f1758, %fd225;

$L__BB8_140:
	cvt.rn.f32.s32 	%f1617, %r639;
	sub.f32 	%f1616, %f1617, %f1774;
	add.f32 	%f1615, %f1616, 0f3F000000;
	mul.f32 	%f1614, %f1615, %f160;
	abs.f32 	%f1613, %f1614;
	mov.f32 	%f945, 0f47C35000;
	min.f32 	%f214, %f1757, %f945;
	setp.ltu.f32 	%p202, %f1613, 0f3F8060FE;
	mov.f32 	%f1759, %f162;
	@%p202 bra 	$L__BB8_142;

	mov.f32 	%f1659, 0f3F800000;
	ex2.approx.ftz.f32 	%f946, %f162;
	sub.f32 	%f948, %f1659, %f946;
	mov.b32 	%r384, %f948;
	or.b32  	%r385, %r71, %r384;
	mov.b32 	%f1759, %r385;

$L__BB8_142:
	cvt.rn.f32.s32 	%f1622, %r639;
	sub.f32 	%f1621, %f1622, %f1774;
	add.f32 	%f1620, %f1621, 0fBF000000;
	mul.f32 	%f1619, %f1620, %f160;
	abs.f32 	%f1618, %f1619;
	setp.ltu.f32 	%p203, %f1618, 0f3F8060FE;
	mov.f32 	%f1760, %f165;
	@%p203 bra 	$L__BB8_144;

	mov.f32 	%f1658, 0f3F800000;
	ex2.approx.ftz.f32 	%f949, %f165;
	sub.f32 	%f951, %f1658, %f949;
	mov.b32 	%r386, %f951;
	or.b32  	%r387, %r72, %r386;
	mov.b32 	%f1760, %r387;

$L__BB8_144:
	sub.f32 	%f219, %f1759, %f1760;
	sub.f32 	%f220, %f187, %f1773;
	add.f32 	%f952, %f220, 0f3F000000;
	mul.f32 	%f221, %f952, %f160;
	abs.f32 	%f953, %f221;
	setp.ltu.f32 	%p204, %f953, 0f3F8060FE;
	setp.ge.f32 	%p205, %f953, 0f3F8060FE;
	mul.f32 	%f954, %f221, %f221;
	selp.f32 	%f955, %f953, %f954, %p205;
	selp.f32 	%f956, 0f3789CA3C, 0f38B1E96A, %p205;
	selp.f32 	%f957, 0fB9F560B9, 0fBA574D20, %p205;
	fma.rn.f32 	%f958, %f956, %f955, %f957;
	selp.f32 	%f959, 0f3BAC840B, 0f3BAAD5EA, %p205;
	fma.rn.f32 	%f960, %f958, %f955, %f959;
	selp.f32 	%f961, 0fBD0C8162, 0fBCDC1BE7, %p205;
	fma.rn.f32 	%f962, %f960, %f955, %f961;
	selp.f32 	%f963, 0f3E1CF906, 0f3DE718AF, %p205;
	fma.rn.f32 	%f964, %f962, %f955, %f963;
	selp.f32 	%f965, 0f3F6A937E, 0fBEC093AC, %p205;
	fma.rn.f32 	%f966, %f964, %f955, %f965;
	selp.f32 	%f967, 0f3F20D842, 0f3E0375D3, %p205;
	fma.rn.f32 	%f968, %f966, %f955, %f967;
	neg.f32 	%f969, %f953;
	selp.f32 	%f970, %f969, %f221, %p205;
	fma.rn.f32 	%f1761, %f968, %f970, %f970;
	@%p204 bra 	$L__BB8_146;

	mov.f32 	%f1657, 0f3F800000;
	ex2.approx.ftz.f32 	%f971, %f1761;
	sub.f32 	%f973, %f1657, %f971;
	mov.b32 	%r388, %f973;
	mov.b32 	%r389, %f221;
	and.b32  	%r390, %r389, -2147483648;
	or.b32  	%r391, %r390, %r388;
	mov.b32 	%f1761, %r391;

$L__BB8_146:
	cvt.rn.f32.s32 	%f1624, %r640;
	sub.f32 	%f1623, %f1624, %f1773;
	add.f32 	%f225, %f1623, 0fBF000000;
	mul.f32 	%f226, %f225, %f160;
	abs.f32 	%f974, %f226;
	setp.ltu.f32 	%p206, %f974, 0f3F8060FE;
	setp.ge.f32 	%p207, %f974, 0f3F8060FE;
	mul.f32 	%f975, %f226, %f226;
	selp.f32 	%f976, %f974, %f975, %p207;
	selp.f32 	%f977, 0f3789CA3C, 0f38B1E96A, %p207;
	selp.f32 	%f978, 0fB9F560B9, 0fBA574D20, %p207;
	fma.rn.f32 	%f979, %f977, %f976, %f978;
	selp.f32 	%f980, 0f3BAC840B, 0f3BAAD5EA, %p207;
	fma.rn.f32 	%f981, %f979, %f976, %f980;
	selp.f32 	%f982, 0fBD0C8162, 0fBCDC1BE7, %p207;
	fma.rn.f32 	%f983, %f981, %f976, %f982;
	selp.f32 	%f984, 0f3E1CF906, 0f3DE718AF, %p207;
	fma.rn.f32 	%f985, %f983, %f976, %f984;
	selp.f32 	%f986, 0f3F6A937E, 0fBEC093AC, %p207;
	fma.rn.f32 	%f987, %f985, %f976, %f986;
	selp.f32 	%f988, 0f3F20D842, 0f3E0375D3, %p207;
	fma.rn.f32 	%f989, %f987, %f976, %f988;
	neg.f32 	%f990, %f974;
	selp.f32 	%f991, %f990, %f226, %p207;
	fma.rn.f32 	%f1762, %f989, %f991, %f991;
	@%p206 bra 	$L__BB8_148;

	mov.f32 	%f1656, 0f3F800000;
	ex2.approx.ftz.f32 	%f992, %f1762;
	sub.f32 	%f994, %f1656, %f992;
	mov.b32 	%r392, %f994;
	mov.b32 	%r393, %f226;
	and.b32  	%r394, %r393, -2147483648;
	or.b32  	%r395, %r394, %r392;
	mov.b32 	%f1762, %r395;

$L__BB8_148:
	sub.f32 	%f996, %f1761, %f1762;
	mul.f32 	%f230, %f996, 0f3F000000;
	setp.eq.f32 	%p208, %f171, 0f7F800000;
	mov.f32 	%f1763, 0f7F800000;
	@%p208 bra 	$L__BB8_150;

	fma.rn.f32 	%f1763, %f171, %f170, %f171;

$L__BB8_150:
	setp.geu.f32 	%p405, %f167, 0f00000000;
	mov.b32 	%r396, %f1763;
	xor.b32  	%r397, %r396, -2147483648;
	mov.b32 	%f997, %r397;
	selp.f32 	%f233, %f997, %f1763, %p5;
	setp.eq.f32 	%p209, %f167, 0f00000000;
	selp.f32 	%f1764, %f172, %f233, %p209;
	@%p405 bra 	$L__BB8_153;

	mov.f32 	%f1625, 0f40000000;
	cvt.rzi.f32.f32 	%f999, %f1625;
	setp.eq.f32 	%p210, %f999, 0f40000000;
	mov.f32 	%f1764, %f233;
	@%p210 bra 	$L__BB8_153;

	mov.f32 	%f1764, 0f7FFFFFFF;

$L__BB8_153:
	abs.f32 	%f1630, %f167;
	mov.f32 	%f1629, 0f3FB8AA3B;
	add.f32 	%f1628, %f1630, 0f40000000;
	mov.b32 	%r599, %f1628;
	selp.f32 	%f1627, 0fFF800000, 0f7F800000, %p5;
	add.f32 	%f1626, %f167, 0f40000000;
	setp.gtu.f32 	%p211, %f1630, 0f7F800000;
	mov.f32 	%f1765, 0f7F800000;
	selp.f32 	%f1002, %f1626, %f1764, %p211;
	setp.neu.f32 	%p212, %f1630, 0f7F800000;
	selp.f32 	%f1003, %f1002, %f1627, %p212;
	setp.gt.s32 	%p213, %r599, 2139095039;
	selp.f32 	%f1004, %f1003, %f1764, %p213;
	mul.f32 	%f1005, %f1004, 0fBF000000;
	setp.eq.f32 	%p214, %f167, 0f3F800000;
	selp.f32 	%f1006, 0fBF000000, %f1005, %p214;
	mov.f32 	%f1008, 0f3BBB989D;
	fma.rn.f32 	%f1009, %f1006, %f1008, %f413;
	mov.f32 	%f1011, 0f437C0000;
	cvt.sat.f32.f32 	%f1012, %f1009;
	mov.f32 	%f1013, 0f4B400001;
	fma.rm.f32 	%f1014, %f1012, %f1011, %f1013;
	add.f32 	%f1015, %f1014, 0fCB40007F;
	neg.f32 	%f1016, %f1015;
	fma.rn.f32 	%f1017, %f1006, %f1629, %f1016;
	mov.f32 	%f1018, 0f32A57060;
	fma.rn.f32 	%f1019, %f1006, %f1018, %f1017;
	mov.b32 	%r398, %f1014;
	shl.b32 	%r399, %r398, 23;
	mov.b32 	%f1020, %r399;
	ex2.approx.ftz.f32 	%f1021, %f1019;
	mul.f32 	%f236, %f1021, %f1020;
	setp.eq.f32 	%p215, %f176, 0f7F800000;
	@%p215 bra 	$L__BB8_155;

	fma.rn.f32 	%f1765, %f176, %f175, %f176;

$L__BB8_155:
	setp.geu.f32 	%p406, %f173, 0f00000000;
	mov.b32 	%r400, %f1765;
	xor.b32  	%r401, %r400, -2147483648;
	mov.b32 	%f1022, %r401;
	selp.f32 	%f239, %f1022, %f1765, %p6;
	setp.eq.f32 	%p216, %f173, 0f00000000;
	selp.f32 	%f1766, %f179, %f239, %p216;
	@%p406 bra 	$L__BB8_158;

	mov.f32 	%f1631, 0f40000000;
	cvt.rzi.f32.f32 	%f1024, %f1631;
	setp.eq.f32 	%p217, %f1024, 0f40000000;
	mov.f32 	%f1766, %f239;
	@%p217 bra 	$L__BB8_158;

	mov.f32 	%f1766, 0f7FFFFFFF;

$L__BB8_158:
	abs.f32 	%f1640, %f173;
	mov.f32 	%f1639, 0f32A57060;
	mov.f32 	%f1638, 0f4B400001;
	mov.f32 	%f1637, 0f437C0000;
	mov.f32 	%f1636, 0f3BBB989D;
	add.f32 	%f1635, %f1640, 0f40000000;
	mov.b32 	%r600, %f1635;
	selp.f32 	%f1634, 0fFF800000, 0f7F800000, %p6;
	add.f32 	%f1633, %f173, 0f40000000;
	mov.f32 	%f1632, 0f3FB8AA3B;
	setp.gtu.f32 	%p218, %f1640, 0f7F800000;
	selp.f32 	%f1026, %f1633, %f1766, %p218;
	setp.neu.f32 	%p219, %f1640, 0f7F800000;
	selp.f32 	%f1027, %f1026, %f1634, %p219;
	setp.gt.s32 	%p220, %r600, 2139095039;
	selp.f32 	%f1028, %f1027, %f1766, %p220;
	mul.f32 	%f1029, %f1028, 0fBF000000;
	setp.eq.f32 	%p221, %f173, 0f3F800000;
	selp.f32 	%f1030, 0fBF000000, %f1029, %p221;
	fma.rn.f32 	%f1033, %f1030, %f1636, %f413;
	cvt.sat.f32.f32 	%f1036, %f1033;
	fma.rm.f32 	%f1038, %f1036, %f1637, %f1638;
	add.f32 	%f1039, %f1038, 0fCB40007F;
	neg.f32 	%f1040, %f1039;
	fma.rn.f32 	%f1041, %f1030, %f1632, %f1040;
	fma.rn.f32 	%f1043, %f1030, %f1639, %f1041;
	mov.b32 	%r402, %f1038;
	shl.b32 	%r403, %r402, 23;
	mov.b32 	%f1044, %r403;
	ex2.approx.ftz.f32 	%f1045, %f1043;
	mul.f32 	%f242, %f1045, %f1044;
	sub.f32 	%f1046, %f236, %f242;
	mul.f32 	%f1047, %f49, %f1046;
	mul.f32 	%f243, %f230, %f1047;
	not.pred 	%p222, %p7;
	mov.f64 	%fd386, %fd48;
	@%p222 bra 	$L__BB8_160;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r404}, %fd48;
	}
	xor.b32  	%r405, %r404, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r406, %temp}, %fd48;
	}
	mov.b64 	%fd386, {%r406, %r405};

$L__BB8_160:
	setp.eq.f32 	%p223, %f378, 0f00000000;
	@%p223 bra 	$L__BB8_164;
	bra.uni 	$L__BB8_161;

$L__BB8_164:
	mov.u32 	%r407, 0;
	mov.b64 	%fd386, {%r407, %r76};
	bra.uni 	$L__BB8_165;

$L__BB8_161:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r601}, %fd35;
	}
	setp.gt.s32 	%p224, %r601, -1;
	@%p224 bra 	$L__BB8_165;

	mov.f64 	%fd347, 0d4008000000000000;
	cvt.rzi.f64.f64 	%fd227, %fd347;
	setp.eq.f64 	%p225, %fd227, 0d4008000000000000;
	@%p225 bra 	$L__BB8_165;

	mov.f64 	%fd386, 0dFFF8000000000000;

$L__BB8_165:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r603}, %fd36;
	}
	and.b32  	%r602, %r603, 2146435072;
	setp.ne.s32 	%p407, %r602, 2146435072;
	selp.f64 	%fd387, %fd386, %fd36, %p407;
	@%p10 bra 	$L__BB8_170;

	mov.f64 	%fd346, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r605}, %fd346;
	}
	and.b32  	%r604, %r605, 2147483647;
	setp.eq.s32 	%p227, %r604, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r408, %temp}, %fd346;
	}
	setp.eq.s32 	%p228, %r408, 0;
	and.pred  	%p229, %p227, %p228;
	@%p229 bra 	$L__BB8_169;
	bra.uni 	$L__BB8_167;

$L__BB8_169:
	mov.u32 	%r411, 0;
	mov.b64 	%fd387, {%r411, %r79};
	bra.uni 	$L__BB8_170;

$L__BB8_167:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r607}, %fd35;
	}
	and.b32  	%r606, %r607, 2147483647;
	setp.ne.s32 	%p230, %r606, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r409, %temp}, %fd35;
	}
	setp.ne.s32 	%p231, %r409, 0;
	or.pred  	%p232, %p230, %p231;
	mov.f64 	%fd387, %fd386;
	@%p232 bra 	$L__BB8_170;

	mov.u32 	%r410, 0;
	mov.b64 	%fd387, {%r410, %r81};

$L__BB8_170:
	cvt.rn.f32.s32 	%f1655, %r639;
	cvt.rn.f32.s32 	%f1654, %r640;
	mov.f32 	%f1653, 0f3102E308;
	mov.f32 	%f1652, 0fBF317218;
	mov.f32 	%f1651, 0f35BFBE8E;
	mov.f32 	%f1650, 0f3F317200;
	mov.f32 	%f1649, 0f3DAAAABD;
	mov.f32 	%f1648, 0f3C4CAF63;
	mov.f32 	%f1647, 0f3B18F0FE;
	add.f32 	%f1646, %f1655, 0f3F000000;
	sub.f32 	%f1645, %f1646, %f1774;
	sub.f32 	%f1644, %f1655, %f1774;
	add.f32 	%f1643, %f1644, 0fBF000000;
	mov.f32 	%f1642, 0f3FB8AA3B;
	mov.f32 	%f1641, 0f40000000;
	mul.f32 	%f244, %f219, 0f3F000000;
	setp.eq.f32 	%p233, %f378, 0f3F800000;
	selp.f64 	%fd230, 0d3FF0000000000000, %fd387, %p233;
	div.rn.f64 	%fd68, %fd34, %fd230;
	mul.f32 	%f1049, %f1643, %f242;
	mul.f32 	%f1050, %f1645, %f236;
	sub.f32 	%f1051, %f1050, %f1049;
	cvt.f64.f32 	%fd231, %f1051;
	mul.f64 	%fd232, %fd68, %fd231;
	cvt.f64.f32 	%fd233, %f230;
	mul.f64 	%fd234, %fd232, %fd233;
	cvt.rn.f32.f64 	%f245, %fd234;
	add.f32 	%f1052, %f1654, 0f3F000000;
	sub.f32 	%f246, %f1052, %f1773;
	div.rn.f32 	%f247, %f246, %f378;
	abs.f32 	%f248, %f247;
	setp.lt.f32 	%p234, %f248, 0f00800000;
	mul.f32 	%f1053, %f248, 0f4B800000;
	selp.f32 	%f1054, %f1053, %f248, %p234;
	selp.f32 	%f1055, 0fC3170000, 0fC2FE0000, %p234;
	mov.b32 	%r412, %f1054;
	and.b32  	%r413, %r412, 8388607;
	or.b32  	%r414, %r413, 1065353216;
	mov.b32 	%f1056, %r414;
	shr.u32 	%r415, %r412, 23;
	cvt.rn.f32.u32 	%f1057, %r415;
	add.f32 	%f1058, %f1055, %f1057;
	setp.gt.f32 	%p235, %f1056, 0f3FB504F3;
	mul.f32 	%f1059, %f1056, 0f3F000000;
	add.f32 	%f1060, %f1058, 0f3F800000;
	selp.f32 	%f1061, %f1060, %f1058, %p235;
	selp.f32 	%f1062, %f1059, %f1056, %p235;
	add.f32 	%f1063, %f1062, 0fBF800000;
	add.f32 	%f1064, %f1062, 0f3F800000;
	rcp.approx.ftz.f32 	%f1065, %f1064;
	add.f32 	%f1066, %f1063, %f1063;
	mul.f32 	%f1068, %f1066, %f1065;
	mul.f32 	%f1069, %f1068, %f1068;
	fma.rn.f32 	%f1072, %f1647, %f1069, %f1648;
	fma.rn.f32 	%f1074, %f1072, %f1069, %f1649;
	mul.rn.f32 	%f1075, %f1074, %f1069;
	mul.rn.f32 	%f1076, %f1075, %f1068;
	sub.f32 	%f1077, %f1063, %f1068;
	add.f32 	%f1078, %f1077, %f1077;
	neg.f32 	%f1079, %f1068;
	fma.rn.f32 	%f1080, %f1079, %f1063, %f1078;
	mul.rn.f32 	%f1081, %f1065, %f1080;
	add.f32 	%f1082, %f1076, %f1068;
	sub.f32 	%f1083, %f1068, %f1082;
	add.f32 	%f1084, %f1076, %f1083;
	add.f32 	%f1085, %f1081, %f1084;
	add.f32 	%f1086, %f1082, %f1085;
	sub.f32 	%f1087, %f1082, %f1086;
	add.f32 	%f1088, %f1085, %f1087;
	mul.rn.f32 	%f1090, %f1061, %f1650;
	mul.rn.f32 	%f1092, %f1061, %f1651;
	add.f32 	%f1093, %f1090, %f1086;
	sub.f32 	%f1094, %f1090, %f1093;
	add.f32 	%f1095, %f1086, %f1094;
	add.f32 	%f1096, %f1088, %f1095;
	add.f32 	%f1097, %f1092, %f1096;
	add.f32 	%f1098, %f1093, %f1097;
	sub.f32 	%f1099, %f1093, %f1098;
	add.f32 	%f1100, %f1097, %f1099;
	mul.rn.f32 	%f1101, %f1641, %f1098;
	neg.f32 	%f1102, %f1101;
	fma.rn.f32 	%f1103, %f1641, %f1098, %f1102;
	fma.rn.f32 	%f1104, %f1641, %f1100, %f1103;
	mov.f32 	%f1105, 0f00000000;
	fma.rn.f32 	%f1106, %f1105, %f1098, %f1104;
	add.rn.f32 	%f1107, %f1101, %f1106;
	neg.f32 	%f1108, %f1107;
	add.rn.f32 	%f1109, %f1101, %f1108;
	add.rn.f32 	%f1110, %f1109, %f1106;
	mov.b32 	%r416, %f1107;
	setp.eq.s32 	%p236, %r416, 1118925336;
	add.s32 	%r417, %r416, -1;
	mov.b32 	%f1111, %r417;
	add.f32 	%f1112, %f1110, 0f37000000;
	selp.f32 	%f249, %f1112, %f1110, %p236;
	selp.f32 	%f1113, %f1111, %f1107, %p236;
	mul.rn.f32 	%f1115, %f1113, %f1642;
	cvt.rzi.f32.f32 	%f1116, %f1115;
	abs.f32 	%f1117, %f1116;
	setp.gt.f32 	%p237, %f1117, 0f42FC0000;
	mov.b32 	%r418, %f1116;
	and.b32  	%r419, %r418, -2147483648;
	or.b32  	%r420, %r419, 1123811328;
	mov.b32 	%f1118, %r420;
	selp.f32 	%f1119, %f1118, %f1116, %p237;
	fma.rn.f32 	%f1121, %f1119, %f1652, %f1113;
	fma.rn.f32 	%f1123, %f1119, %f1653, %f1121;
	mul.f32 	%f1124, %f1123, 0f3FB8AA3B;
	add.f32 	%f1125, %f1119, 0f4B40007F;
	mov.b32 	%r421, %f1125;
	shl.b32 	%r422, %r421, 23;
	mov.b32 	%f1126, %r422;
	ex2.approx.ftz.f32 	%f1127, %f1124;
	mul.f32 	%f250, %f1127, %f1126;
	setp.eq.f32 	%p238, %f250, 0f7F800000;
	mov.f32 	%f1767, 0f7F800000;
	@%p238 bra 	$L__BB8_172;

	fma.rn.f32 	%f1767, %f250, %f249, %f250;

$L__BB8_172:
	setp.lt.f32 	%p239, %f247, 0f00000000;
	and.pred  	%p12, %p239, %p147;
	setp.eq.f32 	%p241, %f247, 0f00000000;
	@%p241 bra 	$L__BB8_176;
	bra.uni 	$L__BB8_173;

$L__BB8_176:
	add.f32 	%f1132, %f247, %f247;
	selp.f32 	%f1769, %f1132, 0f00000000, %p147;
	bra.uni 	$L__BB8_177;

$L__BB8_173:
	mov.b32 	%r423, %f1767;
	xor.b32  	%r424, %r423, -2147483648;
	mov.b32 	%f1128, %r424;
	selp.f32 	%f1769, %f1128, %f1767, %p12;
	setp.geu.f32 	%p242, %f247, 0f00000000;
	@%p242 bra 	$L__BB8_177;

	mov.f32 	%f1667, 0f40000000;
	cvt.rzi.f32.f32 	%f1130, %f1667;
	setp.eq.f32 	%p243, %f1130, 0f40000000;
	@%p243 bra 	$L__BB8_177;

	mov.f32 	%f1769, 0f7FFFFFFF;

$L__BB8_177:
	abs.f32 	%f1573, %f247;
	add.f32 	%f1133, %f1573, 0f40000000;
	mov.b32 	%r425, %f1133;
	setp.lt.s32 	%p245, %r425, 2139095040;
	@%p245 bra 	$L__BB8_182;

	abs.f32 	%f1665, %f247;
	setp.gtu.f32 	%p246, %f1665, 0f7F800000;
	@%p246 bra 	$L__BB8_181;
	bra.uni 	$L__BB8_179;

$L__BB8_181:
	add.f32 	%f1769, %f247, 0f40000000;
	bra.uni 	$L__BB8_182;

$L__BB8_179:
	abs.f32 	%f1666, %f247;
	setp.neu.f32 	%p247, %f1666, 0f7F800000;
	@%p247 bra 	$L__BB8_182;

	selp.f32 	%f1769, 0fFF800000, 0f7F800000, %p12;

$L__BB8_182:
	mov.f32 	%f1590, 0f00000000;
	cvt.rn.f32.s32 	%f1589, %r640;
	sub.f32 	%f1588, %f1589, %f1773;
	add.f32 	%f1587, %f1588, 0fBF000000;
	mov.f32 	%f1586, 0f3102E308;
	mov.f32 	%f1585, 0fBF317218;
	mov.f32 	%f1584, 0f35BFBE8E;
	mov.f32 	%f1583, 0f3F317200;
	mov.f32 	%f1582, 0f3DAAAABD;
	mov.f32 	%f1581, 0f3C4CAF63;
	mov.f32 	%f1580, 0f3B18F0FE;
	mov.f32 	%f1579, 0f32A57060;
	mov.f32 	%f1578, 0f4B400001;
	mov.f32 	%f1577, 0f437C0000;
	mov.f32 	%f1576, 0f3BBB989D;
	mov.f32 	%f1575, 0f3FB8AA3B;
	mov.f32 	%f1574, 0f40000000;
	mul.f32 	%f1135, %f1769, 0fBF000000;
	setp.eq.f32 	%p248, %f247, 0f3F800000;
	selp.f32 	%f1136, 0fBF000000, %f1135, %p248;
	fma.rn.f32 	%f1139, %f1136, %f1576, %f413;
	cvt.sat.f32.f32 	%f1142, %f1139;
	fma.rm.f32 	%f1144, %f1142, %f1577, %f1578;
	add.f32 	%f1145, %f1144, 0fCB40007F;
	neg.f32 	%f1146, %f1145;
	fma.rn.f32 	%f1147, %f1136, %f1575, %f1146;
	fma.rn.f32 	%f1149, %f1136, %f1579, %f1147;
	mov.b32 	%r426, %f1144;
	shl.b32 	%r427, %r426, 23;
	mov.b32 	%f1150, %r427;
	ex2.approx.ftz.f32 	%f1151, %f1149;
	mul.f32 	%f259, %f1151, %f1150;
	div.rn.f32 	%f260, %f1587, %f378;
	abs.f32 	%f261, %f260;
	setp.lt.f32 	%p249, %f261, 0f00800000;
	mul.f32 	%f1152, %f261, 0f4B800000;
	selp.f32 	%f1153, %f1152, %f261, %p249;
	selp.f32 	%f1154, 0fC3170000, 0fC2FE0000, %p249;
	mov.b32 	%r428, %f1153;
	and.b32  	%r429, %r428, 8388607;
	or.b32  	%r430, %r429, 1065353216;
	mov.b32 	%f1155, %r430;
	shr.u32 	%r431, %r428, 23;
	cvt.rn.f32.u32 	%f1156, %r431;
	add.f32 	%f1157, %f1154, %f1156;
	setp.gt.f32 	%p250, %f1155, 0f3FB504F3;
	mul.f32 	%f1158, %f1155, 0f3F000000;
	add.f32 	%f1159, %f1157, 0f3F800000;
	selp.f32 	%f1160, %f1159, %f1157, %p250;
	selp.f32 	%f1161, %f1158, %f1155, %p250;
	add.f32 	%f1162, %f1161, 0fBF800000;
	add.f32 	%f1163, %f1161, 0f3F800000;
	rcp.approx.ftz.f32 	%f1164, %f1163;
	add.f32 	%f1165, %f1162, %f1162;
	mul.f32 	%f1167, %f1165, %f1164;
	mul.f32 	%f1168, %f1167, %f1167;
	fma.rn.f32 	%f1171, %f1580, %f1168, %f1581;
	fma.rn.f32 	%f1173, %f1171, %f1168, %f1582;
	mul.rn.f32 	%f1174, %f1173, %f1168;
	mul.rn.f32 	%f1175, %f1174, %f1167;
	sub.f32 	%f1176, %f1162, %f1167;
	add.f32 	%f1177, %f1176, %f1176;
	neg.f32 	%f1178, %f1167;
	fma.rn.f32 	%f1179, %f1178, %f1162, %f1177;
	mul.rn.f32 	%f1180, %f1164, %f1179;
	add.f32 	%f1181, %f1175, %f1167;
	sub.f32 	%f1182, %f1167, %f1181;
	add.f32 	%f1183, %f1175, %f1182;
	add.f32 	%f1184, %f1180, %f1183;
	add.f32 	%f1185, %f1181, %f1184;
	sub.f32 	%f1186, %f1181, %f1185;
	add.f32 	%f1187, %f1184, %f1186;
	mul.rn.f32 	%f1189, %f1160, %f1583;
	mul.rn.f32 	%f1191, %f1160, %f1584;
	add.f32 	%f1192, %f1189, %f1185;
	sub.f32 	%f1193, %f1189, %f1192;
	add.f32 	%f1194, %f1185, %f1193;
	add.f32 	%f1195, %f1187, %f1194;
	add.f32 	%f1196, %f1191, %f1195;
	add.f32 	%f1197, %f1192, %f1196;
	sub.f32 	%f1198, %f1192, %f1197;
	add.f32 	%f1199, %f1196, %f1198;
	mul.rn.f32 	%f1200, %f1574, %f1197;
	neg.f32 	%f1201, %f1200;
	fma.rn.f32 	%f1202, %f1574, %f1197, %f1201;
	fma.rn.f32 	%f1203, %f1574, %f1199, %f1202;
	fma.rn.f32 	%f1205, %f1590, %f1197, %f1203;
	add.rn.f32 	%f1206, %f1200, %f1205;
	neg.f32 	%f1207, %f1206;
	add.rn.f32 	%f1208, %f1200, %f1207;
	add.rn.f32 	%f1209, %f1208, %f1205;
	mov.b32 	%r432, %f1206;
	setp.eq.s32 	%p251, %r432, 1118925336;
	add.s32 	%r433, %r432, -1;
	mov.b32 	%f1210, %r433;
	add.f32 	%f1211, %f1209, 0f37000000;
	selp.f32 	%f262, %f1211, %f1209, %p251;
	selp.f32 	%f1212, %f1210, %f1206, %p251;
	mul.rn.f32 	%f1213, %f1212, %f1575;
	cvt.rzi.f32.f32 	%f1214, %f1213;
	abs.f32 	%f1215, %f1214;
	setp.gt.f32 	%p252, %f1215, 0f42FC0000;
	mov.b32 	%r434, %f1214;
	and.b32  	%r435, %r434, -2147483648;
	or.b32  	%r436, %r435, 1123811328;
	mov.b32 	%f1216, %r436;
	selp.f32 	%f1217, %f1216, %f1214, %p252;
	fma.rn.f32 	%f1219, %f1217, %f1585, %f1212;
	fma.rn.f32 	%f1221, %f1217, %f1586, %f1219;
	mul.f32 	%f1222, %f1221, 0f3FB8AA3B;
	add.f32 	%f1223, %f1217, 0f4B40007F;
	mov.b32 	%r437, %f1223;
	shl.b32 	%r438, %r437, 23;
	mov.b32 	%f1224, %r438;
	ex2.approx.ftz.f32 	%f1225, %f1222;
	mul.f32 	%f263, %f1225, %f1224;
	setp.eq.f32 	%p253, %f263, 0f7F800000;
	mov.f32 	%f1770, 0f7F800000;
	@%p253 bra 	$L__BB8_184;

	fma.rn.f32 	%f1770, %f263, %f262, %f263;

$L__BB8_184:
	setp.lt.f32 	%p254, %f260, 0f00000000;
	and.pred  	%p13, %p254, %p147;
	setp.eq.f32 	%p256, %f260, 0f00000000;
	@%p256 bra 	$L__BB8_188;
	bra.uni 	$L__BB8_185;

$L__BB8_188:
	add.f32 	%f1230, %f260, %f260;
	selp.f32 	%f1772, %f1230, 0f00000000, %p147;
	bra.uni 	$L__BB8_189;

$L__BB8_185:
	mov.b32 	%r439, %f1770;
	xor.b32  	%r440, %r439, -2147483648;
	mov.b32 	%f1226, %r440;
	selp.f32 	%f1772, %f1226, %f1770, %p13;
	setp.geu.f32 	%p257, %f260, 0f00000000;
	@%p257 bra 	$L__BB8_189;

	mov.f32 	%f1664, 0f40000000;
	cvt.rzi.f32.f32 	%f1228, %f1664;
	setp.eq.f32 	%p258, %f1228, 0f40000000;
	@%p258 bra 	$L__BB8_189;

	mov.f32 	%f1772, 0f7FFFFFFF;

$L__BB8_189:
	abs.f32 	%f1668, %f260;
	add.f32 	%f1231, %f1668, 0f40000000;
	mov.b32 	%r441, %f1231;
	setp.lt.s32 	%p260, %r441, 2139095040;
	@%p260 bra 	$L__BB8_194;

	abs.f32 	%f1669, %f260;
	setp.gtu.f32 	%p261, %f1669, 0f7F800000;
	@%p261 bra 	$L__BB8_193;
	bra.uni 	$L__BB8_191;

$L__BB8_193:
	add.f32 	%f1772, %f260, 0f40000000;
	bra.uni 	$L__BB8_194;

$L__BB8_191:
	abs.f32 	%f1670, %f260;
	setp.neu.f32 	%p262, %f1670, 0f7F800000;
	@%p262 bra 	$L__BB8_194;

	selp.f32 	%f1772, 0fFF800000, 0f7F800000, %p13;

$L__BB8_194:
	cvt.rn.f32.s32 	%f1600, %r640;
	add.f32 	%f1599, %f1600, 0f3F000000;
	sub.f32 	%f1598, %f1599, %f1773;
	sub.f32 	%f1597, %f1600, %f1773;
	add.f32 	%f1596, %f1597, 0fBF000000;
	mov.f32 	%f1595, 0f32A57060;
	mov.f32 	%f1594, 0f4B400001;
	mov.f32 	%f1593, 0f437C0000;
	mov.f32 	%f1592, 0f3BBB989D;
	mov.f32 	%f1591, 0f3FB8AA3B;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r595}, %fd207;
	}
	and.b32  	%r594, %r595, 2146435072;
	mul.f32 	%f1232, %f1772, 0fBF000000;
	setp.eq.f32 	%p263, %f260, 0f3F800000;
	selp.f32 	%f1233, 0fBF000000, %f1232, %p263;
	fma.rn.f32 	%f1236, %f1233, %f1592, %f413;
	cvt.sat.f32.f32 	%f1239, %f1236;
	fma.rm.f32 	%f1241, %f1239, %f1593, %f1594;
	add.f32 	%f1242, %f1241, 0fCB40007F;
	neg.f32 	%f1243, %f1242;
	fma.rn.f32 	%f1244, %f1233, %f1591, %f1243;
	fma.rn.f32 	%f1246, %f1233, %f1595, %f1244;
	mov.b32 	%r442, %f1241;
	shl.b32 	%r443, %r442, 23;
	mov.b32 	%f1247, %r443;
	ex2.approx.ftz.f32 	%f1248, %f1246;
	mul.f32 	%f1249, %f1248, %f1247;
	sub.f32 	%f1250, %f259, %f1249;
	mul.f32 	%f1251, %f49, %f1250;
	mul.f32 	%f272, %f244, %f1251;
	mul.f32 	%f1252, %f1596, %f1249;
	mul.f32 	%f1253, %f1598, %f259;
	sub.f32 	%f1254, %f1253, %f1252;
	cvt.f64.f32 	%fd235, %f1254;
	mul.f64 	%fd236, %fd68, %fd235;
	cvt.f64.f32 	%fd237, %f244;
	mul.f64 	%fd69, %fd236, %fd237;
	cvt.f64.f32 	%fd70, %f243;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd70;
	}
	abs.f64 	%fd71, %fd70;
	{ // callseq 179, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd207;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd389, [retval0+0];
	} // callseq 179
	setp.lt.s32 	%p264, %r91, 0;
	setp.eq.s32 	%p265, %r594, 1062207488;
	and.pred  	%p14, %p264, %p265;
	not.pred 	%p266, %p14;
	@%p266 bra 	$L__BB8_196;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r444}, %fd389;
	}
	xor.b32  	%r445, %r444, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r446, %temp}, %fd389;
	}
	mov.b64 	%fd389, {%r446, %r445};

$L__BB8_196:
	setp.eq.f32 	%p267, %f243, 0f00000000;
	@%p267 bra 	$L__BB8_200;
	bra.uni 	$L__BB8_197;

$L__BB8_200:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r615}, %fd207;
	}
	setp.lt.s32 	%p270, %r615, 0;
	mov.u32 	%r447, 0;
	selp.b32 	%r448, %r91, 0, %p265;
	or.b32  	%r449, %r448, 2146435072;
	selp.b32 	%r450, %r449, %r448, %p270;
	mov.b64 	%fd389, {%r447, %r450};
	bra.uni 	$L__BB8_201;

$L__BB8_197:
	setp.gt.s32 	%p268, %r91, -1;
	@%p268 bra 	$L__BB8_201;

	cvt.rzi.f64.f64 	%fd240, %fd207;
	setp.eq.f64 	%p269, %fd240, 0d4000000000000000;
	@%p269 bra 	$L__BB8_201;

	mov.f64 	%fd389, 0dFFF8000000000000;

$L__BB8_201:
	add.f64 	%fd77, %fd70, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r451}, %fd77;
	}
	and.b32  	%r452, %r451, 2146435072;
	setp.ne.s32 	%p272, %r452, 2146435072;
	mov.f64 	%fd390, %fd389;
	@%p272 bra 	$L__BB8_207;

	setp.gtu.f64 	%p273, %fd71, 0d7FF0000000000000;
	mov.f64 	%fd390, %fd77;
	@%p273 bra 	$L__BB8_207;

	setp.eq.s32 	%p274, %r84, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r453, %temp}, %fd207;
	}
	setp.eq.s32 	%p275, %r453, 0;
	and.pred  	%p276, %p274, %p275;
	@%p276 bra 	$L__BB8_206;
	bra.uni 	$L__BB8_204;

$L__BB8_206:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r614}, %fd207;
	}
	setp.lt.s32 	%p282, %r614, 0;
	mov.u32 	%r458, 0;
	setp.gt.f64 	%p283, %fd71, 0d3FF0000000000000;
	selp.b32 	%r459, 2146435072, 0, %p283;
	xor.b32  	%r460, %r459, 2146435072;
	selp.b32 	%r461, %r460, %r459, %p282;
	setp.eq.f32 	%p284, %f243, 0fBF800000;
	selp.b32 	%r462, 1072693248, %r461, %p284;
	mov.b64 	%fd390, {%r458, %r462};
	bra.uni 	$L__BB8_207;

$L__BB8_204:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r454, %temp}, %fd70;
	}
	and.b32  	%r455, %r91, 2147483647;
	setp.ne.s32 	%p277, %r455, 2146435072;
	setp.ne.s32 	%p278, %r454, 0;
	or.pred  	%p279, %p277, %p278;
	mov.f64 	%fd390, %fd389;
	@%p279 bra 	$L__BB8_207;

	setp.ne.s32 	%p280, %r84, 1071644672;
	and.pred  	%p281, %p280, %p14;
	selp.b32 	%r456, %r86, %r85, %p281;
	mov.u32 	%r457, 0;
	mov.b64 	%fd390, {%r457, %r456};

$L__BB8_207:
	mov.f32 	%f1601, 0f47C35000;
	setp.eq.f32 	%p285, %f243, 0f3F800000;
	selp.f64 	%fd243, 0d3FF0000000000000, %fd390, %p285;
	min.f32 	%f1256, %f1758, %f1601;
	cvt.f64.f32 	%fd81, %f1256;
	mul.f64 	%fd244, %fd243, %fd81;
	mul.f32 	%f1257, %f214, %f245;
	cvt.f64.f32 	%fd245, %f1257;
	sub.f64 	%fd246, %fd245, %fd244;
	cvt.f64.f32 	%fd247, %f1749;
	add.f64 	%fd248, %fd246, %fd247;
	cvt.rn.f32.f64 	%f1749, %fd248;
	cvt.f64.f32 	%fd82, %f272;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r92}, %fd82;
	}
	abs.f64 	%fd83, %fd82;
	{ // callseq 180, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd207;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd392, [retval0+0];
	} // callseq 180
	setp.lt.s32 	%p286, %r92, 0;
	and.pred  	%p15, %p286, %p265;
	not.pred 	%p288, %p15;
	@%p288 bra 	$L__BB8_209;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r463}, %fd392;
	}
	xor.b32  	%r464, %r463, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r465, %temp}, %fd392;
	}
	mov.b64 	%fd392, {%r465, %r464};

$L__BB8_209:
	setp.eq.f32 	%p289, %f272, 0f00000000;
	@%p289 bra 	$L__BB8_213;
	bra.uni 	$L__BB8_210;

$L__BB8_213:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r613}, %fd207;
	}
	setp.lt.s32 	%p292, %r613, 0;
	mov.u32 	%r466, 0;
	selp.b32 	%r467, %r92, 0, %p265;
	or.b32  	%r468, %r467, 2146435072;
	selp.b32 	%r469, %r468, %r467, %p292;
	mov.b64 	%fd392, {%r466, %r469};
	bra.uni 	$L__BB8_214;

$L__BB8_210:
	setp.gt.s32 	%p290, %r92, -1;
	@%p290 bra 	$L__BB8_214;

	cvt.rzi.f64.f64 	%fd251, %fd207;
	setp.eq.f64 	%p291, %fd251, 0d4000000000000000;
	@%p291 bra 	$L__BB8_214;

	mov.f64 	%fd392, 0dFFF8000000000000;

$L__BB8_214:
	add.f64 	%fd89, %fd82, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r470}, %fd89;
	}
	and.b32  	%r471, %r470, 2146435072;
	setp.ne.s32 	%p294, %r471, 2146435072;
	mov.f64 	%fd393, %fd392;
	@%p294 bra 	$L__BB8_220;

	setp.gtu.f64 	%p295, %fd83, 0d7FF0000000000000;
	mov.f64 	%fd393, %fd89;
	@%p295 bra 	$L__BB8_220;

	setp.eq.s32 	%p296, %r84, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r472, %temp}, %fd207;
	}
	setp.eq.s32 	%p297, %r472, 0;
	and.pred  	%p298, %p296, %p297;
	@%p298 bra 	$L__BB8_219;
	bra.uni 	$L__BB8_217;

$L__BB8_219:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r612}, %fd207;
	}
	setp.lt.s32 	%p304, %r612, 0;
	mov.u32 	%r477, 0;
	setp.gt.f64 	%p305, %fd83, 0d3FF0000000000000;
	selp.b32 	%r478, 2146435072, 0, %p305;
	xor.b32  	%r479, %r478, 2146435072;
	selp.b32 	%r480, %r479, %r478, %p304;
	setp.eq.f32 	%p306, %f272, 0fBF800000;
	selp.b32 	%r481, 1072693248, %r480, %p306;
	mov.b64 	%fd393, {%r477, %r481};
	bra.uni 	$L__BB8_220;

$L__BB8_217:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r473, %temp}, %fd82;
	}
	and.b32  	%r474, %r92, 2147483647;
	setp.ne.s32 	%p299, %r474, 2146435072;
	setp.ne.s32 	%p300, %r473, 0;
	or.pred  	%p301, %p299, %p300;
	mov.f64 	%fd393, %fd392;
	@%p301 bra 	$L__BB8_220;

	setp.ne.s32 	%p302, %r84, 1071644672;
	and.pred  	%p303, %p302, %p15;
	selp.b32 	%r475, %r86, %r85, %p303;
	mov.u32 	%r476, 0;
	mov.b64 	%fd393, {%r476, %r475};

$L__BB8_220:
	setp.eq.f32 	%p307, %f272, 0f3F800000;
	selp.f64 	%fd254, 0d3FF0000000000000, %fd393, %p307;
	mul.f64 	%fd255, %fd254, %fd81;
	cvt.rn.f32.f64 	%f1258, %fd69;
	mul.f32 	%f1259, %f214, %f1258;
	cvt.f64.f32 	%fd256, %f1259;
	sub.f64 	%fd257, %fd256, %fd255;
	cvt.f64.f32 	%fd258, %f1748;
	add.f64 	%fd259, %fd257, %fd258;
	cvt.rn.f32.f64 	%f1748, %fd259;
	fma.rn.f32 	%f1750, %f214, %f243, %f1750;
	fma.rn.f32 	%f1751, %f214, %f272, %f1751;
	add.s32 	%r640, %r640, 1;
	setp.lt.s32 	%p308, %r640, %r151;
	@%p308 bra 	$L__BB8_113;

	add.s32 	%r639, %r639, 1;
	setp.lt.s32 	%p309, %r639, %r151;
	@%p309 bra 	$L__BB8_112;

$L__BB8_222:
	mov.f32 	%f1604, 0fBF800000;
	mov.f32 	%f1603, 0f3F800000;
	cvt.rn.f32.s32 	%f1602, %r628;
	div.rn.f32 	%f1260, %f1750, %f1749;
	max.f32 	%f1262, %f1260, %f1604;
	min.f32 	%f1264, %f1262, %f1603;
	div.rn.f32 	%f1265, %f1264, %f1602;
	mul.f32 	%f1266, %f1265, 0f3F000000;
	sub.f32 	%f1774, %f1774, %f1266;
	div.rn.f32 	%f1267, %f1751, %f1748;
	max.f32 	%f1268, %f1267, %f1604;
	min.f32 	%f1269, %f1268, %f1603;
	div.rn.f32 	%f1270, %f1269, %f1602;
	mul.f32 	%f1271, %f1270, 0f3F000000;
	sub.f32 	%f1773, %f1773, %f1271;
	shl.b64 	%rd90, %rd14, 2;
	add.s64 	%rd91, %rd2, %rd90;
	st.local.f32 	[%rd91], %f1774;
	add.s64 	%rd92, %rd3, %rd90;
	st.local.f32 	[%rd92], %f1773;
	cvt.u32.u64 	%r482, %rd14;
	add.s32 	%r638, %r482, 1;
	setp.lt.u32 	%p310, %r638, %r628;
	@%p310 bra 	$L__BB8_110;

	ld.param.u32 	%r596, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_3];
	add.s32 	%r634, %r634, 1;
	setp.lt.s32 	%p311, %r634, %r596;
	@%p311 bra 	$L__BB8_77;

$L__BB8_224:
	mov.f32 	%f1787, 0f00000000;
	mov.f32 	%f1790, 0fC47A0000;
	mov.f32 	%f1791, 0f447A0000;
	mov.f32 	%f1789, %f1791;
	mov.f32 	%f1788, %f1790;
	@%p18 bra 	$L__BB8_250;

	mov.u32 	%r483, 0;
	mov.u32 	%r642, %r483;

$L__BB8_226:
	cvt.rn.f32.s32 	%f293, %r642;
	sqrt.rn.f32 	%f294, %f34;
	mov.u32 	%r643, %r483;

$L__BB8_227:
	cvt.rn.f32.s32 	%f300, %r643;
	mov.f32 	%f1792, %f1781;
	mov.u32 	%r644, %r483;

$L__BB8_228:
	mul.wide.s32 	%rd93, %r644, 4;
	add.s64 	%rd94, %rd2, %rd93;
	add.s64 	%rd95, %rd3, %rd93;
	ld.local.f32 	%f1774, [%rd94];
	setp.gt.f32 	%p313, %f1774, %f1790;
	selp.f32 	%f1790, %f1774, %f1790, %p313;
	setp.lt.f32 	%p314, %f1774, %f1791;
	selp.f32 	%f1791, %f1774, %f1791, %p314;
	ld.local.f32 	%f1773, [%rd95];
	setp.gt.f32 	%p315, %f1773, %f1788;
	selp.f32 	%f1788, %f1773, %f1788, %p315;
	setp.lt.f32 	%p316, %f1773, %f1789;
	selp.f32 	%f1789, %f1773, %f1789, %p316;
	sub.f32 	%f312, %f293, %f1774;
	add.f32 	%f1282, %f312, 0f3F000000;
	mul.f32 	%f313, %f1282, %f294;
	abs.f32 	%f1283, %f313;
	setp.ltu.f32 	%p317, %f1283, 0f3F8060FE;
	setp.ge.f32 	%p318, %f1283, 0f3F8060FE;
	mul.f32 	%f1284, %f313, %f313;
	selp.f32 	%f1285, %f1283, %f1284, %p318;
	selp.f32 	%f1286, 0f3789CA3C, 0f38B1E96A, %p318;
	selp.f32 	%f1287, 0fB9F560B9, 0fBA574D20, %p318;
	fma.rn.f32 	%f1288, %f1286, %f1285, %f1287;
	selp.f32 	%f1289, 0f3BAC840B, 0f3BAAD5EA, %p318;
	fma.rn.f32 	%f1290, %f1288, %f1285, %f1289;
	selp.f32 	%f1291, 0fBD0C8162, 0fBCDC1BE7, %p318;
	fma.rn.f32 	%f1292, %f1290, %f1285, %f1291;
	selp.f32 	%f1293, 0f3E1CF906, 0f3DE718AF, %p318;
	fma.rn.f32 	%f1294, %f1292, %f1285, %f1293;
	selp.f32 	%f1295, 0f3F6A937E, 0fBEC093AC, %p318;
	fma.rn.f32 	%f1296, %f1294, %f1285, %f1295;
	selp.f32 	%f1297, 0f3F20D842, 0f3E0375D3, %p318;
	fma.rn.f32 	%f1298, %f1296, %f1285, %f1297;
	neg.f32 	%f1299, %f1283;
	selp.f32 	%f1300, %f1299, %f313, %p318;
	fma.rn.f32 	%f1797, %f1298, %f1300, %f1300;
	@%p317 bra 	$L__BB8_230;

	ex2.approx.ftz.f32 	%f1301, %f1797;
	mov.f32 	%f1302, 0f3F800000;
	sub.f32 	%f1303, %f1302, %f1301;
	mov.b32 	%r486, %f1303;
	mov.b32 	%r487, %f313;
	and.b32  	%r488, %r487, -2147483648;
	or.b32  	%r489, %r488, %r486;
	mov.b32 	%f1797, %r489;

$L__BB8_230:
	add.f32 	%f1304, %f312, 0fBF000000;
	mul.f32 	%f317, %f1304, %f294;
	abs.f32 	%f1305, %f317;
	setp.ltu.f32 	%p319, %f1305, 0f3F8060FE;
	setp.ge.f32 	%p320, %f1305, 0f3F8060FE;
	mul.f32 	%f1306, %f317, %f317;
	selp.f32 	%f1307, %f1305, %f1306, %p320;
	selp.f32 	%f1308, 0f3789CA3C, 0f38B1E96A, %p320;
	selp.f32 	%f1309, 0fB9F560B9, 0fBA574D20, %p320;
	fma.rn.f32 	%f1310, %f1308, %f1307, %f1309;
	selp.f32 	%f1311, 0f3BAC840B, 0f3BAAD5EA, %p320;
	fma.rn.f32 	%f1312, %f1310, %f1307, %f1311;
	selp.f32 	%f1313, 0fBD0C8162, 0fBCDC1BE7, %p320;
	fma.rn.f32 	%f1314, %f1312, %f1307, %f1313;
	selp.f32 	%f1315, 0f3E1CF906, 0f3DE718AF, %p320;
	fma.rn.f32 	%f1316, %f1314, %f1307, %f1315;
	selp.f32 	%f1317, 0f3F6A937E, 0fBEC093AC, %p320;
	fma.rn.f32 	%f1318, %f1316, %f1307, %f1317;
	selp.f32 	%f1319, 0f3F20D842, 0f3E0375D3, %p320;
	fma.rn.f32 	%f1320, %f1318, %f1307, %f1319;
	neg.f32 	%f1321, %f1305;
	selp.f32 	%f1322, %f1321, %f317, %p320;
	fma.rn.f32 	%f1798, %f1320, %f1322, %f1322;
	@%p319 bra 	$L__BB8_232;

	ex2.approx.ftz.f32 	%f1323, %f1798;
	mov.f32 	%f1324, 0f3F800000;
	sub.f32 	%f1325, %f1324, %f1323;
	mov.b32 	%r490, %f1325;
	mov.b32 	%r491, %f317;
	and.b32  	%r492, %r491, -2147483648;
	or.b32  	%r493, %r492, %r490;
	mov.b32 	%f1798, %r493;

$L__BB8_232:
	sub.f32 	%f321, %f1797, %f1798;
	sub.f32 	%f322, %f300, %f1773;
	add.f32 	%f1326, %f322, 0f3F000000;
	mul.f32 	%f323, %f1326, %f294;
	abs.f32 	%f1327, %f323;
	setp.ltu.f32 	%p321, %f1327, 0f3F8060FE;
	setp.ge.f32 	%p322, %f1327, 0f3F8060FE;
	mul.f32 	%f1328, %f323, %f323;
	selp.f32 	%f1329, %f1327, %f1328, %p322;
	selp.f32 	%f1330, 0f3789CA3C, 0f38B1E96A, %p322;
	selp.f32 	%f1331, 0fB9F560B9, 0fBA574D20, %p322;
	fma.rn.f32 	%f1332, %f1330, %f1329, %f1331;
	selp.f32 	%f1333, 0f3BAC840B, 0f3BAAD5EA, %p322;
	fma.rn.f32 	%f1334, %f1332, %f1329, %f1333;
	selp.f32 	%f1335, 0fBD0C8162, 0fBCDC1BE7, %p322;
	fma.rn.f32 	%f1336, %f1334, %f1329, %f1335;
	selp.f32 	%f1337, 0f3E1CF906, 0f3DE718AF, %p322;
	fma.rn.f32 	%f1338, %f1336, %f1329, %f1337;
	selp.f32 	%f1339, 0f3F6A937E, 0fBEC093AC, %p322;
	fma.rn.f32 	%f1340, %f1338, %f1329, %f1339;
	selp.f32 	%f1341, 0f3F20D842, 0f3E0375D3, %p322;
	fma.rn.f32 	%f1342, %f1340, %f1329, %f1341;
	neg.f32 	%f1343, %f1327;
	selp.f32 	%f1344, %f1343, %f323, %p322;
	fma.rn.f32 	%f1799, %f1342, %f1344, %f1344;
	@%p321 bra 	$L__BB8_234;

	ex2.approx.ftz.f32 	%f1345, %f1799;
	mov.f32 	%f1346, 0f3F800000;
	sub.f32 	%f1347, %f1346, %f1345;
	mov.b32 	%r494, %f1347;
	mov.b32 	%r495, %f323;
	and.b32  	%r496, %r495, -2147483648;
	or.b32  	%r497, %r496, %r494;
	mov.b32 	%f1799, %r497;

$L__BB8_234:
	add.f32 	%f1348, %f322, 0fBF000000;
	mul.f32 	%f327, %f1348, %f294;
	abs.f32 	%f1349, %f327;
	setp.ltu.f32 	%p323, %f1349, 0f3F8060FE;
	setp.ge.f32 	%p324, %f1349, 0f3F8060FE;
	mul.f32 	%f1350, %f327, %f327;
	selp.f32 	%f1351, %f1349, %f1350, %p324;
	selp.f32 	%f1352, 0f3789CA3C, 0f38B1E96A, %p324;
	selp.f32 	%f1353, 0fB9F560B9, 0fBA574D20, %p324;
	fma.rn.f32 	%f1354, %f1352, %f1351, %f1353;
	selp.f32 	%f1355, 0f3BAC840B, 0f3BAAD5EA, %p324;
	fma.rn.f32 	%f1356, %f1354, %f1351, %f1355;
	selp.f32 	%f1357, 0fBD0C8162, 0fBCDC1BE7, %p324;
	fma.rn.f32 	%f1358, %f1356, %f1351, %f1357;
	selp.f32 	%f1359, 0f3E1CF906, 0f3DE718AF, %p324;
	fma.rn.f32 	%f1360, %f1358, %f1351, %f1359;
	selp.f32 	%f1361, 0f3F6A937E, 0fBEC093AC, %p324;
	fma.rn.f32 	%f1362, %f1360, %f1351, %f1361;
	selp.f32 	%f1363, 0f3F20D842, 0f3E0375D3, %p324;
	fma.rn.f32 	%f1364, %f1362, %f1351, %f1363;
	neg.f32 	%f1365, %f1349;
	selp.f32 	%f1366, %f1365, %f327, %p324;
	fma.rn.f32 	%f1800, %f1364, %f1366, %f1366;
	@%p323 bra 	$L__BB8_236;

	ex2.approx.ftz.f32 	%f1367, %f1800;
	mov.f32 	%f1368, 0f3F800000;
	sub.f32 	%f1369, %f1368, %f1367;
	mov.b32 	%r498, %f1369;
	mov.b32 	%r499, %f327;
	and.b32  	%r500, %r499, -2147483648;
	or.b32  	%r501, %r500, %r498;
	mov.b32 	%f1800, %r501;

$L__BB8_236:
	sub.f32 	%f1370, %f1799, %f1800;
	mul.f32 	%f1371, %f1370, 0f3F000000;
	mul.f32 	%f1372, %f321, 0f3F000000;
	mul.f32 	%f1373, %f1372, %f379;
	fma.rn.f32 	%f1792, %f1373, %f1371, %f1792;
	add.s32 	%r644, %r644, 1;
	setp.lt.u32 	%p325, %r644, %r628;
	@%p325 bra 	$L__BB8_228;

	mad.lo.s32 	%r502, %r643, %r151, %r642;
	add.s32 	%r503, %r502, %r1;
	mul.wide.s32 	%rd96, %r503, 4;
	add.s64 	%rd97, %rd1, %rd96;
	ld.global.f32 	%f332, [%rd97];
	mul.f32 	%f1374, %f1792, 0f4B000000;
	setp.lt.f32 	%p326, %f1792, 0f00800000;
	selp.f32 	%f333, %f1374, %f1792, %p326;
	selp.f32 	%f1375, 0fC1B80000, 0f00000000, %p326;
	mov.b32 	%r504, %f333;
	add.s32 	%r505, %r504, -1059760811;
	and.b32  	%r506, %r505, -8388608;
	sub.s32 	%r507, %r504, %r506;
	mov.b32 	%f1376, %r507;
	cvt.rn.f32.s32 	%f1377, %r506;
	mov.f32 	%f1378, 0f34000000;
	fma.rn.f32 	%f1379, %f1377, %f1378, %f1375;
	add.f32 	%f1380, %f1376, 0fBF800000;
	mov.f32 	%f1381, 0f3E1039F6;
	mov.f32 	%f1382, 0fBE055027;
	fma.rn.f32 	%f1383, %f1382, %f1380, %f1381;
	mov.f32 	%f1384, 0fBDF8CDCC;
	fma.rn.f32 	%f1385, %f1383, %f1380, %f1384;
	mov.f32 	%f1386, 0f3E0F2955;
	fma.rn.f32 	%f1387, %f1385, %f1380, %f1386;
	mov.f32 	%f1388, 0fBE2AD8B9;
	fma.rn.f32 	%f1389, %f1387, %f1380, %f1388;
	mov.f32 	%f1390, 0f3E4CED0B;
	fma.rn.f32 	%f1391, %f1389, %f1380, %f1390;
	mov.f32 	%f1392, 0fBE7FFF22;
	fma.rn.f32 	%f1393, %f1391, %f1380, %f1392;
	mov.f32 	%f1394, 0f3EAAAA78;
	fma.rn.f32 	%f1395, %f1393, %f1380, %f1394;
	mov.f32 	%f1396, 0fBF000000;
	fma.rn.f32 	%f1397, %f1395, %f1380, %f1396;
	mul.f32 	%f1398, %f1380, %f1397;
	fma.rn.f32 	%f1399, %f1398, %f1380, %f1380;
	mov.f32 	%f1400, 0f3F317218;
	fma.rn.f32 	%f1801, %f1379, %f1400, %f1399;
	setp.lt.u32 	%p327, %r504, 2139095040;
	@%p327 bra 	$L__BB8_239;

	mov.f32 	%f1401, 0f7F800000;
	fma.rn.f32 	%f1801, %f333, %f1401, %f1401;

$L__BB8_239:
	setp.eq.f32 	%p328, %f333, 0f00000000;
	selp.f32 	%f337, 0fFF800000, %f1801, %p328;
	mul.f32 	%f1402, %f1792, 0f40C90FD8;
	setp.lt.f32 	%p329, %f1402, 0f00800000;
	mul.f32 	%f1403, %f1402, 0f4B000000;
	selp.f32 	%f338, %f1403, %f1402, %p329;
	selp.f32 	%f1404, 0fC1B80000, 0f00000000, %p329;
	mov.b32 	%r508, %f338;
	add.s32 	%r509, %r508, -1059760811;
	and.b32  	%r510, %r509, -8388608;
	sub.s32 	%r511, %r508, %r510;
	mov.b32 	%f1405, %r511;
	cvt.rn.f32.s32 	%f1406, %r510;
	fma.rn.f32 	%f1408, %f1406, %f1378, %f1404;
	add.f32 	%f1409, %f1405, 0fBF800000;
	fma.rn.f32 	%f1412, %f1382, %f1409, %f1381;
	fma.rn.f32 	%f1414, %f1412, %f1409, %f1384;
	fma.rn.f32 	%f1416, %f1414, %f1409, %f1386;
	fma.rn.f32 	%f1418, %f1416, %f1409, %f1388;
	fma.rn.f32 	%f1420, %f1418, %f1409, %f1390;
	fma.rn.f32 	%f1422, %f1420, %f1409, %f1392;
	fma.rn.f32 	%f1424, %f1422, %f1409, %f1394;
	fma.rn.f32 	%f1426, %f1424, %f1409, %f1396;
	mul.f32 	%f1427, %f1409, %f1426;
	fma.rn.f32 	%f1428, %f1427, %f1409, %f1409;
	fma.rn.f32 	%f1802, %f1408, %f1400, %f1428;
	setp.lt.u32 	%p330, %r508, 2139095040;
	@%p330 bra 	$L__BB8_241;

	mov.f32 	%f1430, 0f7F800000;
	fma.rn.f32 	%f1802, %f338, %f1430, %f1430;

$L__BB8_241:
	setp.gt.f32 	%p331, %f332, 0f00000000;
	@%p331 bra 	$L__BB8_243;
	bra.uni 	$L__BB8_242;

$L__BB8_243:
	mul.f32 	%f1431, %f332, 0f4B000000;
	setp.lt.f32 	%p332, %f332, 0f00800000;
	selp.f32 	%f343, %f1431, %f332, %p332;
	selp.f32 	%f1432, 0fC1B80000, 0f00000000, %p332;
	mov.b32 	%r512, %f343;
	add.s32 	%r513, %r512, -1059760811;
	and.b32  	%r514, %r513, -8388608;
	sub.s32 	%r515, %r512, %r514;
	mov.b32 	%f1433, %r515;
	cvt.rn.f32.s32 	%f1434, %r514;
	fma.rn.f32 	%f1436, %f1434, %f1378, %f1432;
	add.f32 	%f1437, %f1433, 0fBF800000;
	fma.rn.f32 	%f1440, %f1382, %f1437, %f1381;
	fma.rn.f32 	%f1442, %f1440, %f1437, %f1384;
	fma.rn.f32 	%f1444, %f1442, %f1437, %f1386;
	fma.rn.f32 	%f1446, %f1444, %f1437, %f1388;
	fma.rn.f32 	%f1448, %f1446, %f1437, %f1390;
	fma.rn.f32 	%f1450, %f1448, %f1437, %f1392;
	fma.rn.f32 	%f1452, %f1450, %f1437, %f1394;
	fma.rn.f32 	%f1454, %f1452, %f1437, %f1396;
	mul.f32 	%f1455, %f1437, %f1454;
	fma.rn.f32 	%f1456, %f1455, %f1437, %f1437;
	fma.rn.f32 	%f1803, %f1436, %f1400, %f1456;
	setp.lt.u32 	%p333, %r512, 2139095040;
	@%p333 bra 	$L__BB8_245;

	mov.f32 	%f1458, 0f7F800000;
	fma.rn.f32 	%f1803, %f343, %f1458, %f1458;

$L__BB8_245:
	setp.eq.f32 	%p334, %f343, 0f00000000;
	selp.f32 	%f1459, 0fFF800000, %f1803, %p334;
	mul.f32 	%f1460, %f332, %f1459;
	mul.f32 	%f1461, %f332, %f337;
	sub.f32 	%f1462, %f1461, %f1792;
	sub.f32 	%f1463, %f1462, %f1460;
	add.f32 	%f347, %f332, %f1463;
	mul.f32 	%f1464, %f332, 0f40C90FD8;
	setp.lt.f32 	%p335, %f1464, 0f00800000;
	mul.f32 	%f1465, %f1464, 0f4B000000;
	selp.f32 	%f348, %f1465, %f1464, %p335;
	selp.f32 	%f1466, 0fC1B80000, 0f00000000, %p335;
	mov.b32 	%r516, %f348;
	add.s32 	%r517, %r516, -1059760811;
	and.b32  	%r518, %r517, -8388608;
	sub.s32 	%r519, %r516, %r518;
	mov.b32 	%f1467, %r519;
	cvt.rn.f32.s32 	%f1468, %r518;
	fma.rn.f32 	%f1470, %f1468, %f1378, %f1466;
	add.f32 	%f1471, %f1467, 0fBF800000;
	fma.rn.f32 	%f1474, %f1382, %f1471, %f1381;
	fma.rn.f32 	%f1476, %f1474, %f1471, %f1384;
	fma.rn.f32 	%f1478, %f1476, %f1471, %f1386;
	fma.rn.f32 	%f1480, %f1478, %f1471, %f1388;
	fma.rn.f32 	%f1482, %f1480, %f1471, %f1390;
	fma.rn.f32 	%f1484, %f1482, %f1471, %f1392;
	fma.rn.f32 	%f1486, %f1484, %f1471, %f1394;
	fma.rn.f32 	%f1488, %f1486, %f1471, %f1396;
	mul.f32 	%f1489, %f1471, %f1488;
	fma.rn.f32 	%f1490, %f1489, %f1471, %f1471;
	fma.rn.f32 	%f1804, %f1470, %f1400, %f1490;
	setp.lt.u32 	%p336, %r516, 2139095040;
	@%p336 bra 	$L__BB8_247;

	mov.f32 	%f1492, 0f7F800000;
	fma.rn.f32 	%f1804, %f348, %f1492, %f1492;

$L__BB8_247:
	mul.f32 	%f1493, %f1804, 0f3F000000;
	setp.eq.f32 	%p337, %f348, 0f00000000;
	selp.f32 	%f1494, 0fFF800000, %f1493, %p337;
	sub.f32 	%f1805, %f347, %f1494;
	bra.uni 	$L__BB8_248;

$L__BB8_242:
	neg.f32 	%f1805, %f1792;

$L__BB8_248:
	mul.f32 	%f1495, %f1792, %f337;
	sub.f32 	%f1496, %f1805, %f1495;
	add.f32 	%f1497, %f1792, %f1496;
	add.f32 	%f1498, %f1495, %f1497;
	sub.f32 	%f1499, %f1498, %f1792;
	setp.eq.f32 	%p338, %f338, 0f00000000;
	mul.f32 	%f1500, %f1802, 0f3F000000;
	selp.f32 	%f1501, 0fFF800000, %f1500, %p338;
	add.f32 	%f1502, %f1501, %f1499;
	add.f32 	%f1503, %f1502, %f1502;
	sub.f32 	%f1787, %f1787, %f1503;
	add.s32 	%r643, %r643, 1;
	setp.lt.s32 	%p339, %r643, %r151;
	@%p339 bra 	$L__BB8_227;

	add.s32 	%r642, %r642, 1;
	setp.lt.s32 	%p340, %r642, %r151;
	@%p340 bra 	$L__BB8_226;

$L__BB8_250:
	shl.b32 	%r520, %r628, 1;
	not.b32 	%r521, %r520;
	mad.lo.s32 	%r522, %r151, %r151, %r521;
	cvt.rn.f32.s32 	%f1504, %r522;
	sqrt.rn.f32 	%f1505, %f1504;
	sqrt.rn.f32 	%f1506, %f1787;
	sub.f32 	%f362, %f1506, %f1505;
	cvt.f64.f32 	%fd93, %f362;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r103}, %fd93;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r104}, %fd207;
	}
	and.b32  	%r105, %r104, 2146435072;
	setp.eq.s32 	%p341, %r105, 1062207488;
	abs.f64 	%fd94, %fd93;
	{ // callseq 181, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd94;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd207;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd395, [retval0+0];
	} // callseq 181
	setp.lt.s32 	%p342, %r103, 0;
	and.pred  	%p16, %p342, %p341;
	not.pred 	%p343, %p16;
	@%p343 bra 	$L__BB8_252;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r523}, %fd395;
	}
	xor.b32  	%r524, %r523, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r525, %temp}, %fd395;
	}
	mov.b64 	%fd395, {%r525, %r524};

$L__BB8_252:
	setp.eq.f32 	%p344, %f362, 0f00000000;
	@%p344 bra 	$L__BB8_256;
	bra.uni 	$L__BB8_253;

$L__BB8_256:
	selp.b32 	%r526, %r103, 0, %p341;
	mov.u32 	%r527, 0;
	or.b32  	%r528, %r526, 2146435072;
	setp.lt.s32 	%p348, %r104, 0;
	selp.b32 	%r529, %r528, %r526, %p348;
	mov.b64 	%fd395, {%r527, %r529};
	bra.uni 	$L__BB8_257;

$L__BB8_253:
	setp.gt.s32 	%p345, %r103, -1;
	@%p345 bra 	$L__BB8_257;

	cvt.rzi.f64.f64 	%fd262, %fd207;
	setp.eq.f64 	%p346, %fd262, 0d4000000000000000;
	@%p346 bra 	$L__BB8_257;

	mov.f64 	%fd395, 0dFFF8000000000000;

$L__BB8_257:
	add.f64 	%fd100, %fd93, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r530}, %fd100;
	}
	and.b32  	%r531, %r530, 2146435072;
	setp.ne.s32 	%p349, %r531, 2146435072;
	mov.f64 	%fd396, %fd395;
	@%p349 bra 	$L__BB8_263;

	setp.gtu.f64 	%p350, %fd94, 0d7FF0000000000000;
	mov.f64 	%fd396, %fd100;
	@%p350 bra 	$L__BB8_263;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r532, %temp}, %fd207;
	}
	and.b32  	%r106, %r104, 2147483647;
	setp.eq.s32 	%p351, %r106, 2146435072;
	setp.eq.s32 	%p352, %r532, 0;
	and.pred  	%p353, %p351, %p352;
	@%p353 bra 	$L__BB8_262;
	bra.uni 	$L__BB8_260;

$L__BB8_262:
	setp.gt.f64 	%p360, %fd94, 0d3FF0000000000000;
	selp.b32 	%r539, 2146435072, 0, %p360;
	mov.u32 	%r540, 0;
	xor.b32  	%r541, %r539, 2146435072;
	setp.lt.s32 	%p361, %r104, 0;
	selp.b32 	%r542, %r541, %r539, %p361;
	setp.eq.f32 	%p362, %f362, 0fBF800000;
	selp.b32 	%r543, 1072693248, %r542, %p362;
	mov.b64 	%fd396, {%r540, %r543};
	bra.uni 	$L__BB8_263;

$L__BB8_260:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r533, %temp}, %fd93;
	}
	and.b32  	%r534, %r103, 2147483647;
	setp.ne.s32 	%p354, %r534, 2146435072;
	setp.ne.s32 	%p355, %r533, 0;
	or.pred  	%p356, %p354, %p355;
	mov.f64 	%fd396, %fd395;
	@%p356 bra 	$L__BB8_263;

	setp.gt.s32 	%p357, %r104, -1;
	selp.b32 	%r535, 2146435072, 0, %p357;
	mov.u32 	%r536, 0;
	setp.ne.s32 	%p358, %r106, 1071644672;
	and.pred  	%p359, %p358, %p16;
	or.b32  	%r537, %r535, -2147483648;
	selp.b32 	%r538, %r537, %r535, %p359;
	mov.b64 	%fd396, {%r536, %r538};

$L__BB8_263:
	setp.eq.f32 	%p363, %f362, 0f3F800000;
	selp.f64 	%fd104, 0d3FF0000000000000, %fd396, %p363;
	mov.f64 	%fd265, 0d3FF0000000000000;
	mul.f32 	%f1507, %f362, 0f3F4E353F;
	cvt.f64.f32 	%fd266, %f1507;
	fma.rn.f64 	%fd105, %fd104, 0dBFEFB71760000000, %fd266;
	mov.f64 	%fd267, 0d4338000000000000;
	mov.f64 	%fd268, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd269, %fd105, %fd268, %fd267;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r107, %temp}, %fd269;
	}
	mov.f64 	%fd270, 0dC338000000000000;
	add.rn.f64 	%fd271, %fd269, %fd270;
	mov.f64 	%fd272, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd273, %fd271, %fd272, %fd105;
	mov.f64 	%fd274, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd275, %fd271, %fd274, %fd273;
	mov.f64 	%fd276, 0d3E928AF3FCA213EA;
	mov.f64 	%fd277, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd278, %fd277, %fd275, %fd276;
	mov.f64 	%fd279, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd280, %fd278, %fd275, %fd279;
	mov.f64 	%fd281, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd282, %fd280, %fd275, %fd281;
	mov.f64 	%fd283, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd284, %fd282, %fd275, %fd283;
	mov.f64 	%fd285, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd286, %fd284, %fd275, %fd285;
	mov.f64 	%fd287, 0d3F81111111122322;
	fma.rn.f64 	%fd288, %fd286, %fd275, %fd287;
	mov.f64 	%fd289, 0d3FA55555555502A1;
	fma.rn.f64 	%fd290, %fd288, %fd275, %fd289;
	mov.f64 	%fd291, 0d3FC5555555555511;
	fma.rn.f64 	%fd292, %fd290, %fd275, %fd291;
	mov.f64 	%fd293, 0d3FE000000000000B;
	fma.rn.f64 	%fd294, %fd292, %fd275, %fd293;
	fma.rn.f64 	%fd295, %fd294, %fd275, %fd265;
	fma.rn.f64 	%fd296, %fd295, %fd275, %fd265;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r108, %temp}, %fd296;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r109}, %fd296;
	}
	shl.b32 	%r544, %r107, 20;
	add.s32 	%r545, %r109, %r544;
	mov.b64 	%fd397, {%r108, %r545};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r546}, %fd105;
	}
	mov.b32 	%f1508, %r546;
	abs.f32 	%f363, %f1508;
	setp.lt.f32 	%p364, %f363, 0f4086232B;
	@%p364 bra 	$L__BB8_266;

	setp.lt.f64 	%p365, %fd105, 0d0000000000000000;
	add.f64 	%fd297, %fd105, 0d7FF0000000000000;
	selp.f64 	%fd397, 0d0000000000000000, %fd297, %p365;
	setp.geu.f32 	%p366, %f363, 0f40874800;
	@%p366 bra 	$L__BB8_266;

	mov.f64 	%fd368, 0d4338000000000000;
	mov.f64 	%fd367, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd364, %fd105, %fd367, %fd368;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r617, %temp}, %fd364;
	}
	shr.u32 	%r547, %r617, 31;
	add.s32 	%r548, %r617, %r547;
	shr.s32 	%r549, %r548, 1;
	shl.b32 	%r550, %r549, 20;
	add.s32 	%r551, %r109, %r550;
	mov.b64 	%fd298, {%r108, %r551};
	sub.s32 	%r552, %r617, %r549;
	shl.b32 	%r553, %r552, 20;
	add.s32 	%r554, %r553, 1072693248;
	mov.u32 	%r555, 0;
	mov.b64 	%fd299, {%r555, %r554};
	mul.f64 	%fd397, %fd298, %fd299;

$L__BB8_266:
	mov.f64 	%fd370, 0d4338000000000000;
	mov.f64 	%fd369, 0d3FF71547652B82FE;
	mov.f64 	%fd365, 0d3FF0000000000000;
	mul.f32 	%f1509, %f362, 0fBF9F5F70;
	cvt.f64.f32 	%fd300, %f1509;
	fma.rn.f64 	%fd110, %fd104, 0dBFE5A43FE0000000, %fd300;
	fma.rn.f64 	%fd303, %fd110, %fd369, %fd370;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r110, %temp}, %fd303;
	}
	add.rn.f64 	%fd305, %fd303, %fd270;
	fma.rn.f64 	%fd307, %fd305, %fd272, %fd110;
	fma.rn.f64 	%fd309, %fd305, %fd274, %fd307;
	fma.rn.f64 	%fd312, %fd277, %fd309, %fd276;
	fma.rn.f64 	%fd314, %fd312, %fd309, %fd279;
	fma.rn.f64 	%fd316, %fd314, %fd309, %fd281;
	fma.rn.f64 	%fd318, %fd316, %fd309, %fd283;
	fma.rn.f64 	%fd320, %fd318, %fd309, %fd285;
	fma.rn.f64 	%fd322, %fd320, %fd309, %fd287;
	fma.rn.f64 	%fd324, %fd322, %fd309, %fd289;
	fma.rn.f64 	%fd326, %fd324, %fd309, %fd291;
	fma.rn.f64 	%fd328, %fd326, %fd309, %fd293;
	fma.rn.f64 	%fd330, %fd328, %fd309, %fd365;
	fma.rn.f64 	%fd331, %fd330, %fd309, %fd365;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r111, %temp}, %fd331;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd331;
	}
	shl.b32 	%r556, %r110, 20;
	add.s32 	%r557, %r112, %r556;
	mov.b64 	%fd398, {%r111, %r557};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r558}, %fd110;
	}
	mov.b32 	%f1510, %r558;
	abs.f32 	%f364, %f1510;
	setp.lt.f32 	%p367, %f364, 0f4086232B;
	@%p367 bra 	$L__BB8_269;

	setp.lt.f64 	%p368, %fd110, 0d0000000000000000;
	add.f64 	%fd332, %fd110, 0d7FF0000000000000;
	selp.f64 	%fd398, 0d0000000000000000, %fd332, %p368;
	setp.geu.f32 	%p369, %f364, 0f40874800;
	@%p369 bra 	$L__BB8_269;

	shr.u32 	%r559, %r110, 31;
	add.s32 	%r560, %r110, %r559;
	shr.s32 	%r561, %r560, 1;
	shl.b32 	%r562, %r561, 20;
	add.s32 	%r563, %r112, %r562;
	mov.b64 	%fd333, {%r111, %r563};
	sub.s32 	%r564, %r110, %r561;
	shl.b32 	%r565, %r564, 20;
	add.s32 	%r566, %r565, 1072693248;
	mov.u32 	%r567, 0;
	mov.b64 	%fd334, {%r567, %r566};
	mul.f64 	%fd398, %fd333, %fd334;

$L__BB8_269:
	mov.f64 	%fd366, 0d3FF0000000000000;
	mul.f64 	%fd335, %fd398, 0d3FE0000000000000;
	setp.gt.f32 	%p370, %f362, 0f00000000;
	selp.f64 	%fd336, 0d3FF0000000000000, 0d0000000000000000, %p370;
	mul.f64 	%fd337, %fd335, %fd336;
	setp.lt.f32 	%p371, %f362, 0f00000000;
	selp.f64 	%fd338, 0d3FF0000000000000, 0d0000000000000000, %p371;
	mul.f64 	%fd339, %fd397, 0d3FE0000000000000;
	sub.f64 	%fd341, %fd366, %fd339;
	fma.rn.f64 	%fd342, %fd341, %fd338, %fd337;
	cvt.rn.f32.f64 	%f365, %fd342;
	setp.geu.f32 	%p372, %f1814, %f365;
	@%p372 bra 	$L__BB8_279;

	mov.b32 	%r568, %f50;
	and.b32  	%r569, %r568, -2147483648;
	or.b32  	%r570, %r569, 1056964608;
	mov.b32 	%f1511, %r570;
	add.rz.f32 	%f1512, %f50, %f1511;
	cvt.rzi.f32.f32 	%f366, %f1512;
	neg.f32 	%f367, %f366;
	setp.leu.f32 	%p373, %f1791, %f367;
	@%p373 bra 	$L__BB8_279;

	cvt.rn.f32.s32 	%f1607, %r241;
	add.f32 	%f1513, %f366, %f1607;
	setp.geu.f32 	%p374, %f1790, %f1513;
	setp.leu.f32 	%p375, %f1789, %f367;
	or.pred  	%p376, %p375, %p374;
	setp.geu.f32 	%p377, %f1788, %f1513;
	or.pred  	%p378, %p377, %p376;
	@%p378 bra 	$L__BB8_279;

	and.b32  	%r113, %r628, 3;
	setp.lt.u32 	%p379, %r44, 3;
	mov.u32 	%r647, 0;
	@%p379 bra 	$L__BB8_275;

	sub.s32 	%r646, %r628, %r113;

$L__BB8_274:
	mul.wide.s32 	%rd98, %r647, 4;
	add.s64 	%rd99, %rd2, %rd98;
	ld.local.v4.f32 	{%f1514, %f1515, %f1516, %f1517}, [%rd99];
	add.s64 	%rd100, %rd4, %rd98;
	add.s64 	%rd101, %rd3, %rd98;
	ld.local.v4.f32 	{%f1522, %f1523, %f1524, %f1525}, [%rd101];
	add.s64 	%rd102, %rd5, %rd98;
	st.local.v4.f32 	[%rd100], {%f1514, %f1515, %f1516, %f1517};
	st.local.v4.f32 	[%rd102], {%f1522, %f1523, %f1524, %f1525};
	add.s32 	%r647, %r647, 4;
	add.s32 	%r646, %r646, -4;
	setp.ne.s32 	%p380, %r646, 0;
	@%p380 bra 	$L__BB8_274;

$L__BB8_275:
	setp.eq.s32 	%p381, %r113, 0;
	mov.u32 	%r648, %r628;
	mov.f32 	%f1813, %f1781;
	mov.f32 	%f1814, %f365;
	@%p381 bra 	$L__BB8_279;

	mul.wide.s32 	%rd103, %r647, 4;
	add.s64 	%rd15, %rd2, %rd103;
	ld.local.f32 	%f1530, [%rd15];
	add.s64 	%rd16, %rd4, %rd103;
	st.local.f32 	[%rd16], %f1530;
	add.s64 	%rd17, %rd3, %rd103;
	ld.local.f32 	%f1531, [%rd17];
	add.s64 	%rd18, %rd5, %rd103;
	st.local.f32 	[%rd18], %f1531;
	setp.eq.s32 	%p382, %r113, 1;
	mov.u32 	%r648, %r628;
	mov.f32 	%f1813, %f1781;
	mov.f32 	%f1814, %f365;
	@%p382 bra 	$L__BB8_279;

	ld.local.f32 	%f1532, [%rd15+4];
	st.local.f32 	[%rd16+4], %f1532;
	ld.local.f32 	%f1533, [%rd17+4];
	st.local.f32 	[%rd18+4], %f1533;
	setp.eq.s32 	%p383, %r113, 2;
	mov.u32 	%r648, %r628;
	mov.f32 	%f1813, %f1781;
	mov.f32 	%f1814, %f365;
	@%p383 bra 	$L__BB8_279;

	ld.local.f32 	%f1534, [%rd15+8];
	st.local.f32 	[%rd16+8], %f1534;
	ld.local.f32 	%f1535, [%rd17+8];
	st.local.f32 	[%rd18+8], %f1535;
	mov.u32 	%r648, %r628;
	mov.f32 	%f1813, %f1781;
	mov.f32 	%f1814, %f365;

$L__BB8_279:
	add.s32 	%r626, %r628, 1;
	setp.lt.s32 	%p384, %r628, %r153;
	@%p384 bra 	$L__BB8_53;

$L__BB8_280:
	ld.param.f32 	%f1605, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_6];
	ld.local.f32 	%f1818, [%rd4];
	setp.eq.f32 	%p385, %f1818, 0f00000000;
	cvt.f64.f32 	%fd343, %f1605;
	mul.f64 	%fd344, %fd343, 0d3F847AE147AE147B;
	cvt.f64.f32 	%fd345, %f1814;
	setp.geu.f64 	%p386, %fd344, %fd345;
	or.pred  	%p387, %p386, %p385;
	setp.lt.s32 	%p388, %r648, 1;
	or.pred  	%p389, %p387, %p388;
	@%p389 bra 	$L__BB8_288;

	add.s32 	%r574, %r648, -1;
	and.b32  	%r653, %r648, 3;
	setp.lt.u32 	%p390, %r574, 3;
	mov.u32 	%r650, 0;
	@%p390 bra 	$L__BB8_285;

	sub.s32 	%r651, %r648, %r653;
	mov.f32 	%f1817, %f1818;
	bra.uni 	$L__BB8_283;

$L__BB8_284:
	ld.local.f32 	%f1817, [%rd19+12];

$L__BB8_283:
	mul.wide.s32 	%rd104, %r650, 4;
	add.s64 	%rd105, %rd2, %rd104;
	add.s64 	%rd106, %rd5, %rd104;
	ld.local.v4.f32 	{%f1536, %f1537, %f1538, %f1539}, [%rd106];
	add.s64 	%rd107, %rd3, %rd104;
	add.s32 	%r576, %r650, 1;
	mul.wide.s32 	%rd108, %r576, 4;
	add.s64 	%rd19, %rd4, %rd108;
	ld.local.f32 	%f1544, [%rd19+8];
	ld.local.f32 	%f1545, [%rd19+4];
	ld.local.f32 	%f1546, [%rd19];
	st.local.v4.f32 	[%rd105], {%f1817, %f1546, %f1545, %f1544};
	st.local.v4.f32 	[%rd107], {%f1536, %f1537, %f1538, %f1539};
	add.s32 	%r650, %r650, 4;
	add.s32 	%r651, %r651, -4;
	setp.eq.s32 	%p391, %r651, 0;
	@%p391 bra 	$L__BB8_285;
	bra.uni 	$L__BB8_284;

$L__BB8_285:
	setp.eq.s32 	%p392, %r653, 0;
	@%p392 bra 	$L__BB8_288;

	mul.wide.s32 	%rd109, %r650, 4;
	add.s64 	%rd139, %rd3, %rd109;
	add.s64 	%rd138, %rd5, %rd109;
	add.s64 	%rd137, %rd2, %rd109;
	add.s64 	%rd136, %rd4, %rd109;

$L__BB8_287:
	.pragma "nounroll";
	ld.local.f32 	%f1547, [%rd136];
	st.local.f32 	[%rd137], %f1547;
	ld.local.f32 	%f1548, [%rd138];
	st.local.f32 	[%rd139], %f1548;
	add.s64 	%rd139, %rd139, 4;
	add.s64 	%rd138, %rd138, 4;
	add.s64 	%rd137, %rd137, 4;
	add.s64 	%rd136, %rd136, 4;
	add.s32 	%r653, %r653, -1;
	setp.ne.s32 	%p393, %r653, 0;
	@%p393 bra 	$L__BB8_287;

$L__BB8_288:
	setp.lt.s32 	%p404, %r153, 1;
	ld.param.f32 	%f1606, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_6];
	setp.gt.f32 	%p394, %f1814, %f1606;
	selp.f32 	%f375, 0f3F800000, 0f00000000, %p394;
	@%p404 bra 	$L__BB8_302;

	mul.lo.s32 	%r132, %r158, %r153;
	and.b32  	%r661, %r153, 3;
	add.s32 	%r134, %r153, -1;
	setp.lt.u32 	%p396, %r134, 3;
	mov.u32 	%r654, 0;
	@%p396 bra 	$L__BB8_293;

	ld.param.u64 	%rd130, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_7];
	sub.s32 	%r655, %r153, %r661;
	cvta.to.global.u64 	%rd32, %rd130;
	bra.uni 	$L__BB8_291;

$L__BB8_292:
	ld.local.f32 	%f1818, [%rd33+12];

$L__BB8_291:
	add.s32 	%r583, %r654, %r132;
	mul.wide.s32 	%rd110, %r583, 4;
	add.s64 	%rd111, %rd32, %rd110;
	mul.f32 	%f1549, %f1818, %f375;
	st.global.f32 	[%rd111], %f1549;
	add.s32 	%r584, %r654, 1;
	mul.wide.s32 	%rd112, %r584, 4;
	add.s64 	%rd33, %rd4, %rd112;
	ld.local.f32 	%f1550, [%rd33];
	mul.f32 	%f1551, %f1550, %f375;
	st.global.f32 	[%rd111+4], %f1551;
	ld.local.f32 	%f1552, [%rd33+4];
	mul.f32 	%f1553, %f1552, %f375;
	st.global.f32 	[%rd111+8], %f1553;
	ld.local.f32 	%f1554, [%rd33+8];
	mul.f32 	%f1555, %f1554, %f375;
	st.global.f32 	[%rd111+12], %f1555;
	add.s32 	%r654, %r654, 4;
	add.s32 	%r655, %r655, -4;
	setp.eq.s32 	%p397, %r655, 0;
	@%p397 bra 	$L__BB8_293;
	bra.uni 	$L__BB8_292;

$L__BB8_293:
	setp.eq.s32 	%p398, %r661, 0;
	@%p398 bra 	$L__BB8_296;

	ld.param.u64 	%rd131, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_7];
	add.s32 	%r585, %r654, %r132;
	cvta.to.global.u64 	%rd113, %rd131;
	mul.wide.s32 	%rd114, %r585, 4;
	add.s64 	%rd141, %rd113, %rd114;
	mul.wide.s32 	%rd115, %r654, 4;
	add.s64 	%rd140, %rd4, %rd115;
	mov.u32 	%r657, %r661;

$L__BB8_295:
	.pragma "nounroll";
	ld.local.f32 	%f1556, [%rd140];
	mul.f32 	%f1557, %f1556, %f375;
	st.global.f32 	[%rd141], %f1557;
	add.s64 	%rd141, %rd141, 4;
	add.s64 	%rd140, %rd140, 4;
	add.s32 	%r657, %r657, -1;
	setp.ne.s32 	%p399, %r657, 0;
	@%p399 bra 	$L__BB8_295;

$L__BB8_296:
	mov.u32 	%r660, 0;
	@%p396 bra 	$L__BB8_299;

	ld.param.u64 	%rd132, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_8];
	sub.s32 	%r659, %r153, %r661;
	cvta.to.global.u64 	%rd40, %rd132;

$L__BB8_298:
	mul.wide.s32 	%rd116, %r660, 4;
	add.s64 	%rd117, %rd5, %rd116;
	ld.local.v4.f32 	{%f1558, %f1559, %f1560, %f1561}, [%rd117];
	mul.f32 	%f1566, %f1558, %f375;
	add.s32 	%r588, %r660, %r132;
	mul.wide.s32 	%rd118, %r588, 4;
	add.s64 	%rd119, %rd40, %rd118;
	st.global.f32 	[%rd119], %f1566;
	mul.f32 	%f1567, %f1559, %f375;
	st.global.f32 	[%rd119+4], %f1567;
	mul.f32 	%f1568, %f1560, %f375;
	st.global.f32 	[%rd119+8], %f1568;
	mul.f32 	%f1569, %f1561, %f375;
	st.global.f32 	[%rd119+12], %f1569;
	add.s32 	%r660, %r660, 4;
	add.s32 	%r659, %r659, -4;
	setp.ne.s32 	%p401, %r659, 0;
	@%p401 bra 	$L__BB8_298;

$L__BB8_299:
	@%p398 bra 	$L__BB8_302;

	ld.param.u64 	%rd133, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_8];
	add.s32 	%r589, %r660, %r132;
	cvta.to.global.u64 	%rd120, %rd133;
	mul.wide.s32 	%rd121, %r589, 4;
	add.s64 	%rd143, %rd120, %rd121;
	mul.wide.s32 	%rd122, %r660, 4;
	add.s64 	%rd142, %rd5, %rd122;

$L__BB8_301:
	.pragma "nounroll";
	ld.local.f32 	%f1570, [%rd142];
	mul.f32 	%f1571, %f1570, %f375;
	st.global.f32 	[%rd143], %f1571;
	add.s64 	%rd143, %rd143, 4;
	add.s64 	%rd142, %rd142, 4;
	add.s32 	%r661, %r661, -1;
	setp.ne.s32 	%p403, %r661, 0;
	@%p403 bra 	$L__BB8_301;

$L__BB8_302:
	ld.param.u64 	%rd129, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_10];
	ld.param.u64 	%rd128, [_Z15kernel_gaussMFAPKffiiiffPfS1_S1_S1_i_param_9];
	mul.f32 	%f1572, %f1813, %f375;
	cvta.to.global.u64 	%rd123, %rd128;
	mul.wide.s32 	%rd124, %r158, 4;
	add.s64 	%rd125, %rd123, %rd124;
	st.global.f32 	[%rd125], %f1572;
	cvta.to.global.u64 	%rd126, %rd129;
	add.s64 	%rd127, %rd126, %rd124;
	st.global.f32 	[%rd127], %f1814;

$L__BB8_303:
	ret;

}
	// .globl	_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1_
.visible .entry _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1_(
	.param .u32 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_0,
	.param .u32 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_1,
	.param .f32 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_2,
	.param .f32 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_3,
	.param .u64 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_4,
	.param .u64 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_5,
	.param .u64 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_6,
	.param .u64 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_7,
	.param .u64 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_8,
	.param .u32 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_9,
	.param .u64 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_10,
	.param .u64 _Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_11
)
{
	.local .align 4 .b8 	__local_depot9[1552];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<249>;
	.reg .f32 	%f<1230>;
	.reg .b32 	%r<614>;
	.reg .f64 	%fd<49>;
	.reg .b64 	%rd<314>;


	mov.u64 	%SPL, __local_depot9;
	ld.param.u32 	%r213, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_0];
	ld.param.u32 	%r214, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_1];
	ld.param.f32 	%f181, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_2];
	ld.param.f32 	%f182, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_3];
	ld.param.u64 	%rd57, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_4];
	ld.param.u64 	%rd58, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_5];
	ld.param.u64 	%rd56, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_6];
	ld.param.u64 	%rd59, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_7];
	ld.param.u64 	%rd60, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_8];
	ld.param.u32 	%r215, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_9];
	ld.param.u64 	%rd61, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_10];
	ld.param.u64 	%rd62, [_Z11kernel_CRLBiiffPKfS0_S0_PfS1_iS1_S1__param_11];
	cvta.to.global.u64 	%rd1, %rd62;
	cvta.to.global.u64 	%rd2, %rd61;
	cvta.to.global.u64 	%rd3, %rd60;
	add.u64 	%rd4, %SPL, 0;
	add.u64 	%rd5, %SPL, 484;
	add.u64 	%rd6, %SPL, 968;
	mov.u32 	%r545, 0;
	st.local.u32 	[%rd5], %r545;
	st.local.u32 	[%rd4], %r545;
	st.local.u32 	[%rd5+4], %r545;
	st.local.u32 	[%rd4+4], %r545;
	st.local.u32 	[%rd5+8], %r545;
	st.local.u32 	[%rd4+8], %r545;
	st.local.u32 	[%rd5+12], %r545;
	st.local.u32 	[%rd4+12], %r545;
	st.local.u32 	[%rd5+16], %r545;
	st.local.u32 	[%rd4+16], %r545;
	st.local.u32 	[%rd5+20], %r545;
	st.local.u32 	[%rd4+20], %r545;
	st.local.u32 	[%rd5+24], %r545;
	st.local.u32 	[%rd4+24], %r545;
	st.local.u32 	[%rd5+28], %r545;
	st.local.u32 	[%rd4+28], %r545;
	st.local.u32 	[%rd5+32], %r545;
	st.local.u32 	[%rd4+32], %r545;
	st.local.u32 	[%rd5+36], %r545;
	st.local.u32 	[%rd4+36], %r545;
	st.local.u32 	[%rd5+40], %r545;
	st.local.u32 	[%rd4+40], %r545;
	st.local.u32 	[%rd5+44], %r545;
	st.local.u32 	[%rd4+44], %r545;
	st.local.u32 	[%rd5+48], %r545;
	st.local.u32 	[%rd4+48], %r545;
	st.local.u32 	[%rd5+52], %r545;
	st.local.u32 	[%rd4+52], %r545;
	st.local.u32 	[%rd5+56], %r545;
	st.local.u32 	[%rd4+56], %r545;
	st.local.u32 	[%rd5+60], %r545;
	st.local.u32 	[%rd4+60], %r545;
	st.local.u32 	[%rd5+64], %r545;
	st.local.u32 	[%rd4+64], %r545;
	st.local.u32 	[%rd5+68], %r545;
	st.local.u32 	[%rd4+68], %r545;
	st.local.u32 	[%rd5+72], %r545;
	st.local.u32 	[%rd4+72], %r545;
	st.local.u32 	[%rd5+76], %r545;
	st.local.u32 	[%rd4+76], %r545;
	st.local.u32 	[%rd5+80], %r545;
	st.local.u32 	[%rd4+80], %r545;
	st.local.u32 	[%rd5+84], %r545;
	st.local.u32 	[%rd4+84], %r545;
	st.local.u32 	[%rd5+88], %r545;
	st.local.u32 	[%rd4+88], %r545;
	st.local.u32 	[%rd5+92], %r545;
	st.local.u32 	[%rd4+92], %r545;
	st.local.u32 	[%rd5+96], %r545;
	st.local.u32 	[%rd4+96], %r545;
	st.local.u32 	[%rd5+100], %r545;
	st.local.u32 	[%rd4+100], %r545;
	st.local.u32 	[%rd5+104], %r545;
	st.local.u32 	[%rd4+104], %r545;
	st.local.u32 	[%rd5+108], %r545;
	st.local.u32 	[%rd4+108], %r545;
	st.local.u32 	[%rd5+112], %r545;
	st.local.u32 	[%rd4+112], %r545;
	st.local.u32 	[%rd5+116], %r545;
	st.local.u32 	[%rd4+116], %r545;
	st.local.u32 	[%rd5+120], %r545;
	st.local.u32 	[%rd4+120], %r545;
	st.local.u32 	[%rd5+124], %r545;
	st.local.u32 	[%rd4+124], %r545;
	st.local.u32 	[%rd5+128], %r545;
	st.local.u32 	[%rd4+128], %r545;
	st.local.u32 	[%rd5+132], %r545;
	st.local.u32 	[%rd4+132], %r545;
	st.local.u32 	[%rd5+136], %r545;
	st.local.u32 	[%rd4+136], %r545;
	st.local.u32 	[%rd5+140], %r545;
	st.local.u32 	[%rd4+140], %r545;
	st.local.u32 	[%rd5+144], %r545;
	st.local.u32 	[%rd4+144], %r545;
	st.local.u32 	[%rd5+148], %r545;
	st.local.u32 	[%rd4+148], %r545;
	st.local.u32 	[%rd5+152], %r545;
	st.local.u32 	[%rd4+152], %r545;
	st.local.u32 	[%rd5+156], %r545;
	st.local.u32 	[%rd4+156], %r545;
	st.local.u32 	[%rd5+160], %r545;
	st.local.u32 	[%rd4+160], %r545;
	st.local.u32 	[%rd5+164], %r545;
	st.local.u32 	[%rd4+164], %r545;
	st.local.u32 	[%rd5+168], %r545;
	st.local.u32 	[%rd4+168], %r545;
	st.local.u32 	[%rd5+172], %r545;
	st.local.u32 	[%rd4+172], %r545;
	st.local.u32 	[%rd5+176], %r545;
	st.local.u32 	[%rd4+176], %r545;
	st.local.u32 	[%rd5+180], %r545;
	st.local.u32 	[%rd4+180], %r545;
	st.local.u32 	[%rd5+184], %r545;
	st.local.u32 	[%rd4+184], %r545;
	st.local.u32 	[%rd5+188], %r545;
	st.local.u32 	[%rd4+188], %r545;
	st.local.u32 	[%rd5+192], %r545;
	st.local.u32 	[%rd4+192], %r545;
	st.local.u32 	[%rd5+196], %r545;
	st.local.u32 	[%rd4+196], %r545;
	st.local.u32 	[%rd5+200], %r545;
	st.local.u32 	[%rd4+200], %r545;
	st.local.u32 	[%rd5+204], %r545;
	st.local.u32 	[%rd4+204], %r545;
	st.local.u32 	[%rd5+208], %r545;
	st.local.u32 	[%rd4+208], %r545;
	st.local.u32 	[%rd5+212], %r545;
	st.local.u32 	[%rd4+212], %r545;
	st.local.u32 	[%rd5+216], %r545;
	st.local.u32 	[%rd4+216], %r545;
	st.local.u32 	[%rd5+220], %r545;
	st.local.u32 	[%rd4+220], %r545;
	st.local.u32 	[%rd5+224], %r545;
	st.local.u32 	[%rd4+224], %r545;
	st.local.u32 	[%rd5+228], %r545;
	st.local.u32 	[%rd4+228], %r545;
	st.local.u32 	[%rd5+232], %r545;
	st.local.u32 	[%rd4+232], %r545;
	st.local.u32 	[%rd5+236], %r545;
	st.local.u32 	[%rd4+236], %r545;
	st.local.u32 	[%rd5+240], %r545;
	st.local.u32 	[%rd4+240], %r545;
	st.local.u32 	[%rd5+244], %r545;
	st.local.u32 	[%rd4+244], %r545;
	st.local.u32 	[%rd5+248], %r545;
	st.local.u32 	[%rd4+248], %r545;
	st.local.u32 	[%rd5+252], %r545;
	st.local.u32 	[%rd4+252], %r545;
	st.local.u32 	[%rd5+256], %r545;
	st.local.u32 	[%rd4+256], %r545;
	st.local.u32 	[%rd5+260], %r545;
	st.local.u32 	[%rd4+260], %r545;
	st.local.u32 	[%rd5+264], %r545;
	st.local.u32 	[%rd4+264], %r545;
	st.local.u32 	[%rd5+268], %r545;
	st.local.u32 	[%rd4+268], %r545;
	st.local.u32 	[%rd5+272], %r545;
	st.local.u32 	[%rd4+272], %r545;
	st.local.u32 	[%rd5+276], %r545;
	st.local.u32 	[%rd4+276], %r545;
	st.local.u32 	[%rd5+280], %r545;
	st.local.u32 	[%rd4+280], %r545;
	st.local.u32 	[%rd5+284], %r545;
	st.local.u32 	[%rd4+284], %r545;
	st.local.u32 	[%rd5+288], %r545;
	st.local.u32 	[%rd4+288], %r545;
	st.local.u32 	[%rd5+292], %r545;
	st.local.u32 	[%rd4+292], %r545;
	st.local.u32 	[%rd5+296], %r545;
	st.local.u32 	[%rd4+296], %r545;
	st.local.u32 	[%rd5+300], %r545;
	st.local.u32 	[%rd4+300], %r545;
	st.local.u32 	[%rd5+304], %r545;
	st.local.u32 	[%rd4+304], %r545;
	st.local.u32 	[%rd5+308], %r545;
	st.local.u32 	[%rd4+308], %r545;
	st.local.u32 	[%rd5+312], %r545;
	st.local.u32 	[%rd4+312], %r545;
	st.local.u32 	[%rd5+316], %r545;
	st.local.u32 	[%rd4+316], %r545;
	st.local.u32 	[%rd5+320], %r545;
	st.local.u32 	[%rd4+320], %r545;
	st.local.u32 	[%rd5+324], %r545;
	st.local.u32 	[%rd4+324], %r545;
	st.local.u32 	[%rd5+328], %r545;
	st.local.u32 	[%rd4+328], %r545;
	st.local.u32 	[%rd5+332], %r545;
	st.local.u32 	[%rd4+332], %r545;
	st.local.u32 	[%rd5+336], %r545;
	st.local.u32 	[%rd4+336], %r545;
	st.local.u32 	[%rd5+340], %r545;
	st.local.u32 	[%rd4+340], %r545;
	st.local.u32 	[%rd5+344], %r545;
	st.local.u32 	[%rd4+344], %r545;
	st.local.u32 	[%rd5+348], %r545;
	st.local.u32 	[%rd4+348], %r545;
	st.local.u32 	[%rd5+352], %r545;
	st.local.u32 	[%rd4+352], %r545;
	st.local.u32 	[%rd5+356], %r545;
	st.local.u32 	[%rd4+356], %r545;
	st.local.u32 	[%rd5+360], %r545;
	st.local.u32 	[%rd4+360], %r545;
	st.local.u32 	[%rd5+364], %r545;
	st.local.u32 	[%rd4+364], %r545;
	st.local.u32 	[%rd5+368], %r545;
	st.local.u32 	[%rd4+368], %r545;
	st.local.u32 	[%rd5+372], %r545;
	st.local.u32 	[%rd4+372], %r545;
	st.local.u32 	[%rd5+376], %r545;
	st.local.u32 	[%rd4+376], %r545;
	st.local.u32 	[%rd5+380], %r545;
	st.local.u32 	[%rd4+380], %r545;
	st.local.u32 	[%rd5+384], %r545;
	st.local.u32 	[%rd4+384], %r545;
	st.local.u32 	[%rd5+388], %r545;
	st.local.u32 	[%rd4+388], %r545;
	st.local.u32 	[%rd5+392], %r545;
	st.local.u32 	[%rd4+392], %r545;
	st.local.u32 	[%rd5+396], %r545;
	st.local.u32 	[%rd4+396], %r545;
	st.local.u32 	[%rd5+400], %r545;
	st.local.u32 	[%rd4+400], %r545;
	st.local.u32 	[%rd5+404], %r545;
	st.local.u32 	[%rd4+404], %r545;
	st.local.u32 	[%rd5+408], %r545;
	st.local.u32 	[%rd4+408], %r545;
	st.local.u32 	[%rd5+412], %r545;
	st.local.u32 	[%rd4+412], %r545;
	st.local.u32 	[%rd5+416], %r545;
	st.local.u32 	[%rd4+416], %r545;
	st.local.u32 	[%rd5+420], %r545;
	st.local.u32 	[%rd4+420], %r545;
	st.local.u32 	[%rd5+424], %r545;
	st.local.u32 	[%rd4+424], %r545;
	st.local.u32 	[%rd5+428], %r545;
	st.local.u32 	[%rd4+428], %r545;
	st.local.u32 	[%rd5+432], %r545;
	st.local.u32 	[%rd4+432], %r545;
	st.local.u32 	[%rd5+436], %r545;
	st.local.u32 	[%rd4+436], %r545;
	st.local.u32 	[%rd5+440], %r545;
	st.local.u32 	[%rd4+440], %r545;
	st.local.u32 	[%rd5+444], %r545;
	st.local.u32 	[%rd4+444], %r545;
	st.local.u32 	[%rd5+448], %r545;
	st.local.u32 	[%rd4+448], %r545;
	st.local.u32 	[%rd5+452], %r545;
	st.local.u32 	[%rd4+452], %r545;
	st.local.u32 	[%rd5+456], %r545;
	st.local.u32 	[%rd4+456], %r545;
	st.local.u32 	[%rd5+460], %r545;
	st.local.u32 	[%rd4+460], %r545;
	st.local.u32 	[%rd5+464], %r545;
	st.local.u32 	[%rd4+464], %r545;
	st.local.u32 	[%rd5+468], %r545;
	st.local.u32 	[%rd4+468], %r545;
	st.local.u32 	[%rd5+472], %r545;
	st.local.u32 	[%rd4+472], %r545;
	st.local.u32 	[%rd5+476], %r545;
	st.local.u32 	[%rd4+476], %r545;
	st.local.u32 	[%rd5+480], %r545;
	st.local.u32 	[%rd4+480], %r545;
	cvta.to.global.u64 	%rd7, %rd58;
	cvta.to.global.u64 	%rd8, %rd57;
	cvta.to.global.u64 	%rd9, %rd59;
	add.u64 	%rd10, %SPL, 1452;
	mov.u32 	%r217, %ntid.x;
	mov.u32 	%r218, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	mad.lo.s32 	%r2, %r217, %r218, %r1;
	mul.lo.s32 	%r3, %r2, %r214;
	cvt.s64.s32 	%rd11, %r3;
	setp.ge.s32 	%p7, %r2, %r215;
	@%p7 bra 	$L__BB9_254;

	setp.lt.s32 	%p8, %r213, 1;
	@%p8 bra 	$L__BB9_85;

	cvta.to.global.u64 	%rd67, %rd56;
	add.s32 	%r221, %r2, %r1;
	mul.wide.s32 	%rd68, %r221, 4;
	add.s64 	%rd69, %rd67, %rd68;
	mov.f32 	%f183, 0f3F000000;
	div.rn.f32 	%f184, %f183, %f182;
	div.rn.f32 	%f1, %f184, %f182;
	div.rn.f32 	%f185, %f181, 0fC0206C98;
	div.rn.f32 	%f2, %f185, %f182;
	ld.global.f32 	%f3, [%rd69];
	mov.u32 	%r220, 0;
	setp.lt.s32 	%p9, %r214, 1;
	mov.u32 	%r540, %r220;

$L__BB9_3:
	mov.u32 	%r541, %r220;

$L__BB9_4:
	mov.f32 	%f1181, %f3;
	@%p9 bra 	$L__BB9_15;

	sqrt.rn.f32 	%f6, %f1;
	cvt.rn.f32.s32 	%f7, %r541;
	mov.u32 	%r542, 0;
	mov.f32 	%f1181, %f3;

$L__BB9_6:
	cvt.rn.f32.s32 	%f1132, %r540;
	add.s32 	%r224, %r542, %r3;
	mul.wide.s32 	%rd70, %r224, 4;
	add.s64 	%rd71, %rd8, %rd70;
	add.s64 	%rd72, %rd7, %rd70;
	ld.global.f32 	%f9, [%rd72];
	ld.global.f32 	%f10, [%rd71];
	sub.f32 	%f11, %f1132, %f10;
	add.f32 	%f186, %f11, 0f3F000000;
	mul.f32 	%f12, %f186, %f6;
	abs.f32 	%f187, %f12;
	setp.ltu.f32 	%p10, %f187, 0f3F8060FE;
	setp.ge.f32 	%p11, %f187, 0f3F8060FE;
	mul.f32 	%f188, %f12, %f12;
	selp.f32 	%f189, %f187, %f188, %p11;
	selp.f32 	%f190, 0f3789CA3C, 0f38B1E96A, %p11;
	selp.f32 	%f191, 0fB9F560B9, 0fBA574D20, %p11;
	fma.rn.f32 	%f192, %f190, %f189, %f191;
	selp.f32 	%f193, 0f3BAC840B, 0f3BAAD5EA, %p11;
	fma.rn.f32 	%f194, %f192, %f189, %f193;
	selp.f32 	%f195, 0fBD0C8162, 0fBCDC1BE7, %p11;
	fma.rn.f32 	%f196, %f194, %f189, %f195;
	selp.f32 	%f197, 0f3E1CF906, 0f3DE718AF, %p11;
	fma.rn.f32 	%f198, %f196, %f189, %f197;
	selp.f32 	%f199, 0f3F6A937E, 0fBEC093AC, %p11;
	fma.rn.f32 	%f200, %f198, %f189, %f199;
	selp.f32 	%f201, 0f3F20D842, 0f3E0375D3, %p11;
	fma.rn.f32 	%f202, %f200, %f189, %f201;
	neg.f32 	%f203, %f187;
	selp.f32 	%f204, %f203, %f12, %p11;
	fma.rn.f32 	%f1177, %f202, %f204, %f204;
	@%p10 bra 	$L__BB9_8;

	ex2.approx.ftz.f32 	%f205, %f1177;
	mov.f32 	%f206, 0f3F800000;
	sub.f32 	%f207, %f206, %f205;
	mov.b32 	%r225, %f207;
	mov.b32 	%r226, %f12;
	and.b32  	%r227, %r226, -2147483648;
	or.b32  	%r228, %r227, %r225;
	mov.b32 	%f1177, %r228;

$L__BB9_8:
	add.f32 	%f208, %f11, 0fBF000000;
	mul.f32 	%f16, %f208, %f6;
	abs.f32 	%f209, %f16;
	setp.ltu.f32 	%p12, %f209, 0f3F8060FE;
	setp.ge.f32 	%p13, %f209, 0f3F8060FE;
	mul.f32 	%f210, %f16, %f16;
	selp.f32 	%f211, %f209, %f210, %p13;
	selp.f32 	%f212, 0f3789CA3C, 0f38B1E96A, %p13;
	selp.f32 	%f213, 0fB9F560B9, 0fBA574D20, %p13;
	fma.rn.f32 	%f214, %f212, %f211, %f213;
	selp.f32 	%f215, 0f3BAC840B, 0f3BAAD5EA, %p13;
	fma.rn.f32 	%f216, %f214, %f211, %f215;
	selp.f32 	%f217, 0fBD0C8162, 0fBCDC1BE7, %p13;
	fma.rn.f32 	%f218, %f216, %f211, %f217;
	selp.f32 	%f219, 0f3E1CF906, 0f3DE718AF, %p13;
	fma.rn.f32 	%f220, %f218, %f211, %f219;
	selp.f32 	%f221, 0f3F6A937E, 0fBEC093AC, %p13;
	fma.rn.f32 	%f222, %f220, %f211, %f221;
	selp.f32 	%f223, 0f3F20D842, 0f3E0375D3, %p13;
	fma.rn.f32 	%f224, %f222, %f211, %f223;
	neg.f32 	%f225, %f209;
	selp.f32 	%f226, %f225, %f16, %p13;
	fma.rn.f32 	%f1178, %f224, %f226, %f226;
	@%p12 bra 	$L__BB9_10;

	ex2.approx.ftz.f32 	%f227, %f1178;
	mov.f32 	%f228, 0f3F800000;
	sub.f32 	%f229, %f228, %f227;
	mov.b32 	%r229, %f229;
	mov.b32 	%r230, %f16;
	and.b32  	%r231, %r230, -2147483648;
	or.b32  	%r232, %r231, %r229;
	mov.b32 	%f1178, %r232;

$L__BB9_10:
	sub.f32 	%f20, %f1177, %f1178;
	sub.f32 	%f21, %f7, %f9;
	add.f32 	%f230, %f21, 0f3F000000;
	mul.f32 	%f22, %f230, %f6;
	abs.f32 	%f231, %f22;
	setp.ltu.f32 	%p14, %f231, 0f3F8060FE;
	setp.ge.f32 	%p15, %f231, 0f3F8060FE;
	mul.f32 	%f232, %f22, %f22;
	selp.f32 	%f233, %f231, %f232, %p15;
	selp.f32 	%f234, 0f3789CA3C, 0f38B1E96A, %p15;
	selp.f32 	%f235, 0fB9F560B9, 0fBA574D20, %p15;
	fma.rn.f32 	%f236, %f234, %f233, %f235;
	selp.f32 	%f237, 0f3BAC840B, 0f3BAAD5EA, %p15;
	fma.rn.f32 	%f238, %f236, %f233, %f237;
	selp.f32 	%f239, 0fBD0C8162, 0fBCDC1BE7, %p15;
	fma.rn.f32 	%f240, %f238, %f233, %f239;
	selp.f32 	%f241, 0f3E1CF906, 0f3DE718AF, %p15;
	fma.rn.f32 	%f242, %f240, %f233, %f241;
	selp.f32 	%f243, 0f3F6A937E, 0fBEC093AC, %p15;
	fma.rn.f32 	%f244, %f242, %f233, %f243;
	selp.f32 	%f245, 0f3F20D842, 0f3E0375D3, %p15;
	fma.rn.f32 	%f246, %f244, %f233, %f245;
	neg.f32 	%f247, %f231;
	selp.f32 	%f248, %f247, %f22, %p15;
	fma.rn.f32 	%f1179, %f246, %f248, %f248;
	@%p14 bra 	$L__BB9_12;

	ex2.approx.ftz.f32 	%f249, %f1179;
	mov.f32 	%f250, 0f3F800000;
	sub.f32 	%f251, %f250, %f249;
	mov.b32 	%r233, %f251;
	mov.b32 	%r234, %f22;
	and.b32  	%r235, %r234, -2147483648;
	or.b32  	%r236, %r235, %r233;
	mov.b32 	%f1179, %r236;

$L__BB9_12:
	add.f32 	%f252, %f21, 0fBF000000;
	mul.f32 	%f26, %f252, %f6;
	abs.f32 	%f253, %f26;
	setp.ltu.f32 	%p16, %f253, 0f3F8060FE;
	setp.ge.f32 	%p17, %f253, 0f3F8060FE;
	mul.f32 	%f254, %f26, %f26;
	selp.f32 	%f255, %f253, %f254, %p17;
	selp.f32 	%f256, 0f3789CA3C, 0f38B1E96A, %p17;
	selp.f32 	%f257, 0fB9F560B9, 0fBA574D20, %p17;
	fma.rn.f32 	%f258, %f256, %f255, %f257;
	selp.f32 	%f259, 0f3BAC840B, 0f3BAAD5EA, %p17;
	fma.rn.f32 	%f260, %f258, %f255, %f259;
	selp.f32 	%f261, 0fBD0C8162, 0fBCDC1BE7, %p17;
	fma.rn.f32 	%f262, %f260, %f255, %f261;
	selp.f32 	%f263, 0f3E1CF906, 0f3DE718AF, %p17;
	fma.rn.f32 	%f264, %f262, %f255, %f263;
	selp.f32 	%f265, 0f3F6A937E, 0fBEC093AC, %p17;
	fma.rn.f32 	%f266, %f264, %f255, %f265;
	selp.f32 	%f267, 0f3F20D842, 0f3E0375D3, %p17;
	fma.rn.f32 	%f268, %f266, %f255, %f267;
	neg.f32 	%f269, %f253;
	selp.f32 	%f270, %f269, %f26, %p17;
	fma.rn.f32 	%f1180, %f268, %f270, %f270;
	@%p16 bra 	$L__BB9_14;

	ex2.approx.ftz.f32 	%f271, %f1180;
	mov.f32 	%f272, 0f3F800000;
	sub.f32 	%f273, %f272, %f271;
	mov.b32 	%r237, %f273;
	mov.b32 	%r238, %f26;
	and.b32  	%r239, %r238, -2147483648;
	or.b32  	%r240, %r239, %r237;
	mov.b32 	%f1180, %r240;

$L__BB9_14:
	setp.neu.f32 	%p18, %f10, 0f00000000;
	selp.f32 	%f274, 0f3F800000, 0f00000000, %p18;
	sub.f32 	%f275, %f1179, %f1180;
	mul.f32 	%f276, %f275, 0f3F000000;
	mul.f32 	%f277, %f276, %f274;
	mul.f32 	%f278, %f20, 0f3F000000;
	mul.f32 	%f279, %f278, %f274;
	mul.f32 	%f280, %f279, %f181;
	fma.rn.f32 	%f1181, %f280, %f277, %f1181;
	add.s32 	%r542, %r542, 1;
	setp.lt.s32 	%p19, %r542, %r214;
	@%p19 bra 	$L__BB9_6;

$L__BB9_15:
	mov.u32 	%r545, 0;
	@%p9 bra 	$L__BB9_74;

	sqrt.rn.f32 	%f32, %f1;
	mov.u32 	%r544, %r545;

$L__BB9_17:
	cvt.rn.f32.s32 	%f1133, %r540;
	add.s32 	%r244, %r544, %r3;
	mul.wide.s32 	%rd73, %r244, 4;
	add.s64 	%rd74, %rd8, %rd73;
	add.s64 	%rd75, %rd7, %rd73;
	ld.global.f32 	%f36, [%rd75];
	ld.global.f32 	%f37, [%rd74];
	sub.f32 	%f38, %f1133, %f37;
	add.f32 	%f286, %f38, 0f3F000000;
	mul.f32 	%f39, %f286, %f32;
	abs.f32 	%f287, %f39;
	setp.ltu.f32 	%p21, %f287, 0f3F8060FE;
	setp.ge.f32 	%p22, %f287, 0f3F8060FE;
	mul.f32 	%f288, %f39, %f39;
	selp.f32 	%f289, %f287, %f288, %p22;
	selp.f32 	%f290, 0f3789CA3C, 0f38B1E96A, %p22;
	selp.f32 	%f291, 0fB9F560B9, 0fBA574D20, %p22;
	fma.rn.f32 	%f292, %f290, %f289, %f291;
	selp.f32 	%f293, 0f3BAC840B, 0f3BAAD5EA, %p22;
	fma.rn.f32 	%f294, %f292, %f289, %f293;
	selp.f32 	%f295, 0fBD0C8162, 0fBCDC1BE7, %p22;
	fma.rn.f32 	%f296, %f294, %f289, %f295;
	selp.f32 	%f297, 0f3E1CF906, 0f3DE718AF, %p22;
	fma.rn.f32 	%f298, %f296, %f289, %f297;
	selp.f32 	%f299, 0f3F6A937E, 0fBEC093AC, %p22;
	fma.rn.f32 	%f300, %f298, %f289, %f299;
	selp.f32 	%f301, 0f3F20D842, 0f3E0375D3, %p22;
	fma.rn.f32 	%f302, %f300, %f289, %f301;
	neg.f32 	%f303, %f287;
	selp.f32 	%f304, %f303, %f39, %p22;
	fma.rn.f32 	%f1182, %f302, %f304, %f304;
	@%p21 bra 	$L__BB9_19;

	mov.f32 	%f1161, 0f3F800000;
	ex2.approx.ftz.f32 	%f305, %f1182;
	sub.f32 	%f307, %f1161, %f305;
	mov.b32 	%r245, %f307;
	mov.b32 	%r246, %f39;
	and.b32  	%r247, %r246, -2147483648;
	or.b32  	%r248, %r247, %r245;
	mov.b32 	%f1182, %r248;

$L__BB9_19:
	add.f32 	%f43, %f38, 0fBF000000;
	mul.f32 	%f44, %f43, %f32;
	abs.f32 	%f308, %f44;
	setp.ltu.f32 	%p23, %f308, 0f3F8060FE;
	setp.ge.f32 	%p24, %f308, 0f3F8060FE;
	mul.f32 	%f309, %f44, %f44;
	selp.f32 	%f310, %f308, %f309, %p24;
	selp.f32 	%f311, 0f3789CA3C, 0f38B1E96A, %p24;
	selp.f32 	%f312, 0fB9F560B9, 0fBA574D20, %p24;
	fma.rn.f32 	%f313, %f311, %f310, %f312;
	selp.f32 	%f314, 0f3BAC840B, 0f3BAAD5EA, %p24;
	fma.rn.f32 	%f315, %f313, %f310, %f314;
	selp.f32 	%f316, 0fBD0C8162, 0fBCDC1BE7, %p24;
	fma.rn.f32 	%f317, %f315, %f310, %f316;
	selp.f32 	%f318, 0f3E1CF906, 0f3DE718AF, %p24;
	fma.rn.f32 	%f319, %f317, %f310, %f318;
	selp.f32 	%f320, 0f3F6A937E, 0fBEC093AC, %p24;
	fma.rn.f32 	%f321, %f319, %f310, %f320;
	selp.f32 	%f322, 0f3F20D842, 0f3E0375D3, %p24;
	fma.rn.f32 	%f323, %f321, %f310, %f322;
	neg.f32 	%f324, %f308;
	selp.f32 	%f325, %f324, %f44, %p24;
	fma.rn.f32 	%f1183, %f323, %f325, %f325;
	@%p23 bra 	$L__BB9_21;

	mov.f32 	%f1160, 0f3F800000;
	ex2.approx.ftz.f32 	%f326, %f1183;
	sub.f32 	%f328, %f1160, %f326;
	mov.b32 	%r249, %f328;
	mov.b32 	%r250, %f44;
	and.b32  	%r251, %r250, -2147483648;
	or.b32  	%r252, %r251, %r249;
	mov.b32 	%f1183, %r252;

$L__BB9_21:
	cvt.rn.f32.s32 	%f1134, %r541;
	sub.f32 	%f48, %f1182, %f1183;
	sub.f32 	%f50, %f1134, %f36;
	add.f32 	%f329, %f50, 0f3F000000;
	mul.f32 	%f51, %f329, %f32;
	abs.f32 	%f330, %f51;
	setp.ltu.f32 	%p26, %f330, 0f3F8060FE;
	setp.ge.f32 	%p27, %f330, 0f3F8060FE;
	mul.f32 	%f331, %f51, %f51;
	selp.f32 	%f332, %f330, %f331, %p27;
	selp.f32 	%f333, 0f3789CA3C, 0f38B1E96A, %p27;
	selp.f32 	%f334, 0fB9F560B9, 0fBA574D20, %p27;
	fma.rn.f32 	%f335, %f333, %f332, %f334;
	selp.f32 	%f336, 0f3BAC840B, 0f3BAAD5EA, %p27;
	fma.rn.f32 	%f337, %f335, %f332, %f336;
	selp.f32 	%f338, 0fBD0C8162, 0fBCDC1BE7, %p27;
	fma.rn.f32 	%f339, %f337, %f332, %f338;
	selp.f32 	%f340, 0f3E1CF906, 0f3DE718AF, %p27;
	fma.rn.f32 	%f341, %f339, %f332, %f340;
	selp.f32 	%f342, 0f3F6A937E, 0fBEC093AC, %p27;
	fma.rn.f32 	%f343, %f341, %f332, %f342;
	selp.f32 	%f344, 0f3F20D842, 0f3E0375D3, %p27;
	fma.rn.f32 	%f345, %f343, %f332, %f344;
	neg.f32 	%f346, %f330;
	selp.f32 	%f347, %f346, %f51, %p27;
	fma.rn.f32 	%f1184, %f345, %f347, %f347;
	@%p26 bra 	$L__BB9_23;

	mov.f32 	%f1159, 0f3F800000;
	ex2.approx.ftz.f32 	%f348, %f1184;
	sub.f32 	%f350, %f1159, %f348;
	mov.b32 	%r253, %f350;
	mov.b32 	%r254, %f51;
	and.b32  	%r255, %r254, -2147483648;
	or.b32  	%r256, %r255, %r253;
	mov.b32 	%f1184, %r256;

$L__BB9_23:
	cvt.rn.f32.s32 	%f1136, %r541;
	sub.f32 	%f1135, %f1134, %f36;
	add.f32 	%f55, %f1135, 0fBF000000;
	mul.f32 	%f56, %f55, %f32;
	abs.f32 	%f351, %f56;
	setp.ltu.f32 	%p28, %f351, 0f3F8060FE;
	setp.ge.f32 	%p29, %f351, 0f3F8060FE;
	mul.f32 	%f352, %f56, %f56;
	selp.f32 	%f353, %f351, %f352, %p29;
	selp.f32 	%f354, 0f3789CA3C, 0f38B1E96A, %p29;
	selp.f32 	%f355, 0fB9F560B9, 0fBA574D20, %p29;
	fma.rn.f32 	%f356, %f354, %f353, %f355;
	selp.f32 	%f357, 0f3BAC840B, 0f3BAAD5EA, %p29;
	fma.rn.f32 	%f358, %f356, %f353, %f357;
	selp.f32 	%f359, 0fBD0C8162, 0fBCDC1BE7, %p29;
	fma.rn.f32 	%f360, %f358, %f353, %f359;
	selp.f32 	%f361, 0f3E1CF906, 0f3DE718AF, %p29;
	fma.rn.f32 	%f362, %f360, %f353, %f361;
	selp.f32 	%f363, 0f3F6A937E, 0fBEC093AC, %p29;
	fma.rn.f32 	%f364, %f362, %f353, %f363;
	selp.f32 	%f365, 0f3F20D842, 0f3E0375D3, %p29;
	fma.rn.f32 	%f366, %f364, %f353, %f365;
	neg.f32 	%f367, %f351;
	selp.f32 	%f368, %f367, %f56, %p29;
	fma.rn.f32 	%f1185, %f366, %f368, %f368;
	@%p28 bra 	$L__BB9_25;

	mov.f32 	%f1158, 0f3F800000;
	ex2.approx.ftz.f32 	%f369, %f1185;
	sub.f32 	%f371, %f1158, %f369;
	mov.b32 	%r257, %f371;
	mov.b32 	%r258, %f56;
	and.b32  	%r259, %r258, -2147483648;
	or.b32  	%r260, %r259, %r257;
	mov.b32 	%f1185, %r260;

$L__BB9_25:
	setp.neu.f32 	%p248, %f37, 0f00000000;
	selp.f32 	%f1140, 0f3F800000, 0f00000000, %p248;
	mov.f32 	%f1139, 0f40000000;
	cvt.rn.f32.s32 	%f1138, %r540;
	add.f32 	%f1137, %f1138, 0f3F000000;
	sub.f32 	%f373, %f1184, %f1185;
	mul.f32 	%f374, %f373, 0f3F000000;
	mul.f32 	%f60, %f374, %f1140;
	sub.f32 	%f375, %f1137, %f37;
	div.rn.f32 	%f61, %f375, %f182;
	abs.f32 	%f62, %f61;
	setp.lt.f32 	%p30, %f62, 0f00800000;
	mul.f32 	%f376, %f62, 0f4B800000;
	selp.f32 	%f377, %f376, %f62, %p30;
	selp.f32 	%f378, 0fC3170000, 0fC2FE0000, %p30;
	mov.b32 	%r261, %f377;
	and.b32  	%r262, %r261, 8388607;
	or.b32  	%r263, %r262, 1065353216;
	mov.b32 	%f379, %r263;
	shr.u32 	%r264, %r261, 23;
	cvt.rn.f32.u32 	%f380, %r264;
	add.f32 	%f381, %f378, %f380;
	setp.gt.f32 	%p31, %f379, 0f3FB504F3;
	mul.f32 	%f382, %f379, 0f3F000000;
	add.f32 	%f383, %f381, 0f3F800000;
	selp.f32 	%f384, %f383, %f381, %p31;
	selp.f32 	%f385, %f382, %f379, %p31;
	add.f32 	%f386, %f385, 0fBF800000;
	add.f32 	%f387, %f385, 0f3F800000;
	rcp.approx.ftz.f32 	%f388, %f387;
	add.f32 	%f389, %f386, %f386;
	mul.f32 	%f391, %f389, %f388;
	mul.f32 	%f392, %f391, %f391;
	mov.f32 	%f393, 0f3C4CAF63;
	mov.f32 	%f394, 0f3B18F0FE;
	fma.rn.f32 	%f395, %f394, %f392, %f393;
	mov.f32 	%f396, 0f3DAAAABD;
	fma.rn.f32 	%f397, %f395, %f392, %f396;
	mul.rn.f32 	%f398, %f397, %f392;
	mul.rn.f32 	%f399, %f398, %f391;
	sub.f32 	%f400, %f386, %f391;
	add.f32 	%f401, %f400, %f400;
	neg.f32 	%f402, %f391;
	fma.rn.f32 	%f403, %f402, %f386, %f401;
	mul.rn.f32 	%f404, %f388, %f403;
	add.f32 	%f405, %f399, %f391;
	sub.f32 	%f406, %f391, %f405;
	add.f32 	%f407, %f399, %f406;
	add.f32 	%f408, %f404, %f407;
	add.f32 	%f409, %f405, %f408;
	sub.f32 	%f410, %f405, %f409;
	add.f32 	%f411, %f408, %f410;
	mov.f32 	%f412, 0f3F317200;
	mul.rn.f32 	%f413, %f384, %f412;
	mov.f32 	%f414, 0f35BFBE8E;
	mul.rn.f32 	%f415, %f384, %f414;
	add.f32 	%f416, %f413, %f409;
	sub.f32 	%f417, %f413, %f416;
	add.f32 	%f418, %f409, %f417;
	add.f32 	%f419, %f411, %f418;
	add.f32 	%f420, %f415, %f419;
	add.f32 	%f421, %f416, %f420;
	sub.f32 	%f422, %f416, %f421;
	add.f32 	%f423, %f420, %f422;
	mul.rn.f32 	%f424, %f1139, %f421;
	neg.f32 	%f425, %f424;
	fma.rn.f32 	%f426, %f1139, %f421, %f425;
	fma.rn.f32 	%f427, %f1139, %f423, %f426;
	mov.f32 	%f428, 0f00000000;
	fma.rn.f32 	%f429, %f428, %f421, %f427;
	add.rn.f32 	%f430, %f424, %f429;
	neg.f32 	%f431, %f430;
	add.rn.f32 	%f432, %f424, %f431;
	add.rn.f32 	%f433, %f432, %f429;
	mov.b32 	%r265, %f430;
	setp.eq.s32 	%p32, %r265, 1118925336;
	add.s32 	%r266, %r265, -1;
	mov.b32 	%f434, %r266;
	add.f32 	%f435, %f433, 0f37000000;
	selp.f32 	%f63, %f435, %f433, %p32;
	selp.f32 	%f436, %f434, %f430, %p32;
	mov.f32 	%f437, 0f3FB8AA3B;
	mul.rn.f32 	%f438, %f436, %f437;
	cvt.rzi.f32.f32 	%f439, %f438;
	abs.f32 	%f440, %f439;
	setp.gt.f32 	%p33, %f440, 0f42FC0000;
	mov.b32 	%r267, %f439;
	and.b32  	%r268, %r267, -2147483648;
	or.b32  	%r269, %r268, 1123811328;
	mov.b32 	%f441, %r269;
	selp.f32 	%f442, %f441, %f439, %p33;
	mov.f32 	%f443, 0fBF317218;
	fma.rn.f32 	%f444, %f442, %f443, %f436;
	mov.f32 	%f445, 0f3102E308;
	fma.rn.f32 	%f446, %f442, %f445, %f444;
	mul.f32 	%f447, %f446, 0f3FB8AA3B;
	add.f32 	%f448, %f442, 0f4B40007F;
	mov.b32 	%r270, %f448;
	shl.b32 	%r271, %r270, 23;
	mov.b32 	%f449, %r271;
	ex2.approx.ftz.f32 	%f450, %f447;
	mul.f32 	%f64, %f450, %f449;
	setp.eq.f32 	%p34, %f64, 0f7F800000;
	mov.f32 	%f1186, 0f7F800000;
	@%p34 bra 	$L__BB9_27;

	fma.rn.f32 	%f1186, %f64, %f63, %f64;

$L__BB9_27:
	mov.f32 	%f1146, 0f3F800000;
	cvt.rzi.f32.f32 	%f1145, %f1146;
	add.f32 	%f1144, %f1145, %f1145;
	mov.f32 	%f1143, 0f40000000;
	sub.f32 	%f1142, %f1143, %f1144;
	abs.f32 	%f1141, %f1142;
	setp.lt.f32 	%p35, %f61, 0f00000000;
	setp.eq.f32 	%p36, %f1141, 0f3F800000;
	and.pred  	%p1, %p35, %p36;
	setp.eq.f32 	%p37, %f61, 0f00000000;
	@%p37 bra 	$L__BB9_31;
	bra.uni 	$L__BB9_28;

$L__BB9_31:
	add.f32 	%f455, %f61, %f61;
	selp.f32 	%f1188, %f455, 0f00000000, %p36;
	bra.uni 	$L__BB9_32;

$L__BB9_28:
	mov.b32 	%r272, %f1186;
	xor.b32  	%r273, %r272, -2147483648;
	mov.b32 	%f451, %r273;
	selp.f32 	%f1188, %f451, %f1186, %p1;
	setp.geu.f32 	%p38, %f61, 0f00000000;
	@%p38 bra 	$L__BB9_32;

	mov.f32 	%f1157, 0f40000000;
	cvt.rzi.f32.f32 	%f453, %f1157;
	setp.eq.f32 	%p39, %f453, 0f40000000;
	@%p39 bra 	$L__BB9_32;

	mov.f32 	%f1188, 0f7FFFFFFF;

$L__BB9_32:
	abs.f32 	%f1167, %f61;
	add.f32 	%f456, %f1167, 0f40000000;
	mov.b32 	%r274, %f456;
	setp.lt.s32 	%p41, %r274, 2139095040;
	@%p41 bra 	$L__BB9_37;

	abs.f32 	%f1168, %f61;
	setp.gtu.f32 	%p42, %f1168, 0f7F800000;
	@%p42 bra 	$L__BB9_36;
	bra.uni 	$L__BB9_34;

$L__BB9_36:
	add.f32 	%f1188, %f61, 0f40000000;
	bra.uni 	$L__BB9_37;

$L__BB9_34:
	abs.f32 	%f1169, %f61;
	setp.neu.f32 	%p43, %f1169, 0f7F800000;
	@%p43 bra 	$L__BB9_37;

	selp.f32 	%f1188, 0fFF800000, 0f7F800000, %p1;

$L__BB9_37:
	mov.f32 	%f1156, 0f3102E308;
	mov.f32 	%f1155, 0fBF317218;
	mov.f32 	%f1154, 0f00000000;
	mov.f32 	%f1153, 0f35BFBE8E;
	mov.f32 	%f1152, 0f3F317200;
	mov.f32 	%f1151, 0f3DAAAABD;
	mov.f32 	%f1150, 0f3C4CAF63;
	mov.f32 	%f1149, 0f3B18F0FE;
	mov.f32 	%f1148, 0f3FB8AA3B;
	mov.f32 	%f1147, 0f40000000;
	mul.f32 	%f458, %f1188, 0fBF000000;
	setp.eq.f32 	%p44, %f61, 0f3F800000;
	selp.f32 	%f459, 0fBF000000, %f458, %p44;
	mov.f32 	%f461, 0f3BBB989D;
	fma.rn.f32 	%f462, %f459, %f461, %f183;
	mov.f32 	%f464, 0f437C0000;
	cvt.sat.f32.f32 	%f465, %f462;
	mov.f32 	%f466, 0f4B400001;
	fma.rm.f32 	%f467, %f465, %f464, %f466;
	add.f32 	%f468, %f467, 0fCB40007F;
	neg.f32 	%f469, %f468;
	fma.rn.f32 	%f470, %f459, %f1148, %f469;
	mov.f32 	%f471, 0f32A57060;
	fma.rn.f32 	%f472, %f459, %f471, %f470;
	mov.b32 	%r275, %f467;
	shl.b32 	%r276, %r275, 23;
	mov.b32 	%f473, %r276;
	ex2.approx.ftz.f32 	%f474, %f472;
	mul.f32 	%f73, %f474, %f473;
	div.rn.f32 	%f74, %f43, %f182;
	abs.f32 	%f75, %f74;
	setp.lt.f32 	%p45, %f75, 0f00800000;
	mul.f32 	%f475, %f75, 0f4B800000;
	selp.f32 	%f476, %f475, %f75, %p45;
	selp.f32 	%f477, 0fC3170000, 0fC2FE0000, %p45;
	mov.b32 	%r277, %f476;
	and.b32  	%r278, %r277, 8388607;
	or.b32  	%r279, %r278, 1065353216;
	mov.b32 	%f478, %r279;
	shr.u32 	%r280, %r277, 23;
	cvt.rn.f32.u32 	%f479, %r280;
	add.f32 	%f480, %f477, %f479;
	setp.gt.f32 	%p46, %f478, 0f3FB504F3;
	mul.f32 	%f481, %f478, 0f3F000000;
	add.f32 	%f482, %f480, 0f3F800000;
	selp.f32 	%f483, %f482, %f480, %p46;
	selp.f32 	%f484, %f481, %f478, %p46;
	add.f32 	%f485, %f484, 0fBF800000;
	add.f32 	%f486, %f484, 0f3F800000;
	rcp.approx.ftz.f32 	%f487, %f486;
	add.f32 	%f488, %f485, %f485;
	mul.f32 	%f490, %f488, %f487;
	mul.f32 	%f491, %f490, %f490;
	fma.rn.f32 	%f494, %f1149, %f491, %f1150;
	fma.rn.f32 	%f496, %f494, %f491, %f1151;
	mul.rn.f32 	%f497, %f496, %f491;
	mul.rn.f32 	%f498, %f497, %f490;
	sub.f32 	%f499, %f485, %f490;
	add.f32 	%f500, %f499, %f499;
	neg.f32 	%f501, %f490;
	fma.rn.f32 	%f502, %f501, %f485, %f500;
	mul.rn.f32 	%f503, %f487, %f502;
	add.f32 	%f504, %f498, %f490;
	sub.f32 	%f505, %f490, %f504;
	add.f32 	%f506, %f498, %f505;
	add.f32 	%f507, %f503, %f506;
	add.f32 	%f508, %f504, %f507;
	sub.f32 	%f509, %f504, %f508;
	add.f32 	%f510, %f507, %f509;
	mul.rn.f32 	%f512, %f483, %f1152;
	mul.rn.f32 	%f514, %f483, %f1153;
	add.f32 	%f515, %f512, %f508;
	sub.f32 	%f516, %f512, %f515;
	add.f32 	%f517, %f508, %f516;
	add.f32 	%f518, %f510, %f517;
	add.f32 	%f519, %f514, %f518;
	add.f32 	%f520, %f515, %f519;
	sub.f32 	%f521, %f515, %f520;
	add.f32 	%f522, %f519, %f521;
	mul.rn.f32 	%f523, %f1147, %f520;
	neg.f32 	%f524, %f523;
	fma.rn.f32 	%f525, %f1147, %f520, %f524;
	fma.rn.f32 	%f526, %f1147, %f522, %f525;
	fma.rn.f32 	%f528, %f1154, %f520, %f526;
	add.rn.f32 	%f529, %f523, %f528;
	neg.f32 	%f530, %f529;
	add.rn.f32 	%f531, %f523, %f530;
	add.rn.f32 	%f532, %f531, %f528;
	mov.b32 	%r281, %f529;
	setp.eq.s32 	%p47, %r281, 1118925336;
	add.s32 	%r282, %r281, -1;
	mov.b32 	%f533, %r282;
	add.f32 	%f534, %f532, 0f37000000;
	selp.f32 	%f76, %f534, %f532, %p47;
	selp.f32 	%f535, %f533, %f529, %p47;
	mul.rn.f32 	%f536, %f535, %f1148;
	cvt.rzi.f32.f32 	%f537, %f536;
	abs.f32 	%f538, %f537;
	setp.gt.f32 	%p48, %f538, 0f42FC0000;
	mov.b32 	%r283, %f537;
	and.b32  	%r284, %r283, -2147483648;
	or.b32  	%r285, %r284, 1123811328;
	mov.b32 	%f539, %r285;
	selp.f32 	%f540, %f539, %f537, %p48;
	fma.rn.f32 	%f542, %f540, %f1155, %f535;
	fma.rn.f32 	%f544, %f540, %f1156, %f542;
	mul.f32 	%f545, %f544, 0f3FB8AA3B;
	add.f32 	%f546, %f540, 0f4B40007F;
	mov.b32 	%r286, %f546;
	shl.b32 	%r287, %r286, 23;
	mov.b32 	%f547, %r287;
	ex2.approx.ftz.f32 	%f548, %f545;
	mul.f32 	%f77, %f548, %f547;
	setp.eq.f32 	%p49, %f77, 0f7F800000;
	mov.f32 	%f1189, 0f7F800000;
	@%p49 bra 	$L__BB9_39;

	fma.rn.f32 	%f1189, %f77, %f76, %f77;

$L__BB9_39:
	setp.lt.f32 	%p50, %f74, 0f00000000;
	and.pred  	%p2, %p50, %p36;
	setp.eq.f32 	%p52, %f74, 0f00000000;
	@%p52 bra 	$L__BB9_43;
	bra.uni 	$L__BB9_40;

$L__BB9_43:
	add.f32 	%f553, %f74, %f74;
	selp.f32 	%f1191, %f553, 0f00000000, %p36;
	bra.uni 	$L__BB9_44;

$L__BB9_40:
	mov.b32 	%r288, %f1189;
	xor.b32  	%r289, %r288, -2147483648;
	mov.b32 	%f549, %r289;
	selp.f32 	%f1191, %f549, %f1189, %p2;
	setp.geu.f32 	%p53, %f74, 0f00000000;
	@%p53 bra 	$L__BB9_44;

	mov.f32 	%f1166, 0f40000000;
	cvt.rzi.f32.f32 	%f551, %f1166;
	setp.eq.f32 	%p54, %f551, 0f40000000;
	@%p54 bra 	$L__BB9_44;

	mov.f32 	%f1191, 0f7FFFFFFF;

$L__BB9_44:
	abs.f32 	%f1092, %f74;
	add.f32 	%f554, %f1092, 0f40000000;
	mov.b32 	%r290, %f554;
	setp.lt.s32 	%p56, %r290, 2139095040;
	@%p56 bra 	$L__BB9_49;

	abs.f32 	%f1164, %f74;
	setp.gtu.f32 	%p57, %f1164, 0f7F800000;
	@%p57 bra 	$L__BB9_48;
	bra.uni 	$L__BB9_46;

$L__BB9_48:
	add.f32 	%f1191, %f74, 0f40000000;
	bra.uni 	$L__BB9_49;

$L__BB9_46:
	abs.f32 	%f1165, %f74;
	setp.neu.f32 	%p58, %f1165, 0f7F800000;
	@%p58 bra 	$L__BB9_49;

	selp.f32 	%f1191, 0fFF800000, 0f7F800000, %p2;

$L__BB9_49:
	cvt.rn.f32.s32 	%f1108, %r541;
	add.f32 	%f1107, %f1108, 0f3F000000;
	mov.f32 	%f1106, 0f32A57060;
	mov.f32 	%f1105, 0f4B400001;
	mov.f32 	%f1104, 0f437C0000;
	mov.f32 	%f1103, 0f3BBB989D;
	mov.f32 	%f1102, 0f3102E308;
	mov.f32 	%f1101, 0fBF317218;
	mov.f32 	%f1100, 0f00000000;
	mov.f32 	%f1099, 0f35BFBE8E;
	mov.f32 	%f1098, 0f3F317200;
	mov.f32 	%f1097, 0f3DAAAABD;
	mov.f32 	%f1096, 0f3C4CAF63;
	mov.f32 	%f1095, 0f3B18F0FE;
	mov.f32 	%f1094, 0f3FB8AA3B;
	mov.f32 	%f1093, 0f40000000;
	mul.f32 	%f556, %f1191, 0fBF000000;
	setp.eq.f32 	%p59, %f74, 0f3F800000;
	selp.f32 	%f557, 0fBF000000, %f556, %p59;
	fma.rn.f32 	%f560, %f557, %f1103, %f183;
	cvt.sat.f32.f32 	%f563, %f560;
	fma.rm.f32 	%f565, %f563, %f1104, %f1105;
	add.f32 	%f566, %f565, 0fCB40007F;
	neg.f32 	%f567, %f566;
	fma.rn.f32 	%f568, %f557, %f1094, %f567;
	fma.rn.f32 	%f570, %f557, %f1106, %f568;
	mov.b32 	%r291, %f565;
	shl.b32 	%r292, %r291, 23;
	mov.b32 	%f571, %r292;
	ex2.approx.ftz.f32 	%f572, %f570;
	mul.f32 	%f573, %f572, %f571;
	sub.f32 	%f574, %f73, %f573;
	mul.f32 	%f575, %f2, %f574;
	mul.f32 	%f86, %f60, %f575;
	sub.f32 	%f576, %f1107, %f36;
	div.rn.f32 	%f87, %f576, %f182;
	abs.f32 	%f88, %f87;
	setp.lt.f32 	%p60, %f88, 0f00800000;
	mul.f32 	%f577, %f88, 0f4B800000;
	selp.f32 	%f578, %f577, %f88, %p60;
	selp.f32 	%f579, 0fC3170000, 0fC2FE0000, %p60;
	mov.b32 	%r293, %f578;
	and.b32  	%r294, %r293, 8388607;
	or.b32  	%r295, %r294, 1065353216;
	mov.b32 	%f580, %r295;
	shr.u32 	%r296, %r293, 23;
	cvt.rn.f32.u32 	%f581, %r296;
	add.f32 	%f582, %f579, %f581;
	setp.gt.f32 	%p61, %f580, 0f3FB504F3;
	mul.f32 	%f583, %f580, 0f3F000000;
	add.f32 	%f584, %f582, 0f3F800000;
	selp.f32 	%f585, %f584, %f582, %p61;
	selp.f32 	%f586, %f583, %f580, %p61;
	add.f32 	%f587, %f586, 0fBF800000;
	add.f32 	%f588, %f586, 0f3F800000;
	rcp.approx.ftz.f32 	%f589, %f588;
	add.f32 	%f590, %f587, %f587;
	mul.f32 	%f592, %f590, %f589;
	mul.f32 	%f593, %f592, %f592;
	fma.rn.f32 	%f596, %f1095, %f593, %f1096;
	fma.rn.f32 	%f598, %f596, %f593, %f1097;
	mul.rn.f32 	%f599, %f598, %f593;
	mul.rn.f32 	%f600, %f599, %f592;
	sub.f32 	%f601, %f587, %f592;
	add.f32 	%f602, %f601, %f601;
	neg.f32 	%f603, %f592;
	fma.rn.f32 	%f604, %f603, %f587, %f602;
	mul.rn.f32 	%f605, %f589, %f604;
	add.f32 	%f606, %f600, %f592;
	sub.f32 	%f607, %f592, %f606;
	add.f32 	%f608, %f600, %f607;
	add.f32 	%f609, %f605, %f608;
	add.f32 	%f610, %f606, %f609;
	sub.f32 	%f611, %f606, %f610;
	add.f32 	%f612, %f609, %f611;
	mul.rn.f32 	%f614, %f585, %f1098;
	mul.rn.f32 	%f616, %f585, %f1099;
	add.f32 	%f617, %f614, %f610;
	sub.f32 	%f618, %f614, %f617;
	add.f32 	%f619, %f610, %f618;
	add.f32 	%f620, %f612, %f619;
	add.f32 	%f621, %f616, %f620;
	add.f32 	%f622, %f617, %f621;
	sub.f32 	%f623, %f617, %f622;
	add.f32 	%f624, %f621, %f623;
	mul.rn.f32 	%f625, %f1093, %f622;
	neg.f32 	%f626, %f625;
	fma.rn.f32 	%f627, %f1093, %f622, %f626;
	fma.rn.f32 	%f628, %f1093, %f624, %f627;
	fma.rn.f32 	%f630, %f1100, %f622, %f628;
	add.rn.f32 	%f631, %f625, %f630;
	neg.f32 	%f632, %f631;
	add.rn.f32 	%f633, %f625, %f632;
	add.rn.f32 	%f634, %f633, %f630;
	mov.b32 	%r297, %f631;
	setp.eq.s32 	%p62, %r297, 1118925336;
	add.s32 	%r298, %r297, -1;
	mov.b32 	%f635, %r298;
	add.f32 	%f636, %f634, 0f37000000;
	selp.f32 	%f89, %f636, %f634, %p62;
	selp.f32 	%f637, %f635, %f631, %p62;
	mul.rn.f32 	%f638, %f637, %f1094;
	cvt.rzi.f32.f32 	%f639, %f638;
	abs.f32 	%f640, %f639;
	setp.gt.f32 	%p63, %f640, 0f42FC0000;
	mov.b32 	%r299, %f639;
	and.b32  	%r300, %r299, -2147483648;
	or.b32  	%r301, %r300, 1123811328;
	mov.b32 	%f641, %r301;
	selp.f32 	%f642, %f641, %f639, %p63;
	fma.rn.f32 	%f644, %f642, %f1101, %f637;
	fma.rn.f32 	%f646, %f642, %f1102, %f644;
	mul.f32 	%f647, %f646, 0f3FB8AA3B;
	add.f32 	%f648, %f642, 0f4B40007F;
	mov.b32 	%r302, %f648;
	shl.b32 	%r303, %r302, 23;
	mov.b32 	%f649, %r303;
	ex2.approx.ftz.f32 	%f650, %f647;
	mul.f32 	%f90, %f650, %f649;
	setp.eq.f32 	%p64, %f90, 0f7F800000;
	mov.f32 	%f1192, 0f7F800000;
	@%p64 bra 	$L__BB9_51;

	fma.rn.f32 	%f1192, %f90, %f89, %f90;

$L__BB9_51:
	setp.lt.f32 	%p65, %f87, 0f00000000;
	and.pred  	%p3, %p65, %p36;
	setp.eq.f32 	%p67, %f87, 0f00000000;
	@%p67 bra 	$L__BB9_55;
	bra.uni 	$L__BB9_52;

$L__BB9_55:
	add.f32 	%f655, %f87, %f87;
	selp.f32 	%f1194, %f655, 0f00000000, %p36;
	bra.uni 	$L__BB9_56;

$L__BB9_52:
	mov.b32 	%r304, %f1192;
	xor.b32  	%r305, %r304, -2147483648;
	mov.b32 	%f651, %r305;
	selp.f32 	%f1194, %f651, %f1192, %p3;
	setp.geu.f32 	%p68, %f87, 0f00000000;
	@%p68 bra 	$L__BB9_56;

	mov.f32 	%f1163, 0f40000000;
	cvt.rzi.f32.f32 	%f653, %f1163;
	setp.eq.f32 	%p69, %f653, 0f40000000;
	@%p69 bra 	$L__BB9_56;

	mov.f32 	%f1194, 0f7FFFFFFF;

$L__BB9_56:
	abs.f32 	%f1170, %f87;
	add.f32 	%f656, %f1170, 0f40000000;
	mov.b32 	%r306, %f656;
	setp.lt.s32 	%p71, %r306, 2139095040;
	@%p71 bra 	$L__BB9_61;

	abs.f32 	%f1171, %f87;
	setp.gtu.f32 	%p72, %f1171, 0f7F800000;
	@%p72 bra 	$L__BB9_60;
	bra.uni 	$L__BB9_58;

$L__BB9_60:
	add.f32 	%f1194, %f87, 0f40000000;
	bra.uni 	$L__BB9_61;

$L__BB9_58:
	abs.f32 	%f1172, %f87;
	setp.neu.f32 	%p73, %f1172, 0f7F800000;
	@%p73 bra 	$L__BB9_61;

	selp.f32 	%f1194, 0fFF800000, 0f7F800000, %p3;

$L__BB9_61:
	cvt.rn.f32.s32 	%f1125, %r541;
	sub.f32 	%f1124, %f1125, %f36;
	add.f32 	%f1123, %f1124, 0fBF000000;
	mov.f32 	%f1122, 0f32A57060;
	mov.f32 	%f1121, 0f4B400001;
	mov.f32 	%f1120, 0f437C0000;
	mov.f32 	%f1119, 0f3BBB989D;
	mov.f32 	%f1118, 0f3102E308;
	mov.f32 	%f1117, 0fBF317218;
	mov.f32 	%f1116, 0f00000000;
	mov.f32 	%f1115, 0f35BFBE8E;
	mov.f32 	%f1114, 0f3F317200;
	mov.f32 	%f1113, 0f3DAAAABD;
	mov.f32 	%f1112, 0f3C4CAF63;
	mov.f32 	%f1111, 0f3B18F0FE;
	mov.f32 	%f1110, 0f3FB8AA3B;
	mov.f32 	%f1109, 0f40000000;
	mul.f32 	%f658, %f1194, 0fBF000000;
	setp.eq.f32 	%p74, %f87, 0f3F800000;
	selp.f32 	%f659, 0fBF000000, %f658, %p74;
	fma.rn.f32 	%f662, %f659, %f1119, %f183;
	cvt.sat.f32.f32 	%f665, %f662;
	fma.rm.f32 	%f667, %f665, %f1120, %f1121;
	add.f32 	%f668, %f667, 0fCB40007F;
	neg.f32 	%f669, %f668;
	fma.rn.f32 	%f670, %f659, %f1110, %f669;
	fma.rn.f32 	%f672, %f659, %f1122, %f670;
	mov.b32 	%r307, %f667;
	shl.b32 	%r308, %r307, 23;
	mov.b32 	%f673, %r308;
	ex2.approx.ftz.f32 	%f674, %f672;
	mul.f32 	%f99, %f674, %f673;
	div.rn.f32 	%f100, %f1123, %f182;
	abs.f32 	%f101, %f100;
	setp.lt.f32 	%p75, %f101, 0f00800000;
	mul.f32 	%f675, %f101, 0f4B800000;
	selp.f32 	%f676, %f675, %f101, %p75;
	selp.f32 	%f677, 0fC3170000, 0fC2FE0000, %p75;
	mov.b32 	%r309, %f676;
	and.b32  	%r310, %r309, 8388607;
	or.b32  	%r311, %r310, 1065353216;
	mov.b32 	%f678, %r311;
	shr.u32 	%r312, %r309, 23;
	cvt.rn.f32.u32 	%f679, %r312;
	add.f32 	%f680, %f677, %f679;
	setp.gt.f32 	%p76, %f678, 0f3FB504F3;
	mul.f32 	%f681, %f678, 0f3F000000;
	add.f32 	%f682, %f680, 0f3F800000;
	selp.f32 	%f683, %f682, %f680, %p76;
	selp.f32 	%f684, %f681, %f678, %p76;
	add.f32 	%f685, %f684, 0fBF800000;
	add.f32 	%f686, %f684, 0f3F800000;
	rcp.approx.ftz.f32 	%f687, %f686;
	add.f32 	%f688, %f685, %f685;
	mul.f32 	%f690, %f688, %f687;
	mul.f32 	%f691, %f690, %f690;
	fma.rn.f32 	%f694, %f1111, %f691, %f1112;
	fma.rn.f32 	%f696, %f694, %f691, %f1113;
	mul.rn.f32 	%f697, %f696, %f691;
	mul.rn.f32 	%f698, %f697, %f690;
	sub.f32 	%f699, %f685, %f690;
	add.f32 	%f700, %f699, %f699;
	neg.f32 	%f701, %f690;
	fma.rn.f32 	%f702, %f701, %f685, %f700;
	mul.rn.f32 	%f703, %f687, %f702;
	add.f32 	%f704, %f698, %f690;
	sub.f32 	%f705, %f690, %f704;
	add.f32 	%f706, %f698, %f705;
	add.f32 	%f707, %f703, %f706;
	add.f32 	%f708, %f704, %f707;
	sub.f32 	%f709, %f704, %f708;
	add.f32 	%f710, %f707, %f709;
	mul.rn.f32 	%f712, %f683, %f1114;
	mul.rn.f32 	%f714, %f683, %f1115;
	add.f32 	%f715, %f712, %f708;
	sub.f32 	%f716, %f712, %f715;
	add.f32 	%f717, %f708, %f716;
	add.f32 	%f718, %f710, %f717;
	add.f32 	%f719, %f714, %f718;
	add.f32 	%f720, %f715, %f719;
	sub.f32 	%f721, %f715, %f720;
	add.f32 	%f722, %f719, %f721;
	mul.rn.f32 	%f723, %f1109, %f720;
	neg.f32 	%f724, %f723;
	fma.rn.f32 	%f725, %f1109, %f720, %f724;
	fma.rn.f32 	%f726, %f1109, %f722, %f725;
	fma.rn.f32 	%f728, %f1116, %f720, %f726;
	add.rn.f32 	%f729, %f723, %f728;
	neg.f32 	%f730, %f729;
	add.rn.f32 	%f731, %f723, %f730;
	add.rn.f32 	%f732, %f731, %f728;
	mov.b32 	%r313, %f729;
	setp.eq.s32 	%p77, %r313, 1118925336;
	add.s32 	%r314, %r313, -1;
	mov.b32 	%f733, %r314;
	add.f32 	%f734, %f732, 0f37000000;
	selp.f32 	%f102, %f734, %f732, %p77;
	selp.f32 	%f735, %f733, %f729, %p77;
	mul.rn.f32 	%f736, %f735, %f1110;
	cvt.rzi.f32.f32 	%f737, %f736;
	abs.f32 	%f738, %f737;
	setp.gt.f32 	%p78, %f738, 0f42FC0000;
	mov.b32 	%r315, %f737;
	and.b32  	%r316, %r315, -2147483648;
	or.b32  	%r317, %r316, 1123811328;
	mov.b32 	%f739, %r317;
	selp.f32 	%f740, %f739, %f737, %p78;
	fma.rn.f32 	%f742, %f740, %f1117, %f735;
	fma.rn.f32 	%f744, %f740, %f1118, %f742;
	mul.f32 	%f745, %f744, 0f3FB8AA3B;
	add.f32 	%f746, %f740, 0f4B40007F;
	mov.b32 	%r318, %f746;
	shl.b32 	%r319, %r318, 23;
	mov.b32 	%f747, %r319;
	ex2.approx.ftz.f32 	%f748, %f745;
	mul.f32 	%f103, %f748, %f747;
	setp.eq.f32 	%p79, %f103, 0f7F800000;
	mov.f32 	%f1195, 0f7F800000;
	@%p79 bra 	$L__BB9_63;

	fma.rn.f32 	%f1195, %f103, %f102, %f103;

$L__BB9_63:
	setp.lt.f32 	%p80, %f100, 0f00000000;
	and.pred  	%p4, %p80, %p36;
	setp.eq.f32 	%p82, %f100, 0f00000000;
	@%p82 bra 	$L__BB9_67;
	bra.uni 	$L__BB9_64;

$L__BB9_67:
	add.f32 	%f753, %f100, %f100;
	selp.f32 	%f1197, %f753, 0f00000000, %p36;
	bra.uni 	$L__BB9_68;

$L__BB9_64:
	mov.b32 	%r320, %f1195;
	xor.b32  	%r321, %r320, -2147483648;
	mov.b32 	%f749, %r321;
	selp.f32 	%f1197, %f749, %f1195, %p4;
	setp.geu.f32 	%p83, %f100, 0f00000000;
	@%p83 bra 	$L__BB9_68;

	mov.f32 	%f1162, 0f40000000;
	cvt.rzi.f32.f32 	%f751, %f1162;
	setp.eq.f32 	%p84, %f751, 0f40000000;
	@%p84 bra 	$L__BB9_68;

	mov.f32 	%f1197, 0f7FFFFFFF;

$L__BB9_68:
	abs.f32 	%f1173, %f100;
	add.f32 	%f754, %f1173, 0f40000000;
	mov.b32 	%r322, %f754;
	setp.lt.s32 	%p86, %r322, 2139095040;
	@%p86 bra 	$L__BB9_73;

	abs.f32 	%f1174, %f100;
	setp.gtu.f32 	%p87, %f1174, 0f7F800000;
	@%p87 bra 	$L__BB9_72;
	bra.uni 	$L__BB9_70;

$L__BB9_72:
	add.f32 	%f1197, %f100, 0f40000000;
	bra.uni 	$L__BB9_73;

$L__BB9_70:
	abs.f32 	%f1175, %f100;
	setp.neu.f32 	%p88, %f1175, 0f7F800000;
	@%p88 bra 	$L__BB9_73;

	selp.f32 	%f1197, 0fFF800000, 0f7F800000, %p4;

$L__BB9_73:
	setp.neu.f32 	%p247, %f37, 0f00000000;
	setp.neu.f32 	%p246, %f37, 0f00000000;
	selp.f32 	%f1131, 0f3F800000, 0f00000000, %p246;
	mov.f32 	%f1130, 0f32A57060;
	mov.f32 	%f1129, 0f4B400001;
	mov.f32 	%f1128, 0f437C0000;
	mov.f32 	%f1127, 0f3BBB989D;
	mov.f32 	%f1126, 0f3FB8AA3B;
	mul.f32 	%f755, %f1197, 0fBF000000;
	setp.eq.f32 	%p89, %f100, 0f3F800000;
	selp.f32 	%f756, 0fBF000000, %f755, %p89;
	fma.rn.f32 	%f759, %f756, %f1127, %f183;
	cvt.sat.f32.f32 	%f762, %f759;
	fma.rm.f32 	%f764, %f762, %f1128, %f1129;
	add.f32 	%f765, %f764, 0fCB40007F;
	neg.f32 	%f766, %f765;
	fma.rn.f32 	%f767, %f756, %f1126, %f766;
	fma.rn.f32 	%f769, %f756, %f1130, %f767;
	mov.b32 	%r323, %f764;
	shl.b32 	%r324, %r323, 23;
	mov.b32 	%f770, %r324;
	ex2.approx.ftz.f32 	%f771, %f769;
	mul.f32 	%f772, %f771, %f770;
	sub.f32 	%f773, %f99, %f772;
	mul.f32 	%f774, %f2, %f773;
	mul.f32 	%f775, %f48, 0f3F000000;
	mul.f32 	%f776, %f775, %f1131;
	mul.f32 	%f777, %f776, %f774;
	mul.f32 	%f778, %f777, %f1131;
	shl.b32 	%r325, %r544, 1;
	mul.wide.s32 	%rd76, %r325, 4;
	add.s64 	%rd77, %rd4, %rd76;
	mul.f32 	%f779, %f86, %f1131;
	st.local.f32 	[%rd77], %f779;
	st.local.f32 	[%rd77+4], %f778;
	selp.u32 	%r326, 1, 0, %p246;
	add.s32 	%r545, %r545, %r326;
	add.s32 	%r544, %r544, 1;
	setp.lt.s32 	%p91, %r544, %r214;
	@%p91 bra 	$L__BB9_17;

$L__BB9_74:
	shl.b32 	%r13, %r545, 1;
	setp.eq.s32 	%p92, %r545, 0;
	@%p92 bra 	$L__BB9_76;

	mul.wide.s32 	%rd78, %r13, 4;
	add.s64 	%rd79, %rd4, %rd78;
	mov.u32 	%r327, 1065353216;
	st.local.u32 	[%rd79], %r327;

$L__BB9_76:
	add.s32 	%r14, %r13, 1;
	mov.u32 	%r328, 0;
	max.s32 	%r15, %r13, 0;
	add.s32 	%r329, %r15, 1;
	and.b32  	%r16, %r329, 3;
	sub.s32 	%r17, %r329, %r16;
	mov.u32 	%r546, %r328;

$L__BB9_77:
	mul.wide.s32 	%rd80, %r546, 4;
	add.s64 	%rd81, %rd4, %rd80;
	ld.local.f32 	%f112, [%rd81];
	mul.lo.s32 	%r19, %r546, %r14;
	setp.lt.u32 	%p93, %r15, 3;
	mov.u32 	%r549, %r328;
	@%p93 bra 	$L__BB9_80;

	mov.u32 	%r549, %r328;
	mov.u32 	%r548, %r17;

$L__BB9_79:
	mul.wide.s32 	%rd82, %r549, 4;
	add.s64 	%rd83, %rd4, %rd82;
	ld.local.f32 	%f780, [%rd83];
	mul.f32 	%f781, %f112, %f780;
	div.rn.f32 	%f782, %f781, %f1181;
	add.s32 	%r332, %r549, %r19;
	mul.wide.s32 	%rd84, %r332, 4;
	add.s64 	%rd85, %rd5, %rd84;
	ld.local.f32 	%f783, [%rd85];
	add.f32 	%f784, %f783, %f782;
	st.local.f32 	[%rd85], %f784;
	ld.local.f32 	%f785, [%rd83+4];
	mul.f32 	%f786, %f112, %f785;
	div.rn.f32 	%f787, %f786, %f1181;
	ld.local.f32 	%f788, [%rd85+4];
	add.f32 	%f789, %f788, %f787;
	st.local.f32 	[%rd85+4], %f789;
	ld.local.f32 	%f790, [%rd83+8];
	mul.f32 	%f791, %f112, %f790;
	div.rn.f32 	%f792, %f791, %f1181;
	ld.local.f32 	%f793, [%rd85+8];
	add.f32 	%f794, %f793, %f792;
	st.local.f32 	[%rd85+8], %f794;
	ld.local.f32 	%f795, [%rd83+12];
	mul.f32 	%f796, %f112, %f795;
	div.rn.f32 	%f797, %f796, %f1181;
	ld.local.f32 	%f798, [%rd85+12];
	add.f32 	%f799, %f798, %f797;
	st.local.f32 	[%rd85+12], %f799;
	add.s32 	%r549, %r549, 4;
	add.s32 	%r548, %r548, -4;
	setp.ne.s32 	%p94, %r548, 0;
	@%p94 bra 	$L__BB9_79;

$L__BB9_80:
	mul.wide.s32 	%rd86, %r549, 4;
	add.s64 	%rd13, %rd4, %rd86;
	ld.local.f32 	%f800, [%rd13];
	mul.f32 	%f801, %f112, %f800;
	div.rn.f32 	%f802, %f801, %f1181;
	add.s32 	%r333, %r549, %r19;
	mul.wide.s32 	%rd87, %r333, 4;
	add.s64 	%rd14, %rd5, %rd87;
	ld.local.f32 	%f803, [%rd14];
	add.f32 	%f804, %f803, %f802;
	st.local.f32 	[%rd14], %f804;
	setp.eq.s32 	%p95, %r16, 1;
	@%p95 bra 	$L__BB9_82;

	ld.local.f32 	%f805, [%rd13+4];
	mul.f32 	%f806, %f112, %f805;
	div.rn.f32 	%f807, %f806, %f1181;
	ld.local.f32 	%f808, [%rd14+4];
	add.f32 	%f809, %f808, %f807;
	st.local.f32 	[%rd14+4], %f809;
	ld.local.f32 	%f810, [%rd13+8];
	mul.f32 	%f811, %f112, %f810;
	div.rn.f32 	%f812, %f811, %f1181;
	ld.local.f32 	%f813, [%rd14+8];
	add.f32 	%f814, %f813, %f812;
	st.local.f32 	[%rd14+8], %f814;

$L__BB9_82:
	add.s32 	%r25, %r546, 1;
	setp.lt.s32 	%p96, %r546, %r13;
	mov.u32 	%r546, %r25;
	@%p96 bra 	$L__BB9_77;

	add.s32 	%r541, %r541, 1;
	setp.lt.s32 	%p97, %r541, %r213;
	@%p97 bra 	$L__BB9_4;

	add.s32 	%r540, %r540, 1;
	setp.lt.s32 	%p98, %r540, %r213;
	@%p98 bra 	$L__BB9_3;

$L__BB9_85:
	mov.u32 	%r535, 0;
	st.local.u32 	[%rd4], %r535;
	st.local.u32 	[%rd4+4], %r535;
	st.local.u32 	[%rd4+8], %r535;
	st.local.u32 	[%rd4+12], %r535;
	st.local.u32 	[%rd4+16], %r535;
	st.local.u32 	[%rd4+20], %r535;
	st.local.u32 	[%rd4+24], %r535;
	st.local.u32 	[%rd4+28], %r535;
	st.local.u32 	[%rd4+32], %r535;
	st.local.u32 	[%rd4+36], %r535;
	st.local.u32 	[%rd4+40], %r535;
	st.local.u32 	[%rd4+44], %r535;
	st.local.u32 	[%rd4+48], %r535;
	st.local.u32 	[%rd4+52], %r535;
	st.local.u32 	[%rd4+56], %r535;
	st.local.u32 	[%rd4+60], %r535;
	st.local.u32 	[%rd4+64], %r535;
	st.local.u32 	[%rd4+68], %r535;
	st.local.u32 	[%rd4+72], %r535;
	st.local.u32 	[%rd4+76], %r535;
	st.local.u32 	[%rd4+80], %r535;
	st.local.u32 	[%rd4+84], %r535;
	st.local.u32 	[%rd4+88], %r535;
	st.local.u32 	[%rd4+92], %r535;
	st.local.u32 	[%rd4+96], %r535;
	st.local.u32 	[%rd4+100], %r535;
	st.local.u32 	[%rd4+104], %r535;
	st.local.u32 	[%rd4+108], %r535;
	st.local.u32 	[%rd4+112], %r535;
	st.local.u32 	[%rd4+116], %r535;
	st.local.u32 	[%rd4+120], %r535;
	st.local.u32 	[%rd4+124], %r535;
	st.local.u32 	[%rd4+128], %r535;
	st.local.u32 	[%rd4+132], %r535;
	st.local.u32 	[%rd4+136], %r535;
	st.local.u32 	[%rd4+140], %r535;
	st.local.u32 	[%rd4+144], %r535;
	st.local.u32 	[%rd4+148], %r535;
	st.local.u32 	[%rd4+152], %r535;
	st.local.u32 	[%rd4+156], %r535;
	st.local.u32 	[%rd4+160], %r535;
	st.local.u32 	[%rd4+164], %r535;
	st.local.u32 	[%rd4+168], %r535;
	st.local.u32 	[%rd4+172], %r535;
	st.local.u32 	[%rd4+176], %r535;
	st.local.u32 	[%rd4+180], %r535;
	st.local.u32 	[%rd4+184], %r535;
	st.local.u32 	[%rd4+188], %r535;
	st.local.u32 	[%rd4+192], %r535;
	st.local.u32 	[%rd4+196], %r535;
	st.local.u32 	[%rd4+200], %r535;
	st.local.u32 	[%rd4+204], %r535;
	st.local.u32 	[%rd4+208], %r535;
	st.local.u32 	[%rd4+212], %r535;
	st.local.u32 	[%rd4+216], %r535;
	st.local.u32 	[%rd4+220], %r535;
	st.local.u32 	[%rd4+224], %r535;
	st.local.u32 	[%rd4+228], %r535;
	st.local.u32 	[%rd4+232], %r535;
	st.local.u32 	[%rd4+236], %r535;
	st.local.u32 	[%rd4+240], %r535;
	st.local.u32 	[%rd4+244], %r535;
	st.local.u32 	[%rd4+248], %r535;
	st.local.u32 	[%rd4+252], %r535;
	st.local.u32 	[%rd4+256], %r535;
	st.local.u32 	[%rd4+260], %r535;
	st.local.u32 	[%rd4+264], %r535;
	st.local.u32 	[%rd4+268], %r535;
	st.local.u32 	[%rd4+272], %r535;
	st.local.u32 	[%rd4+276], %r535;
	st.local.u32 	[%rd4+280], %r535;
	st.local.u32 	[%rd4+284], %r535;
	st.local.u32 	[%rd4+288], %r535;
	st.local.u32 	[%rd4+292], %r535;
	st.local.u32 	[%rd4+296], %r535;
	st.local.u32 	[%rd4+300], %r535;
	st.local.u32 	[%rd4+304], %r535;
	st.local.u32 	[%rd4+308], %r535;
	st.local.u32 	[%rd4+312], %r535;
	st.local.u32 	[%rd4+316], %r535;
	st.local.u32 	[%rd4+320], %r535;
	st.local.u32 	[%rd4+324], %r535;
	st.local.u32 	[%rd4+328], %r535;
	st.local.u32 	[%rd4+332], %r535;
	st.local.u32 	[%rd4+336], %r535;
	st.local.u32 	[%rd4+340], %r535;
	st.local.u32 	[%rd4+344], %r535;
	st.local.u32 	[%rd4+348], %r535;
	st.local.u32 	[%rd4+352], %r535;
	st.local.u32 	[%rd4+356], %r535;
	st.local.u32 	[%rd4+360], %r535;
	st.local.u32 	[%rd4+364], %r535;
	st.local.u32 	[%rd4+368], %r535;
	st.local.u32 	[%rd4+372], %r535;
	st.local.u32 	[%rd4+376], %r535;
	st.local.u32 	[%rd4+380], %r535;
	st.local.u32 	[%rd4+384], %r535;
	st.local.u32 	[%rd4+388], %r535;
	st.local.u32 	[%rd4+392], %r535;
	st.local.u32 	[%rd4+396], %r535;
	st.local.u32 	[%rd4+400], %r535;
	st.local.u32 	[%rd4+404], %r535;
	st.local.u32 	[%rd4+408], %r535;
	st.local.u32 	[%rd4+412], %r535;
	st.local.u32 	[%rd4+416], %r535;
	st.local.u32 	[%rd4+420], %r535;
	st.local.u32 	[%rd4+424], %r535;
	st.local.u32 	[%rd4+428], %r535;
	st.local.u32 	[%rd4+432], %r535;
	st.local.u32 	[%rd4+436], %r535;
	st.local.u32 	[%rd4+440], %r535;
	st.local.u32 	[%rd4+444], %r535;
	st.local.u32 	[%rd4+448], %r535;
	st.local.u32 	[%rd4+452], %r535;
	st.local.u32 	[%rd4+456], %r535;
	st.local.u32 	[%rd4+460], %r535;
	st.local.u32 	[%rd4+464], %r535;
	st.local.u32 	[%rd4+468], %r535;
	st.local.u32 	[%rd4+472], %r535;
	st.local.u32 	[%rd4+476], %r535;
	st.local.u32 	[%rd4+480], %r535;
	shl.b32 	%r29, %r545, 1;
	or.b32  	%r30, %r29, 1;
	setp.lt.s32 	%p99, %r545, 1;
	@%p99 bra 	$L__BB9_247;

	add.s64 	%rd15, %rd5, 4;
	mov.u32 	%r335, 0;
	max.s32 	%r31, %r29, 0;
	add.s32 	%r336, %r31, 1;
	and.b32  	%r32, %r336, 3;
	sub.s32 	%r33, %r336, %r32;
	mul.wide.s32 	%rd88, %r29, 4;
	add.s64 	%rd16, %rd88, 4;
	setp.lt.u32 	%p100, %r31, 3;
	setp.eq.s32 	%p102, %r32, 1;
	mov.u32 	%r551, %r335;

$L__BB9_87:
	mov.u32 	%r554, %r335;
	@%p100 bra 	$L__BB9_90;

	mov.u32 	%r554, %r335;
	mov.u32 	%r553, %r33;

$L__BB9_89:
	mad.lo.s32 	%r339, %r554, %r30, %r551;
	mul.wide.s32 	%rd89, %r339, 4;
	add.s64 	%rd90, %rd5, %rd89;
	ld.local.f32 	%f815, [%rd90];
	add.s64 	%rd91, %rd6, %rd89;
	st.local.f32 	[%rd91], %f815;
	add.s64 	%rd92, %rd90, %rd16;
	ld.local.f32 	%f816, [%rd92];
	add.s64 	%rd93, %rd91, %rd16;
	st.local.f32 	[%rd93], %f816;
	add.s64 	%rd94, %rd92, %rd16;
	ld.local.f32 	%f817, [%rd94];
	add.s64 	%rd95, %rd93, %rd16;
	st.local.f32 	[%rd95], %f817;
	add.s64 	%rd96, %rd94, %rd16;
	ld.local.f32 	%f818, [%rd96];
	add.s64 	%rd97, %rd95, %rd16;
	st.local.f32 	[%rd97], %f818;
	add.s32 	%r554, %r554, 4;
	add.s32 	%r553, %r553, -4;
	setp.ne.s32 	%p101, %r553, 0;
	@%p101 bra 	$L__BB9_89;

$L__BB9_90:
	mad.lo.s32 	%r40, %r554, %r30, %r551;
	mul.wide.s32 	%rd98, %r40, 4;
	add.s64 	%rd99, %rd5, %rd98;
	ld.local.f32 	%f819, [%rd99];
	add.s64 	%rd100, %rd6, %rd98;
	st.local.f32 	[%rd100], %f819;
	@%p102 bra 	$L__BB9_92;

	add.s32 	%r340, %r40, %r30;
	mul.wide.s32 	%rd101, %r340, 4;
	add.s64 	%rd102, %rd5, %rd101;
	ld.local.f32 	%f820, [%rd102];
	add.s64 	%rd103, %rd6, %rd101;
	st.local.f32 	[%rd103], %f820;
	add.s32 	%r341, %r340, %r30;
	mul.wide.s32 	%rd104, %r341, 4;
	add.s64 	%rd105, %rd5, %rd104;
	ld.local.f32 	%f821, [%rd105];
	add.s64 	%rd106, %rd6, %rd104;
	st.local.f32 	[%rd106], %f821;

$L__BB9_92:
	add.s32 	%r41, %r551, 1;
	setp.lt.s32 	%p103, %r551, %r29;
	mov.u32 	%r551, %r41;
	@%p103 bra 	$L__BB9_87;

	add.s32 	%r42, %r545, -1;
	and.b32  	%r582, %r545, 3;
	sub.s32 	%r579, %r545, %r582;
	mov.u32 	%r342, 0;
	setp.lt.u32 	%p104, %r42, 3;
	setp.eq.s32 	%p110, %r582, 0;
	setp.eq.s32 	%p112, %r582, 1;
	setp.eq.s32 	%p114, %r582, 2;
	mov.u32 	%r555, %r342;

$L__BB9_94:
	shl.b32 	%r344, %r555, 1;
	or.b32  	%r345, %r344, 1;
	mad.lo.s32 	%r46, %r345, %r30, 1;
	mul.lo.s32 	%r47, %r344, %r30;
	mov.u32 	%r558, %r342;
	@%p104 bra 	$L__BB9_105;

	mov.u32 	%r558, %r342;
	mov.u32 	%r557, %r579;

$L__BB9_96:
	shl.b32 	%r347, %r558, 1;
	add.s32 	%r348, %r46, %r347;
	mul.wide.s32 	%rd107, %r348, 4;
	add.s64 	%rd17, %rd6, %rd107;
	add.s32 	%r349, %r347, %r47;
	mul.wide.s32 	%rd108, %r349, 4;
	add.s64 	%rd18, %rd6, %rd108;
	setp.eq.s32 	%p105, %r555, %r558;
	@%p105 bra 	$L__BB9_98;

	mov.u32 	%r350, 0;
	st.local.u32 	[%rd17], %r350;
	st.local.u32 	[%rd18], %r350;

$L__BB9_98:
	add.s32 	%r351, %r558, 1;
	setp.eq.s32 	%p106, %r555, %r351;
	@%p106 bra 	$L__BB9_100;

	mov.u32 	%r352, 0;
	st.local.u32 	[%rd17+8], %r352;
	st.local.u32 	[%rd18+8], %r352;

$L__BB9_100:
	add.s32 	%r353, %r558, 2;
	setp.eq.s32 	%p107, %r555, %r353;
	@%p107 bra 	$L__BB9_102;

	mov.u32 	%r354, 0;
	st.local.u32 	[%rd17+16], %r354;
	st.local.u32 	[%rd18+16], %r354;

$L__BB9_102:
	add.s32 	%r355, %r558, 3;
	setp.eq.s32 	%p108, %r555, %r355;
	@%p108 bra 	$L__BB9_104;

	mov.u32 	%r356, 0;
	st.local.u32 	[%rd17+24], %r356;
	st.local.u32 	[%rd18+24], %r356;

$L__BB9_104:
	add.s32 	%r558, %r558, 4;
	add.s32 	%r557, %r557, -4;
	setp.ne.s32 	%p109, %r557, 0;
	@%p109 bra 	$L__BB9_96;

$L__BB9_105:
	@%p110 bra 	$L__BB9_113;

	setp.eq.s32 	%p111, %r555, %r558;
	shl.b32 	%r357, %r558, 1;
	add.s32 	%r358, %r46, %r357;
	mul.wide.s32 	%rd109, %r358, 4;
	add.s64 	%rd19, %rd6, %rd109;
	add.s32 	%r359, %r357, %r47;
	mul.wide.s32 	%rd110, %r359, 4;
	add.s64 	%rd20, %rd6, %rd110;
	@%p111 bra 	$L__BB9_108;

	mov.u32 	%r360, 0;
	st.local.u32 	[%rd19], %r360;
	st.local.u32 	[%rd20], %r360;

$L__BB9_108:
	@%p112 bra 	$L__BB9_113;

	add.s32 	%r361, %r558, 1;
	setp.eq.s32 	%p113, %r555, %r361;
	@%p113 bra 	$L__BB9_111;

	mov.u32 	%r362, 0;
	st.local.u32 	[%rd19+8], %r362;
	st.local.u32 	[%rd20+8], %r362;

$L__BB9_111:
	add.s32 	%r363, %r558, 2;
	setp.eq.s32 	%p115, %r555, %r363;
	or.pred  	%p116, %p114, %p115;
	@%p116 bra 	$L__BB9_113;

	mov.u32 	%r364, 0;
	st.local.u32 	[%rd19+16], %r364;
	st.local.u32 	[%rd20+16], %r364;

$L__BB9_113:
	add.s32 	%r555, %r555, 1;
	setp.lt.s32 	%p117, %r555, %r545;
	@%p117 bra 	$L__BB9_94;

	mov.u32 	%r365, 0;
	mov.f32 	%f845, 0f00000000;
	mov.u32 	%r559, %r365;

$L__BB9_115:
	add.s32 	%r55, %r559, -1;
	mul.lo.s32 	%r56, %r559, %r30;
	mov.u32 	%r560, %r365;

$L__BB9_116:
	setp.eq.s32 	%p118, %r560, 0;
	@%p118 bra 	$L__BB9_125;

	add.s32 	%r368, %r560, -1;
	and.b32  	%r58, %r560, 3;
	setp.lt.u32 	%p119, %r368, 3;
	mov.u32 	%r563, 0;
	mov.f32 	%f1201, 0f00000000;
	@%p119 bra 	$L__BB9_120;

	sub.s32 	%r562, %r560, %r58;

$L__BB9_119:
	mad.lo.s32 	%r370, %r563, %r30, %r560;
	mul.wide.s32 	%rd112, %r370, 4;
	add.s64 	%rd113, %rd6, %rd112;
	add.s32 	%r371, %r563, %r56;
	mul.wide.s32 	%rd114, %r371, 4;
	add.s64 	%rd115, %rd6, %rd114;
	ld.local.f32 	%f825, [%rd115];
	ld.local.f32 	%f826, [%rd113];
	fma.rn.f32 	%f827, %f826, %f825, %f1201;
	add.s64 	%rd116, %rd113, %rd16;
	ld.local.f32 	%f828, [%rd115+4];
	ld.local.f32 	%f829, [%rd116];
	fma.rn.f32 	%f830, %f829, %f828, %f827;
	add.s64 	%rd117, %rd116, %rd16;
	ld.local.f32 	%f831, [%rd115+8];
	ld.local.f32 	%f832, [%rd117];
	fma.rn.f32 	%f833, %f832, %f831, %f830;
	add.s64 	%rd118, %rd117, %rd16;
	ld.local.f32 	%f834, [%rd115+12];
	ld.local.f32 	%f835, [%rd118];
	fma.rn.f32 	%f1201, %f835, %f834, %f833;
	add.s32 	%r563, %r563, 4;
	add.s32 	%r562, %r562, -4;
	setp.ne.s32 	%p120, %r562, 0;
	@%p120 bra 	$L__BB9_119;

$L__BB9_120:
	setp.eq.s32 	%p121, %r58, 0;
	@%p121 bra 	$L__BB9_124;

	mad.lo.s32 	%r65, %r563, %r30, %r560;
	mul.wide.s32 	%rd119, %r65, 4;
	add.s64 	%rd120, %rd6, %rd119;
	add.s32 	%r372, %r563, %r56;
	mul.wide.s32 	%rd121, %r372, 4;
	add.s64 	%rd22, %rd6, %rd121;
	ld.local.f32 	%f836, [%rd22];
	ld.local.f32 	%f837, [%rd120];
	fma.rn.f32 	%f1201, %f837, %f836, %f1201;
	setp.eq.s32 	%p122, %r58, 1;
	@%p122 bra 	$L__BB9_124;

	add.s32 	%r66, %r65, %r30;
	mul.wide.s32 	%rd122, %r66, 4;
	add.s64 	%rd123, %rd6, %rd122;
	ld.local.f32 	%f838, [%rd22+4];
	ld.local.f32 	%f839, [%rd123];
	fma.rn.f32 	%f1201, %f839, %f838, %f1201;
	setp.eq.s32 	%p123, %r58, 2;
	@%p123 bra 	$L__BB9_124;

	add.s32 	%r373, %r66, %r30;
	mul.wide.s32 	%rd124, %r373, 4;
	add.s64 	%rd125, %rd6, %rd124;
	ld.local.f32 	%f840, [%rd22+8];
	ld.local.f32 	%f841, [%rd125];
	fma.rn.f32 	%f1201, %f841, %f840, %f1201;

$L__BB9_124:
	add.s32 	%r374, %r560, %r56;
	mul.wide.s32 	%rd126, %r374, 4;
	add.s64 	%rd127, %rd6, %rd126;
	ld.local.f32 	%f842, [%rd127];
	sub.f32 	%f843, %f842, %f1201;
	st.local.f32 	[%rd127], %f843;

$L__BB9_125:
	add.s32 	%r67, %r560, 1;
	setp.lt.u32 	%p124, %r560, %r559;
	mov.u32 	%r560, %r67;
	@%p124 bra 	$L__BB9_116;

	setp.ge.s32 	%p125, %r559, %r29;
	@%p125 bra 	$L__BB9_139;

	add.s32 	%r375, %r56, %r559;
	mul.wide.s32 	%rd128, %r375, 4;
	add.s64 	%rd23, %rd6, %rd128;
	and.b32  	%r68, %r559, 3;
	sub.s32 	%r69, %r559, %r68;
	mov.u32 	%r564, %r559;

$L__BB9_128:
	add.s32 	%r564, %r564, 1;
	setp.eq.s32 	%p126, %r559, 0;
	@%p126 bra 	$L__BB9_137;

	setp.lt.u32 	%p127, %r55, 3;
	mov.u32 	%r567, 0;
	mov.f32 	%f1205, %f845;
	@%p127 bra 	$L__BB9_132;

	mov.f32 	%f1205, %f845;
	mov.u32 	%r566, %r69;

$L__BB9_131:
	mad.lo.s32 	%r378, %r567, %r30, %r564;
	mul.wide.s32 	%rd129, %r378, 4;
	add.s64 	%rd130, %rd6, %rd129;
	add.s32 	%r379, %r567, %r56;
	mul.wide.s32 	%rd131, %r379, 4;
	add.s64 	%rd132, %rd6, %rd131;
	ld.local.f32 	%f847, [%rd132];
	ld.local.f32 	%f848, [%rd130];
	fma.rn.f32 	%f849, %f848, %f847, %f1205;
	add.s64 	%rd133, %rd130, %rd16;
	ld.local.f32 	%f850, [%rd132+4];
	ld.local.f32 	%f851, [%rd133];
	fma.rn.f32 	%f852, %f851, %f850, %f849;
	add.s64 	%rd134, %rd133, %rd16;
	ld.local.f32 	%f853, [%rd132+8];
	ld.local.f32 	%f854, [%rd134];
	fma.rn.f32 	%f855, %f854, %f853, %f852;
	add.s64 	%rd135, %rd134, %rd16;
	ld.local.f32 	%f856, [%rd132+12];
	ld.local.f32 	%f857, [%rd135];
	fma.rn.f32 	%f1205, %f857, %f856, %f855;
	add.s32 	%r567, %r567, 4;
	add.s32 	%r566, %r566, -4;
	setp.ne.s32 	%p128, %r566, 0;
	@%p128 bra 	$L__BB9_131;

$L__BB9_132:
	setp.eq.s32 	%p129, %r68, 0;
	@%p129 bra 	$L__BB9_136;

	setp.eq.s32 	%p130, %r68, 1;
	mad.lo.s32 	%r77, %r567, %r30, %r564;
	mul.wide.s32 	%rd136, %r77, 4;
	add.s64 	%rd137, %rd6, %rd136;
	add.s32 	%r380, %r567, %r56;
	mul.wide.s32 	%rd138, %r380, 4;
	add.s64 	%rd24, %rd6, %rd138;
	ld.local.f32 	%f858, [%rd24];
	ld.local.f32 	%f859, [%rd137];
	fma.rn.f32 	%f1205, %f859, %f858, %f1205;
	@%p130 bra 	$L__BB9_136;

	setp.eq.s32 	%p131, %r68, 2;
	add.s32 	%r78, %r77, %r30;
	mul.wide.s32 	%rd139, %r78, 4;
	add.s64 	%rd140, %rd6, %rd139;
	ld.local.f32 	%f860, [%rd24+4];
	ld.local.f32 	%f861, [%rd140];
	fma.rn.f32 	%f1205, %f861, %f860, %f1205;
	@%p131 bra 	$L__BB9_136;

	add.s32 	%r381, %r78, %r30;
	mul.wide.s32 	%rd141, %r381, 4;
	add.s64 	%rd142, %rd6, %rd141;
	ld.local.f32 	%f862, [%rd24+8];
	ld.local.f32 	%f863, [%rd142];
	fma.rn.f32 	%f1205, %f863, %f862, %f1205;

$L__BB9_136:
	ld.local.f32 	%f864, [%rd23];
	rcp.rn.f32 	%f865, %f864;
	add.s32 	%r382, %r564, %r56;
	mul.wide.s32 	%rd143, %r382, 4;
	add.s64 	%rd144, %rd6, %rd143;
	ld.local.f32 	%f866, [%rd144];
	sub.f32 	%f867, %f866, %f1205;
	mul.f32 	%f868, %f865, %f867;
	st.local.f32 	[%rd144], %f868;
	bra.uni 	$L__BB9_138;

$L__BB9_137:
	ld.local.f32 	%f869, [%rd6];
	rcp.rn.f32 	%f870, %f869;
	mul.wide.s32 	%rd145, %r564, 4;
	add.s64 	%rd146, %rd6, %rd145;
	ld.local.f32 	%f871, [%rd146];
	mul.f32 	%f872, %f870, %f871;
	st.local.f32 	[%rd146], %f872;

$L__BB9_138:
	setp.lt.s32 	%p132, %r564, %r29;
	@%p132 bra 	$L__BB9_128;

$L__BB9_139:
	setp.lt.s32 	%p133, %r559, %r29;
	add.s32 	%r559, %r559, 1;
	@%p133 bra 	$L__BB9_115;

	cvt.s64.s32 	%rd25, %r29;
	add.s64 	%rd26, %rd10, %rd88;
	mad.lo.s32 	%r384, %r30, %r29, %r29;
	cvt.s64.s32 	%rd27, %r384;
	mul.wide.s32 	%rd148, %r384, 4;
	add.s64 	%rd149, %rd6, %rd148;
	ld.local.f32 	%f129, [%rd149];
	mov.u32 	%r385, 1;
	sub.s32 	%r80, %r385, %r29;
	mov.u32 	%r568, 0;
	setp.eq.s32 	%p135, %r545, 0;
	mov.f32 	%f898, 0f00000000;

$L__BB9_141:
	setp.eq.s32 	%p134, %r568, 0;
	selp.f32 	%f873, 0f3F800000, 0f00000000, %p134;
	st.local.f32 	[%rd10], %f873;
	@%p135 bra 	$L__BB9_151;

	mov.u32 	%r386, 0;
	mov.u32 	%r569, %r385;
	mov.u32 	%r570, %r386;

$L__BB9_143:
	mov.u32 	%r82, %r570;
	mov.u32 	%r570, %r569;
	and.b32  	%r84, %r570, 3;
	setp.lt.u32 	%p136, %r82, 3;
	mov.f32 	%f1209, 0f00000000;
	mov.u32 	%r573, %r386;
	@%p136 bra 	$L__BB9_146;

	sub.s32 	%r572, %r570, %r84;
	mov.u32 	%r573, %r386;

$L__BB9_145:
	mad.lo.s32 	%r390, %r573, %r30, %r570;
	mul.wide.s32 	%rd150, %r390, 4;
	add.s64 	%rd151, %rd6, %rd150;
	mul.wide.s32 	%rd152, %r573, 4;
	add.s64 	%rd153, %rd10, %rd152;
	ld.local.f32 	%f877, [%rd153];
	ld.local.f32 	%f878, [%rd151];
	fma.rn.f32 	%f879, %f878, %f877, %f1209;
	add.s64 	%rd154, %rd151, %rd16;
	ld.local.f32 	%f880, [%rd153+4];
	ld.local.f32 	%f881, [%rd154];
	fma.rn.f32 	%f882, %f881, %f880, %f879;
	add.s64 	%rd155, %rd154, %rd16;
	ld.local.f32 	%f883, [%rd153+8];
	ld.local.f32 	%f884, [%rd155];
	fma.rn.f32 	%f885, %f884, %f883, %f882;
	add.s64 	%rd156, %rd155, %rd16;
	ld.local.f32 	%f886, [%rd153+12];
	ld.local.f32 	%f887, [%rd156];
	fma.rn.f32 	%f1209, %f887, %f886, %f885;
	add.s32 	%r573, %r573, 4;
	add.s32 	%r572, %r572, -4;
	setp.ne.s32 	%p137, %r572, 0;
	@%p137 bra 	$L__BB9_145;

$L__BB9_146:
	setp.eq.s32 	%p138, %r84, 0;
	@%p138 bra 	$L__BB9_150;

	mad.lo.s32 	%r91, %r573, %r30, %r570;
	mul.wide.s32 	%rd157, %r91, 4;
	add.s64 	%rd158, %rd6, %rd157;
	mul.wide.s32 	%rd159, %r573, 4;
	add.s64 	%rd30, %rd10, %rd159;
	ld.local.f32 	%f888, [%rd30];
	ld.local.f32 	%f889, [%rd158];
	fma.rn.f32 	%f1209, %f889, %f888, %f1209;
	setp.eq.s32 	%p139, %r84, 1;
	@%p139 bra 	$L__BB9_150;

	add.s32 	%r92, %r91, %r30;
	mul.wide.s32 	%rd160, %r92, 4;
	add.s64 	%rd161, %rd6, %rd160;
	ld.local.f32 	%f890, [%rd30+4];
	ld.local.f32 	%f891, [%rd161];
	fma.rn.f32 	%f1209, %f891, %f890, %f1209;
	setp.eq.s32 	%p140, %r84, 2;
	@%p140 bra 	$L__BB9_150;

	add.s32 	%r391, %r92, %r30;
	mul.wide.s32 	%rd162, %r391, 4;
	add.s64 	%rd163, %rd6, %rd162;
	ld.local.f32 	%f892, [%rd30+8];
	ld.local.f32 	%f893, [%rd163];
	fma.rn.f32 	%f1209, %f893, %f892, %f1209;

$L__BB9_150:
	setp.eq.s32 	%p141, %r570, %r568;
	selp.f32 	%f894, 0f3F800000, 0f00000000, %p141;
	sub.f32 	%f895, %f894, %f1209;
	mul.wide.s32 	%rd164, %r570, 4;
	add.s64 	%rd165, %rd10, %rd164;
	st.local.f32 	[%rd165], %f895;
	add.s32 	%r569, %r570, 1;
	setp.lt.s32 	%p142, %r570, %r29;
	@%p142 bra 	$L__BB9_143;

$L__BB9_151:
	ld.local.f32 	%f896, [%rd26];
	div.rn.f32 	%f897, %f896, %f129;
	mul.lo.s32 	%r94, %r568, %r30;
	add.s32 	%r392, %r94, %r29;
	mul.wide.s32 	%rd166, %r392, 4;
	add.s64 	%rd167, %rd4, %rd166;
	st.local.f32 	[%rd167], %f897;
	@%p135 bra 	$L__BB9_161;

	mov.u32 	%r574, 0;
	mov.u32 	%r575, %r29;

$L__BB9_153:
	mov.u32 	%r96, %r575;
	sub.s32 	%r394, %r29, %r574;
	max.s32 	%r395, %r394, %r29;
	add.s32 	%r396, %r80, %r574;
	add.s32 	%r97, %r395, %r396;
	add.s32 	%r575, %r96, -1;
	add.s32 	%r397, %r96, %r94;
	mul.wide.s32 	%rd168, %r397, 4;
	add.s64 	%rd31, %rd4, %rd168;
	setp.gt.s32 	%p144, %r96, %r29;
	mov.f32 	%f1213, %f898;
	@%p144 bra 	$L__BB9_160;

	and.b32  	%r99, %r97, 3;
	setp.eq.s32 	%p145, %r99, 0;
	mov.u32 	%r576, %r96;
	mov.f32 	%f1213, %f898;
	@%p145 bra 	$L__BB9_158;

	mad.lo.s32 	%r100, %r96, %r30, %r575;
	mul.wide.s32 	%rd169, %r100, 4;
	add.s64 	%rd170, %rd6, %rd169;
	ld.local.f32 	%f901, [%rd31];
	ld.local.f32 	%f902, [%rd170];
	fma.rn.f32 	%f1213, %f902, %f901, 0f00000000;
	add.s32 	%r576, %r96, 1;
	setp.eq.s32 	%p146, %r99, 1;
	@%p146 bra 	$L__BB9_158;

	add.s32 	%r102, %r100, %r30;
	mul.wide.s32 	%rd171, %r102, 4;
	add.s64 	%rd172, %rd6, %rd171;
	ld.local.f32 	%f903, [%rd31+4];
	ld.local.f32 	%f904, [%rd172];
	fma.rn.f32 	%f1213, %f904, %f903, %f1213;
	add.s32 	%r576, %r96, 2;
	setp.eq.s32 	%p147, %r99, 2;
	@%p147 bra 	$L__BB9_158;

	add.s32 	%r398, %r102, %r30;
	mul.wide.s32 	%rd173, %r398, 4;
	add.s64 	%rd174, %rd6, %rd173;
	ld.local.f32 	%f905, [%rd31+8];
	ld.local.f32 	%f906, [%rd174];
	fma.rn.f32 	%f1213, %f906, %f905, %f1213;
	add.s32 	%r576, %r96, 3;

$L__BB9_158:
	add.s32 	%r399, %r97, -1;
	setp.lt.u32 	%p148, %r399, 3;
	@%p148 bra 	$L__BB9_160;

$L__BB9_159:
	mad.lo.s32 	%r400, %r576, %r30, %r575;
	mul.wide.s32 	%rd175, %r400, 4;
	add.s64 	%rd176, %rd6, %rd175;
	add.s32 	%r401, %r576, %r94;
	mul.wide.s32 	%rd177, %r401, 4;
	add.s64 	%rd178, %rd4, %rd177;
	ld.local.f32 	%f907, [%rd178];
	ld.local.f32 	%f908, [%rd176];
	fma.rn.f32 	%f909, %f908, %f907, %f1213;
	add.s64 	%rd179, %rd176, %rd16;
	ld.local.f32 	%f910, [%rd178+4];
	ld.local.f32 	%f911, [%rd179];
	fma.rn.f32 	%f912, %f911, %f910, %f909;
	add.s64 	%rd180, %rd179, %rd16;
	ld.local.f32 	%f913, [%rd178+8];
	ld.local.f32 	%f914, [%rd180];
	fma.rn.f32 	%f915, %f914, %f913, %f912;
	add.s64 	%rd181, %rd180, %rd16;
	ld.local.f32 	%f916, [%rd178+12];
	ld.local.f32 	%f917, [%rd181];
	fma.rn.f32 	%f1213, %f917, %f916, %f915;
	add.s32 	%r107, %r576, 4;
	add.s32 	%r402, %r576, 3;
	setp.lt.s32 	%p149, %r402, %r29;
	mov.u32 	%r576, %r107;
	@%p149 bra 	$L__BB9_159;

$L__BB9_160:
	mad.lo.s32 	%r403, %r575, %r30, %r575;
	mul.wide.s32 	%rd182, %r403, 4;
	add.s64 	%rd183, %rd6, %rd182;
	ld.local.f32 	%f918, [%rd183];
	rcp.rn.f32 	%f919, %f918;
	mul.wide.s32 	%rd184, %r575, 4;
	add.s64 	%rd185, %rd10, %rd184;
	ld.local.f32 	%f920, [%rd185];
	sub.f32 	%f921, %f920, %f1213;
	mul.f32 	%f922, %f919, %f921;
	st.local.f32 	[%rd31+-4], %f922;
	add.s32 	%r574, %r574, 1;
	setp.gt.s32 	%p150, %r96, 1;
	@%p150 bra 	$L__BB9_153;

$L__BB9_161:
	add.s32 	%r109, %r568, 1;
	setp.lt.s32 	%p151, %r568, %r29;
	mov.u32 	%r568, %r109;
	@%p151 bra 	$L__BB9_141;

	mov.u32 	%r580, 0;
	@%p104 bra 	$L__BB9_165;

	shl.b64 	%rd186, %rd25, 2;
	add.s64 	%rd32, %rd186, 8;

$L__BB9_164:
	shl.b32 	%r406, %r580, 1;
	mad.lo.s32 	%r407, %r406, %r30, %r406;
	mul.wide.s32 	%rd187, %r407, 4;
	add.s64 	%rd188, %rd4, %rd187;
	ld.local.f32 	%f923, [%rd188];
	abs.f32 	%f924, %f923;
	sqrt.rn.f32 	%f925, %f924;
	add.s32 	%r408, %r580, %r3;
	mul.wide.s32 	%rd189, %r408, 4;
	add.s64 	%rd190, %rd2, %rd189;
	st.global.f32 	[%rd190], %f925;
	add.s64 	%rd191, %rd188, %rd32;
	ld.local.f32 	%f926, [%rd191];
	abs.f32 	%f927, %f926;
	sqrt.rn.f32 	%f928, %f927;
	add.s64 	%rd192, %rd1, %rd189;
	st.global.f32 	[%rd192], %f928;
	add.s64 	%rd193, %rd191, %rd32;
	ld.local.f32 	%f929, [%rd193];
	abs.f32 	%f930, %f929;
	sqrt.rn.f32 	%f931, %f930;
	st.global.f32 	[%rd190+4], %f931;
	add.s64 	%rd194, %rd193, %rd32;
	ld.local.f32 	%f932, [%rd194];
	abs.f32 	%f933, %f932;
	sqrt.rn.f32 	%f934, %f933;
	st.global.f32 	[%rd192+4], %f934;
	add.s64 	%rd195, %rd194, %rd32;
	ld.local.f32 	%f935, [%rd195];
	abs.f32 	%f936, %f935;
	sqrt.rn.f32 	%f937, %f936;
	st.global.f32 	[%rd190+8], %f937;
	add.s64 	%rd196, %rd195, %rd32;
	ld.local.f32 	%f938, [%rd196];
	abs.f32 	%f939, %f938;
	sqrt.rn.f32 	%f940, %f939;
	st.global.f32 	[%rd192+8], %f940;
	add.s64 	%rd197, %rd196, %rd32;
	ld.local.f32 	%f941, [%rd197];
	abs.f32 	%f942, %f941;
	sqrt.rn.f32 	%f943, %f942;
	st.global.f32 	[%rd190+12], %f943;
	add.s64 	%rd198, %rd197, %rd32;
	ld.local.f32 	%f944, [%rd198];
	abs.f32 	%f945, %f944;
	sqrt.rn.f32 	%f946, %f945;
	st.global.f32 	[%rd192+12], %f946;
	add.s32 	%r580, %r580, 4;
	add.s32 	%r579, %r579, -4;
	setp.ne.s32 	%p153, %r579, 0;
	@%p153 bra 	$L__BB9_164;

$L__BB9_165:
	@%p110 bra 	$L__BB9_167;

$L__BB9_166:
	.pragma "nounroll";
	shl.b32 	%r409, %r580, 1;
	mul.lo.s32 	%r410, %r409, %r30;
	add.s32 	%r411, %r410, %r409;
	mul.wide.s32 	%rd199, %r411, 4;
	add.s64 	%rd200, %rd4, %rd199;
	ld.local.f32 	%f947, [%rd200];
	abs.f32 	%f948, %f947;
	sqrt.rn.f32 	%f949, %f948;
	add.s32 	%r412, %r580, %r3;
	mul.wide.s32 	%rd201, %r412, 4;
	add.s64 	%rd202, %rd2, %rd201;
	st.global.f32 	[%rd202], %f949;
	add.s32 	%r413, %r410, %r30;
	add.s32 	%r414, %r413, %r409;
	add.s32 	%r415, %r414, 1;
	mul.wide.s32 	%rd203, %r415, 4;
	add.s64 	%rd204, %rd4, %rd203;
	ld.local.f32 	%f950, [%rd204];
	abs.f32 	%f951, %f950;
	sqrt.rn.f32 	%f952, %f951;
	add.s64 	%rd205, %rd1, %rd201;
	st.global.f32 	[%rd205], %f952;
	add.s32 	%r580, %r580, 1;
	add.s32 	%r582, %r582, -1;
	setp.ne.s32 	%p155, %r582, 0;
	@%p155 bra 	$L__BB9_166;

$L__BB9_167:
	mov.u32 	%r416, 0;
	mov.f64 	%fd24, 0d4000000000000000;
	mov.u32 	%r583, %r416;

$L__BB9_168:
	add.s32 	%r418, %r583, %r3;
	mul.wide.s32 	%rd206, %r418, 4;
	add.s64 	%rd33, %rd8, %rd206;
	add.s64 	%rd34, %rd2, %rd206;
	add.s64 	%rd35, %rd7, %rd206;
	add.s64 	%rd36, %rd1, %rd206;
	shl.b32 	%r419, %r583, 1;
	or.b32  	%r420, %r419, 1;
	mad.lo.s32 	%r120, %r420, %r30, 1;
	mul.lo.s32 	%r121, %r419, %r30;
	mov.u32 	%r584, %r416;

$L__BB9_169:
	setp.eq.s32 	%p156, %r583, %r584;
	@%p156 bra 	$L__BB9_197;

	ld.global.f32 	%f953, [%rd33];
	add.s32 	%r123, %r584, %r3;
	mul.wide.s32 	%rd207, %r123, 4;
	add.s64 	%rd208, %rd8, %rd207;
	ld.global.f32 	%f954, [%rd208];
	sub.f32 	%f955, %f953, %f954;
	abs.f32 	%f146, %f955;
	cvt.f64.f32 	%fd1, %f146;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r124}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r125}, %fd24;
	}
	and.b32  	%r126, %r125, 2146435072;
	setp.eq.s32 	%p157, %r126, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 182, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd44, [retval0+0];
	} // callseq 182
	setp.lt.s32 	%p158, %r124, 0;
	and.pred  	%p5, %p158, %p157;
	not.pred 	%p159, %p5;
	@%p159 bra 	$L__BB9_172;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r421}, %fd44;
	}
	xor.b32  	%r422, %r421, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r423, %temp}, %fd44;
	}
	mov.b64 	%fd44, {%r423, %r422};

$L__BB9_172:
	setp.eq.f32 	%p160, %f146, 0f00000000;
	@%p160 bra 	$L__BB9_176;
	bra.uni 	$L__BB9_173;

$L__BB9_176:
	selp.b32 	%r424, %r124, 0, %p157;
	mov.u32 	%r425, 0;
	or.b32  	%r426, %r424, 2146435072;
	setp.lt.s32 	%p164, %r125, 0;
	selp.b32 	%r427, %r426, %r424, %p164;
	mov.b64 	%fd44, {%r425, %r427};
	bra.uni 	$L__BB9_177;

$L__BB9_173:
	setp.gt.s32 	%p161, %r124, -1;
	@%p161 bra 	$L__BB9_177;

	cvt.rzi.f64.f64 	%fd26, %fd24;
	setp.eq.f64 	%p162, %fd26, 0d4000000000000000;
	@%p162 bra 	$L__BB9_177;

	mov.f64 	%fd44, 0dFFF8000000000000;

$L__BB9_177:
	add.f64 	%fd8, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r428}, %fd8;
	}
	and.b32  	%r429, %r428, 2146435072;
	setp.ne.s32 	%p165, %r429, 2146435072;
	mov.f64 	%fd45, %fd44;
	@%p165 bra 	$L__BB9_183;

	setp.gtu.f64 	%p166, %fd2, 0d7FF0000000000000;
	mov.f64 	%fd45, %fd8;
	@%p166 bra 	$L__BB9_183;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r430, %temp}, %fd24;
	}
	and.b32  	%r127, %r125, 2147483647;
	setp.eq.s32 	%p167, %r127, 2146435072;
	setp.eq.s32 	%p168, %r430, 0;
	and.pred  	%p169, %p167, %p168;
	@%p169 bra 	$L__BB9_182;
	bra.uni 	$L__BB9_180;

$L__BB9_182:
	setp.gt.f64 	%p176, %fd2, 0d3FF0000000000000;
	selp.b32 	%r437, 2146435072, 0, %p176;
	mov.u32 	%r438, 0;
	xor.b32  	%r439, %r437, 2146435072;
	setp.lt.s32 	%p177, %r125, 0;
	selp.b32 	%r440, %r439, %r437, %p177;
	setp.eq.f32 	%p178, %f146, 0fBF800000;
	selp.b32 	%r441, 1072693248, %r440, %p178;
	mov.b64 	%fd45, {%r438, %r441};
	bra.uni 	$L__BB9_183;

$L__BB9_180:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r431, %temp}, %fd1;
	}
	and.b32  	%r432, %r124, 2147483647;
	setp.ne.s32 	%p170, %r432, 2146435072;
	setp.ne.s32 	%p171, %r431, 0;
	or.pred  	%p172, %p170, %p171;
	mov.f64 	%fd45, %fd44;
	@%p172 bra 	$L__BB9_183;

	setp.gt.s32 	%p173, %r125, -1;
	selp.b32 	%r433, 2146435072, 0, %p173;
	mov.u32 	%r434, 0;
	setp.ne.s32 	%p174, %r127, 1071644672;
	and.pred  	%p175, %p174, %p5;
	or.b32  	%r435, %r433, -2147483648;
	selp.b32 	%r436, %r435, %r433, %p175;
	mov.b64 	%fd45, {%r434, %r436};

$L__BB9_183:
	setp.eq.f32 	%p179, %f146, 0f3F800000;
	selp.f64 	%fd29, 0d3FF0000000000000, %fd45, %p179;
	ld.global.f32 	%f956, [%rd34];
	cvt.f64.f32 	%fd30, %f956;
	div.rn.f64 	%fd31, %fd29, %fd30;
	add.s64 	%rd210, %rd2, %rd207;
	ld.global.f32 	%f957, [%rd210];
	cvt.f64.f32 	%fd32, %f957;
	div.rn.f64 	%fd12, %fd31, %fd32;
	add.s64 	%rd211, %rd7, %rd207;
	ld.global.f32 	%f958, [%rd211];
	ld.global.f32 	%f959, [%rd35];
	sub.f32 	%f960, %f959, %f958;
	abs.f32 	%f147, %f960;
	cvt.f64.f32 	%fd13, %f147;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd13;
	}
	abs.f64 	%fd14, %fd13;
	{ // callseq 183, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd14;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd47, [retval0+0];
	} // callseq 183
	setp.lt.s32 	%p180, %r128, 0;
	and.pred  	%p6, %p180, %p157;
	not.pred 	%p182, %p6;
	@%p182 bra 	$L__BB9_185;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r442}, %fd47;
	}
	xor.b32  	%r443, %r442, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r444, %temp}, %fd47;
	}
	mov.b64 	%fd47, {%r444, %r443};

$L__BB9_185:
	setp.eq.f32 	%p183, %f147, 0f00000000;
	@%p183 bra 	$L__BB9_189;
	bra.uni 	$L__BB9_186;

$L__BB9_189:
	selp.b32 	%r445, %r128, 0, %p157;
	mov.u32 	%r446, 0;
	or.b32  	%r447, %r445, 2146435072;
	setp.lt.s32 	%p187, %r125, 0;
	selp.b32 	%r448, %r447, %r445, %p187;
	mov.b64 	%fd47, {%r446, %r448};
	bra.uni 	$L__BB9_190;

$L__BB9_186:
	setp.gt.s32 	%p184, %r128, -1;
	@%p184 bra 	$L__BB9_190;

	cvt.rzi.f64.f64 	%fd35, %fd24;
	setp.eq.f64 	%p185, %fd35, 0d4000000000000000;
	@%p185 bra 	$L__BB9_190;

	mov.f64 	%fd47, 0dFFF8000000000000;

$L__BB9_190:
	add.f64 	%fd20, %fd13, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r449}, %fd20;
	}
	and.b32  	%r450, %r449, 2146435072;
	setp.ne.s32 	%p188, %r450, 2146435072;
	mov.f64 	%fd48, %fd47;
	@%p188 bra 	$L__BB9_196;

	setp.gtu.f64 	%p189, %fd14, 0d7FF0000000000000;
	mov.f64 	%fd48, %fd20;
	@%p189 bra 	$L__BB9_196;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r451, %temp}, %fd24;
	}
	and.b32  	%r129, %r125, 2147483647;
	setp.eq.s32 	%p190, %r129, 2146435072;
	setp.eq.s32 	%p191, %r451, 0;
	and.pred  	%p192, %p190, %p191;
	@%p192 bra 	$L__BB9_195;
	bra.uni 	$L__BB9_193;

$L__BB9_195:
	setp.gt.f64 	%p199, %fd14, 0d3FF0000000000000;
	selp.b32 	%r458, 2146435072, 0, %p199;
	mov.u32 	%r459, 0;
	xor.b32  	%r460, %r458, 2146435072;
	setp.lt.s32 	%p200, %r125, 0;
	selp.b32 	%r461, %r460, %r458, %p200;
	setp.eq.f32 	%p201, %f147, 0fBF800000;
	selp.b32 	%r462, 1072693248, %r461, %p201;
	mov.b64 	%fd48, {%r459, %r462};
	bra.uni 	$L__BB9_196;

$L__BB9_193:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r452, %temp}, %fd13;
	}
	and.b32  	%r453, %r128, 2147483647;
	setp.ne.s32 	%p193, %r453, 2146435072;
	setp.ne.s32 	%p194, %r452, 0;
	or.pred  	%p195, %p193, %p194;
	mov.f64 	%fd48, %fd47;
	@%p195 bra 	$L__BB9_196;

	setp.gt.s32 	%p196, %r125, -1;
	selp.b32 	%r454, 2146435072, 0, %p196;
	mov.u32 	%r455, 0;
	setp.ne.s32 	%p197, %r129, 1071644672;
	and.pred  	%p198, %p197, %p6;
	or.b32  	%r456, %r454, -2147483648;
	selp.b32 	%r457, %r456, %r454, %p198;
	mov.b64 	%fd48, {%r455, %r457};

$L__BB9_196:
	cvt.rn.f32.f64 	%f961, %fd12;
	setp.eq.f32 	%p202, %f147, 0f3F800000;
	selp.f64 	%fd38, 0d3FF0000000000000, %fd48, %p202;
	ld.global.f32 	%f962, [%rd36];
	cvt.f64.f32 	%fd39, %f962;
	div.rn.f64 	%fd40, %fd38, %fd39;
	add.s64 	%rd213, %rd1, %rd207;
	ld.global.f32 	%f963, [%rd213];
	cvt.f64.f32 	%fd41, %f963;
	div.rn.f64 	%fd42, %fd40, %fd41;
	cvt.rn.f32.f64 	%f964, %fd42;
	add.f32 	%f965, %f964, 0f3F800000;
	div.rn.f32 	%f966, %f964, %f965;
	shl.b32 	%r463, %r584, 1;
	add.s32 	%r464, %r120, %r463;
	mul.wide.s32 	%rd214, %r464, 4;
	add.s64 	%rd215, %rd5, %rd214;
	ld.local.f32 	%f967, [%rd215];
	mul.f32 	%f968, %f967, %f966;
	st.local.f32 	[%rd215], %f968;
	add.f32 	%f969, %f961, 0f3F800000;
	div.rn.f32 	%f970, %f961, %f969;
	add.s32 	%r465, %r463, %r121;
	mul.wide.s32 	%rd216, %r465, 4;
	add.s64 	%rd217, %rd5, %rd216;
	ld.local.f32 	%f971, [%rd217];
	mul.f32 	%f972, %f970, %f971;
	st.local.f32 	[%rd217], %f972;

$L__BB9_197:
	add.s32 	%r584, %r584, 1;
	setp.lt.s32 	%p203, %r584, %r545;
	@%p203 bra 	$L__BB9_169;

	add.s32 	%r583, %r583, 1;
	setp.lt.s32 	%p204, %r583, %r545;
	@%p204 bra 	$L__BB9_168;

	mov.u32 	%r466, 0;
	st.local.u32 	[%rd4], %r466;
	st.local.u32 	[%rd4+4], %r466;
	st.local.u32 	[%rd4+8], %r466;
	st.local.u32 	[%rd4+12], %r466;
	st.local.u32 	[%rd4+16], %r466;
	st.local.u32 	[%rd4+20], %r466;
	st.local.u32 	[%rd4+24], %r466;
	st.local.u32 	[%rd4+28], %r466;
	st.local.u32 	[%rd4+32], %r466;
	st.local.u32 	[%rd4+36], %r466;
	st.local.u32 	[%rd4+40], %r466;
	st.local.u32 	[%rd4+44], %r466;
	st.local.u32 	[%rd4+48], %r466;
	st.local.u32 	[%rd4+52], %r466;
	st.local.u32 	[%rd4+56], %r466;
	st.local.u32 	[%rd4+60], %r466;
	st.local.u32 	[%rd4+64], %r466;
	st.local.u32 	[%rd4+68], %r466;
	st.local.u32 	[%rd4+72], %r466;
	st.local.u32 	[%rd4+76], %r466;
	st.local.u32 	[%rd4+80], %r466;
	st.local.u32 	[%rd4+84], %r466;
	st.local.u32 	[%rd4+88], %r466;
	st.local.u32 	[%rd4+92], %r466;
	st.local.u32 	[%rd4+96], %r466;
	st.local.u32 	[%rd4+100], %r466;
	st.local.u32 	[%rd4+104], %r466;
	st.local.u32 	[%rd4+108], %r466;
	st.local.u32 	[%rd4+112], %r466;
	st.local.u32 	[%rd4+116], %r466;
	st.local.u32 	[%rd4+120], %r466;
	st.local.u32 	[%rd4+124], %r466;
	st.local.u32 	[%rd4+128], %r466;
	st.local.u32 	[%rd4+132], %r466;
	st.local.u32 	[%rd4+136], %r466;
	st.local.u32 	[%rd4+140], %r466;
	st.local.u32 	[%rd4+144], %r466;
	st.local.u32 	[%rd4+148], %r466;
	st.local.u32 	[%rd4+152], %r466;
	st.local.u32 	[%rd4+156], %r466;
	st.local.u32 	[%rd4+160], %r466;
	st.local.u32 	[%rd4+164], %r466;
	st.local.u32 	[%rd4+168], %r466;
	st.local.u32 	[%rd4+172], %r466;
	st.local.u32 	[%rd4+176], %r466;
	st.local.u32 	[%rd4+180], %r466;
	st.local.u32 	[%rd4+184], %r466;
	st.local.u32 	[%rd4+188], %r466;
	st.local.u32 	[%rd4+192], %r466;
	st.local.u32 	[%rd4+196], %r466;
	st.local.u32 	[%rd4+200], %r466;
	st.local.u32 	[%rd4+204], %r466;
	st.local.u32 	[%rd4+208], %r466;
	st.local.u32 	[%rd4+212], %r466;
	st.local.u32 	[%rd4+216], %r466;
	st.local.u32 	[%rd4+220], %r466;
	st.local.u32 	[%rd4+224], %r466;
	st.local.u32 	[%rd4+228], %r466;
	st.local.u32 	[%rd4+232], %r466;
	st.local.u32 	[%rd4+236], %r466;
	st.local.u32 	[%rd4+240], %r466;
	st.local.u32 	[%rd4+244], %r466;
	st.local.u32 	[%rd4+248], %r466;
	st.local.u32 	[%rd4+252], %r466;
	st.local.u32 	[%rd4+256], %r466;
	st.local.u32 	[%rd4+260], %r466;
	st.local.u32 	[%rd4+264], %r466;
	st.local.u32 	[%rd4+268], %r466;
	st.local.u32 	[%rd4+272], %r466;
	st.local.u32 	[%rd4+276], %r466;
	st.local.u32 	[%rd4+280], %r466;
	st.local.u32 	[%rd4+284], %r466;
	st.local.u32 	[%rd4+288], %r466;
	st.local.u32 	[%rd4+292], %r466;
	st.local.u32 	[%rd4+296], %r466;
	st.local.u32 	[%rd4+300], %r466;
	st.local.u32 	[%rd4+304], %r466;
	st.local.u32 	[%rd4+308], %r466;
	st.local.u32 	[%rd4+312], %r466;
	st.local.u32 	[%rd4+316], %r466;
	st.local.u32 	[%rd4+320], %r466;
	st.local.u32 	[%rd4+324], %r466;
	st.local.u32 	[%rd4+328], %r466;
	st.local.u32 	[%rd4+332], %r466;
	st.local.u32 	[%rd4+336], %r466;
	st.local.u32 	[%rd4+340], %r466;
	st.local.u32 	[%rd4+344], %r466;
	st.local.u32 	[%rd4+348], %r466;
	st.local.u32 	[%rd4+352], %r466;
	st.local.u32 	[%rd4+356], %r466;
	st.local.u32 	[%rd4+360], %r466;
	st.local.u32 	[%rd4+364], %r466;
	st.local.u32 	[%rd4+368], %r466;
	st.local.u32 	[%rd4+372], %r466;
	st.local.u32 	[%rd4+376], %r466;
	st.local.u32 	[%rd4+380], %r466;
	st.local.u32 	[%rd4+384], %r466;
	st.local.u32 	[%rd4+388], %r466;
	st.local.u32 	[%rd4+392], %r466;
	st.local.u32 	[%rd4+396], %r466;
	st.local.u32 	[%rd4+400], %r466;
	st.local.u32 	[%rd4+404], %r466;
	st.local.u32 	[%rd4+408], %r466;
	st.local.u32 	[%rd4+412], %r466;
	st.local.u32 	[%rd4+416], %r466;
	st.local.u32 	[%rd4+420], %r466;
	st.local.u32 	[%rd4+424], %r466;
	st.local.u32 	[%rd4+428], %r466;
	st.local.u32 	[%rd4+432], %r466;
	st.local.u32 	[%rd4+436], %r466;
	st.local.u32 	[%rd4+440], %r466;
	st.local.u32 	[%rd4+444], %r466;
	st.local.u32 	[%rd4+448], %r466;
	st.local.u32 	[%rd4+452], %r466;
	st.local.u32 	[%rd4+456], %r466;
	st.local.u32 	[%rd4+460], %r466;
	st.local.u32 	[%rd4+464], %r466;
	st.local.u32 	[%rd4+468], %r466;
	st.local.u32 	[%rd4+472], %r466;
	st.local.u32 	[%rd4+476], %r466;
	st.local.u32 	[%rd4+480], %r466;
	shl.b64 	%rd218, %rd25, 2;
	add.s64 	%rd37, %rd218, 4;
	mov.f32 	%f996, 0f00000000;
	mov.u32 	%r585, %r466;

$L__BB9_200:
	add.s32 	%r133, %r585, -1;
	mul.lo.s32 	%r134, %r585, %r30;
	mov.u32 	%r586, %r466;

$L__BB9_201:
	setp.eq.s32 	%p205, %r586, 0;
	@%p205 bra 	$L__BB9_210;

	add.s32 	%r469, %r586, -1;
	and.b32  	%r136, %r586, 3;
	setp.lt.u32 	%p206, %r469, 3;
	mov.u32 	%r589, 0;
	mov.f32 	%f1217, 0f00000000;
	@%p206 bra 	$L__BB9_205;

	sub.s32 	%r588, %r586, %r136;

$L__BB9_204:
	mad.lo.s32 	%r471, %r589, %r30, %r586;
	mul.wide.s32 	%rd219, %r471, 4;
	add.s64 	%rd220, %rd5, %rd219;
	add.s32 	%r472, %r589, %r134;
	mul.wide.s32 	%rd221, %r472, 4;
	add.s64 	%rd222, %rd5, %rd221;
	ld.local.f32 	%f976, [%rd222];
	ld.local.f32 	%f977, [%rd220];
	fma.rn.f32 	%f978, %f977, %f976, %f1217;
	add.s64 	%rd223, %rd220, %rd37;
	ld.local.f32 	%f979, [%rd222+4];
	ld.local.f32 	%f980, [%rd223];
	fma.rn.f32 	%f981, %f980, %f979, %f978;
	add.s64 	%rd224, %rd223, %rd37;
	ld.local.f32 	%f982, [%rd222+8];
	ld.local.f32 	%f983, [%rd224];
	fma.rn.f32 	%f984, %f983, %f982, %f981;
	add.s64 	%rd225, %rd224, %rd37;
	ld.local.f32 	%f985, [%rd222+12];
	ld.local.f32 	%f986, [%rd225];
	fma.rn.f32 	%f1217, %f986, %f985, %f984;
	add.s32 	%r589, %r589, 4;
	add.s32 	%r588, %r588, -4;
	setp.ne.s32 	%p207, %r588, 0;
	@%p207 bra 	$L__BB9_204;

$L__BB9_205:
	setp.eq.s32 	%p208, %r136, 0;
	@%p208 bra 	$L__BB9_209;

	mad.lo.s32 	%r143, %r589, %r30, %r586;
	mul.wide.s32 	%rd226, %r143, 4;
	add.s64 	%rd227, %rd5, %rd226;
	add.s32 	%r473, %r589, %r134;
	mul.wide.s32 	%rd228, %r473, 4;
	add.s64 	%rd38, %rd5, %rd228;
	ld.local.f32 	%f987, [%rd38];
	ld.local.f32 	%f988, [%rd227];
	fma.rn.f32 	%f1217, %f988, %f987, %f1217;
	setp.eq.s32 	%p209, %r136, 1;
	@%p209 bra 	$L__BB9_209;

	add.s32 	%r144, %r143, %r30;
	mul.wide.s32 	%rd229, %r144, 4;
	add.s64 	%rd230, %rd5, %rd229;
	ld.local.f32 	%f989, [%rd38+4];
	ld.local.f32 	%f990, [%rd230];
	fma.rn.f32 	%f1217, %f990, %f989, %f1217;
	setp.eq.s32 	%p210, %r136, 2;
	@%p210 bra 	$L__BB9_209;

	add.s32 	%r474, %r144, %r30;
	mul.wide.s32 	%rd231, %r474, 4;
	add.s64 	%rd232, %rd5, %rd231;
	ld.local.f32 	%f991, [%rd38+8];
	ld.local.f32 	%f992, [%rd232];
	fma.rn.f32 	%f1217, %f992, %f991, %f1217;

$L__BB9_209:
	add.s32 	%r475, %r586, %r134;
	mul.wide.s32 	%rd233, %r475, 4;
	add.s64 	%rd234, %rd5, %rd233;
	ld.local.f32 	%f993, [%rd234];
	sub.f32 	%f994, %f993, %f1217;
	st.local.f32 	[%rd234], %f994;

$L__BB9_210:
	add.s32 	%r145, %r586, 1;
	setp.lt.u32 	%p211, %r586, %r585;
	mov.u32 	%r586, %r145;
	@%p211 bra 	$L__BB9_201;

	setp.ge.s32 	%p212, %r585, %r29;
	@%p212 bra 	$L__BB9_224;

	add.s32 	%r476, %r134, %r585;
	mul.wide.s32 	%rd235, %r476, 4;
	add.s64 	%rd39, %rd5, %rd235;
	and.b32  	%r146, %r585, 3;
	sub.s32 	%r147, %r585, %r146;
	mov.u32 	%r590, %r585;

$L__BB9_213:
	add.s32 	%r149, %r590, 1;
	setp.eq.s32 	%p213, %r585, 0;
	@%p213 bra 	$L__BB9_222;

	setp.lt.u32 	%p214, %r133, 3;
	mov.u32 	%r593, 0;
	mov.f32 	%f1221, %f996;
	@%p214 bra 	$L__BB9_217;

	mov.f32 	%f1221, %f996;
	mov.u32 	%r592, %r147;

$L__BB9_216:
	mad.lo.s32 	%r479, %r593, %r30, %r149;
	mul.wide.s32 	%rd236, %r479, 4;
	add.s64 	%rd237, %rd5, %rd236;
	add.s32 	%r480, %r593, %r134;
	mul.wide.s32 	%rd238, %r480, 4;
	add.s64 	%rd239, %rd5, %rd238;
	ld.local.f32 	%f998, [%rd239];
	ld.local.f32 	%f999, [%rd237];
	fma.rn.f32 	%f1000, %f999, %f998, %f1221;
	add.s64 	%rd240, %rd237, %rd37;
	ld.local.f32 	%f1001, [%rd239+4];
	ld.local.f32 	%f1002, [%rd240];
	fma.rn.f32 	%f1003, %f1002, %f1001, %f1000;
	add.s64 	%rd241, %rd240, %rd37;
	ld.local.f32 	%f1004, [%rd239+8];
	ld.local.f32 	%f1005, [%rd241];
	fma.rn.f32 	%f1006, %f1005, %f1004, %f1003;
	add.s64 	%rd242, %rd241, %rd37;
	ld.local.f32 	%f1007, [%rd239+12];
	ld.local.f32 	%f1008, [%rd242];
	fma.rn.f32 	%f1221, %f1008, %f1007, %f1006;
	add.s32 	%r593, %r593, 4;
	add.s32 	%r592, %r592, -4;
	setp.ne.s32 	%p215, %r592, 0;
	@%p215 bra 	$L__BB9_216;

$L__BB9_217:
	setp.eq.s32 	%p216, %r146, 0;
	@%p216 bra 	$L__BB9_221;

	setp.eq.s32 	%p217, %r146, 1;
	mad.lo.s32 	%r155, %r593, %r30, %r149;
	mul.wide.s32 	%rd243, %r155, 4;
	add.s64 	%rd244, %rd5, %rd243;
	add.s32 	%r481, %r593, %r134;
	mul.wide.s32 	%rd245, %r481, 4;
	add.s64 	%rd40, %rd5, %rd245;
	ld.local.f32 	%f1009, [%rd40];
	ld.local.f32 	%f1010, [%rd244];
	fma.rn.f32 	%f1221, %f1010, %f1009, %f1221;
	@%p217 bra 	$L__BB9_221;

	setp.eq.s32 	%p218, %r146, 2;
	add.s32 	%r156, %r155, %r30;
	mul.wide.s32 	%rd246, %r156, 4;
	add.s64 	%rd247, %rd5, %rd246;
	ld.local.f32 	%f1011, [%rd40+4];
	ld.local.f32 	%f1012, [%rd247];
	fma.rn.f32 	%f1221, %f1012, %f1011, %f1221;
	@%p218 bra 	$L__BB9_221;

	add.s32 	%r482, %r156, %r30;
	mul.wide.s32 	%rd248, %r482, 4;
	add.s64 	%rd249, %rd5, %rd248;
	ld.local.f32 	%f1013, [%rd40+8];
	ld.local.f32 	%f1014, [%rd249];
	fma.rn.f32 	%f1221, %f1014, %f1013, %f1221;

$L__BB9_221:
	ld.local.f32 	%f1015, [%rd39];
	rcp.rn.f32 	%f1016, %f1015;
	add.s32 	%r483, %r149, %r134;
	mul.wide.s32 	%rd250, %r483, 4;
	add.s64 	%rd251, %rd5, %rd250;
	ld.local.f32 	%f1017, [%rd251];
	sub.f32 	%f1018, %f1017, %f1221;
	mul.f32 	%f1019, %f1016, %f1018;
	st.local.f32 	[%rd251], %f1019;
	bra.uni 	$L__BB9_223;

$L__BB9_222:
	ld.local.f32 	%f1020, [%rd5];
	rcp.rn.f32 	%f1021, %f1020;
	mul.wide.s32 	%rd252, %r590, 4;
	add.s64 	%rd253, %rd15, %rd252;
	ld.local.f32 	%f1022, [%rd253];
	mul.f32 	%f1023, %f1021, %f1022;
	st.local.f32 	[%rd253], %f1023;

$L__BB9_223:
	setp.lt.s32 	%p219, %r149, %r29;
	mov.u32 	%r590, %r149;
	@%p219 bra 	$L__BB9_213;

$L__BB9_224:
	setp.lt.s32 	%p220, %r585, %r29;
	add.s32 	%r585, %r585, 1;
	@%p220 bra 	$L__BB9_200;

	shl.b64 	%rd254, %rd27, 2;
	add.s64 	%rd255, %rd5, %rd254;
	ld.local.f32 	%f164, [%rd255];
	shl.b32 	%r485, %r545, 3;
	or.b32  	%r486, %r485, 4;
	mul.wide.s32 	%rd41, %r486, 4;
	mov.u32 	%r594, 0;
	mov.f32 	%f1049, 0f00000000;

$L__BB9_226:
	setp.eq.s32 	%p221, %r594, 0;
	selp.f32 	%f1024, 0f3F800000, 0f00000000, %p221;
	st.local.f32 	[%rd10], %f1024;
	@%p135 bra 	$L__BB9_236;

	mov.u32 	%r487, 0;
	mov.u32 	%r595, %r487;

$L__BB9_228:
	mov.u32 	%r159, %r595;
	add.s32 	%r595, %r159, 1;
	and.b32  	%r160, %r595, 3;
	setp.lt.u32 	%p223, %r159, 3;
	mov.f32 	%f1225, 0f00000000;
	mov.u32 	%r598, %r487;
	@%p223 bra 	$L__BB9_231;

	sub.s32 	%r596, %r159, %r160;
	mul.wide.s32 	%rd257, %r595, 4;
	add.s64 	%rd312, %rd5, %rd257;
	add.s32 	%r492, %r29, %r595;
	mul.wide.s32 	%rd258, %r492, 4;
	add.s64 	%rd310, %rd15, %rd258;
	mov.u64 	%rd311, %rd10;
	mov.u32 	%r598, %r487;

$L__BB9_230:
	ld.local.f32 	%f1028, [%rd311];
	ld.local.f32 	%f1029, [%rd312];
	fma.rn.f32 	%f1030, %f1029, %f1028, %f1225;
	ld.local.f32 	%f1031, [%rd311+4];
	ld.local.f32 	%f1032, [%rd310];
	fma.rn.f32 	%f1033, %f1032, %f1031, %f1030;
	add.s64 	%rd259, %rd310, %rd37;
	ld.local.f32 	%f1034, [%rd311+8];
	ld.local.f32 	%f1035, [%rd259];
	fma.rn.f32 	%f1036, %f1035, %f1034, %f1033;
	add.s64 	%rd260, %rd259, %rd37;
	ld.local.f32 	%f1037, [%rd311+12];
	ld.local.f32 	%f1038, [%rd260];
	fma.rn.f32 	%f1225, %f1038, %f1037, %f1036;
	add.s32 	%r598, %r598, 4;
	add.s64 	%rd312, %rd312, %rd41;
	add.s64 	%rd311, %rd311, 16;
	add.s64 	%rd310, %rd310, %rd41;
	add.s32 	%r596, %r596, -4;
	setp.ne.s32 	%p224, %r596, -1;
	@%p224 bra 	$L__BB9_230;

$L__BB9_231:
	setp.eq.s32 	%p225, %r160, 0;
	@%p225 bra 	$L__BB9_235;

	mad.lo.s32 	%r493, %r598, %r30, %r159;
	add.s32 	%r167, %r493, 1;
	mul.wide.s32 	%rd261, %r167, 4;
	add.s64 	%rd262, %rd5, %rd261;
	mul.wide.s32 	%rd263, %r598, 4;
	add.s64 	%rd51, %rd10, %rd263;
	ld.local.f32 	%f1039, [%rd51];
	ld.local.f32 	%f1040, [%rd262];
	fma.rn.f32 	%f1225, %f1040, %f1039, %f1225;
	setp.eq.s32 	%p226, %r160, 1;
	@%p226 bra 	$L__BB9_235;

	add.s32 	%r168, %r167, %r30;
	mul.wide.s32 	%rd264, %r168, 4;
	add.s64 	%rd265, %rd5, %rd264;
	ld.local.f32 	%f1041, [%rd51+4];
	ld.local.f32 	%f1042, [%rd265];
	fma.rn.f32 	%f1225, %f1042, %f1041, %f1225;
	setp.eq.s32 	%p227, %r160, 2;
	@%p227 bra 	$L__BB9_235;

	add.s32 	%r494, %r168, %r30;
	mul.wide.s32 	%rd266, %r494, 4;
	add.s64 	%rd267, %rd5, %rd266;
	ld.local.f32 	%f1043, [%rd51+8];
	ld.local.f32 	%f1044, [%rd267];
	fma.rn.f32 	%f1225, %f1044, %f1043, %f1225;

$L__BB9_235:
	setp.eq.s32 	%p228, %r595, %r594;
	selp.f32 	%f1045, 0f3F800000, 0f00000000, %p228;
	sub.f32 	%f1046, %f1045, %f1225;
	mul.wide.s32 	%rd268, %r595, 4;
	add.s64 	%rd269, %rd10, %rd268;
	st.local.f32 	[%rd269], %f1046;
	setp.lt.s32 	%p229, %r595, %r29;
	@%p229 bra 	$L__BB9_228;

$L__BB9_236:
	ld.local.f32 	%f1047, [%rd26];
	div.rn.f32 	%f1048, %f1047, %f164;
	mul.lo.s32 	%r170, %r594, %r30;
	add.s32 	%r495, %r170, %r29;
	mul.wide.s32 	%rd270, %r495, 4;
	add.s64 	%rd271, %rd4, %rd270;
	st.local.f32 	[%rd271], %f1048;
	@%p135 bra 	$L__BB9_246;

	mov.u32 	%r599, 0;
	mov.u32 	%r600, %r29;

$L__BB9_238:
	mov.u32 	%r172, %r600;
	sub.s32 	%r497, %r29, %r599;
	max.s32 	%r498, %r497, %r29;
	add.s32 	%r499, %r80, %r599;
	add.s32 	%r173, %r498, %r499;
	add.s32 	%r600, %r172, -1;
	add.s32 	%r500, %r172, %r170;
	mul.wide.s32 	%rd272, %r500, 4;
	add.s64 	%rd52, %rd4, %rd272;
	setp.gt.s32 	%p231, %r172, %r29;
	mov.f32 	%f1229, %f1049;
	@%p231 bra 	$L__BB9_245;

	and.b32  	%r175, %r173, 3;
	setp.eq.s32 	%p232, %r175, 0;
	mov.u32 	%r601, %r172;
	mov.f32 	%f1229, %f1049;
	@%p232 bra 	$L__BB9_243;

	mad.lo.s32 	%r176, %r172, %r30, %r600;
	mul.wide.s32 	%rd273, %r176, 4;
	add.s64 	%rd274, %rd5, %rd273;
	ld.local.f32 	%f1052, [%rd52];
	ld.local.f32 	%f1053, [%rd274];
	fma.rn.f32 	%f1229, %f1053, %f1052, 0f00000000;
	add.s32 	%r601, %r172, 1;
	setp.eq.s32 	%p233, %r175, 1;
	@%p233 bra 	$L__BB9_243;

	add.s32 	%r178, %r176, %r30;
	mul.wide.s32 	%rd275, %r178, 4;
	add.s64 	%rd276, %rd5, %rd275;
	ld.local.f32 	%f1054, [%rd52+4];
	ld.local.f32 	%f1055, [%rd276];
	fma.rn.f32 	%f1229, %f1055, %f1054, %f1229;
	add.s32 	%r601, %r172, 2;
	setp.eq.s32 	%p234, %r175, 2;
	@%p234 bra 	$L__BB9_243;

	add.s32 	%r501, %r178, %r30;
	mul.wide.s32 	%rd277, %r501, 4;
	add.s64 	%rd278, %rd5, %rd277;
	ld.local.f32 	%f1056, [%rd52+8];
	ld.local.f32 	%f1057, [%rd278];
	fma.rn.f32 	%f1229, %f1057, %f1056, %f1229;
	add.s32 	%r601, %r172, 3;

$L__BB9_243:
	add.s32 	%r502, %r173, -1;
	setp.lt.u32 	%p235, %r502, 3;
	@%p235 bra 	$L__BB9_245;

$L__BB9_244:
	mad.lo.s32 	%r503, %r601, %r30, %r600;
	mul.wide.s32 	%rd279, %r503, 4;
	add.s64 	%rd280, %rd5, %rd279;
	add.s32 	%r504, %r601, %r170;
	mul.wide.s32 	%rd281, %r504, 4;
	add.s64 	%rd282, %rd4, %rd281;
	ld.local.f32 	%f1058, [%rd282];
	ld.local.f32 	%f1059, [%rd280];
	fma.rn.f32 	%f1060, %f1059, %f1058, %f1229;
	add.s64 	%rd283, %rd280, %rd37;
	ld.local.f32 	%f1061, [%rd282+4];
	ld.local.f32 	%f1062, [%rd283];
	fma.rn.f32 	%f1063, %f1062, %f1061, %f1060;
	add.s64 	%rd284, %rd283, %rd37;
	ld.local.f32 	%f1064, [%rd282+8];
	ld.local.f32 	%f1065, [%rd284];
	fma.rn.f32 	%f1066, %f1065, %f1064, %f1063;
	add.s64 	%rd285, %rd284, %rd37;
	ld.local.f32 	%f1067, [%rd282+12];
	ld.local.f32 	%f1068, [%rd285];
	fma.rn.f32 	%f1229, %f1068, %f1067, %f1066;
	add.s32 	%r183, %r601, 4;
	add.s32 	%r505, %r601, 3;
	setp.lt.s32 	%p236, %r505, %r29;
	mov.u32 	%r601, %r183;
	@%p236 bra 	$L__BB9_244;

$L__BB9_245:
	mad.lo.s32 	%r506, %r600, %r30, %r600;
	mul.wide.s32 	%rd286, %r506, 4;
	add.s64 	%rd287, %rd5, %rd286;
	ld.local.f32 	%f1069, [%rd287];
	rcp.rn.f32 	%f1070, %f1069;
	mul.wide.s32 	%rd288, %r600, 4;
	add.s64 	%rd289, %rd10, %rd288;
	ld.local.f32 	%f1071, [%rd289];
	sub.f32 	%f1072, %f1071, %f1229;
	mul.f32 	%f1073, %f1070, %f1072;
	st.local.f32 	[%rd52+-4], %f1073;
	add.s32 	%r599, %r599, 1;
	setp.gt.s32 	%p237, %r172, 1;
	@%p237 bra 	$L__BB9_238;

$L__BB9_246:
	add.s32 	%r185, %r594, 1;
	setp.lt.s32 	%p238, %r594, %r29;
	mov.u32 	%r594, %r185;
	@%p238 bra 	$L__BB9_226;

$L__BB9_247:
	mov.u32 	%r539, %tid.x;
	mov.u32 	%r538, %ctaid.x;
	mov.u32 	%r537, %ntid.x;
	mad.lo.s32 	%r536, %r537, %r538, %r539;
	cvt.s64.s32 	%rd309, %r536;
	cvt.u32.u64 	%r509, %rd309;
	shl.b32 	%r510, %r214, 1;
	or.b32  	%r511, %r510, 1;
	mul.lo.s32 	%r186, %r509, %r511;
	mov.u32 	%r613, 0;
	max.s32 	%r512, %r29, 0;
	add.s32 	%r187, %r512, 1;
	and.b32  	%r188, %r187, 3;
	setp.lt.u32 	%p239, %r512, 3;
	mov.u32 	%r607, %r613;
	@%p239 bra 	$L__BB9_250;

	sub.s32 	%r605, %r187, %r188;

$L__BB9_249:
	mul.lo.s32 	%r515, %r607, %r30;
	add.s32 	%r516, %r515, %r607;
	mul.wide.s32 	%rd290, %r516, 4;
	add.s64 	%rd291, %rd4, %rd290;
	ld.local.f32 	%f1074, [%rd291];
	abs.f32 	%f1075, %f1074;
	sqrt.rn.f32 	%f1076, %f1075;
	add.s32 	%r517, %r607, %r186;
	mul.wide.s32 	%rd292, %r517, 4;
	add.s64 	%rd293, %rd9, %rd292;
	st.global.f32 	[%rd293], %f1076;
	add.s32 	%r518, %r515, %r30;
	add.s32 	%r519, %r518, %r607;
	add.s32 	%r520, %r519, 1;
	mul.wide.s32 	%rd294, %r520, 4;
	add.s64 	%rd295, %rd4, %rd294;
	ld.local.f32 	%f1077, [%rd295];
	abs.f32 	%f1078, %f1077;
	sqrt.rn.f32 	%f1079, %f1078;
	st.global.f32 	[%rd293+4], %f1079;
	ld.local.f32 	%f1080, [%rd291+4];
	cvt.u32.u64 	%r521, %rd11;
	add.s32 	%r522, %r613, %r521;
	mul.wide.s32 	%rd296, %r522, 4;
	add.s64 	%rd297, %rd3, %rd296;
	st.global.f32 	[%rd297], %f1080;
	add.s32 	%r523, %r518, %r30;
	add.s32 	%r524, %r523, %r607;
	add.s32 	%r525, %r524, 2;
	mul.wide.s32 	%rd298, %r525, 4;
	add.s64 	%rd299, %rd4, %rd298;
	ld.local.f32 	%f1081, [%rd299];
	abs.f32 	%f1082, %f1081;
	sqrt.rn.f32 	%f1083, %f1082;
	st.global.f32 	[%rd293+8], %f1083;
	add.s32 	%r526, %r523, %r30;
	add.s32 	%r527, %r526, %r607;
	add.s32 	%r528, %r527, 3;
	mul.wide.s32 	%rd300, %r528, 4;
	add.s64 	%rd301, %rd4, %rd300;
	ld.local.f32 	%f1084, [%rd301];
	abs.f32 	%f1085, %f1084;
	sqrt.rn.f32 	%f1086, %f1085;
	st.global.f32 	[%rd293+12], %f1086;
	ld.local.f32 	%f1087, [%rd299+4];
	st.global.f32 	[%rd297+4], %f1087;
	add.s32 	%r613, %r613, 2;
	add.s32 	%r607, %r607, 4;
	add.s32 	%r605, %r605, -4;
	setp.ne.s32 	%p240, %r605, 0;
	@%p240 bra 	$L__BB9_249;

$L__BB9_250:
	add.s32 	%r198, %r29, 2;
	mul.lo.s32 	%r609, %r607, %r198;
	add.s32 	%r529, %r609, -1;
	sub.s32 	%r610, %r529, %r29;
	add.s32 	%r530, %r607, %r186;
	mul.wide.s32 	%rd302, %r530, 4;
	add.s64 	%rd313, %rd9, %rd302;
	add.s32 	%r531, %r188, -1;
	not.b32 	%r608, %r531;
	mov.pred 	%p242, 0;

$L__BB9_251:
	.pragma "nounroll";
	mul.wide.s32 	%rd303, %r609, 4;
	add.s64 	%rd304, %rd4, %rd303;
	ld.local.f32 	%f1088, [%rd304];
	abs.f32 	%f1089, %f1088;
	sqrt.rn.f32 	%f1090, %f1089;
	st.global.f32 	[%rd313], %f1090;
	and.b32  	%r532, %r607, 1;
	setp.eq.b32 	%p241, %r532, 1;
	xor.pred  	%p243, %p241, %p242;
	not.pred 	%p244, %p243;
	@%p244 bra 	$L__BB9_253;

	cvt.u32.u64 	%r533, %rd11;
	mul.wide.s32 	%rd305, %r610, 4;
	add.s64 	%rd306, %rd4, %rd305;
	ld.local.f32 	%f1091, [%rd306];
	add.s32 	%r534, %r613, %r533;
	mul.wide.s32 	%rd307, %r534, 4;
	add.s64 	%rd308, %rd3, %rd307;
	st.global.f32 	[%rd308], %f1091;
	add.s32 	%r613, %r613, 1;

$L__BB9_253:
	add.s32 	%r607, %r607, 1;
	add.s32 	%r610, %r610, %r198;
	add.s64 	%rd313, %rd313, 4;
	add.s32 	%r609, %r609, %r198;
	add.s32 	%r608, %r608, 1;
	setp.ne.s32 	%p245, %r608, 0;
	@%p245 bra 	$L__BB9_251;

$L__BB9_254:
	ret;

}
.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0,
	.param .b64 __internal_accurate_pow_param_1
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<138>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	ld.param.f64 	%fd13, [__internal_accurate_pow_param_1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd12;
	}
	shr.u32 	%r51, %r50, 20;
	setp.ne.s32 	%p1, %r51, 0;
	@%p1 bra 	$L__BB10_2;

	mul.f64 	%fd14, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd14;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd14;
	}
	shr.u32 	%r16, %r50, 20;
	add.s32 	%r51, %r16, -54;

$L__BB10_2:
	add.s32 	%r52, %r51, -1023;
	and.b32  	%r17, %r50, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd135, {%r49, %r18};
	setp.lt.u32 	%p2, %r18, 1073127583;
	@%p2 bra 	$L__BB10_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd135;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd135, {%r19, %r21};
	add.s32 	%r52, %r51, -1022;

$L__BB10_4:
	add.f64 	%fd15, %fd135, 0d3FF0000000000000;
	mov.f64 	%fd16, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd17, %fd15;
	neg.f64 	%fd18, %fd15;
	fma.rn.f64 	%fd19, %fd18, %fd17, %fd16;
	fma.rn.f64 	%fd20, %fd19, %fd19, %fd19;
	fma.rn.f64 	%fd21, %fd20, %fd17, %fd17;
	add.f64 	%fd22, %fd135, 0dBFF0000000000000;
	mul.f64 	%fd23, %fd22, %fd21;
	fma.rn.f64 	%fd24, %fd22, %fd21, %fd23;
	mul.f64 	%fd25, %fd24, %fd24;
	mov.f64 	%fd26, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd27, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd28, %fd27, %fd25, %fd26;
	mov.f64 	%fd29, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd30, %fd28, %fd25, %fd29;
	mov.f64 	%fd31, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd32, %fd30, %fd25, %fd31;
	mov.f64 	%fd33, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd34, %fd32, %fd25, %fd33;
	mov.f64 	%fd35, 0d3F6249249242B910;
	fma.rn.f64 	%fd36, %fd34, %fd25, %fd35;
	mov.f64 	%fd37, 0d3F89999999999DFB;
	fma.rn.f64 	%fd38, %fd36, %fd25, %fd37;
	sub.f64 	%fd39, %fd22, %fd24;
	add.f64 	%fd40, %fd39, %fd39;
	neg.f64 	%fd41, %fd24;
	fma.rn.f64 	%fd42, %fd41, %fd22, %fd40;
	mul.f64 	%fd43, %fd21, %fd42;
	fma.rn.f64 	%fd44, %fd25, %fd38, 0d3FB5555555555555;
	mov.f64 	%fd45, 0d3FB5555555555555;
	sub.f64 	%fd46, %fd45, %fd44;
	fma.rn.f64 	%fd47, %fd25, %fd38, %fd46;
	add.f64 	%fd48, %fd47, 0d0000000000000000;
	add.f64 	%fd49, %fd48, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd50, %fd44, %fd49;
	sub.f64 	%fd51, %fd44, %fd50;
	add.f64 	%fd52, %fd49, %fd51;
	mul.rn.f64 	%fd53, %fd24, %fd24;
	neg.f64 	%fd54, %fd53;
	fma.rn.f64 	%fd55, %fd24, %fd24, %fd54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd43;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd56, {%r22, %r24};
	fma.rn.f64 	%fd57, %fd24, %fd56, %fd55;
	mul.rn.f64 	%fd58, %fd53, %fd24;
	neg.f64 	%fd59, %fd58;
	fma.rn.f64 	%fd60, %fd53, %fd24, %fd59;
	fma.rn.f64 	%fd61, %fd53, %fd43, %fd60;
	fma.rn.f64 	%fd62, %fd57, %fd24, %fd61;
	mul.rn.f64 	%fd63, %fd50, %fd58;
	neg.f64 	%fd64, %fd63;
	fma.rn.f64 	%fd65, %fd50, %fd58, %fd64;
	fma.rn.f64 	%fd66, %fd50, %fd62, %fd65;
	fma.rn.f64 	%fd67, %fd52, %fd58, %fd66;
	add.f64 	%fd68, %fd63, %fd67;
	sub.f64 	%fd69, %fd63, %fd68;
	add.f64 	%fd70, %fd67, %fd69;
	add.f64 	%fd71, %fd24, %fd68;
	sub.f64 	%fd72, %fd24, %fd71;
	add.f64 	%fd73, %fd68, %fd72;
	add.f64 	%fd74, %fd70, %fd73;
	add.f64 	%fd75, %fd43, %fd74;
	add.f64 	%fd76, %fd71, %fd75;
	sub.f64 	%fd77, %fd71, %fd76;
	add.f64 	%fd78, %fd75, %fd77;
	xor.b32  	%r25, %r52, -2147483648;
	mov.u32 	%r26, -2147483648;
	mov.u32 	%r27, 1127219200;
	mov.b64 	%fd79, {%r25, %r27};
	mov.b64 	%fd80, {%r26, %r27};
	sub.f64 	%fd81, %fd79, %fd80;
	mov.f64 	%fd82, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd83, %fd81, %fd82, %fd76;
	neg.f64 	%fd84, %fd81;
	fma.rn.f64 	%fd85, %fd84, %fd82, %fd83;
	sub.f64 	%fd86, %fd85, %fd76;
	sub.f64 	%fd87, %fd78, %fd86;
	mov.f64 	%fd88, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd89, %fd81, %fd88, %fd87;
	add.f64 	%fd90, %fd83, %fd89;
	sub.f64 	%fd91, %fd83, %fd90;
	add.f64 	%fd92, %fd89, %fd91;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd13;
	}
	shl.b32 	%r29, %r28, 1;
	setp.gt.u32 	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32 	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd13;
	}
	mov.b64 	%fd93, {%r32, %r31};
	mul.rn.f64 	%fd94, %fd90, %fd93;
	neg.f64 	%fd95, %fd94;
	fma.rn.f64 	%fd96, %fd90, %fd93, %fd95;
	fma.rn.f64 	%fd97, %fd92, %fd93, %fd96;
	add.f64 	%fd4, %fd94, %fd97;
	sub.f64 	%fd98, %fd94, %fd4;
	add.f64 	%fd5, %fd97, %fd98;
	mov.f64 	%fd99, 0d4338000000000000;
	mov.f64 	%fd100, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd101, %fd4, %fd100, %fd99;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd101;
	}
	mov.f64 	%fd102, 0dC338000000000000;
	add.rn.f64 	%fd103, %fd101, %fd102;
	mov.f64 	%fd104, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd105, %fd103, %fd104, %fd4;
	mov.f64 	%fd106, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd107, %fd103, %fd106, %fd105;
	mov.f64 	%fd108, 0d3E928AF3FCA213EA;
	mov.f64 	%fd109, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd110, %fd109, %fd107, %fd108;
	mov.f64 	%fd111, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd112, %fd110, %fd107, %fd111;
	mov.f64 	%fd113, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd114, %fd112, %fd107, %fd113;
	mov.f64 	%fd115, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd116, %fd114, %fd107, %fd115;
	mov.f64 	%fd117, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd118, %fd116, %fd107, %fd117;
	mov.f64 	%fd119, 0d3F81111111122322;
	fma.rn.f64 	%fd120, %fd118, %fd107, %fd119;
	mov.f64 	%fd121, 0d3FA55555555502A1;
	fma.rn.f64 	%fd122, %fd120, %fd107, %fd121;
	mov.f64 	%fd123, 0d3FC5555555555511;
	fma.rn.f64 	%fd124, %fd122, %fd107, %fd123;
	mov.f64 	%fd125, 0d3FE000000000000B;
	fma.rn.f64 	%fd126, %fd124, %fd107, %fd125;
	fma.rn.f64 	%fd127, %fd126, %fd107, %fd16;
	fma.rn.f64 	%fd128, %fd127, %fd107, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd128;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd128;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd136, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	%f2, %r35;
	abs.f32 	%f1, %f2;
	setp.lt.f32 	%p4, %f1, 0f4086232B;
	@%p4 bra 	$L__BB10_7;

	setp.lt.f64 	%p5, %fd4, 0d0000000000000000;
	add.f64 	%fd129, %fd4, 0d7FF0000000000000;
	selp.f64 	%fd136, 0d0000000000000000, %fd129, %p5;
	setp.geu.f32 	%p6, %f1, 0f40874800;
	@%p6 bra 	$L__BB10_7;

	mov.f64 	%fd134, 0d4338000000000000;
	mov.f64 	%fd133, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd132, %fd4, %fd133, %fd134;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd132;
	}
	shr.u32 	%r36, %r48, 31;
	add.s32 	%r37, %r48, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r15, %r39;
	mov.b64 	%fd130, {%r14, %r40};
	sub.s32 	%r41, %r48, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd131, {%r44, %r43};
	mul.f64 	%fd136, %fd130, %fd131;

$L__BB10_7:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd136;
	}
	and.b32  	%r46, %r45, 2147483647;
	setp.eq.s32 	%p7, %r46, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd136;
	}
	setp.eq.s32 	%p8, %r47, 0;
	and.pred  	%p9, %p8, %p7;
	@%p9 bra 	$L__BB10_9;

	fma.rn.f64 	%fd136, %fd136, %fd5, %fd136;

$L__BB10_9:
	st.param.f64 	[func_retval0+0], %fd136;
	ret;

}

